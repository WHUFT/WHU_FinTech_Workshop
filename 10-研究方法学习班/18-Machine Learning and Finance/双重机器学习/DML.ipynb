{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "79a3956b",
   "metadata": {},
   "source": [
    "# Double Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e0b656c",
   "metadata": {},
   "source": [
    "## 一、为什么需要DML？"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "471cd745",
   "metadata": {},
   "source": [
    "在Robinson（1988）的半参数回归模型中，\n",
    "\n",
    "主方程：$Y = D \\theta_0 + g_0(X) + U, \\quad \\mathbb{E}[U \\mid X, D] = 0$\n",
    "\n",
    "处理模型：$D = m_0(X) + V, \\quad \\mathbb{E}[V \\mid X] = 0$\n",
    "\n",
    "其中 $Y$ 是被解释变量，$D$ 是处理变量。这里，我们关注 $\\theta$，即处理的因果效应。由于扰动项 $U$ 均值独立于 $D$ 和 $X$，故部分线性模型并无内生性。\n",
    "\n",
    "传统的参数回归（parametric regression）假设的函数形式已知（例如常见的线性假设），然后直接对主方程进行线性回归估计。但对的函数形式 $g_0(\\cdot)$ 很可能误设（misspecified），则会导致偏差，因为根据处理方程，处理变量也依赖于 $X$。\n",
    "\n",
    "为了避免函数形式误设，经典的半参数回归（Robinson, 1988）使用非参数回归（nonparametric regression）来估计 $\\mathbb{E}[Y \\mid X]$ 与 $\\mathbb{E}[D \\mid X]$ 。比如，核回归（kernel regression）或局部线性回归（local linear regression）。但传统的非参数回归由于协变量的维度通常较高，容易遇到“维度诅咒”问题。\n",
    "\n",
    "对此，很多机器学习的方法在高维数据依然适用，如Lasso、随机森林、梯度提升、神经网络等。但机器学习方法通常有“正则化偏差”（regularization bias），例如以Lasso为代表的惩罚回归（penalized regression）若直接以机器学习方法估计，可能导致偏差。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03608580",
   "metadata": {},
   "source": [
    "但是根据上述方法估计 $\\hat{g}_0$，随后利用线性回归得到的 ​$\\hat{\\theta}_0$ 是有偏的：\n",
    "$$\\begin{equation*}\n",
    "\\hat{\\theta}_0 = \\frac{\\mathrm{cov}\\left(D, Y - \\hat{g}_0(X)\\right)}{\\mathrm{var}(D)}\n",
    "= \\frac{\\frac{1}{n} \\sum_{i \\in I} D_i \\left(Y_i - \\hat{g}_0(X_i)\\right)}{\\frac{1}{n} \\sum_{i \\in I} D_i^2}\n",
    "\\end{equation*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d966e71a",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{align*}\n",
    "\\sqrt{n}(\\hat{\\theta}_0 - \\theta_0)\n",
    "&= \n",
    "\\sqrt{n} \\frac{\\frac{1}{n} \\sum_{i \\in I} D_i (Y_i - \\hat{g}_0(X_i))}{\\frac{1}{n} \\sum_{i \\in I} D_i^2}\n",
    "- \n",
    "(\\sqrt{n} \\frac{\\frac{1}{n} \\sum_{i \\in I} D_i (Y_i - g_0(X_i))}{\\frac{1}{n} \\sum_{i \\in I} D_i^2}\n",
    "- \n",
    "\\sqrt{n} \\frac{\\frac{1}{n} \\sum_{i \\in I} D_i U_i}{\\frac{1}{n} \\sum_{i \\in I} D_i^2}) \\\\\n",
    "&= \n",
    "\\underbrace{\n",
    "\\left( \\frac{1}{n} \\sum_{i \\in I} D_i^2 \\right)^{-1} \\cdot \\left( \\frac{1}{\\sqrt{n}} \\sum_{i \\in I} D_i U_i \\right)\n",
    "}_{A}\n",
    "+ \n",
    "\\underbrace{\n",
    "\\left( \\frac{1}{n} \\sum_{i \\in I} D_i^2 \\right)^{-1} \\cdot \\left( \\frac{1}{\\sqrt{n}} \\sum_{i \\in I} D_i (g_0(X_i) - \\hat{g}_0(X_i)) \\right)\n",
    "}_{B}\n",
    "\\end{align*}\n",
    "\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93ca5f61",
   "metadata": {},
   "source": [
    "可以看出误差分为两项。$A$ 项来自于 $U$ 和 $U$ 的独立性，即$\\frac{\\mathrm{cov}\\left(D, U\\right)}{\\mathrm{var}(D)}$，若二者不独立则会造成偏误。然而问题来源于 $B$ 项，我们将其展开为以下形式：\n",
    "$$\n",
    "B = \\left( \\mathbb{E}[D_i^2] \\right)^{-1} \\cdot \\frac{1}{n} \\sum_{i \\in I} m_0(X_i) \\left( g_0(X_i) - \\hat{g}_0(X_i) \\right) + o_P(1)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "897f1bc7",
   "metadata": {},
   "source": [
    "注意到 $m_0(X_i) \\left( g_0(X_i) - \\hat{g}_0(X_i) \\right)$ 项。首先， ${g}_0$ 的估计往往存在误差，例如对于高维数据，往往会采用正则项处理，造成正则化误差，此时的 $B$ 项发散。此外，$m_0(X_i)$ 是数据本身的性质，因此数据会决定偏误的大小而无法改变，导致估计非常不稳健。综合以上推论，可以说因果模型对于处理效应的传统估计方法并不完美。因此，我们引入双重机器学习的概念，为因果估计提供更稳健的方法。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f82601",
   "metadata": {},
   "source": [
    "## 二、DML的本质"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f238022",
   "metadata": {},
   "source": [
    "根据上述推论，传统因果估计方法不稳健的核心在于  $m_0(X_i) \\left( g_0(X_i) - \\hat{g}_0(X_i) \\right)$ 项，其中 $\\left( g_0(X_i) - \\hat{g}_0(X_i) \\right)$ 部分是${g}_0$ 的估计误差，显然是难以避免的。因此更为实际的考虑是消除 $m_0(X_i)$，其出现原因在于用于回归的 $D$ 实际上包含了 $X$ 的信息。"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjgAAAD1CAIAAADS/hjiAAAgAElEQVR4Ae19d2AUVdf37G520zshBFIghN4k1CABAsGIgGLUBwF9IFKUHgVEIugDIoI+BkQMohSFEEEwUiR0kGIgBEggkRQgRAKBJIT0uu3zfef77ned3Z2d3Z3Zmdmc/evOLaf8zrlzZmfuPZfQwg8QAAQAAUAAEBAwAoSAZQPRAAFAABAABAABLQQqcAJAABAABAABQSMAgUrQ5gHhAAFAABAABCBQgQ8AAoAAIAAICBoBCFSCNg8IBwgAAoAAIACBCnwAEAAEAAFAQNAIQKAStHlAOEAAEAAEAAEIVOADgAAgAAgAAoJGgP9ApVars7KyUlJSNm/eHBsbGxUVFRoaGhIS4uvr6+joKJfLvb29O3To0Lt37+HDh8+YMSM+Pj45OTk9Pb26ulrQ0IJwgAAgAAgIFYHq6ur09PTk5OT4+PgZM2YMHz68d+/eHTp08Pb2lsvljo6Ovr6+ISEhoaGhUVFRsbGxmzdvTklJycrKUqvV1teJn0ClVqvv3bt37NixmJgYJycnwqyfXC4fM2bMrl27cnNz6+vrrY8dcAQEampqCgoKMjIy9u3bt2TJkjFjxgwaNCgkJMTLy0sul3t5eYWEhAwaNGjMmDFLlizZt29fRkZGQUFBTU0NQAcIWB+B+vr63NzcXbt2jRkzRi6Xm3XfJZycnGJiYo4dO3bv3j2rBS2rBiqNRtPU1PTzzz97enqah5GhUTKZbOXKlY2NjVYDzvpOBhwFgoBarW5sbDxw4EBERIQhhzRaHxERceDAAfBYgdjUtsUgPXblypUymcyoZ5rUwdPTc+/evU1NTRqNhlMMrReobt68OWLECDc3NxogevToMWvWrA0bNuzatevo0aPp6emZmZmnT5/eu3dvQkLC+++//+yzz0okEkMUHBwcQkJCfvnlF04hA+ItFoGqqqqVK1cGBAQ4ODgYckKT6h0cHAICAlauXFlVVdViUQXFOUVg//79ISEhNB4rkUieffbZ999/PyEhYe/evadPn87MzExPTz969GhiYuKGDRtmzZrVo0cPGsd2c3MbMWLEzZs3uVPEGoHq5MmTI0eOVCgUFFUlEsngwYNXr1599uzZ/Pz8xsZGJnpqNJri4uJz585t2bJl3Lhxep8Revbs+e233zKhBn0AASYIHDhwYPjw4a6urhQfZuvSxcVl+PDhBw4cYCIM9AEEmCDw7bff9uzZU9dFZTLZuHHjtmzZcu7cueLiYoZ/hhobG/Pz88+ePbt69erBgwfr/mFQKBQjR448efIkE9lM7cNtoLp69WpkZCQFKYlEMnr06C1btpSUlJgqrm5/pVJ58ODByZMne3l5URh17tw5OTmZoRl0KUMNINDQ0LBnz55BgwZRXIu7y0GDBu3Zs6ehoQHABwTMQ0Cj0SQnJ3fu3JnipV5eXpMnTz548KBSqTSPMj6qpKRky5Yto0eP1o1YkZGRV69exTtbXuYqUJWWlq5YsYKCVLt27ZYsWcJKfNLVvLa2NiEhoXv37hTgxo0bl5eXp9sfagABegTOnj2r94GU4tVcXPbs2fPs2bP04kErIKCLQF5e3rhx43CflEgk3bt3T0hIqK2t1e1veU1JScmSJUvatWuHMyUIYsWKFaWlpZbTJymwH6g0Gk1mZqaHhwcut4eHx7p169gSmp7O0aNHg4ODKa8Ev/rqq+bmZvqB0AoIkAhUVlZGR0fjDsxLOTo6urKyEowCCDBBoLm5+auvvsIdVSaTBQcHHz16lMlwy/usW7dO97afmZnJyjst9gPV+++/jwcJmUy2Zs0aKy8fb25uPnbsmKOjIzKbRCIZOnSo5cYACjaPwJ49e5ydnZHn8Ftwdnbes2ePzWMOClqOwNChQ/GXSY6OjseOHbPy03l9ff2aNWso9//333/fcu3YDFSFhYVDhgzBJ/a4cePu3LljuZTmUSgvL4+Li5NKpUikwMDACxcumEcNRtk8ArW1tdOmTUPeIpzCtGnTOHpvY/M2bQkKXrhwITAwELmrVCqNi4srLy/nS/c7d+5QXj8OGTKksLDQEnlYC1QZGRnt27dHYLm6um7dutUSydgam5aW1qlTJyQYQRCJiYlsEQc6NoNAZmZm7969cT8RVLl3796ZmZk2gzYowhYCiYmJuKN26tQpLS2NLeKW0Nm6dSu+SrZ9+/YZGRlmE2QnUF27ds3Hxwfh1atXr/z8fLNlYn1gXV3dpEmTkHgEQSQkJLDOBQiKF4Hr16/7+vriHiLAsq+v77Vr18QLMkjOOgIJCQm4o06aNKmuro51LmYTzM/P79WrF5LQx8fH7NWALASqjIwMtEdKKpVGRUWpVCqzdeNuYHx8PJ415JNPPuGOF1AWCwIajeb69es02yHRNBNCwcHB4fr166x8nRaLgUBOQwisXr0a+aRcLo+PjzfUk8d6lUoVFRWFvr8oFArz/ldZGqhu3LiBf8GbP3++kGfRmTNnkLQSieSzzz7j0YTAWggIHDt2DLkEmvZCLvy9Tf7YsWNCgA5k4BGBNWvWIL+VSCRnzpzhURh61hqNZv78+WhOSSSSGzdu0A/RbbUoUGVkZOBZ+77++muBp9rTaDR5eXkojZNcLv/hhx90QYGaFoLA2bNn8aWhaC4JvODo6Pj777+3EBuBmroI/PDDD+jlkJubW15enpD/Hmi1WrVa/fXXX6Np5enpaer/KvMDVUFBAb7UZNOmTbqACrPmypUrKL5KpdKUlBRhyglScYrApUuX8A+raBaJouDj43Pp0iVO8QHiwkQgJSUFvUnz9PS8cuWKMOXUlWrTpk1ocgUGBhYUFOj2MVRjfqAaOnQoyVUqlS5evFjg/6Uo+icnJ6NHaScnp7t371I6wKVtI1BUVKS7lx7NIlEU2rVrV1RUZNtmAu0oCBQUFKBzkRwdHZOTkykdhHypVqsXL16MoqxJG1vNCVQajebdd99Fk/mFF14Q5uoJept9++23SIXw8HBBrZahlxxaLUTg72RoQl6JjtzSaKFPnz4Cf+djoaVgOI5AXV1deHg48gox5t1WqVQvvPACUuHdd99l6MDmBKqMjAy097hnz544lOIqL1iwAEEWGxsrLuFBWvMQ0Gg0ixcvRnYXe2HRokUMp7p5cMEo4SAQGxuL3HXBggXCEcxUSVAKTZlMxvBjlcmBqrS0FP33dHV1vX//vqlSCqd/fX1927ZtSdvL5XJIWiEc03AnycWLF9Fst43CxYsXuYMLKAsEgQsXLqAFFG3btrVyUjp2Qbh//z7aC+zk5MQkd63JgWrp0qVoem/fvp1dBaxPraioyN3dndTomWeesb4AwNGaCDx58gQ9miA3Fnuhbdu2T548sSaMwMv6CDzzzDOko7q7u9vAt8nt27ejebd06VKjeJoWqNLS0hD1l19+2Sh1UXT48ssvkVLC3DQnChhFIeSqVauQrW2psGrVKlHgD0Kah0B8fDxy1y+//NI8IkIb9fLLLyOljKZ9Mi1QjRgxgiRtZ2cnqCRJFtpgwIABpF4ODg5Pnz61kBoMFyYCf/75J/q2imaIbRRkMtmff/4pTNhBKgsRePr0KcqcMmDAAAupCWd4fn6+nZ0dOQFHjBhBL5gJgerIkSNoVv/3v/+lpyuu1vPnzyPIPvzwQ3EJD9IyRGD8+PHIgW2vMH78eIY4QDdxIfDhhx+S7mpnZ3fu3DlxCU8v7X//+180E48cOULT2YRANXz4cJKok5OT7R06MGXKFFI7mUz24MEDGsigSYwIFBQU2OrfKeS3Ju2gFKMRW6DMDx48QH47ZcoUG0OgtrYWLc0bPnw4jXZMA9WVK1fQmpMNGzbQUBRp05UrV1BshxyAIjUijdijR49G9rXVwujRo2kQgCYxIrB27VrkriJKQsEc6g0bNpAKyuVyGgUZBSqNRoPyUPj7+zMXQlw9J0yYQELm5eUFR4CLy3b00uIPbmja217BJl910FvWtlsrKyu9vLxIR50wYYKtKuvv70/qOHToUEObAhkFKpVKhRK5Llu2zFbxyszMRDcvOP/blqy8ZMkSZFnbLixZssSWDNfCddmzZw9yVxs+NnPZsmWkmm5uboaSHDEKVD/88ANJSKFQlJWV2ar3NDY2uri4kJrazOJ7WzUWc73q6urQW2s07W21IJfLIRkYc98QeE+0gNvFxaWxsVHg0potXllZGTrR0NBxFsYDlVqtRvM8KirKbGlEMRDlopdKpQ0NDaKQGYSkRyA/Px+d3GOr8QnpJZFIbGnfCL1lbbu1oaEB5W/9+uuvbVvZqKgo0oflcrne/ObGA1VBQQGaBlu3bmULryFDhiCyBEGcOnWKOeXr16/jtx4XF5fm5mbmw2l6VlVVoVUoGzdupOkJTWJBICYmBvc0Vsrt2rXDc9ioVKrQ0FCjlAcPHoxPwpqaGj8/P6OjTO0QExMjFtOAnDQIbNy4kTS9k5NTVVUVTU9Tm9AfNZI+wyXv//nPf3BXXLdunal8afpv3boVEde7eNV4oDp06BBJQiqVsrgZFv13IYm/+eabNGpQmqZNm4a0IgiCxYiiVqvRIVsvvPAChS9cig6BhoYG9DoX9xnLy1988QWOBr5q1BDx7OxsfMgXX3xhqKcl9S4uLvAyAMdZpGWUZTwwMBB/vrFcHQEGqqdPn6K/j4cOHdLV0Xigmjx5MjltTDo+RJcTpebp06f4HcTe3r6iooLSR++lRqMJCgpCM9nOzu7Ro0d6e5pX+d5775HEO3bsaB4FGCUcBG7evIlchfVCeno6rukHH3xAw2L16tV45/T0dJrOFjbdvHkT5wVlMSLQsWNH0g3ee+89duUXYKDSarVoYfnkyZN19TUSqJqamlD2jjVr1uiOt6QG7bEl7fHzzz8zoVZVVYW+mREE4efnp1QqmQxk2CcnJ4d8ryiTyWpqahiOgm7CRGD37t0W3vRphvfr1w//xF1dXe3r66u3f0BAQHV1NYJIqVQOGzZMb09WKnfv3o14QUGMCNTU1JD7fCUSSU5ODrsqCDNQrVmzhnR+BweHpqYmispGAhW+Yvv06dOUwRZe/vbbb/i0nDRpEhOClMOEDhw4wGSUSX3Q7Wbz5s0mDYTOQkNg6tSpuI+xXp4+fTqu8tmzZ/WyOHv2LN5t3bp1eruxVTl16lScHZRFh8DmzZtJZ/D19WVdeGEGqtOnTyP/112LbyRQ4bFE7zcuS0Csrq52dnZGwrm5uRml1tDQgJLyEQTh7e3N7ttbUoB+/fqRUr3++utGRYIOQkagT58+yMG4KMjl8sLCQoSAWq2eNGkShdHs2bNxL21oaMDdntKZlcs+ffogkaAgRgRef/110hP69evHuvzCDFT4qr3ffvuNorWRQPXNN9+QeEkkErZW1uESxMXF4TPT6Dbb3NxcvP/IkSNxamyVx40bR3IJDg42tFOaLV5AhzsElEol2p+Buw27ZT8/Pzz1ZWVlJTrhjCAIDw8PfMlWc3Mz17GTIAiFQsHu+3DubASUdRHQaDTBwcGkl44bN063g4U1wgxUzc3NaC33N998Q9HRSKCaN28eiRdHhwpmZGTgdw2jC+0++eQTvD99wl2Kqswv0VfxVq1a6b4tZU4HevKLQF5eHu4t3JWXLFmC/2fCEwocPnwYB2HPnj1oNnInD0EQeXl5OF8oiwiBpqamVq1ake7xwQcfsC65MAOVVqtFh0POmzePorWRQBUZGUniNWfOHMpIVi6bmprwx882bdrQkG1qavL29kbTOyAggKazJU3oRuPq6grrKSxBkt+x+Itr5DYcFf744w9cWXJtMeXB6969exxx1yWr+/IEFw/KQkagpqYGndRu9CWTGYoINlDNmTOH9OTIyEiKXkYCVd++fcmR69evp4xk6zIhIQGfZikpKYYop6am4j1nzZplqKeF9YiRo6Mj/t7GQrIw3MoIoNRfuNtwVO7YsSP+ArCkpMTLy6ukpASprFKp3njjDY6465I1lIoGyQMFwSJQVVXl6OhI2jQ1NZV1OQUbqNavX09q3bdvX4rWRgIVWsu/a9cuyki2LisrK5FVCIIIDQ01RJmyNZomJ7whCgzrb926ReKlUCgY7u5iSBm6WRMByqZy3bs5uzWUtw4Uz0F/09llaoiazSfdsaYjWZlXRUUF+rbK+tp0rVYr2EC1c+dO0p9197AaCVQ+Pj7kSI6+Bmm1WrVa3blzZzTf3N3d8eQ0uIv07t0bdevWrZuhPLv4EPPKxcXFJCM7O7vy8nLziMAo3hFAOzOQ23BasLe3N/TwVFFRgb46cCoDIs76rkferdlyBCgvL0drm4uLi1lXXLCBCh0i7+PjQ9HaSKCyt7cnXT8tLY0yksXLn376CU0wiURy6dIlXeLZ2dmoz9+LqTg9vLG+vp7kJZFIbDhbvC7INlaDjg/APYfTcnBwsN7Fsa+99hqnfHWJ2/BxPDbmpbrqlJWVoRU3hp7adUcxrxFsoEpLSyM92d7enqIO00Bl6FGRQs7sS/TXjSCIUaNG6dJZunQpPhtv3bql24etmoaGBpIXBCq2IOWFjvUDFUEQly9fpijb1NSEjr/DfZjTMgQqihVEdIkHKi7SNtpgoELx4+jRo5xaGm1dImfv48ePKewGDRqEJnavXr0orexePnr0iOQFr/7YBdbK1Kz86o8giOHDh+vVccGCBch7rVOAV396DSGKSvzVH7uJTEn1BRuoUlJSyNlh8qs/KyymILE7duwYPoF///133KUePHiAt9KsDMRHmV3Oyckh2cFiCrMxFMJAKy+moP//jdKd4J7MXRkWUwjBA82TocUupti1axc5I0xeTIF2YHH6TYhcUoGCIkEQlNxFCxcuRFNaKpVy/d3o0qVLJDtYnm7eTBPIKGsuTycIgrKdnvJW4I8//kA+bIUCLE8XiBOaIQa+PF3vB3szaOJDBPuPasOGDeTU0M0vYeQbFdrwq7tVGNeclTKebVYul5eWliKyXbt2RXM7LCyM67RGe/fuJdm5uLjAhl9kBdEVDh8+jNyG68KYMWPwJCb379/v2rXr/fv3cdDQCTJcC0MQBCUjBi4GlAWOQE1NDToCae/evaxLK9hAhRIhmbzhd+7cueSkotnexBaOly9fxicwslBlZSXaVSCVSjMyMtjiaIgO+ggPKZQMQSSKekpmSNy7WC9nZWXhmIwaNYogiOeeew6vLCsrQ4n5WReAQjA3NxdnDWURIYCnUOJiUYxgAxU6Jnvu3LkUexn5R7Vp0yZyAkgkEiukucT/Oc2cOZOUFT8ItW3bthQFuLhEKzvat2/P9b83LuQHmiQCSqUSP7qMcitn61IikWzbtg3H/JdffkHEf/nlF7zpjz/+QCuPUR/WC3K53AqzFdcLyiwioNFo2rdvT3oFF0lpY2JicJdjmKVp5syZ+KjExEQWVdZqtUqlEk2NTZs2UYgbCVT4yxP8OAMKFbYuv//+e4SFl5eXWq1WKpVoLxdBEK+99hpbvGjoDBgwgBRj4sSJNN2gSfgI4JvEkWuxW/D29sZf+lVXV7u5uSEWXl5edXV1CCiNRmOFVRW9e/dGHKEgRgQmTpxIutCAAQNYl//HH39E/kkQREREBJPHcfR3hxx74cIFdgUrLCxEUum+uDYSqPDs5qwfnKir5+3bt5GsfyN47ty5x48fo03aBEHcvn1bdxTrNej9DOXzOOuMgCDXCLz55pu4R7FednFxefLkCdJCrVaPGTOGwmXMmDGog1arbWpqat26NaUPu5dvvvkmzhHKokMAna/ExcGJJSUlFH/Dk1LqxSotLU0qleKjWE/Zgx+cqPt9x0igamxsREfRr127Vq8OLFaq1eqBAwciOGbMmHHq1Cl0qbsUhEXWiFR+fj75D1Qmk1VWVqJ6KIgRAbTgFXkRuwVKsuYTJ07opX/y5Ekcvd27d+vtxlYld5k5cS2gzB0ClZWV6Cj6/Px81hkFBgbizkZJU6nLLjw8HO9P+fiq29+MmrVr15IsHBwcGhsbKRSMBCqtVov+hA4bNowymIvLkydPojeVAwcOnDFjBgJo+fLlXHCk0FyyZAnJMTg4mNIEl6JD4MaNG8h/WC88++yz+Keg8vLyoKAgvVy6dOlCyVE7cuRIvT1Zqbxx44boLAUCUxBAZycuWbKE0mT55fTp0ymeZmiHuFKpnDZtGqUzF2/Xhg8fTnLR+8HFeKA6cOAAOV4qlVrhHwaeTB2t0SQIQiaTWeG9n1qtRs8azz//vOUOART4RaChocHJyYkyzVi5VCgUV69exbVDp+nopb906VK8871793D31jvEvEonJycu8u7gwkPZCgg8//zzpAMEBgbix3Kywvrp06e6WZKHDh166tSpgoKCsv/93b59e+/evT179qT4YVhYGP5RlhV5Kisr0avFAwcO6NI0Hqju3r2LBN2xY4cuCdZrhg0bhjiiwujRo1lnpEuwuroa3de43uOsyx1quECAo89Un3/+OS7txYsXka8aKmRmZuJD0PZGQ/3Nq4cPVDjI4i0j93BycqqurmZdkd27d5uxJrZdu3b44iC2pNqxYwfy9rt37+qSNR6oVCoVWs5A+SysS46VGsqSClKBnTt3skKcnsi3335LspNKpfg5ePSjoFXICOTk5KCXyWgyWFho06YN5aES5XChoTxw4EAcqKampjZt2tD0N6NJIpFwcYIRLjaUrYNAbW0t+pPx7bffcsGUsvzPqL8FBQVR3J4tqdASJDs7O73nNxkPVFqtduvWraQODg4OrC/20Ksqej+LsOMiOSOFdVNTk4eHB8nxpZdeorTCpUgRqK2tRU9ayJ0sLFCCAWWLCQ1xyv5NyuE1NAMZNtnZ2cEDlkgdVVfsl156ibS7h4cHRxEiOzt78ODBRr3L0dFxw4YNHKXpKS8vR0v2tm7dqouDVqtlFKhUKpWrqyupjHVWNCQnJ3+N/VjfXKYXC/zDe1JSkt4+UClGBGJjY41OReYdXF1d586dO+///ebMmYNeFxsl4uLiMmfOnP83dN6cOXPQzDI6lkmH2NhYMRoIZNaLQFJSEjI6pwtkrl+/vm7dupdffrlLly6IY5s2bYYMGTJ37tzdu3fjezD0impJ5fLly0mmrq6uev9OMQ1UGo0mLCyMpBUQEGCJTEIe++qrr5I6enh4UNZoCVlskM0oAjU1NY6OjmgG2mrB0dGRo2deowhDBy4QqKioQO94Xn31VS5YCIFmQEAAOSVp8rgy+kel1WpTU1PR+5OEhAQhqMeuDFevXkX3r9WrV7NLHKjxjkBERASyr60WIiIieMcZBGAXgU8++QS5K2WVKbuM+KKWkJBAKmhnZ0eTKp5poNJqtc8++yxJ0dnZ2fbeg0+dOpXUTiKRUJJe82VC4MsiAnfu3GF9SQW6gwihIJFI7ty5wyJiQEoICNy/fx/57dSpU4UgEosy1NbWOjs7k9Pn2WefpaFsQqA6dOgQupVv3LiRhqjomlJTU1GCdi6214kOEJsUeOzYsUKIKBzJMHbsWJu0GiiFUhAoFIo//vjDlgDZuHEjCsOHDh2iUc2EQKXValEiDblcrne1Ow0nITehdS9WW9YoZDRsVbYbN26QaWk4ChU8kpXJZJx+bLdVlxCFXviiuMGDB4tCZiZC3r17F23kCg8Ppx9iWqBKTU1Fs/Ff//oXPWmxtOIHllshn6FYYLFJOVesWIEc2JYKK1assEl7gVIkAigPHkEQNvM261//+heag6mpqfS2Ni1QabXad999F1G3zqpxegUsbH38+DFaV9OrVy8LqcFwgSNQVlbGdeZyNDusVmjdunVZWZnAkQfxLESgV69epEd5eHg8fvzYQmq8D09MTEQT5N133zUqj8mBqqSkBH3OcXNzEzVkjY2N/v7+JF4ymezs2bNG8YIOYkfg/PnzaIbYRuHcuXNiNwrIbxSBs2fPohfX/v7+uvnFjVIQTofHjx+jM9sUCoXRQ0aY7qOiaHj58mUEWd++fSmtIrpcvHgxulXpHn4sIkVAVOYIqNXq+fPnI7uLvbBgwQLWM5YyBxN6WhOBuXPnInddvHixNVmzy6tv376kIjKZ7PLly0yIm/yPSqvVajQaHLLo6GhD24mZSMBXn23btiGrh4WFwU5Jvgxhfb4ajUY3JzRyBhEVevbsyeRsVusjDBy5QKCmpgYlXiAIYtu2bVxw4ZSmSqWKjo5GU2zu3LkMHdicQEVqgiCTSqXLly8X12Pd4cOHUdobR0dHKxwgwqn5gbipCNy7d8/Pzw9NGDEW/Pz87t27Z6ri0F/UCNy+fRvlWHFyctI9sl3I2qnV6uXLl6NMu2FhYcylNT9Q3b59u23btmiGf//998y58tvz5s2bXl5epOQSieTgwYP8ygPceUHg/PnzyA2QG4ul4OXldf78eV5wA6b8InDw4EG098jLy+vmzZv8ysOc+/fff4/mV9u2bU36e2B+oNJqtVevXsUPf/v+++8Z/o9jrhvrPYuKitzd3Um87OzsvvvuO9ZZAEGxIIC//kVTSPgFiUSyZcsWsYAMcrKOwHfffYcS2rm7uxcVFbHOgl2CGo0Gj1IuLi6mpoOyKFCRsQpNbIlEsmjRInY1ZJfahQsX0DIQgiD8/f3ZpQ/URIRAXV0dnisaubEoCi4uLiKCGkRlHYGgoCDkqDKZ7MKFC6yzYJHgokWL0L9AgiBMjVJmrvqjKHDp0iW0wVgmk02YMEGYays2bdqEFtYjG3fp0oWLAyspEMGlABHAT47HZxHyDQEWcDmjo6MFiCqIxDUCNTU1uqd0KhSKTZs2cc3aDPoqlWrChAno74FcLqfJPEtD39J/VCTpixcvent7o4ndv3//goICGq5Wbqqvr4+JiUHiEQTRo0cPdDlmzBiIVVa2CO/sTp06hVbThIWF/f777z4+PsglhFnw8fE5f/78kCFDSPGkUqkN7Ljn3RPEJUBdXR06TZEgiI4dO+K+GhMTU19fLxyNCgoK+vfvjyT09vY2O1chO4FKq9Wmp6ejY0UIgjSEUL4AACAASURBVHBzcxPILMrMzOzWrRsCi1zWWVtbO2jQIFQ5ZcoUpVIpHAODJJwi0NDQgI6Q9vT0fPDgAfkSu2vXrsglhFbo2rUr+cKkvr4eHWDv7e0tqBsTp1YD4kqlcvbs2cgzQ0NDnz59SvnO2q1bt8zMTCFglZiYiHb1/n3XDQgISE9PN1sw1gKVVqstKChAO7lINKOjo3n80FdVVbV69Wq0GpIgCD8/vzNnzpBglZWVdejQAVkdkqab7UPiGqhWq2fNmkXaXSqVfvXVV0j+2traiRMnIpcQTmHixIn4wTo7duxA71KGDRsGz1jIgjZc+Pt7yscff4x8slOnTg8fPiT1PXPmDL7XQiqVrl69uqqqii80ioqK8M1SBEH07dvXwndsbAYqEpeFCxfib9JlMll8fLyV55JarT537hx6t0Nat3///hTLPXr0CC2eIQhi4cKFlA5waXsIXLp0Cc32kSNH6iq4a9cu3W+ZaIiVCwqFYteuXbpC4gH11KlTuh2gxsYQWLNmDfI9Ozs78jUAriP+ko0gCCcnp3Pnzll5e6tSqYyPj0dPUQRBSCQSVu6r7AcqtVqdmpqKloCT4Pr6+q5fvx6HlbvyyZMne/bsidZ3kAJ8/vnnDQ0NukwfPnzo6upK9rGzsxPRbjBdXaDGKAIVFRVo85+jo6OhJGMlJSXjx49H9wW+CmPHjjUkYWlpqaenJymYk5OT7m3LKBTQQUQI/PTTT+iR2sPDA/2XwlVoaGj4/PPPcV+Vy+U9e/Y8efIk3o278vr16319fXEB3N3dU1NTWQmW7AcqEoji4mI8kx4pffv27T/++GOOMj3X1dVt3749NDQUf9dHEERUVBT9nrhr166hsGpnZ3fs2DHubAmU+UUAX+lnNANNSkoK5esmPgk5LXfr1i0lJYUeq19//RXJACsA6bESdeuBAwdQlHJ2dqZPjnfz5s2oqCjkGARBSKXS0NDQ7du3c7Rk7O/7+ccff9y+fXucKUEQixcvLi4uZgt5rgIVKd+lS5fQWYtIDYlEMn78+MTExCdPnliuhlKpPH78+IwZM1q1aoVYkIXg4ODdu3cziecHDx7Edy7Dnn/L7SJACsnJyeh/9vDhw5lsoqivr9+xY0doaCjFtbi7DA0N3bFjB5MlEiqV6vXXX0eS/PDDDwLEHESyEIGLFy/a29uTVnZwcNi/f79Rgmq1evfu3Wi5EPKQVq1azZgx4/jx46x8iHny5EliYuL48ePxDz0kr/DwcPPWoNOoxm2gIhmnpKSEhYWhewQCTiKRDB06ND4+Pi0trbCwsKmpiUZQ1KTRaEpLS9PT03fv3h0dHY2/D0WUQ0JCTH3TuGPHDjTcwcEhLS0NcYSCDSBQVVWFtvcqFApTj6fZu3fvgAEDKF89kcNYXnBychowYMDevXtNgvrJkyfOzs4kd19f3/LycpOGQ2eBI5CVlYVOy5PJZN98841JAq9fvz4kJETXOWUyWXR09O7du9PT00tLSxmmE2pqaiosLExLS4uPjx86dKhufJLL5WFhYUbfBJikAupsjUBFMsvMzBw4cCD9VO/du/e8efO2bNmSnJx8/vz5nJycu3fvXr58+fDhwzt27FixYsWwYcN0AUKWkMvlbdu2/emnn5B6JhU2b96MSPn4+FRXV5s0HDoLGYFXXnmFNK5UKv3555/NE7WysjIuLs7b21v3qQt5jkkFuVzu7e29bNmyyspK80RKTU1F77pt6Zxy89CwpVGPHz/Gw4ypT94Iij179rRt25bGYyUSybBhw1asWLFjx47Dhw9fvnz57t27OTk558+f/+WXX7Zs2TJv3rzevXvTOLaTk9PAgQMzMjIQU9YL1gtUWq1WrVZXVVX9+OOP6DGBRnmTmqRSaVxc3NOnTy35V6vRaD777DPEFxIsse5tfBFMTU1FC/mGDBlioRhNTU3l5eVJSUnDhg1D3mJqITw8PCkpqby8nOGLBBqZx4wZQ3KXSCTwhZUGKHE1de7cGTnV/PnzmXzCMKSgUql8+vRpXFwceqZBlC0seHh4/Pjjj1VVVZaIZ0hsvN6qgQoxVqlUOTk5+/fvnzx5MspabypkdnZ2kZGRmzdvvn79Or7LBHExo0B57x8SEsLka4EZjGCI1RCoqKhAC+R8fX1LS0tZZF1ZWXnr1q0LFy7s2LFj/vz5kZGR/fr1Cw4O9vT0tLOz8/T0DA4O7tevX2Rk5Pz583fs2HHhwoVbt26Z/f9Jr+R/P/yhHYH29vamvtXUSxMqeUSgsbER/wfz1ltvMfmeykTg2tra69evb968OTIyEi3QMPXG6+joOHny5P379+fk5LAlmFHh+QlUuFhqtfratWv79+//4osvZs6cGRER0atXrw4dOvj4+Dg4OJCzPTAwsHv37kOGDJkyZcrKlSt37dp18eJFdmc7LtKLL76IjDdq1Cget87hUkHZDARUKtW0adOQNW11xcEvv/yCdHzhhRcs/5dmBtQwhBUEqqqqIiMjkTWff/55jqxZWVl58eLFXbt2rVy5csqUKUOGDOnevXtgYCD5jOXg4ODj49OhQ4devXpFRETMnDnziy++2L9//7Vr17j+86QXRv4DlV6x+K1sbGwcOXIk8pV///vfevdg8SskcGeCAL6Ge9KkSUyGiLTP22+/jTzWVuOxSE3DXOyGhoZ33nkH2TE8PLyxsZH5cBvuCYFKv3Grq6vR6xSCIGbMmMHLc4R+4aCWGQKlpaVoe6+rq6tt74qtra1F2wEdHR3h8F9mPiKgXmq1Gt97GhQUxNGWUwHpzFgUCFQGoSotLUWPNgRBxMXFGewKDYJEAN9mdPr0aUHKyKZQmZmZyGMnTJjAJmmgxT0C69atQ0ua3dzc9Kaf4F4KgXKAQEVnmIcPH6L19HK5/OOPP6brDW1CQmDPnj3oc/HEiRMtWQ4qJLXoZNFoNCgHoEQi+fzzz+l6Q5uQEPjqq6/QwlRHR0cLU7gKSTN2ZIFAZQTHGzduoMX0crlcb4ZQIySg2eoI1NfXo3zSrVq1ajlLN9VqNXrb2apVK9gCbHXXM4dhSkoKSj/h7e1tyXEY5rAXwxgIVMatlJKSghLXEgRx4sQJ42OgB38IKJXKsWPHki/B5HL5kSNH+JOFB84nTpxAd72+ffu2hL+SPKDMHssTJ06gF7aOjo4tzV0ZAgmBihFQO3fuRJOfIAh45GGEGk+dTp06hTY2Tpw4kScp+GQ7Y8YM8t4nkUgEcn4pn3AImPeNGzfQRlK5XA7LNQ3ZCgKVIWSo9Vu3bsUffO7cuUPtAdcCQKCoqAiZycfHh6OM0QJQ1IgIQUFBCAf44GEELJ6ai4uLvby80CMFfoYnTxIJly0EKqa2UavVX3zxBZr8gYGBbKXDYCoB9GOAwJQpU5CNDh06xGCEbXY5efIkwmHo0KG2qaSYtaqtre3ZsyeKUp988gm8pKWxJwQqGnCoTSqVKjY2Fs3/Tp06UXvANa8IJCUlIetMnTq1hW99+/DDDxEaX3/9Na+WAeZUBPr27YusM3PmzObmZmoPuMYQgECFgcGsOGHCBORh3bt3hyTrzGDjvNeDBw/8/f1J07i7u7Ob049z6Tlg8PTp09atW5OAeHh45OXlccAESJqMQF1d3ZAhQ9A95NVXXzWZRMsbAIHKHJuPGjUK+dnkyZPhHaA5ILI95tVXXyWNYmdnd+rUKbbJi5LenTt30PkO4eHhotTBtoSura197bXX0N1j1KhRLWfvhCWWhEBlDnoNDQ29evVC3jZ79myrZRE2R9wWMGbPnj3IHM8//zzDs+BaADBa/KNdfHx8S1BZsDqqVKply5YhR+3RowckEWVoLAhUDIGidqupqcFPr587dy61B1xbC4Ha2lo3Nzdy/nfo0AFe9+PAq9Xq7t27k+A4Ojpyd+YAzhTKehGIi4tDSZJcXFyKi4v1doNKXQQgUOliwrTm3r176OFIKpV++OGHTEdCP/YQUKlUAwYMQIbg6CRs9uTlgdKVK1cQPsHBwZCQmwcbaLVffvkleg3r4uJy69YtXsQQKVMIVBYZ7v79+2gnhFwu/+677ywiB4NNRyAxMRHdhWfOnGk6gRYxYsmSJQglWAFofZMnJiY6ODiQJnB3d8/Ozra+DKLmCIHKUvP98ccfKMGSVCr97bffLKUI4xkjcO/ePZQxJCAgAI5FMIRcXV1dp06dUKz6888/DfWEetYROHfunEwmI8H38PCAP/1mIAyBygzQqEOSk5PR7ZIgiLS0NGoPuOYAAbVajZ/FfPLkSQ6Y2A5J/AXgsGHDYHupdUybmpqKng/kcvlPP/1kHb42xgUCFTsG3bZtG3JHiURy9+5ddugCFcMIbN68GWE+ffp0wx2h5f8i8NFHHyHEli5dCrhwjUBxcbGzszPCfNu2bVxztFX6EKjYsaxGo9m+fTvySD8/v6KiInZIAxV9COAH2rq5ucG2a30gUeuam5vRJ1U49IiKDtvXRUVF6MgVgiDWrl0Lm1jMxhgCldnQUQcqlcr33nsPxaoOHTrAVj4qRixdq1SqQYMGkVArFIqLFy+yRNj2yRQUFKBn/M6dO8OtkyOT19fXo62WEolkwYIFsNjSEqghUFmCHnWsWq2OiYlBsapr164Qq6gYsXG9a9cutB9l2rRpbJBsQTTef/995KIfffRRC9LcWqpWVVWFhYUhkF955ZUWnnbScuAhUFmOIZXCCy+8gHx04MCBLfakCSouLF3n5+cjeLt16waPAmbgGhoaijDMysoygwIMMYRAQ0PDuHHjELyRkZGGekI9cwQgUDHHyoSeeNJJSLBkAnDGuqpUKoStVCo9evSosRHQrgeBnJwcdLakr68vvADUg5FZVSqVaurUqShKhYWFwXOqWUBSB0GgoiLCynVtbW1gYCDy19jYWFbIApENGzYgVJcuXQo5/cx2ifXr1yMkV61aZTYdGIgj8NFHH6GX0oGBgbCxDwfHkjIEKkvQoxtbXFzs5OSE7gWQYIkOLGZtGRkZKKefv7//kydPmI2DXnoQaGhoQFuAFQpFRkaGnk5QZQoCH374IdrY6+TkdPv2bVNGQ186BCBQ0aFjYdvt27dRrJLJZOvXr7eQYAsfPnz4cDLwy2Qy2FVtuTPcu3fPzs6OhLR3796WE2zJFBITE1EqP09Pz2vXrrVkNFjXHQIV65D+g2Bubq6Hhwd5L7Czszt+/Pg/muGCMQKrVq0iYZRIJNOnT4dlVIyRo+v42WefkagSBLFkyRK6rtBmAAGNRnPkyBGUm8bV1RX2SxiAyvxqCFTmY8dw5IkTJxQKBbodnDlzhuFA6IYQqKqqQgkVO3fujOqhYDkC/fr1I51TLpdXVFRYTrClUUhLS0Oz297eHpIkceEAEKi4QJVKMykpCbmyXC6HDP9UgGivm5qa2rRpQwKoUCguXbpE2x0aTUPgyZMnyDkdHBxgub9J8GVmZuKPoTt27DBpOHRmiAAEKoZAWdpty5Yt6HbQunXrwsJCSym2mPHx8fEIuoULF7YYva2nKP4CcNmyZdZjLHJOhYWF+OLe+Ph4eCPNkUkhUHEELJWsWq1et24dWroaEhLy+PFjaie41kEgOzsbPbH27dsX3k3pIMRChVKpjIiIQE8D8J+VCaaPHz/u2rUrCZpEIlm0aBEkpGeCm3l9IFCZh5s5o1Qq1VtvvYVuB8HBwQ0NDeYQajFjGhsbn332WRIxuVwOn/e4s3xWVhZatNajRw/YpkoPdUNDQ48ePUjPlEqlr732WnNzM/0QaLUEAQhUlqBnztjx48ejWNW5c2eIVTQgrlu3DmEFG9FogGKlCT+qBrao00BaU1ODdkoQBDFy5EiaztDECgIQqFiB0TQi+GuW0NBQ0wa3mN4PHz5ES349PT3hIz/XllepVJ6enujJIC8vj2uOIqU/duxYhFK/fv1EqoW4xIZAxYO9Kioq0JpggiDeffddHoQQPMs+ffqQtwPY5G81W+HbADp16mQ1viJiNHfuXDxKlZaWikh48YoKgYof2xUXF/v5+SGPh6VWFDP85z//QQtPFi9eTGmFS+4QwNdYzpo1iztGYqT8wQcfoFwefn5+d+7cEaMWYpQZAhVvVisqKkIJlgiC+OKLL3gTRWCM8/LyUM60AQMGwIlzVrbPqFGjyEcoqVQKqaoQ+Bs3bkRRysnJKTc3FzVBgWsEIFBxjTAd/cePH6MsqzKZ7Ndff4V04HV1dWjVr5OT04ULF+gQhDYOELh9+7aLiwt671pVVcUBEzGR1Gg0hw8fRqsiPTw8bty4ISYFxC8rBCqebZiZmYkmgEQigSTW+EEen3zyCc/maanst27dit5LQw7AtLQ09CLayckJMnZaf1pAoLI+5lSOv/76K7opKBSKc+fOUXu0mOsrV66gsN2zZ8+ampoWo7qwFFUqlQMHDiTdUiKR/Pbbb8KSz4rSpKenOzg4oBm6bds2KzIHVv8XAQhUgnCFzZs3o5nQunXr7OxsQYhlXSEaGhr69++PcIC3K9aFn8rtr7/+QrZo3749tbllXGdnZ7dr1w7h8PXXX7cMvQWnJQQqoZjk008/RfOhY8eOLTAZ4AcffEAiIJFIVq9eLRTDtGA5tm7dila1TJo0qaUhUVhY2LFjRzQrP/jgA5VK1dJAEIi+EKgEYgitWq2eP3++VColJ0ZwcHBlZaVQhONejqysLPQBv1evXnBH4B5y4xzUavWgQYNIh5TJZFeuXDE+xlZ6VFZW9urVCz05vf3225BwlkfbQqDiEXwqa41Gg2969/PzayEp1+rr6/39/cmbgouLC2xPoXoGf9c1NTXe3t6kadzc3FqOQ3bu3BlFqZEjR8JyXP588H84Q6DiF38qd7VaPXLkSHKGEATRQhIsLV26FKm8du1aKihwzSsCeMbFl156iVdZrMG8ubl53LhxyCGjoqLg/701cKflAYGKFh4+Guvq6sLDw9E8efHFF/mQwno8L126hD6EhIeHw/Ze60HPjJNarY6OjkYOef78eWbjxNrr3//+N1L2mWeeefr0qVg1sSG5IVAJ0Zh//fVXt27d0GzhaCNLSUnJgQMHPvvss5iYmMjIyG7dugUFBfn4+Dg7O8tkMgcHBy8vL39//86dOw8ZMuT111+Pi4vbuXMnuysSq6qqevbsSWpqb2+fmZkpRHu0eJlyc3NdXV1JM7Vp04bdo9Sys7N37twZFxf3+uuvDxkypHPnzv7+/l5eXg4ODjKZzNnZ2cfHJygoqFu3bpGRkTExMZ999tmBAwdKSkq4MAta0UMQRLdu3VrgmiYuULWcJgQqyzHkhML9+/e9vLxQrFqzZg3Oxuwj2p48eXLkyJG4uLj+/fujPYyIC8NCQEDA9OnTk5KS8vPzcakYlm/fvo16vv/++4jpV199heqhIDQEkpKSkKWmT5+OxMvKykJl5oX8/PykpKTp06cHBAQgsiYV/t7d1b9//7i4uCNHjjx58oQ5a7wnZR6tXLkSyeDl5XXr1i28M5R5RAACFY/gG2FdUlKCH7uQmJhIftHdu3fvjBkzjAz+Z3N9fX1WVtbs2bPxrYtoTlpSGDFiREpKSllZ2T8Z0l2NHj06JiamtLQ0LS0Nnd7bpUuXFvKhng4aAbepVKqhQ4ciVzl48OCTJ0+mTZvWo0cP5lKXlZWlpKSMGDEC0WGl4ODgMHv27KysLFPPglm5cuWePXu0Wq1Go/n1119RKj83NzeO/rExxwp64ghAoMLREFz5wYMH6FYulUpPnjz5448/EgQxYMAAhrKq1erExERWbgf0RGbMmFFdXc1EKl9fX5JUq1atyIKjoyMklGMCHb99qqurnZ2dSZM5OTmhNJVMpKqurp4xYwZBEGb/j6d3P9SamJjIfB35kCFDCIL48ccf09PT0YdShUIBqXiZ2NSafSBQWRNtc3idOnUKTUL5//4IgnB0dDRKS61Wf/rppygqICLcFVxdXaOjo4uKimhkq6mp0RXgs88+g+W/NKAJpyk5OVnXfA8fPqSRsKioKDo6Gn3i0h3Oeo2vr++nn37KJFyRsVYmk6EjOu3t7Q8fPkyjDjTxggAEKl5gN43p7t27dSfz0aNHaahs3749KChId5QValxcXGbOnGko8OTl5VFksLe3379/P40u0CQQBDQazb59+9C+bGTHy5cv65VQo9HMnDlTtz8ayGkhKCho+/btegUjKw8dOqQrwDfffEMzBJr4QgACFV/Im8C3trY2JCSEMqkiIiL0ksjMzIyKiqJ0tv5lQEBAUlIS5WO1Vqu9cOGCrjASiWTixInl5eV6NYJKISDw+PHjt99+G70fw434yy+/UCRUKpVJSUlmL5TAiVtYjoqKMrSU9KWXXqIQ7969O7yCpphSIJcQqARiCINilJaWTpgwgTKjCILw8fFpbm6mDPvqq6/QNy3dIdaveeWVVyhnde/bt09XDKlU2rdvX0MP5hQd4ZIXBHJycgYOHIhSfOFG3LhxIy5SaWnpK6+8gnfgt6xQKHQXlCqVyjZt2ugKNnLkSHhgwq0pkDIEKoEYwqAYI0aMQIuR8HkllUrxp7+qqip0MCvejfdyu3bt8LNQP//8c1wkiUTi7e29c+dOQ68KDeICDXwgcObMGd37+7Jly5Asubm5eLpx3Nb8lkeNGoXPl8rKSr3Tys7OLioqCqkDBYEgAIFKIIYwKEZzc3Npaek777yjO883bNhADsvKynJ3d9ftIJAahUKxfv16UtQ5c+bgUq1cubKhocGg8tAgPAQaGhq2bduGGzE6OpoUc/369eg4MbyDQMru7u5o19f69et1pZo3b979+/d131cLzwgtTiIIVKIxeWlp6fHjxyMiItAEa926tUqlOn36NFrnjZqEVpBIJORz98svv0yuUZ4yZcqDBw9Egz4I+k8EHj16FBsbS74J7N+/v1arjYuL43rpueVe3apVq9OnT6tUqg4dOiBqw4YNO3z4MKRK+qeFhXUFgUpY9mAiTW5u7qpVq3r06EEQxJdffink/1LoXkAW5s2b16lTpxEjRly7dg3e9TGxtcD7XL9+/aWXXvL09Jw3bx7F1oK9dHd337hxI0EQgYGBH3zwwZ9//ilwkEE8yJ4ubh+IjY0V/jMs5Yb13HPPMdngIm7DtCTp1Wr1c889R7GywC+lUumsWbMgJ7qI/BT+UYnIWP8Q9fr163rXCgv8HkEQxNy5c/+hCVyIGYG5c+cK3+V0JZTJZNevXxcz8C1LdghUorR3ZmamSKMU+YFq+fLlosQdhP4nAsuXL9e7YF03MAiwRiaTGdpi9U8t4Yp/BCBQ8W8DUyW4e/cuOnRVgPOfiUhSqXTfvn2mKg79BYXAvn37xBulSC/19va+e/euoFAFYfQiAIFKLyyCroyMjGQSDATex97ePi8vT9BAg3CGEcjLy0P58QTuafTiRUZGGtYSWoSCAAQqoViCoRyLFy+mn3giag0NDa2oqGCoOHQTDgIVFRWhoaEi8jR6URctWiQcbEESvQhAoNILi0Arb9y4IeQNlfS3A72t8+fPFyjWIJZhBObPn6/XmiKtlMvlN27cMKwutPCPAAQq/m3AUILGxkYPDw+R3gtoxL569SpDBKCbEBC4evUqjTVF2uTh4dHY2CgEeEEGvQhAoNILixAr4+PjRbdrislti/khkEK0SsuTacCAAUzMKq4+EokkPj6+5RlTNBpDoBKHqe7evSv2FVaG7lwSiSQhIUEcZmjxUiYkJNjk0xJBEFKpFFYACtbBIVAJ1jT/EIySy9XQTV+k9R4eHvX19f9QGC6Eh0B9fb1NvnxGs2bOnDnCQx0k+h8EIFCJwA/y8/PRXLLVQmJioggs0bJFTExMtFX3Q3rl5+e3bCMLVHsIVAI1DC6WSLPUoMnPsFBdXY1rDWVBIVBdXc3QjqLuBvm9BOV1SBgIVAgKgRaqq6ttbEm6oRtZcnKyQG0AYmm1ycnJhgxnS/VyuRwemATo7xCoBGiUf4hEORLXlm4KFF2GDh36D83hQkgIDB06lGIvW738/PPPhQQ8yPI/CECgErof2ORqYEP3uOzsbKHbo0XKl52dbchktlcP+yUE6OMQqARolP8vUmlpKRcZ1aKioibT/l5//fXx48ePGDGiTZs21rwTrVmz5v8rDyXBILBmzRrW3cDf3x/3wVdffZXhgQCvvPIKPjAoKIhd2ezt7UtLSwWDPQjyPwhAoBK0HyxcuJDdSUhSS0tLY652QUFBTExM27ZtrbCB5plnnmEuGPS0GgLPPPMM637o6emJ70lQq9URERFGubz22mu41o8ePTI6xIwOCxcuxLlAmXcEIFDxbgKDAqjV6sDAQDOmmdEhJgUqUj61Wr1v3z6jlC3vUFJSYhARaOADgZKSEsvNqpfCzp07cYVqa2uNvj/Izc3Fh4wePVovZQsrAwMD4RxqHGfeyxCoeDeBQQHq6+vd3NwsnHJ6h5sRqEgp79y5M3DgQL002arcvn27QUSggQ8Etm/fzpZxdek8fPgQ12ns2LG6fVDNW2+9pdFoUP/c3FyjgQ2NNang5uaG/9tDHKHAFwIQqPhC3jjfvLw8jtImUQLVqVOnfvrn7/jx43fv3lWpVLpSlpWVjRgxwqRpb1LniRMn6jKFGh4RmDhxokkWNKkzJX1+UVGRg4ODXgoymeyvv/5COCiVyt69e+vtaXmlVCqFw9IQ1EIoQKASghX0y7B8+XLLp5xeCpRAFRUVpbdbQEDAsmXLioqKKPLdvXvXxcVF7xDLK3v16kVhB5f8ItCrVy/LzUpD4fLly7iChrKFxcTE4H+nzpw5w9FjHCnq8uXLcamgzC8CEKj4xZ+O++DBg2mmtyVNDAMVycLJyem3336jCHro0CGO1lb4+PhQeMElvwj4+PhY4mxGx44dOxb/IPTo0SNHR0fKKHd3d/wYDiukyRg8eDC/sAN3HAEIVDgaAiqrVCrKXGXx0qRARfJNT0/H0Wlububu/lVbW4vzgjKPCNTWerglMAAADW9JREFU1rLoeIZInTp1Ctfx448/pvSkZDbaunUrpQMXl3pffeNyQtlqCECgshrUpjEqLS3lYu6RNM0IVC4uLpTUMuvXr+dIwuPHj5sGFvTmDIHjx49zZGWcbPfu3XENioqK8NbWrVs3NTWhDiUlJbp/ufD+bJVhNxXCnPcCBCreTaBfAE4zppsRqAiC2Lx5My5rbW2tQqFg66aA01m1ahXOCMpcIxAVFbVhwwa9XFatWoWbhrvypk2bcAHwx6C4uDi86d133+VODJwyZFLHYee3DIGKX/wNcr958yY+Z9gtmxeo3Nzc8AdbrVbbrVs3dgUjqc2ePdsgLtDAAQLBwcEEQXTs2PG7776jLMuePXs2FybWpenh4VFTU4OUe/r0KblWon379lVVVaj+1q1b1vk7RRDEzZs3EV8o8IsABCp+8TfI/erVq7qTma0a8wIVQRCFhYW4xOHh4WyJhNOhZB/AOUKZCwTIQEWaoF27djt37nz69CnJ6LXXXsNNw2n5o48+wtf1bdiwgSCIb7/9FleZSfYKtoS8evUqzhrKPCIAgYpH8OlYp6amsjXfdOmYHagoSypeeOEFXeJQYwMIeHl57dy5s66uzpqBgSCIgoICfFZ07NgR/zJ65coVa2KbmpqKCwNlHhGAQMUj+HSsf//9d+7mpNmB6ueff8aFhkDFnY14pyyRSNz+92dNSSZNmoQ7GP4eUq1Wd+jQwZrC/P7777gwUOYRAQhUPIJPx/r8+fPczUkIVNxhazOUZTLZ/Pnzu3btamWNKEvV0SQ5fPgwR1v3DCl4/vx5xB0K/CIAgYpf/A1yv3z5sqH5Y3m9wANVjx49voSfFRHw9vbGnUoul8+ePTsnJ0er1T7//PN4kxXKAwcO1N3AVFZWZgXWFBaUlBkG5yo0cI8ABCruMTaLw/Xr1ynThsVLswPVkSNHcG04evX3xhtv4FygzDUCaDGFQqGYNGkS/qHojTfeYNHxGJLatm0bReXVq1czHMtit+vXr1PEgEu+EIBAxRfyRvhyeqaq2YEqKysLl3v48OEs3hcQqdjYWJwLlLlGIDg42MXFZfz48fjKBZJpbGwssovVCn369MFVLi4uthprnBGcN41bgd8yBCp+8TfI/d69e/icYbdsdqCqrKzEJe7Xrx+7gpHUKHs/cY5Q5gKBuLg4Q2mrNm3axIWJ6Wl269YNV5PTuUAjyb1793AxoMwjAhCoeASfjnVVVRXNFLKwybxANXnyZHybi1ardXV1tVASvcMzMjLooIE2KyKQkZGh10acVgokUOEbja0IObDSgwAEKj2gCKFKo9F4eXlxdDswI1BJpVLKK3uO1iUqFAqlUikEE4AMWq1WqVRylCiLxreFEKi8vLwoj2XgDzwiAIGKR/CNsJ4wYQLNZLakyYxAFRYWhscPtVrN0VG/AQEBRnCBZusiEBAQYImzmTFWCIHq5Zdfti7MwI0OAQhUdOjw2/b999+bMcmZDDE1UPn5+eGnAWm12ocPHxo6iZWJADR9wsLC+IUduFMQCAsLo7EXF01CCFRbt26l4ACXPCIAgYpH8I2wrqqqksvlXNwITApUffr0KSsrw2VVKpX9+/fnQjCCIBYsWIDzgjLvCCxYsIAjWxsiy3ugksvlugsgeTdESxYAApVwrd/Y2NiqVStDk9mSeoaBqnXr1gcPHqT8l9JqtTt27LCEO/3YEydOCNckLVKyEydO0JuM9VbeA1WrVq0oBwW0SMsLSGkIVAIyBkUUjUYzaNAg1u8CBEFQAtWdO3du/vOXnZ396NEj/IBwJNtPP/1kb2/PhVQEQbi5uenGRcQaCrwg0NjY6ObmxpHF9ZLlPVANGjQIVlLw4myGmEKgMoSMIOq3b9+udyZbWEkJVMxV/eabbzj6NEVqNH78eObCQE+rITB+/HgLXc6k4bwHqu3bt1sNW2DEBAEIVExQ4rMPF2//TA1UGo0mPz9/4sSJJt1uzOi8e/duPrEG3gYQ2L17txnWNHsIv4GqVatWBmCAat4QgEDFG/QMGY8dO9bsCW9oIJNApVQqGxoaysvL//jjjzFjxhgixWK9XC4vLy9nCAt0syYC5eXlHK3r0es//AaqsWPHWhNb4MUEAQhUTFDis8+hQ4f0TmZLKl1cXNyN/VxdXZ2dnbn7HKUr/6xZs/gEGnjTIjBr1ixdk3FUI5VKcffkKAGKIeEPHTpEiwQ08oAABCoeQDeJpUql6t69u6FJZUv1cPK3SY5h5c5Xr161JWczpEv37t11DxmxMtTAThcBCFS6mAiuJiEhwdC8spn6/v3745kvBGeDFi8Qp5vnhOPGCQkJLd7UQgQAApUQrUKRqaqqqk2bNsKZzKxLYmdnRzlAhIIAXAoBgaysLDs7O9atLxyCbdq0gUS0QvA0XRkgUOliIsQa7tIpCeE20aVLF/g7JUS3+6dMSqWyS5cuQnAYjmT4/vvv/6kxXAkFAQhUQrEEvRz19fXWXNfA0Y1AL1mpVPrgwQN69aFVIAg8ePBAKpXqtaPYK+3t7evr6wWCM4hBQQACFQUQ4V7m5OTY5IuXGTNmCBd0kEwHgZkzZ4o9JunKb2dnl5OTo6MrVAgFAQhUQrGEUTlUKtWLL76oO8dEXRMUFAR7p4yaXlAdysvLg4KCRO11usK/+OKLsNhPUG5GEQYCFQUQQV/W1tb6+fnpTjPx1kAqCkE7nAHhrJyogmv39vPzq62tNaArVAsCAQhUgjADcyGOHz/u6OjI9dS1Dv333nuPueLQU1AIvPfee9ZxEq65ODo6QsJ+QbmWXmEgUOmFRdCVK1as4Hr2WoG+v78/fLsWtJ/RCldfX+/v728FP+GaxfLly2kVhUZBIACBShBmMEmI5uZmLhIAcn1HwOk7ODg8fPjQJK2hs9AQ4O6UZ9xVOC2PHTu2ublZaMCCPLoIQKDSxUQENZWVlYMHD+Z0DnNH3NPT89atWyJAGUQ0hsCtW7c8PT25cxVOKQ8aNKiystKYitAuCAQgUAnCDGYIUV1dHRISwulM5oK4m5vbyZMnzdAXhggTgZMnT1o5aSwrbhkSEgKHzQvTo/RKBYFKLyziqKyoqBBXpgAXF5fExERxgAtSMkYgMTHRxcWFlfhhHSJdunSpqKhgrB905B8BCFT828ASCZqbm/v162ed6W0hF2dn54sXL1qiLIwVLAIXL150dna20EOsM7xfv37wXUqwjmRIMAhUhpARTb1SqYyIiLDOJDebi0wmKywsFA2mIKjpCBQWFspkMrM9xDoDIyIiIKuk6bblfwQEKv5tYLkEtbW1CxcutM5UN4NLt27d7t+/b7maQEHgCNy/f1/IZ6ctXLgQNvYK3IUMiQeByhAyIqtXq9WHDh1yc3MzI5BwOmTRokV1dXUiQxPENReBurq6RYsWcepRZhB3c3M7dOiQWq02Vy0YxzMCEKh4NgC77HNzc4XzGjAoKCgpKYldBYGaKBBISkoSTj7AiIiI3NxcUeAGQhpCAAKVIWREXL9t2zZfX18zHjzZGqJQKN544w14zSJiH7JY9Nra2qlTpyoUCracygw6vr6+W7dutVgVIMA/AhCo+LcBFxI0Nja+8cYb1j86SCKRdOrU6dGjR1woBTRFh8CjR486deokkUjMCDOWDJFKpW+88UZjY6PoEAOB9SIAgUovLDZSWVxcbM0PBsOGDbt69WpTU5ONwAdqsIFAU1PT1atXhw0bZkngMWnsokWLiouL2ZAdaAgFAQhUQrEEd3IUFhauXbu2Y8eOJs125p1dXFxmzZp1+fJlONGHOyOKnbJKpbp8+fKsWbO42xrcsWPHtWvXwi4IsbuKXvkhUOmFxQYr1Wr16dOnZ82a1b59e+ZBiKanu7v72LFjf/jhB9jkb4PuwplKFRUVP/7449ixY93d3Wm8i3lT+/btZ86cefr0aVjUx5nR+CcMgYp/G1hfgtzc3E8//TQ8PLx9+/bME7XZ29u3bdu2b9++77zzzqlTp+C+YH3D2RJHtVp96tSp2bNn9+3bt23btvb29gyDk6ura/v27cPDw1evXg3L+WzJJWh0gUBFA05LaSopKdm7d29sbOzkyZMjIyP79Onj7+/fpUuX8PDw6Ojod955Z9OmTdnZ2RqNpqUgAnpaHQGNRpOdnb1p06Z33nknOjo6PDy8S5cu/v7+ffr0iYyMnDx5cmxs7N69e0tKSqwuGjDkHwEIVPzbACQABAABQAAQoEEAAhUNONAECAACgAAgwD8CEKj4twFIAAgAAoAAIECDAAQqGnCgCRAABAABQIB/BCBQ8W8DkAAQAAQAAUCABgEIVDTgQBMgAAgAAoAA/whAoOLfBiABIAAIAAKAAA0CEKhowIEmQAAQAAQAAf4RgEDFvw1AAkAAEAAEAAEaBCBQ0YADTYAAIAAIAAL8IwCBin8bgASAACAACAACNAhAoKIBB5oAAUAAEAAE+EcAAhX/NgAJAAFAABAABGgQgEBFAw40AQKAACAACPCPAAQq/m0AEgACgAAgAAjQIACBigYcaAIEAAFAABDgHwEIVPzbACQABAABQAAQoEEAAhUNONAECAACgAAgwD8CEKj4twFIAAgAAoAAIECDwP8BHeULITo/NsEAAAAASUVORK5CYII="
    }
   },
   "cell_type": "markdown",
   "id": "3cfcc114",
   "metadata": {},
   "source": [
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90cb86c7",
   "metadata": {},
   "source": [
    "如图，注意到 $V$ 实际上可以看作工具变量，此时可以构造估计：\n",
    "$$\n",
    "\\theta_0 \n",
    "= \\frac{\\operatorname{cov}(V, Y - g_0(X))}{\\operatorname{cov}(V, D)}\n",
    "= \\frac{\\operatorname{cov}(D - m_0(X), Y - g_0(X))}{\\operatorname{cov}(D - m_0(X), D)}\n",
    "= \\frac{\\operatorname{cov}(D - m_0(X), D \\theta_0 + U)}{\\operatorname{cov}(D - m_0(X), D)}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70886877",
   "metadata": {},
   "source": [
    "为了求 $V$，可以采用：\n",
    "$$\n",
    "\\hat V = D - \\hat m_0(X)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9c6938e",
   "metadata": {},
   "source": [
    "其中$\\hat m_0(X)$ 可以通过 $X$ 对 $D$ 回归得到，因此我们得到一种新的估计：\n",
    "$$\n",
    "\\hat{\\theta}_0 = \n",
    "\\frac{\n",
    "\\frac{1}{n} \\sum_{i \\in I} \\hat{V}_i \\left( Y_i - \\hat{g}_0(X_i) \\right)\n",
    "}{\n",
    "\\frac{1}{n} \\sum_{i \\in I} \\hat{V}_i D_i\n",
    "}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b074bd42",
   "metadata": {},
   "source": [
    "在这个估计下，新的 $B$ 项变为：\n",
    "$$\n",
    "b^\\ast = \\left( \\mathbb{E}[D_i^2] \\right)^{-1} \\cdot \\frac{1}{\\sqrt{n}} \\sum_{i \\in I} \\left( \\hat{m}_0(X_i) - m_0(X_i) \\right) \\left( g_0(X_i) - \\hat{g}_0(X_i) \\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a26fdd1",
   "metadata": {},
   "source": [
    "此时偏误仅仅取决于回归误差，因此这个估计更为稳健。直观角度上，线性回归是拟合 $Y$ 在特征空间 $X$ 的最佳投影，既误差最小化。所以残差垂直于样本空间 $X$，最大限度消除了 $X$ 的相关性。此时我们已经在因果模型中构造了稳健的估计量，我们称这个特征为内曼正交性（Neyman Orthogonality），这种构造就是双重机器学习的思想基础。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d56285b2",
   "metadata": {},
   "source": [
    "## 三、DML的步骤"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14063ecc",
   "metadata": {},
   "source": [
    "### Step 1: 估计干扰函数（Nuisance Parameters）\n",
    "使用机器学习方法分别估计：\n",
    "$$\n",
    "\\hat{g}(X) \\approx \\mathbb{E}[Y \\mid X], \\quad \\hat{m}(X) \\approx \\mathbb{E}[D \\mid X]\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d4bd5e9",
   "metadata": {},
   "source": [
    "### Step 2: 残差化（Residualization）\n",
    "计算残差：\n",
    "$$\n",
    "\\tilde{Y}_i = Y_i - \\hat{g}(X_i), \\quad \\tilde{D}_i = D_i - \\hat{m}(X_i)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4b72226",
   "metadata": {},
   "source": [
    "### Step 3: 回归残差 (Residual Regression)\n",
    "使用 OLS 回归：\n",
    "$$\n",
    "\\tilde{Y}_i = \\theta \\cdot \\tilde{D}_i + \\text{noise}\n",
    "$$\n",
    "此时估计量 $\\hat{\\theta}$ 是对因果效应 $\\theta_0$ 的估计，并且具有渐近正态性与内曼正交性。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6c5e5f3",
   "metadata": {},
   "source": [
    "### Step 4: 交叉拟合（Cross-Fitting）\n",
    "为避免过拟合，将样本分成K折（如5折），在第k折中拟合 $\\hat{g}, \\hat{m}$ ，并在剩余样本中计算残差与估计 $\\hat{\\theta}^{(k)}$ 。最终将各折估计结果平均得到：\n",
    "$$\n",
    "\\hat{\\theta} = \\frac{1}{K} \\sum_{k=1}^{K} \\hat{\\theta}^{(k)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d44254a6",
   "metadata": {},
   "source": [
    "## 四、DML实例"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "637fe952-38d7-474f-8df3-32663b94c1d6",
   "metadata": {},
   "source": [
    "### （一）导入工具"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0fde8332-7e44-40f6-8272-9e1c19853f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install scipy==1.11.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "1f5f3aa7-d291-4d2a-bb37-728546fb4beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import logging\n",
    "import string\n",
    "import argparse\n",
    "import gensim\n",
    "import joblib\n",
    "import multiprocessing\n",
    "import nltk\n",
    "#nltk.download('stopwords')\n",
    "import joblib\n",
    "import datetime\n",
    "import time\n",
    "import re\n",
    "import os\n",
    "import sys\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "#from global_settings import output_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ffb3f1e-50c1-4626-bf9a-b92ad2b762ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_datasets = [\"ipeirotis\", \"textlab_30\", \"textlab_10\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7eae3173-6810-4bfe-831d-fba7aee0b6fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# panel_filename = [x + '_panel.csv' for x in all_datasets]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d458de-9c3d-4116-ba11-635b45f6800c",
   "metadata": {},
   "source": [
    "### （二）分组计算统计量"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e03ccd73-10ec-4559-8efa-fffa07087932",
   "metadata": {},
   "source": [
    "#### 1、数据处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b0c7b85f-a46e-4d25-aeab-0ceaac44dbc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group_id</th>\n",
       "      <th>hits_available</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>301G7MYOAJ2BOPC8GAIX74AGQGQ350</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-01-07 16:25:08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>301G7MYOAJ2BOPC8GAIX74AGQGQ350</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-01-08 15:26:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>301G7MYOAJ2FYU5YANHEGT95DZ835P</td>\n",
       "      <td>9</td>\n",
       "      <td>2015-05-23 21:50:08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>301G7MYOAJ2FYU5YANHEGT95DZ835P</td>\n",
       "      <td>11</td>\n",
       "      <td>2015-05-23 21:55:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>301G7MYOAJ2FYU5YANHEGT95DZ835P</td>\n",
       "      <td>0</td>\n",
       "      <td>2015-05-23 22:05:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17608342</th>\n",
       "      <td>ZZAWVTYW3Z9ZTAX43ZD0</td>\n",
       "      <td>25</td>\n",
       "      <td>2016-02-29 14:01:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17608343</th>\n",
       "      <td>ZZAWVTYW3Z9ZTAX43ZD0</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-02-29 14:38:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17608344</th>\n",
       "      <td>ZZAWVTYW3Z9ZTAX43ZD0</td>\n",
       "      <td>36</td>\n",
       "      <td>2016-02-29 20:01:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17608345</th>\n",
       "      <td>ZZAWVTYW3Z9ZTAX43ZD0</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-02-29 20:08:22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17608346</th>\n",
       "      <td>ZZAWVTYW3Z9ZTAX43ZD0</td>\n",
       "      <td>3</td>\n",
       "      <td>2016-04-04 16:01:01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17608347 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                group_id  hits_available           timestamp\n",
       "0         301G7MYOAJ2BOPC8GAIX74AGQGQ350               1 2016-01-07 16:25:08\n",
       "1         301G7MYOAJ2BOPC8GAIX74AGQGQ350               0 2016-01-08 15:26:01\n",
       "2         301G7MYOAJ2FYU5YANHEGT95DZ835P               9 2015-05-23 21:50:08\n",
       "3         301G7MYOAJ2FYU5YANHEGT95DZ835P              11 2015-05-23 21:55:01\n",
       "4         301G7MYOAJ2FYU5YANHEGT95DZ835P               0 2015-05-23 22:05:01\n",
       "...                                  ...             ...                 ...\n",
       "17608342            ZZAWVTYW3Z9ZTAX43ZD0              25 2016-02-29 14:01:01\n",
       "17608343            ZZAWVTYW3Z9ZTAX43ZD0               0 2016-02-29 14:38:18\n",
       "17608344            ZZAWVTYW3Z9ZTAX43ZD0              36 2016-02-29 20:01:00\n",
       "17608345            ZZAWVTYW3Z9ZTAX43ZD0               0 2016-02-29 20:08:22\n",
       "17608346            ZZAWVTYW3Z9ZTAX43ZD0               3 2016-04-04 16:01:01\n",
       "\n",
       "[17608347 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2014-2016，每六分钟下载一次发布到MTurk平台最新的200个HIT批次，然后每分钟检查每个发现的HIT批次的状态页面，直到页面报告中该批次的所有HIT都被领取。\n",
    "ipeirotis_panel = pd.read_csv('./data/ipeirotis_panel.csv')\n",
    "ipeirotis_panel['timestamp'] = pd.to_datetime(ipeirotis_panel['timestamp'])\n",
    "ipeirotis_panel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "47e33a22-1743-4497-886a-73ffccef1b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 填充虚假变量\n",
    "def addFakeObs(df):\n",
    "    # 检查hits_available是否有所变化\n",
    "    min_hits = df[\"hits_available\"].min()\n",
    "    max_hits = df[\"hits_available\"].max()\n",
    "    no_variation = max_hits == min_hits\n",
    "    \n",
    "    last_hits = df[\"hits_available\"].iloc[-1]\n",
    "    if no_variation and last_hits < 5:\n",
    "        group_id = df[\"group_id\"].iloc[0]\n",
    "        # 构造虚假的时间戳\n",
    "        fake_first = df[\"timestamp\"].iloc[0] - n_mins\n",
    "        fake_last = df[\"timestamp\"].iloc[-1] + n_mins\n",
    "        # 填充虚假的时间戳下的变量\n",
    "        fake_first_df = pd.DataFrame.from_dict({'group_id':[group_id],'hits_available':[0],'timestamp':[fake_first]})\n",
    "        fake_last_df = pd.DataFrame.from_dict({'group_id':[group_id],'hits_available':[0],'timestamp':[fake_last]})\n",
    "        # 将原变量与构造的虚假变量连接\n",
    "        return pd.concat([fake_first_df, df, fake_last_df], ignore_index=True)\n",
    "    else:\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8d3b456a-cd2e-4273-870b-3ace6dd79650",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\183277367.py:5: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  textlab_30_panel = textlab_30_panel.groupby(\"group_id\").apply(addFakeObs).reset_index(level=0,drop=True).reset_index(drop=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group_id</th>\n",
       "      <th>hits_available</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00004bd33574f0bbb5415bc39a5e50cd</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-07-06 08:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00004bd33574f0bbb5415bc39a5e50cd</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-07-06 08:30:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00004bd33574f0bbb5415bc39a5e50cd</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-07-06 09:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00004bd33574f0bbb5415bc39a5e50cd</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-07-06 09:30:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00004bd33574f0bbb5415bc39a5e50cd</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-07-06 10:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34098204</th>\n",
       "      <td>ffffc57feb6f5ee5ef5d95a54548bcc5</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-02-23 21:30:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34098205</th>\n",
       "      <td>ffffc57feb6f5ee5ef5d95a54548bcc5</td>\n",
       "      <td>1</td>\n",
       "      <td>2017-02-23 22:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34098206</th>\n",
       "      <td>ffffc57feb6f5ee5ef5d95a54548bcc5</td>\n",
       "      <td>1</td>\n",
       "      <td>2017-02-23 22:30:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34098207</th>\n",
       "      <td>ffffc57feb6f5ee5ef5d95a54548bcc5</td>\n",
       "      <td>1</td>\n",
       "      <td>2017-02-23 23:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34098208</th>\n",
       "      <td>ffffc57feb6f5ee5ef5d95a54548bcc5</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-02-23 23:30:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>34098209 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  group_id  hits_available           timestamp\n",
       "0         00004bd33574f0bbb5415bc39a5e50cd               0 2016-07-06 08:00:00\n",
       "1         00004bd33574f0bbb5415bc39a5e50cd               1 2016-07-06 08:30:00\n",
       "2         00004bd33574f0bbb5415bc39a5e50cd               1 2016-07-06 09:00:00\n",
       "3         00004bd33574f0bbb5415bc39a5e50cd               1 2016-07-06 09:30:00\n",
       "4         00004bd33574f0bbb5415bc39a5e50cd               1 2016-07-06 10:00:00\n",
       "...                                    ...             ...                 ...\n",
       "34098204  ffffc57feb6f5ee5ef5d95a54548bcc5               0 2017-02-23 21:30:00\n",
       "34098205  ffffc57feb6f5ee5ef5d95a54548bcc5               1 2017-02-23 22:00:00\n",
       "34098206  ffffc57feb6f5ee5ef5d95a54548bcc5               1 2017-02-23 22:30:00\n",
       "34098207  ffffc57feb6f5ee5ef5d95a54548bcc5               1 2017-02-23 23:00:00\n",
       "34098208  ffffc57feb6f5ee5ef5d95a54548bcc5               0 2017-02-23 23:30:00\n",
       "\n",
       "[34098209 rows x 3 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2016.3-2017.8.22 每30分钟在MTutk上记录一次所有HIT批次，从2017年3月开始增加到每10分钟一次。\n",
    "textlab_30_panel = pd.read_csv('./data/textlab_30_panel.csv', index_col=0).rename({\"hit_series\":\"hits_available\",\"ts_parsed\":\"timestamp\"},axis=\"columns\")\n",
    "textlab_30_panel['timestamp'] = pd.to_datetime(textlab_30_panel['timestamp'])\n",
    "n_mins = pd.Timedelta(minutes=30)\n",
    "textlab_30_panel = textlab_30_panel.groupby(\"group_id\").apply(addFakeObs).reset_index(level=0,drop=True).reset_index(drop=True)\n",
    "textlab_30_panel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4b70b1cd-08d1-4637-9154-3b694d16cf5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3590569063.py:4: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  textlab_10_panel = textlab_10_panel.groupby(\"group_id\").apply(addFakeObs).reset_index(level=0,drop=True).reset_index(drop=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group_id</th>\n",
       "      <th>hits_available</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>301G7MYOAJ1RQHRCTOCVAOHMWTZ35U</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-06-17 18:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>301G7MYOAJ1RQHRCTOCVAOHMWTZ35U</td>\n",
       "      <td>1</td>\n",
       "      <td>2017-06-17 18:10:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>301G7MYOAJ1RQHRCTOCVAOHMWTZ35U</td>\n",
       "      <td>1</td>\n",
       "      <td>2017-06-17 18:20:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>301G7MYOAJ1RQHRCTOCVAOHMWTZ35U</td>\n",
       "      <td>1</td>\n",
       "      <td>2017-06-17 18:30:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>301G7MYOAJ1RQHRCTOCVAOHMWTZ35U</td>\n",
       "      <td>1</td>\n",
       "      <td>2017-06-17 18:40:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12445363</th>\n",
       "      <td>DVJZW3YZ9Y0MV14JJA5Z</td>\n",
       "      <td>1</td>\n",
       "      <td>2017-08-20 15:10:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12445364</th>\n",
       "      <td>DVJZW3YZ9Y0MV14JJA5Z</td>\n",
       "      <td>1</td>\n",
       "      <td>2017-08-20 15:20:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12445365</th>\n",
       "      <td>DVJZW3YZ9Y0MV14JJA5Z</td>\n",
       "      <td>1</td>\n",
       "      <td>2017-08-20 15:30:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12445366</th>\n",
       "      <td>DVJZW3YZ9Y0MV14JJA5Z</td>\n",
       "      <td>1</td>\n",
       "      <td>2017-08-20 15:40:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12445367</th>\n",
       "      <td>DVJZW3YZ9Y0MV14JJA5Z</td>\n",
       "      <td>1</td>\n",
       "      <td>2017-08-21 03:30:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12445368 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                group_id  hits_available           timestamp\n",
       "0         301G7MYOAJ1RQHRCTOCVAOHMWTZ35U               0 2017-06-17 18:00:00\n",
       "1         301G7MYOAJ1RQHRCTOCVAOHMWTZ35U               1 2017-06-17 18:10:00\n",
       "2         301G7MYOAJ1RQHRCTOCVAOHMWTZ35U               1 2017-06-17 18:20:00\n",
       "3         301G7MYOAJ1RQHRCTOCVAOHMWTZ35U               1 2017-06-17 18:30:00\n",
       "4         301G7MYOAJ1RQHRCTOCVAOHMWTZ35U               1 2017-06-17 18:40:00\n",
       "...                                  ...             ...                 ...\n",
       "12445363            DVJZW3YZ9Y0MV14JJA5Z               1 2017-08-20 15:10:00\n",
       "12445364            DVJZW3YZ9Y0MV14JJA5Z               1 2017-08-20 15:20:00\n",
       "12445365            DVJZW3YZ9Y0MV14JJA5Z               1 2017-08-20 15:30:00\n",
       "12445366            DVJZW3YZ9Y0MV14JJA5Z               1 2017-08-20 15:40:00\n",
       "12445367            DVJZW3YZ9Y0MV14JJA5Z               1 2017-08-21 03:30:00\n",
       "\n",
       "[12445368 rows x 3 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "textlab_10_panel = pd.read_csv('./data/textlab_10_panel.csv', index_col=0).rename({\"hit_series\":\"hits_available\",\"ts_parsed\":\"timestamp\"},axis=\"columns\")\n",
    "textlab_10_panel['timestamp'] = pd.to_datetime(textlab_10_panel['timestamp'])\n",
    "n_mins = pd.Timedelta(minutes=10)\n",
    "textlab_10_panel = textlab_10_panel.groupby(\"group_id\").apply(addFakeObs).reset_index(level=0,drop=True).reset_index(drop=True)\n",
    "textlab_10_panel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "64953730-c754-4353-804f-84a23844d2cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group_id</th>\n",
       "      <th>hits_available</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12445227</th>\n",
       "      <td>DVJZW3YZ9Y0MV14JJA5Z</td>\n",
       "      <td>1</td>\n",
       "      <td>2017-06-01 17:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12445228</th>\n",
       "      <td>DVJZW3YZ9Y0MV14JJA5Z</td>\n",
       "      <td>1</td>\n",
       "      <td>2017-06-01 19:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12445229</th>\n",
       "      <td>DVJZW3YZ9Y0MV14JJA5Z</td>\n",
       "      <td>2</td>\n",
       "      <td>2017-06-02 04:20:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12445230</th>\n",
       "      <td>DVJZW3YZ9Y0MV14JJA5Z</td>\n",
       "      <td>1</td>\n",
       "      <td>2017-06-02 13:20:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12445231</th>\n",
       "      <td>DVJZW3YZ9Y0MV14JJA5Z</td>\n",
       "      <td>1</td>\n",
       "      <td>2017-06-03 02:20:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12445232</th>\n",
       "      <td>DVJZW3YZ9Y0MV14JJA5Z</td>\n",
       "      <td>4</td>\n",
       "      <td>2017-06-03 06:50:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12445233</th>\n",
       "      <td>DVJZW3YZ9Y0MV14JJA5Z</td>\n",
       "      <td>1</td>\n",
       "      <td>2017-06-03 07:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12445234</th>\n",
       "      <td>DVJZW3YZ9Y0MV14JJA5Z</td>\n",
       "      <td>1</td>\n",
       "      <td>2017-06-03 19:30:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12445235</th>\n",
       "      <td>DVJZW3YZ9Y0MV14JJA5Z</td>\n",
       "      <td>1</td>\n",
       "      <td>2017-06-04 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12445236</th>\n",
       "      <td>DVJZW3YZ9Y0MV14JJA5Z</td>\n",
       "      <td>1</td>\n",
       "      <td>2017-06-04 00:10:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12445237</th>\n",
       "      <td>DVJZW3YZ9Y0MV14JJA5Z</td>\n",
       "      <td>1</td>\n",
       "      <td>2017-06-04 00:20:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12445238</th>\n",
       "      <td>DVJZW3YZ9Y0MV14JJA5Z</td>\n",
       "      <td>1</td>\n",
       "      <td>2017-06-04 13:40:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12445239</th>\n",
       "      <td>DVJZW3YZ9Y0MV14JJA5Z</td>\n",
       "      <td>2</td>\n",
       "      <td>2017-06-05 00:40:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12445240</th>\n",
       "      <td>DVJZW3YZ9Y0MV14JJA5Z</td>\n",
       "      <td>2</td>\n",
       "      <td>2017-06-05 05:20:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12445241</th>\n",
       "      <td>DVJZW3YZ9Y0MV14JJA5Z</td>\n",
       "      <td>1</td>\n",
       "      <td>2017-06-06 23:10:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12445242</th>\n",
       "      <td>DVJZW3YZ9Y0MV14JJA5Z</td>\n",
       "      <td>1</td>\n",
       "      <td>2017-06-07 16:40:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12445243</th>\n",
       "      <td>DVJZW3YZ9Y0MV14JJA5Z</td>\n",
       "      <td>1</td>\n",
       "      <td>2017-06-07 16:50:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12445244</th>\n",
       "      <td>DVJZW3YZ9Y0MV14JJA5Z</td>\n",
       "      <td>3</td>\n",
       "      <td>2017-06-07 17:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12445245</th>\n",
       "      <td>DVJZW3YZ9Y0MV14JJA5Z</td>\n",
       "      <td>4</td>\n",
       "      <td>2017-06-07 17:50:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12445246</th>\n",
       "      <td>DVJZW3YZ9Y0MV14JJA5Z</td>\n",
       "      <td>4</td>\n",
       "      <td>2017-06-07 18:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12445247</th>\n",
       "      <td>DVJZW3YZ9Y0MV14JJA5Z</td>\n",
       "      <td>4</td>\n",
       "      <td>2017-06-07 18:10:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12445248</th>\n",
       "      <td>DVJZW3YZ9Y0MV14JJA5Z</td>\n",
       "      <td>4</td>\n",
       "      <td>2017-06-07 18:20:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12445249</th>\n",
       "      <td>DVJZW3YZ9Y0MV14JJA5Z</td>\n",
       "      <td>1</td>\n",
       "      <td>2017-06-09 15:20:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12445250</th>\n",
       "      <td>DVJZW3YZ9Y0MV14JJA5Z</td>\n",
       "      <td>1</td>\n",
       "      <td>2017-06-09 15:30:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12445251</th>\n",
       "      <td>DVJZW3YZ9Y0MV14JJA5Z</td>\n",
       "      <td>2</td>\n",
       "      <td>2017-06-09 16:30:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12445252</th>\n",
       "      <td>DVJZW3YZ9Y0MV14JJA5Z</td>\n",
       "      <td>2</td>\n",
       "      <td>2017-06-09 16:40:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12445253</th>\n",
       "      <td>DVJZW3YZ9Y0MV14JJA5Z</td>\n",
       "      <td>1</td>\n",
       "      <td>2017-06-09 16:50:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12445254</th>\n",
       "      <td>DVJZW3YZ9Y0MV14JJA5Z</td>\n",
       "      <td>1</td>\n",
       "      <td>2017-06-10 02:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12445255</th>\n",
       "      <td>DVJZW3YZ9Y0MV14JJA5Z</td>\n",
       "      <td>1</td>\n",
       "      <td>2017-06-11 02:30:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12445256</th>\n",
       "      <td>DVJZW3YZ9Y0MV14JJA5Z</td>\n",
       "      <td>1</td>\n",
       "      <td>2017-06-11 02:40:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12445257</th>\n",
       "      <td>DVJZW3YZ9Y0MV14JJA5Z</td>\n",
       "      <td>1</td>\n",
       "      <td>2017-06-11 04:30:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12445258</th>\n",
       "      <td>DVJZW3YZ9Y0MV14JJA5Z</td>\n",
       "      <td>1</td>\n",
       "      <td>2017-06-11 06:20:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12445259</th>\n",
       "      <td>DVJZW3YZ9Y0MV14JJA5Z</td>\n",
       "      <td>1</td>\n",
       "      <td>2017-06-11 08:50:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12445260</th>\n",
       "      <td>DVJZW3YZ9Y0MV14JJA5Z</td>\n",
       "      <td>1</td>\n",
       "      <td>2017-06-12 14:30:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12445261</th>\n",
       "      <td>DVJZW3YZ9Y0MV14JJA5Z</td>\n",
       "      <td>1</td>\n",
       "      <td>2017-06-13 14:50:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12445262</th>\n",
       "      <td>DVJZW3YZ9Y0MV14JJA5Z</td>\n",
       "      <td>1</td>\n",
       "      <td>2017-06-14 08:10:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12445263</th>\n",
       "      <td>DVJZW3YZ9Y0MV14JJA5Z</td>\n",
       "      <td>1</td>\n",
       "      <td>2017-06-14 14:20:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12445264</th>\n",
       "      <td>DVJZW3YZ9Y0MV14JJA5Z</td>\n",
       "      <td>1</td>\n",
       "      <td>2017-06-14 15:40:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12445265</th>\n",
       "      <td>DVJZW3YZ9Y0MV14JJA5Z</td>\n",
       "      <td>1</td>\n",
       "      <td>2017-06-14 15:50:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12445266</th>\n",
       "      <td>DVJZW3YZ9Y0MV14JJA5Z</td>\n",
       "      <td>2</td>\n",
       "      <td>2017-06-14 16:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12445267</th>\n",
       "      <td>DVJZW3YZ9Y0MV14JJA5Z</td>\n",
       "      <td>2</td>\n",
       "      <td>2017-06-14 16:10:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12445268</th>\n",
       "      <td>DVJZW3YZ9Y0MV14JJA5Z</td>\n",
       "      <td>2</td>\n",
       "      <td>2017-06-14 16:20:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12445269</th>\n",
       "      <td>DVJZW3YZ9Y0MV14JJA5Z</td>\n",
       "      <td>1</td>\n",
       "      <td>2017-06-15 20:40:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12445270</th>\n",
       "      <td>DVJZW3YZ9Y0MV14JJA5Z</td>\n",
       "      <td>1</td>\n",
       "      <td>2017-06-16 15:40:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12445271</th>\n",
       "      <td>DVJZW3YZ9Y0MV14JJA5Z</td>\n",
       "      <td>1</td>\n",
       "      <td>2017-06-16 16:30:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12445272</th>\n",
       "      <td>DVJZW3YZ9Y0MV14JJA5Z</td>\n",
       "      <td>1</td>\n",
       "      <td>2017-06-19 14:10:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12445273</th>\n",
       "      <td>DVJZW3YZ9Y0MV14JJA5Z</td>\n",
       "      <td>1</td>\n",
       "      <td>2017-06-19 16:40:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12445274</th>\n",
       "      <td>DVJZW3YZ9Y0MV14JJA5Z</td>\n",
       "      <td>1</td>\n",
       "      <td>2017-06-19 18:20:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12445275</th>\n",
       "      <td>DVJZW3YZ9Y0MV14JJA5Z</td>\n",
       "      <td>1</td>\n",
       "      <td>2017-06-20 04:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12445276</th>\n",
       "      <td>DVJZW3YZ9Y0MV14JJA5Z</td>\n",
       "      <td>2</td>\n",
       "      <td>2017-06-20 14:20:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      group_id  hits_available           timestamp\n",
       "12445227  DVJZW3YZ9Y0MV14JJA5Z               1 2017-06-01 17:00:00\n",
       "12445228  DVJZW3YZ9Y0MV14JJA5Z               1 2017-06-01 19:00:00\n",
       "12445229  DVJZW3YZ9Y0MV14JJA5Z               2 2017-06-02 04:20:00\n",
       "12445230  DVJZW3YZ9Y0MV14JJA5Z               1 2017-06-02 13:20:00\n",
       "12445231  DVJZW3YZ9Y0MV14JJA5Z               1 2017-06-03 02:20:00\n",
       "12445232  DVJZW3YZ9Y0MV14JJA5Z               4 2017-06-03 06:50:00\n",
       "12445233  DVJZW3YZ9Y0MV14JJA5Z               1 2017-06-03 07:00:00\n",
       "12445234  DVJZW3YZ9Y0MV14JJA5Z               1 2017-06-03 19:30:00\n",
       "12445235  DVJZW3YZ9Y0MV14JJA5Z               1 2017-06-04 00:00:00\n",
       "12445236  DVJZW3YZ9Y0MV14JJA5Z               1 2017-06-04 00:10:00\n",
       "12445237  DVJZW3YZ9Y0MV14JJA5Z               1 2017-06-04 00:20:00\n",
       "12445238  DVJZW3YZ9Y0MV14JJA5Z               1 2017-06-04 13:40:00\n",
       "12445239  DVJZW3YZ9Y0MV14JJA5Z               2 2017-06-05 00:40:00\n",
       "12445240  DVJZW3YZ9Y0MV14JJA5Z               2 2017-06-05 05:20:00\n",
       "12445241  DVJZW3YZ9Y0MV14JJA5Z               1 2017-06-06 23:10:00\n",
       "12445242  DVJZW3YZ9Y0MV14JJA5Z               1 2017-06-07 16:40:00\n",
       "12445243  DVJZW3YZ9Y0MV14JJA5Z               1 2017-06-07 16:50:00\n",
       "12445244  DVJZW3YZ9Y0MV14JJA5Z               3 2017-06-07 17:00:00\n",
       "12445245  DVJZW3YZ9Y0MV14JJA5Z               4 2017-06-07 17:50:00\n",
       "12445246  DVJZW3YZ9Y0MV14JJA5Z               4 2017-06-07 18:00:00\n",
       "12445247  DVJZW3YZ9Y0MV14JJA5Z               4 2017-06-07 18:10:00\n",
       "12445248  DVJZW3YZ9Y0MV14JJA5Z               4 2017-06-07 18:20:00\n",
       "12445249  DVJZW3YZ9Y0MV14JJA5Z               1 2017-06-09 15:20:00\n",
       "12445250  DVJZW3YZ9Y0MV14JJA5Z               1 2017-06-09 15:30:00\n",
       "12445251  DVJZW3YZ9Y0MV14JJA5Z               2 2017-06-09 16:30:00\n",
       "12445252  DVJZW3YZ9Y0MV14JJA5Z               2 2017-06-09 16:40:00\n",
       "12445253  DVJZW3YZ9Y0MV14JJA5Z               1 2017-06-09 16:50:00\n",
       "12445254  DVJZW3YZ9Y0MV14JJA5Z               1 2017-06-10 02:00:00\n",
       "12445255  DVJZW3YZ9Y0MV14JJA5Z               1 2017-06-11 02:30:00\n",
       "12445256  DVJZW3YZ9Y0MV14JJA5Z               1 2017-06-11 02:40:00\n",
       "12445257  DVJZW3YZ9Y0MV14JJA5Z               1 2017-06-11 04:30:00\n",
       "12445258  DVJZW3YZ9Y0MV14JJA5Z               1 2017-06-11 06:20:00\n",
       "12445259  DVJZW3YZ9Y0MV14JJA5Z               1 2017-06-11 08:50:00\n",
       "12445260  DVJZW3YZ9Y0MV14JJA5Z               1 2017-06-12 14:30:00\n",
       "12445261  DVJZW3YZ9Y0MV14JJA5Z               1 2017-06-13 14:50:00\n",
       "12445262  DVJZW3YZ9Y0MV14JJA5Z               1 2017-06-14 08:10:00\n",
       "12445263  DVJZW3YZ9Y0MV14JJA5Z               1 2017-06-14 14:20:00\n",
       "12445264  DVJZW3YZ9Y0MV14JJA5Z               1 2017-06-14 15:40:00\n",
       "12445265  DVJZW3YZ9Y0MV14JJA5Z               1 2017-06-14 15:50:00\n",
       "12445266  DVJZW3YZ9Y0MV14JJA5Z               2 2017-06-14 16:00:00\n",
       "12445267  DVJZW3YZ9Y0MV14JJA5Z               2 2017-06-14 16:10:00\n",
       "12445268  DVJZW3YZ9Y0MV14JJA5Z               2 2017-06-14 16:20:00\n",
       "12445269  DVJZW3YZ9Y0MV14JJA5Z               1 2017-06-15 20:40:00\n",
       "12445270  DVJZW3YZ9Y0MV14JJA5Z               1 2017-06-16 15:40:00\n",
       "12445271  DVJZW3YZ9Y0MV14JJA5Z               1 2017-06-16 16:30:00\n",
       "12445272  DVJZW3YZ9Y0MV14JJA5Z               1 2017-06-19 14:10:00\n",
       "12445273  DVJZW3YZ9Y0MV14JJA5Z               1 2017-06-19 16:40:00\n",
       "12445274  DVJZW3YZ9Y0MV14JJA5Z               1 2017-06-19 18:20:00\n",
       "12445275  DVJZW3YZ9Y0MV14JJA5Z               1 2017-06-20 04:00:00\n",
       "12445276  DVJZW3YZ9Y0MV14JJA5Z               2 2017-06-20 14:20:00"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textlab_10_panel[textlab_10_panel['group_id'] == 'DVJZW3YZ9Y0MV14JJA5Z'].iloc[:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d3dac86-9e9d-4244-bd2b-c662001be2d1",
   "metadata": {},
   "source": [
    "#### 2、统计量计算"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59b70b82-a79e-418b-a8b2-2bfbb7a53920",
   "metadata": {},
   "source": [
    "* 最大的hit\n",
    "* 每组在时间序列下的所有hit\n",
    "* 第一个hit，最后一个hit\n",
    "* 时间序列下每组有多少观察值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d2064c25-73c1-42e8-b2ed-7393ca654995",
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeGroupStats(hits_panel):\n",
    "    hits_panel.sort_values(by=['group_id','timestamp'],inplace=True)\n",
    "    hits_panel[\"hit_diffs\"] = hits_panel[\"hits_available\"].diff()\n",
    "    hits_panel[\"time_diffs\"] = hits_panel[\"timestamp\"].diff()\n",
    "    # 将变化率调为正值，观察完成率的变化\n",
    "    hits_panel[\"hits_completed\"] = hits_panel[\"hit_diffs\"].apply(lambda x: -x if x < 0 else np.nan)\n",
    "    # 每组第一个数值更改为NaN\n",
    "    mask = hits_panel[\"group_id\"] != hits_panel[\"group_id\"].shift(1)\n",
    "    hits_panel['hits_completed'][mask] = np.nan\n",
    "    hits_panel['time_diffs'][mask] = np.nan\n",
    "    # 零值比较\n",
    "    hits_panel[\"is_zero\"] = hits_panel[\"hits_available\"].apply(lambda x: int(x == 0.0))\n",
    "    # 以小时为单位创建时间差向量\n",
    "    hits_panel[\"time_diff_hrs\"] = hits_panel[\"time_diffs\"] / pd.Timedelta(hours=1)\n",
    "    # 以分钟为单位创建时间差向量\n",
    "    hits_panel[\"time_diff_mins\"] = hits_panel[\"time_diffs\"] / pd.Timedelta(minutes=1)\n",
    "    # 计算每小时hit完成比率\n",
    "    hits_panel[\"hits_per_hr\"] = hits_panel[\"hits_completed\"] / hits_panel[\"time_diff_hrs\"]\n",
    "\n",
    "    hit_groups = hits_panel.groupby(\"group_id\")\n",
    "    ### 开始分组计算统计量\n",
    "    group_features = []\n",
    "    # 最大hit数\n",
    "    max_df = hit_groups[\"hits_available\"].max().rename(\"max_hits\")\n",
    "    group_features.append(max_df)\n",
    "    # 最开始的hit数\n",
    "    first_df = hit_groups[\"hits_available\"].first().rename(\"first_hits\")\n",
    "    group_features.append(first_df)\n",
    "    # 最后的hit数\n",
    "    last_df = hit_groups[\"hits_available\"].last().rename(\"last_hits\")\n",
    "    group_features.append(last_df)\n",
    "    # 时间序列中共有多少个观察值\n",
    "    numobs_df = hit_groups[\"hits_available\"].size().rename(\"num_obs\")\n",
    "    group_features.append(numobs_df)\n",
    "    # 每小时变化率均值\n",
    "    avg_hitrate_df = hit_groups[\"hits_per_hr\"].mean().rename(\"avg_hitrate\")\n",
    "    # 排除无穷大值找到剩余数值中的最大值，并用最大值替换无穷大值\n",
    "    noninf_max = avg_hitrate_df[~np.isinf(avg_hitrate_df)].max()\n",
    "    avg_hitrate_df.replace(np.inf, noninf_max, inplace=True)\n",
    "    group_features.append(avg_hitrate_df)\n",
    "    # 完成率均值\n",
    "    avg_hits_completed = hit_groups[\"hits_completed\"].mean().rename(\"avg_hits_completed\")\n",
    "    group_features.append(avg_hits_completed)\n",
    "    # 完成率中位数\n",
    "    med_hits_completed = hit_groups[\"hits_completed\"].median().rename(\"med_hits_completed\")\n",
    "    group_features.append(med_hits_completed)\n",
    "    # 完成率最小值\n",
    "    min_hits_completed = hit_groups[\"hits_completed\"].min().rename(\"min_hits_completed\")\n",
    "    group_features.append(min_hits_completed)\n",
    "    # M完成率最大值\n",
    "    max_hits_completed = hit_groups[\"hits_completed\"].max().rename(\"max_hits_completed\")\n",
    "    group_features.append(max_hits_completed)\n",
    "    # 完成率标准差\n",
    "    hits_completed_sd = hit_groups[\"hits_completed\"].std().rename(\"hits_completed_sd\")\n",
    "    group_features.append(hits_completed_sd)\n",
    "\n",
    "    # 记录开始时间\n",
    "    firsttime_df = hit_groups[\"timestamp\"].first().rename(\"first_time\")\n",
    "    group_features.append(firsttime_df)\n",
    "    # 记录结束时间\n",
    "    lasttime_df = hit_groups[\"timestamp\"].last().rename(\"last_time\")\n",
    "    group_features.append(lasttime_df)\n",
    "\n",
    "    ### 计算时间差向量特征\n",
    "    # 平均值\n",
    "    avg_time_gap = hit_groups[\"time_diff_mins\"].mean().rename(\"avg_time_gap\")\n",
    "    group_features.append(avg_time_gap)\n",
    "    # 中位数\n",
    "    med_time_gap = hit_groups[\"time_diff_mins\"].median().rename(\"med_time_gap\")\n",
    "    group_features.append(med_time_gap)\n",
    "    # 最小值\n",
    "    min_time_gap = hit_groups[\"time_diff_mins\"].min().rename(\"min_time_gap\")\n",
    "    group_features.append(min_time_gap)\n",
    "    # 最大值\n",
    "    max_time_gap = hit_groups[\"time_diff_mins\"].max().rename(\"max_time_gap\")\n",
    "    group_features.append(max_time_gap)\n",
    "    # 标准差\n",
    "    time_gap_sd = hit_groups[\"time_diff_mins\"].std().rename(\"time_gap_sd\")\n",
    "    group_features.append(time_gap_sd)\n",
    "\n",
    "    # 0值的数量\n",
    "    numzeros_df = hit_groups[\"is_zero\"].sum().rename(\"num_zeros\")\n",
    "    group_features.append(numzeros_df)\n",
    "\n",
    "    # 将所有统计量打包进group_level\n",
    "    group_level = pd.concat(group_features,axis=1)\n",
    "\n",
    "    # 计算持续期\n",
    "    group_level[\"duration\"] = group_level[\"last_time\"] - group_level[\"first_time\"]\n",
    "    group_level['duration'] = group_level['duration'] / np.timedelta64(1, 'm')\n",
    "    #group_level[\"duration\"] = group_level[\"duration\"].astype('timedelta64[s]')\n",
    "    #group_level[\"duration\"] = group_level[\"duration\"].astype('timedelta64[m]')\n",
    "\n",
    "    return group_level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "acf7cac7-a756-435f-8b4b-8630be895cc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\643954037.py:9: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  hits_panel['hits_completed'][mask] = np.nan\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\643954037.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  hits_panel['hits_completed'][mask] = np.nan\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\643954037.py:10: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  hits_panel['time_diffs'][mask] = np.nan\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\643954037.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  hits_panel['time_diffs'][mask] = np.nan\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\643954037.py:9: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  hits_panel['hits_completed'][mask] = np.nan\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\643954037.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  hits_panel['hits_completed'][mask] = np.nan\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\643954037.py:10: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  hits_panel['time_diffs'][mask] = np.nan\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\643954037.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  hits_panel['time_diffs'][mask] = np.nan\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\643954037.py:9: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  hits_panel['hits_completed'][mask] = np.nan\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\643954037.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  hits_panel['hits_completed'][mask] = np.nan\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\643954037.py:10: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  hits_panel['time_diffs'][mask] = np.nan\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\643954037.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  hits_panel['time_diffs'][mask] = np.nan\n"
     ]
    }
   ],
   "source": [
    "group_level_textlab10 = computeGroupStats(textlab_10_panel)\n",
    "group_level_textlab10.to_pickle('./data/textlab_10_group_stats.pkl')\n",
    "group_level_textlab10.to_csv('./data/textlab_10_group_stats.csv')\n",
    "\n",
    "group_level_textlab30 = computeGroupStats(textlab_30_panel)\n",
    "group_level_textlab30.to_pickle('./data/textlab_30_group_stats.pkl')\n",
    "group_level_textlab30.to_csv('./data/textlab_30_group_stats.csv')\n",
    "\n",
    "group_level_ipeirotis = computeGroupStats(ipeirotis_panel)\n",
    "group_level_ipeirotis.to_pickle('./data/ipeirotis_group_stats.pkl')\n",
    "group_level_ipeirotis.to_csv('./data/ipeirotis_group_stats.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f8bcc249-150f-4ed1-bf23-04981e8f2fba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "requester data length: 411196\n",
      "unique group_ids in requester data: 411196\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_hits</th>\n",
       "      <th>first_hits</th>\n",
       "      <th>last_hits</th>\n",
       "      <th>num_obs</th>\n",
       "      <th>avg_hitrate</th>\n",
       "      <th>avg_hits_completed</th>\n",
       "      <th>med_hits_completed</th>\n",
       "      <th>min_hits_completed</th>\n",
       "      <th>max_hits_completed</th>\n",
       "      <th>hits_completed_sd</th>\n",
       "      <th>...</th>\n",
       "      <th>time_allotted</th>\n",
       "      <th>kind</th>\n",
       "      <th>reward</th>\n",
       "      <th>qualifications</th>\n",
       "      <th>first_seen</th>\n",
       "      <th>last_seen</th>\n",
       "      <th>expiration_date</th>\n",
       "      <th>duration_old</th>\n",
       "      <th>log_duration_old</th>\n",
       "      <th>log_reward</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>group_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>301G7MYOAJ2BOPC8GAIX74AGQGQ350</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.043450</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>3600</td>\n",
       "      <td>mturk#hitgroupItem</td>\n",
       "      <td>55</td>\n",
       "      <td>['Total approved HITs is not less than 100', '...</td>\n",
       "      <td>2016-01-07 16:25:08</td>\n",
       "      <td>2016-01-08 15:21:00</td>\n",
       "      <td>2016-01-27T00:00:00.000Z</td>\n",
       "      <td>1375.0</td>\n",
       "      <td>7.226209</td>\n",
       "      <td>4.007333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301G7MYOAJ2FYU5YANHEGT95DZ835P</th>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>3600</td>\n",
       "      <td>mturk#hitgroupItem</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-05-23 21:50:08</td>\n",
       "      <td>2015-05-23 22:00:02</td>\n",
       "      <td>2015-05-27T00:00:00.000Z</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.197225</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301G7MYOAJ2GKVIZE6OLR130JML53R</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.007929</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1200</td>\n",
       "      <td>mturk#hitgroupItem</td>\n",
       "      <td>50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2014-06-16 21:24:45</td>\n",
       "      <td>2014-06-22 03:26:40</td>\n",
       "      <td>2014-08-25T00:00:00.000Z</td>\n",
       "      <td>7561.0</td>\n",
       "      <td>8.930759</td>\n",
       "      <td>3.912023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301G7MYOAJ2YU4YTD9HY8W55XQD356</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.092967</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3600</td>\n",
       "      <td>mturk#hitgroupItem</td>\n",
       "      <td>50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2014-10-01 12:07:38</td>\n",
       "      <td>2014-10-22 03:41:33</td>\n",
       "      <td>2014-11-04T00:00:00.000Z</td>\n",
       "      <td>29733.0</td>\n",
       "      <td>10.300013</td>\n",
       "      <td>3.912023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301G7MYOAJ2YU4YTD9HY8W57OW9359</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>15.906404</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2400</td>\n",
       "      <td>mturk#hitgroupItem</td>\n",
       "      <td>200</td>\n",
       "      <td>['Location is US']</td>\n",
       "      <td>2015-10-13 17:02:18</td>\n",
       "      <td>2015-10-25 21:01:08</td>\n",
       "      <td>2015-10-25T00:00:00.000Z</td>\n",
       "      <td>17518.0</td>\n",
       "      <td>9.770984</td>\n",
       "      <td>5.298317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4YFZK2ZCCXSZ64ZJNTR0</th>\n",
       "      <td>271</td>\n",
       "      <td>176</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>533.747917</td>\n",
       "      <td>45.166667</td>\n",
       "      <td>41.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>23.016661</td>\n",
       "      <td>...</td>\n",
       "      <td>1200</td>\n",
       "      <td>mturk#hitgroupItem</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2014-09-08 17:45:33</td>\n",
       "      <td>2014-09-08 18:15:21</td>\n",
       "      <td>2014-09-10T00:00:00.000Z</td>\n",
       "      <td>29.0</td>\n",
       "      <td>3.367296</td>\n",
       "      <td>1.609438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DVJZW3YZ9Y0MV14JJA5Z</th>\n",
       "      <td>190</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>34680</td>\n",
       "      <td>16.132259</td>\n",
       "      <td>1.290898</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>1.265982</td>\n",
       "      <td>...</td>\n",
       "      <td>480</td>\n",
       "      <td>mturk#hitgroupItem</td>\n",
       "      <td>5</td>\n",
       "      <td>['HIT approval rate (%) is greater than 95']</td>\n",
       "      <td>2014-05-02 08:25:17</td>\n",
       "      <td>2016-07-16 20:19:12</td>\n",
       "      <td>2016-04-04T00:00:00.000Z</td>\n",
       "      <td>1161353.0</td>\n",
       "      <td>13.965096</td>\n",
       "      <td>1.609438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>J1ZZNQGNTW1YZVD8FWTZ</th>\n",
       "      <td>5474</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>1934</td>\n",
       "      <td>37.801095</td>\n",
       "      <td>4.099866</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>782.0</td>\n",
       "      <td>20.336540</td>\n",
       "      <td>...</td>\n",
       "      <td>3600</td>\n",
       "      <td>mturk#hitgroupItem</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2014-09-15 15:13:09</td>\n",
       "      <td>2014-09-29 15:19:57</td>\n",
       "      <td>2014-09-29T00:00:00.000Z</td>\n",
       "      <td>20166.0</td>\n",
       "      <td>9.911753</td>\n",
       "      <td>1.609438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KY66K9RKG3VZH1ZCWKTZ</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1296</td>\n",
       "      <td>2.388635</td>\n",
       "      <td>1.057971</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.272237</td>\n",
       "      <td>...</td>\n",
       "      <td>7200</td>\n",
       "      <td>mturk#hitgroupItem</td>\n",
       "      <td>20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2014-05-06 09:02:35</td>\n",
       "      <td>2015-11-06 21:46:11</td>\n",
       "      <td>2016-10-27T00:00:00.000Z</td>\n",
       "      <td>791323.0</td>\n",
       "      <td>13.581462</td>\n",
       "      <td>2.995732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZZAWVTYW3Z9ZTAX43ZD0</th>\n",
       "      <td>325</td>\n",
       "      <td>40</td>\n",
       "      <td>3</td>\n",
       "      <td>2515</td>\n",
       "      <td>78241.552539</td>\n",
       "      <td>29.898795</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>325.0</td>\n",
       "      <td>28.131513</td>\n",
       "      <td>...</td>\n",
       "      <td>3600</td>\n",
       "      <td>mturk#hitgroupItem</td>\n",
       "      <td>1</td>\n",
       "      <td>['HIT approval rate (%) is not less than 60', ...</td>\n",
       "      <td>2015-07-25 01:01:05</td>\n",
       "      <td>2016-08-05 22:01:00</td>\n",
       "      <td>2016-04-04T00:00:00.000Z</td>\n",
       "      <td>544139.0</td>\n",
       "      <td>13.206960</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>410284 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                max_hits  first_hits  last_hits  num_obs  \\\n",
       "group_id                                                                   \n",
       "301G7MYOAJ2BOPC8GAIX74AGQGQ350         1           1          0        2   \n",
       "301G7MYOAJ2FYU5YANHEGT95DZ835P        11           9          0        3   \n",
       "301G7MYOAJ2GKVIZE6OLR130JML53R         1           1          0        2   \n",
       "301G7MYOAJ2YU4YTD9HY8W55XQD356         1           1          0        4   \n",
       "301G7MYOAJ2YU4YTD9HY8W57OW9359         1           1          0       60   \n",
       "...                                  ...         ...        ...      ...   \n",
       "4YFZK2ZCCXSZ64ZJNTR0                 271         176          0        8   \n",
       "DVJZW3YZ9Y0MV14JJA5Z                 190           1          1    34680   \n",
       "J1ZZNQGNTW1YZVD8FWTZ                5474          64          0     1934   \n",
       "KY66K9RKG3VZH1ZCWKTZ                   5           2          0     1296   \n",
       "ZZAWVTYW3Z9ZTAX43ZD0                 325          40          3     2515   \n",
       "\n",
       "                                 avg_hitrate  avg_hits_completed  \\\n",
       "group_id                                                           \n",
       "301G7MYOAJ2BOPC8GAIX74AGQGQ350      0.043450            1.000000   \n",
       "301G7MYOAJ2FYU5YANHEGT95DZ835P     66.000000           11.000000   \n",
       "301G7MYOAJ2GKVIZE6OLR130JML53R      0.007929            1.000000   \n",
       "301G7MYOAJ2YU4YTD9HY8W55XQD356      0.092967            1.000000   \n",
       "301G7MYOAJ2YU4YTD9HY8W57OW9359     15.906404            1.000000   \n",
       "...                                      ...                 ...   \n",
       "4YFZK2ZCCXSZ64ZJNTR0              533.747917           45.166667   \n",
       "DVJZW3YZ9Y0MV14JJA5Z               16.132259            1.290898   \n",
       "J1ZZNQGNTW1YZVD8FWTZ               37.801095            4.099866   \n",
       "KY66K9RKG3VZH1ZCWKTZ                2.388635            1.057971   \n",
       "ZZAWVTYW3Z9ZTAX43ZD0            78241.552539           29.898795   \n",
       "\n",
       "                                med_hits_completed  min_hits_completed  \\\n",
       "group_id                                                                 \n",
       "301G7MYOAJ2BOPC8GAIX74AGQGQ350                 1.0                 1.0   \n",
       "301G7MYOAJ2FYU5YANHEGT95DZ835P                11.0                11.0   \n",
       "301G7MYOAJ2GKVIZE6OLR130JML53R                 1.0                 1.0   \n",
       "301G7MYOAJ2YU4YTD9HY8W55XQD356                 1.0                 1.0   \n",
       "301G7MYOAJ2YU4YTD9HY8W57OW9359                 1.0                 1.0   \n",
       "...                                            ...                 ...   \n",
       "4YFZK2ZCCXSZ64ZJNTR0                          41.0                18.0   \n",
       "DVJZW3YZ9Y0MV14JJA5Z                           1.0                 1.0   \n",
       "J1ZZNQGNTW1YZVD8FWTZ                           3.0                 1.0   \n",
       "KY66K9RKG3VZH1ZCWKTZ                           1.0                 1.0   \n",
       "ZZAWVTYW3Z9ZTAX43ZD0                          24.0                 1.0   \n",
       "\n",
       "                                max_hits_completed  hits_completed_sd  ...  \\\n",
       "group_id                                                               ...   \n",
       "301G7MYOAJ2BOPC8GAIX74AGQGQ350                 1.0                NaN  ...   \n",
       "301G7MYOAJ2FYU5YANHEGT95DZ835P                11.0                NaN  ...   \n",
       "301G7MYOAJ2GKVIZE6OLR130JML53R                 1.0                NaN  ...   \n",
       "301G7MYOAJ2YU4YTD9HY8W55XQD356                 1.0           0.000000  ...   \n",
       "301G7MYOAJ2YU4YTD9HY8W57OW9359                 1.0           0.000000  ...   \n",
       "...                                            ...                ...  ...   \n",
       "4YFZK2ZCCXSZ64ZJNTR0                          88.0          23.016661  ...   \n",
       "DVJZW3YZ9Y0MV14JJA5Z                          90.0           1.265982  ...   \n",
       "J1ZZNQGNTW1YZVD8FWTZ                         782.0          20.336540  ...   \n",
       "KY66K9RKG3VZH1ZCWKTZ                           4.0           0.272237  ...   \n",
       "ZZAWVTYW3Z9ZTAX43ZD0                         325.0          28.131513  ...   \n",
       "\n",
       "                               time_allotted                kind  reward  \\\n",
       "group_id                                                                   \n",
       "301G7MYOAJ2BOPC8GAIX74AGQGQ350          3600  mturk#hitgroupItem      55   \n",
       "301G7MYOAJ2FYU5YANHEGT95DZ835P          3600  mturk#hitgroupItem       1   \n",
       "301G7MYOAJ2GKVIZE6OLR130JML53R          1200  mturk#hitgroupItem      50   \n",
       "301G7MYOAJ2YU4YTD9HY8W55XQD356          3600  mturk#hitgroupItem      50   \n",
       "301G7MYOAJ2YU4YTD9HY8W57OW9359          2400  mturk#hitgroupItem     200   \n",
       "...                                      ...                 ...     ...   \n",
       "4YFZK2ZCCXSZ64ZJNTR0                    1200  mturk#hitgroupItem       5   \n",
       "DVJZW3YZ9Y0MV14JJA5Z                     480  mturk#hitgroupItem       5   \n",
       "J1ZZNQGNTW1YZVD8FWTZ                    3600  mturk#hitgroupItem       5   \n",
       "KY66K9RKG3VZH1ZCWKTZ                    7200  mturk#hitgroupItem      20   \n",
       "ZZAWVTYW3Z9ZTAX43ZD0                    3600  mturk#hitgroupItem       1   \n",
       "\n",
       "                                                                   qualifications  \\\n",
       "group_id                                                                            \n",
       "301G7MYOAJ2BOPC8GAIX74AGQGQ350  ['Total approved HITs is not less than 100', '...   \n",
       "301G7MYOAJ2FYU5YANHEGT95DZ835P                                                NaN   \n",
       "301G7MYOAJ2GKVIZE6OLR130JML53R                                                NaN   \n",
       "301G7MYOAJ2YU4YTD9HY8W55XQD356                                                NaN   \n",
       "301G7MYOAJ2YU4YTD9HY8W57OW9359                                 ['Location is US']   \n",
       "...                                                                           ...   \n",
       "4YFZK2ZCCXSZ64ZJNTR0                                                          NaN   \n",
       "DVJZW3YZ9Y0MV14JJA5Z                 ['HIT approval rate (%) is greater than 95']   \n",
       "J1ZZNQGNTW1YZVD8FWTZ                                                          NaN   \n",
       "KY66K9RKG3VZH1ZCWKTZ                                                          NaN   \n",
       "ZZAWVTYW3Z9ZTAX43ZD0            ['HIT approval rate (%) is not less than 60', ...   \n",
       "\n",
       "                                         first_seen            last_seen  \\\n",
       "group_id                                                                   \n",
       "301G7MYOAJ2BOPC8GAIX74AGQGQ350  2016-01-07 16:25:08  2016-01-08 15:21:00   \n",
       "301G7MYOAJ2FYU5YANHEGT95DZ835P  2015-05-23 21:50:08  2015-05-23 22:00:02   \n",
       "301G7MYOAJ2GKVIZE6OLR130JML53R  2014-06-16 21:24:45  2014-06-22 03:26:40   \n",
       "301G7MYOAJ2YU4YTD9HY8W55XQD356  2014-10-01 12:07:38  2014-10-22 03:41:33   \n",
       "301G7MYOAJ2YU4YTD9HY8W57OW9359  2015-10-13 17:02:18  2015-10-25 21:01:08   \n",
       "...                                             ...                  ...   \n",
       "4YFZK2ZCCXSZ64ZJNTR0            2014-09-08 17:45:33  2014-09-08 18:15:21   \n",
       "DVJZW3YZ9Y0MV14JJA5Z            2014-05-02 08:25:17  2016-07-16 20:19:12   \n",
       "J1ZZNQGNTW1YZVD8FWTZ            2014-09-15 15:13:09  2014-09-29 15:19:57   \n",
       "KY66K9RKG3VZH1ZCWKTZ            2014-05-06 09:02:35  2015-11-06 21:46:11   \n",
       "ZZAWVTYW3Z9ZTAX43ZD0            2015-07-25 01:01:05  2016-08-05 22:01:00   \n",
       "\n",
       "                                         expiration_date  duration_old  \\\n",
       "group_id                                                                 \n",
       "301G7MYOAJ2BOPC8GAIX74AGQGQ350  2016-01-27T00:00:00.000Z        1375.0   \n",
       "301G7MYOAJ2FYU5YANHEGT95DZ835P  2015-05-27T00:00:00.000Z           9.0   \n",
       "301G7MYOAJ2GKVIZE6OLR130JML53R  2014-08-25T00:00:00.000Z        7561.0   \n",
       "301G7MYOAJ2YU4YTD9HY8W55XQD356  2014-11-04T00:00:00.000Z       29733.0   \n",
       "301G7MYOAJ2YU4YTD9HY8W57OW9359  2015-10-25T00:00:00.000Z       17518.0   \n",
       "...                                                  ...           ...   \n",
       "4YFZK2ZCCXSZ64ZJNTR0            2014-09-10T00:00:00.000Z          29.0   \n",
       "DVJZW3YZ9Y0MV14JJA5Z            2016-04-04T00:00:00.000Z     1161353.0   \n",
       "J1ZZNQGNTW1YZVD8FWTZ            2014-09-29T00:00:00.000Z       20166.0   \n",
       "KY66K9RKG3VZH1ZCWKTZ            2016-10-27T00:00:00.000Z      791323.0   \n",
       "ZZAWVTYW3Z9ZTAX43ZD0            2016-04-04T00:00:00.000Z      544139.0   \n",
       "\n",
       "                                log_duration_old log_reward  \n",
       "group_id                                                     \n",
       "301G7MYOAJ2BOPC8GAIX74AGQGQ350          7.226209   4.007333  \n",
       "301G7MYOAJ2FYU5YANHEGT95DZ835P          2.197225   0.000000  \n",
       "301G7MYOAJ2GKVIZE6OLR130JML53R          8.930759   3.912023  \n",
       "301G7MYOAJ2YU4YTD9HY8W55XQD356         10.300013   3.912023  \n",
       "301G7MYOAJ2YU4YTD9HY8W57OW9359          9.770984   5.298317  \n",
       "...                                          ...        ...  \n",
       "4YFZK2ZCCXSZ64ZJNTR0                    3.367296   1.609438  \n",
       "DVJZW3YZ9Y0MV14JJA5Z                   13.965096   1.609438  \n",
       "J1ZZNQGNTW1YZVD8FWTZ                    9.911753   1.609438  \n",
       "KY66K9RKG3VZH1ZCWKTZ                   13.581462   2.995732  \n",
       "ZZAWVTYW3Z9ZTAX43ZD0                   13.206960   0.000000  \n",
       "\n",
       "[410284 rows x 34 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ipeirotis_meta = pd.read_csv('./data/ipeirotis_meta.csv', index_col=0)\n",
    "requester_vars = [\"group_id\",\"requester_id\",\"title\",\"description\",\"keywords\",\n",
    "                         \"time_allotted\",\"reward\",\"qualifications\",\"expiration_date\"]\n",
    "print(\"requester data length: \" + str(len(ipeirotis_meta)))\n",
    "print(\"unique group_ids in requester data: \" + str(len(ipeirotis_meta[\"group_id\"].value_counts())))\n",
    "ipeirotis_meta.set_index('group_id', inplace=True)\n",
    "merged_df_ipeirotis = group_level_ipeirotis.merge(ipeirotis_meta, left_index=True, right_index=True, indicator=True)\n",
    "# 检验合并是否正确，indicator在DataFrame最后会生成一个_merge来说明该行数据来源于哪个表格，二者都有标记为both，否则为left_only,right_only\n",
    "num_badmerge = sum(merged_df_ipeirotis[\"_merge\"] != \"both\")\n",
    "if num_badmerge > 0:\n",
    "        print(\"Bad merge!!\")\n",
    "merged_df_ipeirotis.drop(columns=\"_merge\",inplace=True)\n",
    "merged_df_ipeirotis.to_csv('./data/ipeirotis_group.csv')\n",
    "merged_df_ipeirotis.to_pickle('./data/ipeirotis_group.pkl')\n",
    "merged_df_ipeirotis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "88db47b9-055b-40f8-868a-7c1c9f496a72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "requester data length: 363167\n",
      "unique group_ids in requester data: 363167\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_hits</th>\n",
       "      <th>first_hits</th>\n",
       "      <th>last_hits</th>\n",
       "      <th>num_obs</th>\n",
       "      <th>avg_hitrate</th>\n",
       "      <th>avg_hits_completed</th>\n",
       "      <th>med_hits_completed</th>\n",
       "      <th>min_hits_completed</th>\n",
       "      <th>max_hits_completed</th>\n",
       "      <th>hits_completed_sd</th>\n",
       "      <th>...</th>\n",
       "      <th>num_zeros</th>\n",
       "      <th>duration</th>\n",
       "      <th>requester_id</th>\n",
       "      <th>title</th>\n",
       "      <th>requester</th>\n",
       "      <th>expiration_date</th>\n",
       "      <th>hit_info_str</th>\n",
       "      <th>reward</th>\n",
       "      <th>time_allotted</th>\n",
       "      <th>time_left</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>group_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>00004bd33574f0bbb5415bc39a5e50cd</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1890.0</td>\n",
       "      <td>A1DIWKR9NEY82N</td>\n",
       "      <td>Change Sciences Missed Submission</td>\n",
       "      <td>Change Sciences Group</td>\n",
       "      <td>Jul 7, 2016</td>\n",
       "      <td>A1DIWKR9NEY82N|$1.50|Change Sciences Missed Su...</td>\n",
       "      <td>$1.50</td>\n",
       "      <td>60 minutes</td>\n",
       "      <td>23 hours 37 minutes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000057992d4dccafb2c5481d655ae2e5</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>240.0</td>\n",
       "      <td>A1AQ7EJ5P7ME65</td>\n",
       "      <td>Urgent - Higher Pay - Review media transcripti...</td>\n",
       "      <td>Speechpad</td>\n",
       "      <td>Oct 12, 2016</td>\n",
       "      <td>A1AQ7EJ5P7ME65|$1.75|Urgent - Higher Pay - Rev...</td>\n",
       "      <td>$1.75</td>\n",
       "      <td>60 minutes</td>\n",
       "      <td>6 days 23 hours</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0000990eeaa355136a2ef1bdc9b1484a</th>\n",
       "      <td>65</td>\n",
       "      <td>53</td>\n",
       "      <td>65</td>\n",
       "      <td>12</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.57735</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>330.0</td>\n",
       "      <td>A3RXXNTGSUSTQ9</td>\n",
       "      <td>Labeling Tweets 24</td>\n",
       "      <td>Siddharth Suri</td>\n",
       "      <td>Aug 22, 2016</td>\n",
       "      <td>A3RXXNTGSUSTQ9|$0.10|Labeling Tweets 24</td>\n",
       "      <td>$0.10</td>\n",
       "      <td>5 minutes</td>\n",
       "      <td>5 hours 34 minutes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0000f33788d8874bec0c72d6bdb73924</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>180.0</td>\n",
       "      <td>A1AQ7EJ5P7ME65</td>\n",
       "      <td>Urgent - Higher Pay - Review media transcripti...</td>\n",
       "      <td>Speechpad</td>\n",
       "      <td>Aug 26, 2016</td>\n",
       "      <td>A1AQ7EJ5P7ME65|$0.41|Urgent - Higher Pay - Rev...</td>\n",
       "      <td>$0.41</td>\n",
       "      <td>60 minutes</td>\n",
       "      <td>6 days 23 hours</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00011eb8afef8299e0e2ad1886808edc</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>60.0</td>\n",
       "      <td>A3MX44TDYCA6JW</td>\n",
       "      <td>26Retrieve Property Numbers 2016 ML 12.007</td>\n",
       "      <td>Obsidian</td>\n",
       "      <td>Jan 19, 2017</td>\n",
       "      <td>A3MX44TDYCA6JW|$0.07|26Retrieve Property Numbe...</td>\n",
       "      <td>$0.07</td>\n",
       "      <td>7 minutes</td>\n",
       "      <td>2 hours 30 minutes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ffff88efcc2a740c51bbe0723685d9d6</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>750.0</td>\n",
       "      <td>A1AQ7EJ5P7ME65</td>\n",
       "      <td>Transcribe Audio  A2488742  (Audio length: 34 ...</td>\n",
       "      <td>Speechpad</td>\n",
       "      <td>Jul 21, 2016</td>\n",
       "      <td>A1AQ7EJ5P7ME65|$7.67|Transcribe Audio  A248874...</td>\n",
       "      <td>$7.67</td>\n",
       "      <td>5 hours 6 minutes</td>\n",
       "      <td>6 days 23 hours</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ffff9f464f1e1d0a8c9e8588ce435e5e</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>5220.0</td>\n",
       "      <td>A2883M4WUQRXJ1</td>\n",
       "      <td>Converse with Mobile Weather App</td>\n",
       "      <td>MTurkIRL</td>\n",
       "      <td>Mar 16, 2017</td>\n",
       "      <td>A2883M4WUQRXJ1|$0.15|Converse with Mobile Weat...</td>\n",
       "      <td>$0.15</td>\n",
       "      <td>10 minutes</td>\n",
       "      <td>6 days 23 hours</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ffffa737ffbf5907be129d98f9823fe8</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>104</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>4140.0</td>\n",
       "      <td>A1AQ7EJ5P7ME65</td>\n",
       "      <td>Transcribe Audio  A2482487  (Audio length: 36 ...</td>\n",
       "      <td>Speechpad</td>\n",
       "      <td>Jun 23, 2016</td>\n",
       "      <td>A1AQ7EJ5P7ME65|$8.29|Transcribe Audio  A248248...</td>\n",
       "      <td>$8.29</td>\n",
       "      <td>4 hours 54 minutes</td>\n",
       "      <td>6 days 23 hours</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ffffc1d9b78826955e9687d8c6ca714a</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>98</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.57735</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2910.0</td>\n",
       "      <td>A361N9XL4OF4FG</td>\n",
       "      <td>Identify the brands featured in banner ads - 2...</td>\n",
       "      <td>Ad Tagger</td>\n",
       "      <td>Dec 13, 2016</td>\n",
       "      <td>A361N9XL4OF4FG|$0.60|Identify the brands featu...</td>\n",
       "      <td>$0.60</td>\n",
       "      <td>60 minutes</td>\n",
       "      <td>6 days 23 hours</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ffffc57feb6f5ee5ef5d95a54548bcc5</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>120.0</td>\n",
       "      <td>A18U2D0C5M86ZA</td>\n",
       "      <td>[audio] Audio sample quality assurance #21821 ...</td>\n",
       "      <td>Bunny Inc.</td>\n",
       "      <td>Feb 24, 2017</td>\n",
       "      <td>A18U2D0C5M86ZA|$0.02|[audio] Audio sample qual...</td>\n",
       "      <td>$0.02</td>\n",
       "      <td>8 minutes 40 seconds</td>\n",
       "      <td>23 hours 29 minutes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>363167 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  max_hits  first_hits  last_hits  num_obs  \\\n",
       "group_id                                                                     \n",
       "00004bd33574f0bbb5415bc39a5e50cd         1           0          0       63   \n",
       "000057992d4dccafb2c5481d655ae2e5         1           0          0        9   \n",
       "0000990eeaa355136a2ef1bdc9b1484a        65          53         65       12   \n",
       "0000f33788d8874bec0c72d6bdb73924         1           0          0        7   \n",
       "00011eb8afef8299e0e2ad1886808edc         1           0          0        3   \n",
       "...                                    ...         ...        ...      ...   \n",
       "ffff88efcc2a740c51bbe0723685d9d6         1           0          0       25   \n",
       "ffff9f464f1e1d0a8c9e8588ce435e5e         1           0          0      172   \n",
       "ffffa737ffbf5907be129d98f9823fe8         1           0          0      104   \n",
       "ffffc1d9b78826955e9687d8c6ca714a         6           6          1       98   \n",
       "ffffc57feb6f5ee5ef5d95a54548bcc5         1           0          0        5   \n",
       "\n",
       "                                  avg_hitrate  avg_hits_completed  \\\n",
       "group_id                                                            \n",
       "00004bd33574f0bbb5415bc39a5e50cd     2.000000            1.000000   \n",
       "000057992d4dccafb2c5481d655ae2e5     2.000000            1.000000   \n",
       "0000990eeaa355136a2ef1bdc9b1484a     2.666667            1.333333   \n",
       "0000f33788d8874bec0c72d6bdb73924     2.000000            1.000000   \n",
       "00011eb8afef8299e0e2ad1886808edc     2.000000            1.000000   \n",
       "...                                       ...                 ...   \n",
       "ffff88efcc2a740c51bbe0723685d9d6     2.000000            1.000000   \n",
       "ffff9f464f1e1d0a8c9e8588ce435e5e     2.000000            1.000000   \n",
       "ffffa737ffbf5907be129d98f9823fe8     2.000000            1.000000   \n",
       "ffffc1d9b78826955e9687d8c6ca714a     3.333333            1.666667   \n",
       "ffffc57feb6f5ee5ef5d95a54548bcc5     2.000000            1.000000   \n",
       "\n",
       "                                  med_hits_completed  min_hits_completed  \\\n",
       "group_id                                                                   \n",
       "00004bd33574f0bbb5415bc39a5e50cd                 1.0                 1.0   \n",
       "000057992d4dccafb2c5481d655ae2e5                 1.0                 1.0   \n",
       "0000990eeaa355136a2ef1bdc9b1484a                 1.0                 1.0   \n",
       "0000f33788d8874bec0c72d6bdb73924                 1.0                 1.0   \n",
       "00011eb8afef8299e0e2ad1886808edc                 1.0                 1.0   \n",
       "...                                              ...                 ...   \n",
       "ffff88efcc2a740c51bbe0723685d9d6                 1.0                 1.0   \n",
       "ffff9f464f1e1d0a8c9e8588ce435e5e                 1.0                 1.0   \n",
       "ffffa737ffbf5907be129d98f9823fe8                 1.0                 1.0   \n",
       "ffffc1d9b78826955e9687d8c6ca714a                 2.0                 1.0   \n",
       "ffffc57feb6f5ee5ef5d95a54548bcc5                 1.0                 1.0   \n",
       "\n",
       "                                  max_hits_completed  hits_completed_sd  ...  \\\n",
       "group_id                                                                 ...   \n",
       "00004bd33574f0bbb5415bc39a5e50cd                 1.0                NaN  ...   \n",
       "000057992d4dccafb2c5481d655ae2e5                 1.0                NaN  ...   \n",
       "0000990eeaa355136a2ef1bdc9b1484a                 2.0            0.57735  ...   \n",
       "0000f33788d8874bec0c72d6bdb73924                 1.0                NaN  ...   \n",
       "00011eb8afef8299e0e2ad1886808edc                 1.0                NaN  ...   \n",
       "...                                              ...                ...  ...   \n",
       "ffff88efcc2a740c51bbe0723685d9d6                 1.0                NaN  ...   \n",
       "ffff9f464f1e1d0a8c9e8588ce435e5e                 1.0                NaN  ...   \n",
       "ffffa737ffbf5907be129d98f9823fe8                 1.0                NaN  ...   \n",
       "ffffc1d9b78826955e9687d8c6ca714a                 2.0            0.57735  ...   \n",
       "ffffc57feb6f5ee5ef5d95a54548bcc5                 1.0                NaN  ...   \n",
       "\n",
       "                                 num_zeros duration    requester_id  \\\n",
       "group_id                                                              \n",
       "00004bd33574f0bbb5415bc39a5e50cd         2   1890.0  A1DIWKR9NEY82N   \n",
       "000057992d4dccafb2c5481d655ae2e5         2    240.0  A1AQ7EJ5P7ME65   \n",
       "0000990eeaa355136a2ef1bdc9b1484a         0    330.0  A3RXXNTGSUSTQ9   \n",
       "0000f33788d8874bec0c72d6bdb73924         2    180.0  A1AQ7EJ5P7ME65   \n",
       "00011eb8afef8299e0e2ad1886808edc         2     60.0  A3MX44TDYCA6JW   \n",
       "...                                    ...      ...             ...   \n",
       "ffff88efcc2a740c51bbe0723685d9d6         2    750.0  A1AQ7EJ5P7ME65   \n",
       "ffff9f464f1e1d0a8c9e8588ce435e5e         2   5220.0  A2883M4WUQRXJ1   \n",
       "ffffa737ffbf5907be129d98f9823fe8         2   4140.0  A1AQ7EJ5P7ME65   \n",
       "ffffc1d9b78826955e9687d8c6ca714a         0   2910.0  A361N9XL4OF4FG   \n",
       "ffffc57feb6f5ee5ef5d95a54548bcc5         2    120.0  A18U2D0C5M86ZA   \n",
       "\n",
       "                                                                              title  \\\n",
       "group_id                                                                              \n",
       "00004bd33574f0bbb5415bc39a5e50cd                  Change Sciences Missed Submission   \n",
       "000057992d4dccafb2c5481d655ae2e5  Urgent - Higher Pay - Review media transcripti...   \n",
       "0000990eeaa355136a2ef1bdc9b1484a                                 Labeling Tweets 24   \n",
       "0000f33788d8874bec0c72d6bdb73924  Urgent - Higher Pay - Review media transcripti...   \n",
       "00011eb8afef8299e0e2ad1886808edc         26Retrieve Property Numbers 2016 ML 12.007   \n",
       "...                                                                             ...   \n",
       "ffff88efcc2a740c51bbe0723685d9d6  Transcribe Audio  A2488742  (Audio length: 34 ...   \n",
       "ffff9f464f1e1d0a8c9e8588ce435e5e                   Converse with Mobile Weather App   \n",
       "ffffa737ffbf5907be129d98f9823fe8  Transcribe Audio  A2482487  (Audio length: 36 ...   \n",
       "ffffc1d9b78826955e9687d8c6ca714a  Identify the brands featured in banner ads - 2...   \n",
       "ffffc57feb6f5ee5ef5d95a54548bcc5  [audio] Audio sample quality assurance #21821 ...   \n",
       "\n",
       "                                              requester  expiration_date  \\\n",
       "group_id                                                                   \n",
       "00004bd33574f0bbb5415bc39a5e50cd  Change Sciences Group      Jul 7, 2016   \n",
       "000057992d4dccafb2c5481d655ae2e5              Speechpad     Oct 12, 2016   \n",
       "0000990eeaa355136a2ef1bdc9b1484a         Siddharth Suri     Aug 22, 2016   \n",
       "0000f33788d8874bec0c72d6bdb73924              Speechpad     Aug 26, 2016   \n",
       "00011eb8afef8299e0e2ad1886808edc               Obsidian     Jan 19, 2017   \n",
       "...                                                 ...              ...   \n",
       "ffff88efcc2a740c51bbe0723685d9d6              Speechpad     Jul 21, 2016   \n",
       "ffff9f464f1e1d0a8c9e8588ce435e5e               MTurkIRL     Mar 16, 2017   \n",
       "ffffa737ffbf5907be129d98f9823fe8              Speechpad     Jun 23, 2016   \n",
       "ffffc1d9b78826955e9687d8c6ca714a              Ad Tagger     Dec 13, 2016   \n",
       "ffffc57feb6f5ee5ef5d95a54548bcc5             Bunny Inc.     Feb 24, 2017   \n",
       "\n",
       "                                                                       hit_info_str  \\\n",
       "group_id                                                                              \n",
       "00004bd33574f0bbb5415bc39a5e50cd  A1DIWKR9NEY82N|$1.50|Change Sciences Missed Su...   \n",
       "000057992d4dccafb2c5481d655ae2e5  A1AQ7EJ5P7ME65|$1.75|Urgent - Higher Pay - Rev...   \n",
       "0000990eeaa355136a2ef1bdc9b1484a            A3RXXNTGSUSTQ9|$0.10|Labeling Tweets 24   \n",
       "0000f33788d8874bec0c72d6bdb73924  A1AQ7EJ5P7ME65|$0.41|Urgent - Higher Pay - Rev...   \n",
       "00011eb8afef8299e0e2ad1886808edc  A3MX44TDYCA6JW|$0.07|26Retrieve Property Numbe...   \n",
       "...                                                                             ...   \n",
       "ffff88efcc2a740c51bbe0723685d9d6  A1AQ7EJ5P7ME65|$7.67|Transcribe Audio  A248874...   \n",
       "ffff9f464f1e1d0a8c9e8588ce435e5e  A2883M4WUQRXJ1|$0.15|Converse with Mobile Weat...   \n",
       "ffffa737ffbf5907be129d98f9823fe8  A1AQ7EJ5P7ME65|$8.29|Transcribe Audio  A248248...   \n",
       "ffffc1d9b78826955e9687d8c6ca714a  A361N9XL4OF4FG|$0.60|Identify the brands featu...   \n",
       "ffffc57feb6f5ee5ef5d95a54548bcc5  A18U2D0C5M86ZA|$0.02|[audio] Audio sample qual...   \n",
       "\n",
       "                                  reward         time_allotted  \\\n",
       "group_id                                                         \n",
       "00004bd33574f0bbb5415bc39a5e50cd   $1.50            60 minutes   \n",
       "000057992d4dccafb2c5481d655ae2e5   $1.75            60 minutes   \n",
       "0000990eeaa355136a2ef1bdc9b1484a   $0.10             5 minutes   \n",
       "0000f33788d8874bec0c72d6bdb73924   $0.41            60 minutes   \n",
       "00011eb8afef8299e0e2ad1886808edc   $0.07             7 minutes   \n",
       "...                                  ...                   ...   \n",
       "ffff88efcc2a740c51bbe0723685d9d6   $7.67     5 hours 6 minutes   \n",
       "ffff9f464f1e1d0a8c9e8588ce435e5e   $0.15            10 minutes   \n",
       "ffffa737ffbf5907be129d98f9823fe8   $8.29    4 hours 54 minutes   \n",
       "ffffc1d9b78826955e9687d8c6ca714a   $0.60            60 minutes   \n",
       "ffffc57feb6f5ee5ef5d95a54548bcc5   $0.02  8 minutes 40 seconds   \n",
       "\n",
       "                                            time_left  \n",
       "group_id                                               \n",
       "00004bd33574f0bbb5415bc39a5e50cd  23 hours 37 minutes  \n",
       "000057992d4dccafb2c5481d655ae2e5      6 days 23 hours  \n",
       "0000990eeaa355136a2ef1bdc9b1484a   5 hours 34 minutes  \n",
       "0000f33788d8874bec0c72d6bdb73924      6 days 23 hours  \n",
       "00011eb8afef8299e0e2ad1886808edc   2 hours 30 minutes  \n",
       "...                                               ...  \n",
       "ffff88efcc2a740c51bbe0723685d9d6      6 days 23 hours  \n",
       "ffff9f464f1e1d0a8c9e8588ce435e5e      6 days 23 hours  \n",
       "ffffa737ffbf5907be129d98f9823fe8      6 days 23 hours  \n",
       "ffffc1d9b78826955e9687d8c6ca714a      6 days 23 hours  \n",
       "ffffc57feb6f5ee5ef5d95a54548bcc5  23 hours 29 minutes  \n",
       "\n",
       "[363167 rows x 27 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textlab_30_meta = pd.read_csv('./data/textlab_30_meta.csv')\n",
    "requester_vars = [\"group_id\",\"requester_id\",\"title\",\"requester\",\"expiration_date\",\n",
    "                         \"reward\",\"time_allotted\",\"time_left\"]\n",
    "\n",
    "print(\"requester data length: \" + str(len(textlab_30_meta)))\n",
    "print(\"unique group_ids in requester data: \" + str(len(textlab_30_meta[\"group_id\"].value_counts())))\n",
    "textlab_30_meta.set_index('group_id', inplace=True)\n",
    "merged_df_textlab30 = group_level_textlab30.merge(textlab_30_meta, left_index=True, right_index=True, indicator=True)\n",
    "# 检验合并是否正确，indicator在DataFrame最后会生成一个_merge来说明该行数据来源于哪个表格，二者都有标记为both，否则为left_only,right_only\n",
    "num_badmerge = sum(merged_df_textlab30[\"_merge\"] != \"both\")\n",
    "if num_badmerge > 0:\n",
    "        print(\"Bad merge!!\")\n",
    "merged_df_textlab30.drop(columns=\"_merge\",inplace=True)\n",
    "merged_df_textlab30.to_csv('./data/textlab_30_group.csv')\n",
    "merged_df_textlab30.to_pickle('./data/textlab_30_group.pkl')\n",
    "merged_df_textlab30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ad6a9cf9-6874-4f85-9236-f8d8d459aa63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "requester data length: 110313\n",
      "unique group_ids in requester data: 110313\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_hits</th>\n",
       "      <th>first_hits</th>\n",
       "      <th>last_hits</th>\n",
       "      <th>num_obs</th>\n",
       "      <th>avg_hitrate</th>\n",
       "      <th>avg_hits_completed</th>\n",
       "      <th>med_hits_completed</th>\n",
       "      <th>min_hits_completed</th>\n",
       "      <th>max_hits_completed</th>\n",
       "      <th>hits_completed_sd</th>\n",
       "      <th>...</th>\n",
       "      <th>duration</th>\n",
       "      <th>reward</th>\n",
       "      <th>time_left</th>\n",
       "      <th>requester</th>\n",
       "      <th>time_allotted</th>\n",
       "      <th>title</th>\n",
       "      <th>keywords</th>\n",
       "      <th>requester_id</th>\n",
       "      <th>description</th>\n",
       "      <th>expiration_date</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>group_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>301G7MYOAJ1RQHRCTOCVAOHMWTZ35U</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>90.0</td>\n",
       "      <td>$0.15</td>\n",
       "      <td>6 days 23 hours</td>\n",
       "      <td>Zhenglin Liu</td>\n",
       "      <td>30 minutes</td>\n",
       "      <td>Recycling Attitudes and Intentions Questionnaire</td>\n",
       "      <td>survey|recycling|opinions</td>\n",
       "      <td>A2R9VUC7LO7HJU</td>\n",
       "      <td>Complete a questionnaire related to waste recy...</td>\n",
       "      <td>Jun 24, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301G7MYOAJ397EAIS94FMNLGU7035W</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>410.0</td>\n",
       "      <td>$0.03</td>\n",
       "      <td>2 hours 43 minutes</td>\n",
       "      <td>Fred Vollmer</td>\n",
       "      <td>2 minutes</td>\n",
       "      <td>Image Annotation Verification</td>\n",
       "      <td>image annotation|image tagging|directions|navi...</td>\n",
       "      <td>A1W518UWEFCTSE</td>\n",
       "      <td>Verify that the description of an image is acc...</td>\n",
       "      <td>Jun 7, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301G7MYOAJ39FPP8WA9R6K95M9335Z</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>210.0</td>\n",
       "      <td>$0.70</td>\n",
       "      <td>1 week 6 days</td>\n",
       "      <td>Ina Garnefeld</td>\n",
       "      <td>15 minutes</td>\n",
       "      <td>Consumer survey about sales promotions</td>\n",
       "      <td>Sales promotions|consumer survey|academic study</td>\n",
       "      <td>A39EQL8PB8SVTQ</td>\n",
       "      <td>Academic study interested in customer feelings...</td>\n",
       "      <td>Aug 25, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301G7MYOAJ3OHAOZV8UWUP9UZHM53Y</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>40.0</td>\n",
       "      <td>$0.75</td>\n",
       "      <td>2 weeks 5 days</td>\n",
       "      <td>UW Psychology and Law</td>\n",
       "      <td>50 minutes</td>\n",
       "      <td>Investigation of Attitudes Towards Groups(~ 25...</td>\n",
       "      <td>survey|demographics</td>\n",
       "      <td>A2FS313FG0JGW3</td>\n",
       "      <td>You will be asked to complete a variety of que...</td>\n",
       "      <td>Jul 4, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301G7MYOAJ54ES5MA4KIU09DOJ653Q</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>20.0</td>\n",
       "      <td>$0.20</td>\n",
       "      <td>4 weeks 1 day</td>\n",
       "      <td>A.M.</td>\n",
       "      <td>60 minutes</td>\n",
       "      <td>Quick Interesting Survey: Social attitudes(~ 2...</td>\n",
       "      <td>quick survey|short survey|opinions|attitudes|b...</td>\n",
       "      <td>A79USK145OBJJ</td>\n",
       "      <td>This is a quick 2 minute survey on your attitudes</td>\n",
       "      <td>Jul 20, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3ZY19HV01BONLIR1KK5SXUJQHSIGS3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>14720.0</td>\n",
       "      <td>$0.52</td>\n",
       "      <td>23 hours 51 minutes</td>\n",
       "      <td>Foxtrot</td>\n",
       "      <td>26 minutes</td>\n",
       "      <td>Copy Edit English Text</td>\n",
       "      <td>grammatical error correction|proofreading|revi...</td>\n",
       "      <td>A3AYV6BR7VCGW0</td>\n",
       "      <td>Proofreading English Text:  Correct spelling a...</td>\n",
       "      <td>Jul 11, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3ZY19HV01BONLIR1KK5SXUJQIWEGS8</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>19640.0</td>\n",
       "      <td>$0.78</td>\n",
       "      <td>23 hours 46 minutes</td>\n",
       "      <td>Foxtrot</td>\n",
       "      <td>39 minutes</td>\n",
       "      <td>Copy Edit English Text</td>\n",
       "      <td>grammatical error correction|proofreading|revi...</td>\n",
       "      <td>A3AYV6BR7VCGW0</td>\n",
       "      <td>Proofreading English Text:  Correct spelling a...</td>\n",
       "      <td>Aug 1, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3ZY19HV01BPM76GKCNBV9R7GD76SG1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>248</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>5930.0</td>\n",
       "      <td>$0.10</td>\n",
       "      <td>1 day 11 hours</td>\n",
       "      <td>Oregon Researcher</td>\n",
       "      <td>60 minutes</td>\n",
       "      <td>What Are People Thinking? - 2 Minute Survey</td>\n",
       "      <td>survey|demographics|articles|reading|opinion</td>\n",
       "      <td>A3JG43JLET2NUM</td>\n",
       "      <td>What are people think. 2 minute survey on topi...</td>\n",
       "      <td>Jul 27, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3ZY19HV01BSBSMWQ8SJ63FS1C9KSG5</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3187</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>32060.0</td>\n",
       "      <td>$3.50</td>\n",
       "      <td>11 weeks 2 days</td>\n",
       "      <td>Sharon Glazer</td>\n",
       "      <td>5 hours</td>\n",
       "      <td>Meaningfulness in Life &amp; Work Stress Part 3(~ ...</td>\n",
       "      <td>Work Stress; Time Management; Values; Attitudes</td>\n",
       "      <td>A14BIFHITSA2R9</td>\n",
       "      <td>A survey of employed individuals assessing wor...</td>\n",
       "      <td>Oct 18, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DVJZW3YZ9Y0MV14JJA5Z</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>141</td>\n",
       "      <td>2.411669</td>\n",
       "      <td>1.318182</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.716231</td>\n",
       "      <td>...</td>\n",
       "      <td>115830.0</td>\n",
       "      <td>$0.05</td>\n",
       "      <td>51 minutes 59 seconds</td>\n",
       "      <td>AEI</td>\n",
       "      <td>8 minutes</td>\n",
       "      <td>Find the link and image that a forum thread is...</td>\n",
       "      <td>data collection|deals</td>\n",
       "      <td>A1KKUMD9Z4FCD5</td>\n",
       "      <td>Go to the forum thread at the link below and g...</td>\n",
       "      <td>Jun 1, 2017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>110313 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                max_hits  first_hits  last_hits  num_obs  \\\n",
       "group_id                                                                   \n",
       "301G7MYOAJ1RQHRCTOCVAOHMWTZ35U         1           0          0       10   \n",
       "301G7MYOAJ397EAIS94FMNLGU7035W         1           0          0        4   \n",
       "301G7MYOAJ39FPP8WA9R6K95M9335Z         1           0          0       22   \n",
       "301G7MYOAJ3OHAOZV8UWUP9UZHM53Y         1           0          0        5   \n",
       "301G7MYOAJ54ES5MA4KIU09DOJ653Q         1           0          0        3   \n",
       "...                                  ...         ...        ...      ...   \n",
       "3ZY19HV01BONLIR1KK5SXUJQHSIGS3         1           0          0       17   \n",
       "3ZY19HV01BONLIR1KK5SXUJQIWEGS8         1           0          0       31   \n",
       "3ZY19HV01BPM76GKCNBV9R7GD76SG1         1           0          0      248   \n",
       "3ZY19HV01BSBSMWQ8SJ63FS1C9KSG5         1           0          0     3187   \n",
       "DVJZW3YZ9Y0MV14JJA5Z                   4           1          1      141   \n",
       "\n",
       "                                avg_hitrate  avg_hits_completed  \\\n",
       "group_id                                                          \n",
       "301G7MYOAJ1RQHRCTOCVAOHMWTZ35U     6.000000            1.000000   \n",
       "301G7MYOAJ397EAIS94FMNLGU7035W     6.000000            1.000000   \n",
       "301G7MYOAJ39FPP8WA9R6K95M9335Z     6.000000            1.000000   \n",
       "301G7MYOAJ3OHAOZV8UWUP9UZHM53Y     6.000000            1.000000   \n",
       "301G7MYOAJ54ES5MA4KIU09DOJ653Q     6.000000            1.000000   \n",
       "...                                     ...                 ...   \n",
       "3ZY19HV01BONLIR1KK5SXUJQHSIGS3     6.000000            1.000000   \n",
       "3ZY19HV01BONLIR1KK5SXUJQIWEGS8     6.000000            1.000000   \n",
       "3ZY19HV01BPM76GKCNBV9R7GD76SG1     6.000000            1.000000   \n",
       "3ZY19HV01BSBSMWQ8SJ63FS1C9KSG5     6.000000            1.000000   \n",
       "DVJZW3YZ9Y0MV14JJA5Z               2.411669            1.318182   \n",
       "\n",
       "                                med_hits_completed  min_hits_completed  \\\n",
       "group_id                                                                 \n",
       "301G7MYOAJ1RQHRCTOCVAOHMWTZ35U                 1.0                 1.0   \n",
       "301G7MYOAJ397EAIS94FMNLGU7035W                 1.0                 1.0   \n",
       "301G7MYOAJ39FPP8WA9R6K95M9335Z                 1.0                 1.0   \n",
       "301G7MYOAJ3OHAOZV8UWUP9UZHM53Y                 1.0                 1.0   \n",
       "301G7MYOAJ54ES5MA4KIU09DOJ653Q                 1.0                 1.0   \n",
       "...                                            ...                 ...   \n",
       "3ZY19HV01BONLIR1KK5SXUJQHSIGS3                 1.0                 1.0   \n",
       "3ZY19HV01BONLIR1KK5SXUJQIWEGS8                 1.0                 1.0   \n",
       "3ZY19HV01BPM76GKCNBV9R7GD76SG1                 1.0                 1.0   \n",
       "3ZY19HV01BSBSMWQ8SJ63FS1C9KSG5                 1.0                 1.0   \n",
       "DVJZW3YZ9Y0MV14JJA5Z                           1.0                 1.0   \n",
       "\n",
       "                                max_hits_completed  hits_completed_sd  ...  \\\n",
       "group_id                                                               ...   \n",
       "301G7MYOAJ1RQHRCTOCVAOHMWTZ35U                 1.0                NaN  ...   \n",
       "301G7MYOAJ397EAIS94FMNLGU7035W                 1.0                NaN  ...   \n",
       "301G7MYOAJ39FPP8WA9R6K95M9335Z                 1.0                NaN  ...   \n",
       "301G7MYOAJ3OHAOZV8UWUP9UZHM53Y                 1.0                NaN  ...   \n",
       "301G7MYOAJ54ES5MA4KIU09DOJ653Q                 1.0                NaN  ...   \n",
       "...                                            ...                ...  ...   \n",
       "3ZY19HV01BONLIR1KK5SXUJQHSIGS3                 1.0                NaN  ...   \n",
       "3ZY19HV01BONLIR1KK5SXUJQIWEGS8                 1.0                NaN  ...   \n",
       "3ZY19HV01BPM76GKCNBV9R7GD76SG1                 1.0                NaN  ...   \n",
       "3ZY19HV01BSBSMWQ8SJ63FS1C9KSG5                 1.0                NaN  ...   \n",
       "DVJZW3YZ9Y0MV14JJA5Z                           3.0           0.716231  ...   \n",
       "\n",
       "                                duration reward              time_left  \\\n",
       "group_id                                                                 \n",
       "301G7MYOAJ1RQHRCTOCVAOHMWTZ35U      90.0  $0.15        6 days 23 hours   \n",
       "301G7MYOAJ397EAIS94FMNLGU7035W     410.0  $0.03     2 hours 43 minutes   \n",
       "301G7MYOAJ39FPP8WA9R6K95M9335Z     210.0  $0.70          1 week 6 days   \n",
       "301G7MYOAJ3OHAOZV8UWUP9UZHM53Y      40.0  $0.75         2 weeks 5 days   \n",
       "301G7MYOAJ54ES5MA4KIU09DOJ653Q      20.0  $0.20          4 weeks 1 day   \n",
       "...                                  ...    ...                    ...   \n",
       "3ZY19HV01BONLIR1KK5SXUJQHSIGS3   14720.0  $0.52    23 hours 51 minutes   \n",
       "3ZY19HV01BONLIR1KK5SXUJQIWEGS8   19640.0  $0.78    23 hours 46 minutes   \n",
       "3ZY19HV01BPM76GKCNBV9R7GD76SG1    5930.0  $0.10         1 day 11 hours   \n",
       "3ZY19HV01BSBSMWQ8SJ63FS1C9KSG5   32060.0  $3.50        11 weeks 2 days   \n",
       "DVJZW3YZ9Y0MV14JJA5Z            115830.0  $0.05  51 minutes 59 seconds   \n",
       "\n",
       "                                            requester  time_allotted  \\\n",
       "group_id                                                               \n",
       "301G7MYOAJ1RQHRCTOCVAOHMWTZ35U           Zhenglin Liu     30 minutes   \n",
       "301G7MYOAJ397EAIS94FMNLGU7035W           Fred Vollmer      2 minutes   \n",
       "301G7MYOAJ39FPP8WA9R6K95M9335Z          Ina Garnefeld     15 minutes   \n",
       "301G7MYOAJ3OHAOZV8UWUP9UZHM53Y  UW Psychology and Law     50 minutes   \n",
       "301G7MYOAJ54ES5MA4KIU09DOJ653Q                   A.M.     60 minutes   \n",
       "...                                               ...            ...   \n",
       "3ZY19HV01BONLIR1KK5SXUJQHSIGS3                Foxtrot     26 minutes   \n",
       "3ZY19HV01BONLIR1KK5SXUJQIWEGS8                Foxtrot     39 minutes   \n",
       "3ZY19HV01BPM76GKCNBV9R7GD76SG1      Oregon Researcher     60 minutes   \n",
       "3ZY19HV01BSBSMWQ8SJ63FS1C9KSG5          Sharon Glazer        5 hours   \n",
       "DVJZW3YZ9Y0MV14JJA5Z                              AEI      8 minutes   \n",
       "\n",
       "                                                                            title  \\\n",
       "group_id                                                                            \n",
       "301G7MYOAJ1RQHRCTOCVAOHMWTZ35U   Recycling Attitudes and Intentions Questionnaire   \n",
       "301G7MYOAJ397EAIS94FMNLGU7035W                      Image Annotation Verification   \n",
       "301G7MYOAJ39FPP8WA9R6K95M9335Z             Consumer survey about sales promotions   \n",
       "301G7MYOAJ3OHAOZV8UWUP9UZHM53Y  Investigation of Attitudes Towards Groups(~ 25...   \n",
       "301G7MYOAJ54ES5MA4KIU09DOJ653Q  Quick Interesting Survey: Social attitudes(~ 2...   \n",
       "...                                                                           ...   \n",
       "3ZY19HV01BONLIR1KK5SXUJQHSIGS3                             Copy Edit English Text   \n",
       "3ZY19HV01BONLIR1KK5SXUJQIWEGS8                             Copy Edit English Text   \n",
       "3ZY19HV01BPM76GKCNBV9R7GD76SG1        What Are People Thinking? - 2 Minute Survey   \n",
       "3ZY19HV01BSBSMWQ8SJ63FS1C9KSG5  Meaningfulness in Life & Work Stress Part 3(~ ...   \n",
       "DVJZW3YZ9Y0MV14JJA5Z            Find the link and image that a forum thread is...   \n",
       "\n",
       "                                                                         keywords  \\\n",
       "group_id                                                                            \n",
       "301G7MYOAJ1RQHRCTOCVAOHMWTZ35U                          survey|recycling|opinions   \n",
       "301G7MYOAJ397EAIS94FMNLGU7035W  image annotation|image tagging|directions|navi...   \n",
       "301G7MYOAJ39FPP8WA9R6K95M9335Z    Sales promotions|consumer survey|academic study   \n",
       "301G7MYOAJ3OHAOZV8UWUP9UZHM53Y                                survey|demographics   \n",
       "301G7MYOAJ54ES5MA4KIU09DOJ653Q  quick survey|short survey|opinions|attitudes|b...   \n",
       "...                                                                           ...   \n",
       "3ZY19HV01BONLIR1KK5SXUJQHSIGS3  grammatical error correction|proofreading|revi...   \n",
       "3ZY19HV01BONLIR1KK5SXUJQIWEGS8  grammatical error correction|proofreading|revi...   \n",
       "3ZY19HV01BPM76GKCNBV9R7GD76SG1       survey|demographics|articles|reading|opinion   \n",
       "3ZY19HV01BSBSMWQ8SJ63FS1C9KSG5    Work Stress; Time Management; Values; Attitudes   \n",
       "DVJZW3YZ9Y0MV14JJA5Z                                        data collection|deals   \n",
       "\n",
       "                                  requester_id  \\\n",
       "group_id                                         \n",
       "301G7MYOAJ1RQHRCTOCVAOHMWTZ35U  A2R9VUC7LO7HJU   \n",
       "301G7MYOAJ397EAIS94FMNLGU7035W  A1W518UWEFCTSE   \n",
       "301G7MYOAJ39FPP8WA9R6K95M9335Z  A39EQL8PB8SVTQ   \n",
       "301G7MYOAJ3OHAOZV8UWUP9UZHM53Y  A2FS313FG0JGW3   \n",
       "301G7MYOAJ54ES5MA4KIU09DOJ653Q   A79USK145OBJJ   \n",
       "...                                        ...   \n",
       "3ZY19HV01BONLIR1KK5SXUJQHSIGS3  A3AYV6BR7VCGW0   \n",
       "3ZY19HV01BONLIR1KK5SXUJQIWEGS8  A3AYV6BR7VCGW0   \n",
       "3ZY19HV01BPM76GKCNBV9R7GD76SG1  A3JG43JLET2NUM   \n",
       "3ZY19HV01BSBSMWQ8SJ63FS1C9KSG5  A14BIFHITSA2R9   \n",
       "DVJZW3YZ9Y0MV14JJA5Z            A1KKUMD9Z4FCD5   \n",
       "\n",
       "                                                                      description  \\\n",
       "group_id                                                                            \n",
       "301G7MYOAJ1RQHRCTOCVAOHMWTZ35U  Complete a questionnaire related to waste recy...   \n",
       "301G7MYOAJ397EAIS94FMNLGU7035W  Verify that the description of an image is acc...   \n",
       "301G7MYOAJ39FPP8WA9R6K95M9335Z  Academic study interested in customer feelings...   \n",
       "301G7MYOAJ3OHAOZV8UWUP9UZHM53Y  You will be asked to complete a variety of que...   \n",
       "301G7MYOAJ54ES5MA4KIU09DOJ653Q  This is a quick 2 minute survey on your attitudes   \n",
       "...                                                                           ...   \n",
       "3ZY19HV01BONLIR1KK5SXUJQHSIGS3  Proofreading English Text:  Correct spelling a...   \n",
       "3ZY19HV01BONLIR1KK5SXUJQIWEGS8  Proofreading English Text:  Correct spelling a...   \n",
       "3ZY19HV01BPM76GKCNBV9R7GD76SG1  What are people think. 2 minute survey on topi...   \n",
       "3ZY19HV01BSBSMWQ8SJ63FS1C9KSG5  A survey of employed individuals assessing wor...   \n",
       "DVJZW3YZ9Y0MV14JJA5Z            Go to the forum thread at the link below and g...   \n",
       "\n",
       "                               expiration_date  \n",
       "group_id                                        \n",
       "301G7MYOAJ1RQHRCTOCVAOHMWTZ35U    Jun 24, 2017  \n",
       "301G7MYOAJ397EAIS94FMNLGU7035W     Jun 7, 2017  \n",
       "301G7MYOAJ39FPP8WA9R6K95M9335Z    Aug 25, 2017  \n",
       "301G7MYOAJ3OHAOZV8UWUP9UZHM53Y     Jul 4, 2017  \n",
       "301G7MYOAJ54ES5MA4KIU09DOJ653Q    Jul 20, 2017  \n",
       "...                                        ...  \n",
       "3ZY19HV01BONLIR1KK5SXUJQHSIGS3    Jul 11, 2017  \n",
       "3ZY19HV01BONLIR1KK5SXUJQIWEGS8     Aug 1, 2017  \n",
       "3ZY19HV01BPM76GKCNBV9R7GD76SG1    Jul 27, 2017  \n",
       "3ZY19HV01BSBSMWQ8SJ63FS1C9KSG5    Oct 18, 2017  \n",
       "DVJZW3YZ9Y0MV14JJA5Z               Jun 1, 2017  \n",
       "\n",
       "[110313 rows x 28 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textlab_10_meta = pd.read_csv('./data/textlab_10_meta.csv')\n",
    "requester_vars = [\"group_id\",\"reward\",\"time_left\",\"requester\",\"time_allotted\",\"title\",\n",
    "                            \"keywords\",\"requester_id\",\"description\",\"expiration_date\"]\n",
    "print(\"requester data length: \" + str(len(textlab_10_meta)))\n",
    "print(\"unique group_ids in requester data: \" + str(len(textlab_10_meta[\"group_id\"].value_counts())))\n",
    "textlab_10_meta.set_index('group_id', inplace=True)\n",
    "merged_df_textlab10 = group_level_textlab10.merge(textlab_10_meta, left_index=True, right_index=True, indicator=True)\n",
    "# 检验合并是否正确，indicator在DataFrame最后会生成一个_merge来说明该行数据来源于哪个表格，二者都有标记为both，否则为left_only,right_only\n",
    "num_badmerge = sum(merged_df_textlab10[\"_merge\"] != \"both\")\n",
    "if num_badmerge > 0:\n",
    "        print(\"Bad merge!!\")\n",
    "merged_df_textlab10.drop(columns=\"_merge\",inplace=True)\n",
    "merged_df_textlab10.to_csv('./data/textlab_10_group.csv')\n",
    "merged_df_textlab10.to_pickle('./data/textlab_10_group.pkl')\n",
    "merged_df_textlab10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c21de858-93af-4d48-9a2a-fc7e5a167416",
   "metadata": {},
   "source": [
    "#### 3、清洗数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5dd78587-44c7-408e-b846-1a4652f3c2ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanGroupData(hit_df, data_name):\n",
    "    if data_name == 'textlab_10' or data_name == 'textlab_30':\n",
    "        hit_df[\"reward\"] = hit_df[\"reward\"].str.replace(\"$\",\"\").astype(float) * 100\n",
    "    ## 取对数值\n",
    "    hit_df[\"log_reward\"] = hit_df[\"reward\"].apply(np.log)\n",
    "    hit_df[\"log_duration\"] = hit_df[\"duration\"].apply(np.log)\n",
    "    ## 记录有效观测值（最后的hit数小于最开始的hit数）（仅针对ipeirotis数据）\n",
    "    if data_name == \"ipeirotis\":\n",
    "        hit_df[\"valid_duration\"] = hit_df[\"last_hits\"] <= hit_df[\"first_hits\"]\n",
    "    else:\n",
    "        hit_df[\"valid_duration\"] = 1\n",
    "    print(\"Invalid durations marked\")\n",
    "\n",
    "    # 去掉 rewards/durations 为null的数据\n",
    "    print(\"# null log_reward: \" + str(len(np.where(hit_df[\"log_reward\"].isnull())[0])))# 返回空值的行索引\n",
    "    print(\"# null log_duration: \" + str(len(np.where(hit_df[\"log_duration\"].isnull())[0])))\n",
    "    print(\"Total number of obs: \" + str(len(hit_df)))\n",
    "    hit_df[\"log_duration\"] = hit_df[\"log_duration\"].replace(-np.inf, np.nan)\n",
    "    hit_df[\"log_reward\"] = hit_df[\"log_reward\"].replace(-np.inf, np.nan)\n",
    "    hit_df = hit_df.dropna(subset=[\"log_duration\"])\n",
    "    hit_df = hit_df.dropna(subset=[\"log_reward\"])\n",
    "    # 去掉空值后的观测值数量\n",
    "    print(\"New # observations after dropping null rewards/durations: \" + str(len(hit_df)))\n",
    "\n",
    "    ## 去掉无效的观测期间\n",
    "    hit_df = hit_df[hit_df[\"valid_duration\"] == 1]\n",
    "    hit_df = hit_df[hit_df[\"duration\"] > 0]\n",
    "    print(\"Number of HIT batches once invalid durations are dropped: \" + str(len(hit_df.index)))\n",
    "    ## 去掉无效的报酬\n",
    "    hit_df = hit_df[~hit_df[\"log_reward\"].isnull()]\n",
    "    print(\"And once invalid rewards are dropped: \" + str(len(hit_df.index)))\n",
    "\n",
    "    # 筛出异常值\n",
    "    #rew_upper_cutoff = hit_df[\"reward\"].quantile(0.995)\n",
    "    rew_upper_cutoff = 500.0\n",
    "    #dur_upper_cutoff = hit_df[\"duration_new\"].quantile(0.995)\n",
    "    dur_upper_cutoff = 90000.0\n",
    "    print(\"Dropping obs with reward < 0 or reward > \" + str(rew_upper_cutoff))\n",
    "    print(\"Dropping obs with duration_new < 0 or duration_new > \" + str(dur_upper_cutoff))\n",
    "    hit_df = hit_df[(hit_df[\"duration\"] > 0) & (hit_df[\"duration\"] < dur_upper_cutoff)]\n",
    "    hit_df = hit_df[(hit_df[\"reward\"] > 0) & (hit_df[\"reward\"] < rew_upper_cutoff)]\n",
    "    print(\"Number of obs remaining: \" + str(len(hit_df.index)))\n",
    "\n",
    "    ## Description and title 可以直接使用, 但是 keywords 需要在 ipeirotis+textlab_10 中进一步解析\n",
    "    if data_name == \"ipeirotis\":\n",
    "        keyword_reg = r'\\'(\\S+)\\''\n",
    "        hit_df[\"kw_parsed\"] = hit_df[\"keywords\"].apply(lambda x: ' '.join(re.findall(keyword_reg, x)) if pd.notnull(x) else '')\n",
    "    elif data_name == \"textlab_10\":\n",
    "        hit_df[\"kw_parsed\"] = hit_df[\"keywords\"].str.replace('|',' ')\n",
    "        hit_df[\"kw_parsed\"] = hit_df[\"kw_parsed\"].str.replace('nan','')\n",
    "        hit_df[\"kw_parsed\"] = hit_df[\"kw_parsed\"].astype(str)\n",
    "\n",
    "    ## Ipeirotis 数据保留至2016.2.1\n",
    "    if data_name == \"ipeirotis\":\n",
    "        feb1 = datetime.datetime(2016,2,1)\n",
    "        hit_df = hit_df[hit_df[\"last_time\"] < feb1]\n",
    "        print(\"Number of obs after dropping Feb 1 onwards: \" + str(len(hit_df)))\n",
    "\n",
    "    ## 将如 \"30 minutes\" 这样的字符串时间数据转换为整型\n",
    "    min_reg = r'([0-9]+) (?:minute)|(?:minutes)'\n",
    "    hr_reg = r'([0-9]+) (?:hour)|(?:hours)'\n",
    "    day_reg = r'([0-9]+) (?:day)|(?:days)'\n",
    "    week_reg = r'([0-9]+) (?:week)|(?:weeks)'\n",
    "\n",
    "    def convertToMins(cur_time):\n",
    "        if type(cur_time) == int:\n",
    "            return cur_time\n",
    "        total_mins = 0\n",
    "        # 分钟\n",
    "        min_match = re.findall(min_reg, cur_time)\n",
    "        num_mins = int(min_match[0]) if min_match else 0\n",
    "        total_mins += num_mins\n",
    "        # 小时\n",
    "        hr_match = re.findall(hr_reg, cur_time)\n",
    "        num_hrs = int(hr_match[0]) if hr_match else 0\n",
    "        total_mins += 60*num_hrs\n",
    "        # 天\n",
    "        day_match = re.findall(day_reg, cur_time)\n",
    "        num_days = int(day_match[0]) if day_match else 0\n",
    "        total_mins += 60*24*num_days\n",
    "        # 周\n",
    "        week_match = re.findall(week_reg, cur_time)\n",
    "        num_weeks = int(week_match[0]) if week_match else 0\n",
    "        total_mins += 60*24*7*num_weeks\n",
    "        return total_mins\n",
    "\n",
    "    if data_name == \"textlab_10\" or data_name == \"textlab_30\":\n",
    "        hit_df[\"time_allotted\"] = hit_df[\"time_allotted\"].apply(convertToMins)\n",
    "\n",
    "    return hit_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "295e1c04-1bf4-4a5e-a735-a60aca4117fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid durations marked\n",
      "# null log_reward: 11\n",
      "# null log_duration: 0\n",
      "Total number of obs: 410284\n",
      "New # observations after dropping null rewards/durations: 304662\n",
      "Number of HIT batches once invalid durations are dropped: 303858\n",
      "And once invalid rewards are dropped: 303858\n",
      "Dropping obs with reward < 0 or reward > 500.0\n",
      "Dropping obs with duration_new < 0 or duration_new > 90000.0\n",
      "Number of obs remaining: 285327\n",
      "Number of obs after dropping Feb 1 onwards: 259502\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_hits</th>\n",
       "      <th>first_hits</th>\n",
       "      <th>last_hits</th>\n",
       "      <th>num_obs</th>\n",
       "      <th>avg_hitrate</th>\n",
       "      <th>avg_hits_completed</th>\n",
       "      <th>med_hits_completed</th>\n",
       "      <th>min_hits_completed</th>\n",
       "      <th>max_hits_completed</th>\n",
       "      <th>hits_completed_sd</th>\n",
       "      <th>...</th>\n",
       "      <th>qualifications</th>\n",
       "      <th>first_seen</th>\n",
       "      <th>last_seen</th>\n",
       "      <th>expiration_date</th>\n",
       "      <th>duration_old</th>\n",
       "      <th>log_duration_old</th>\n",
       "      <th>log_reward</th>\n",
       "      <th>log_duration</th>\n",
       "      <th>valid_duration</th>\n",
       "      <th>kw_parsed</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>group_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>301G7MYOAJ2BOPC8GAIX74AGQGQ350</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.043450</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>['Total approved HITs is not less than 100', '...</td>\n",
       "      <td>2016-01-07 16:25:08</td>\n",
       "      <td>2016-01-08 15:21:00</td>\n",
       "      <td>2016-01-27T00:00:00.000Z</td>\n",
       "      <td>1375.0</td>\n",
       "      <td>7.226209</td>\n",
       "      <td>4.007333</td>\n",
       "      <td>7.230479</td>\n",
       "      <td>True</td>\n",
       "      <td>politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301G7MYOAJ2FYU5YANHEGT95DZ835P</th>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-05-23 21:50:08</td>\n",
       "      <td>2015-05-23 22:00:02</td>\n",
       "      <td>2015-05-27T00:00:00.000Z</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.197225</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.700242</td>\n",
       "      <td>True</td>\n",
       "      <td>categorize</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301G7MYOAJ2GKVIZE6OLR130JML53R</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.007929</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2014-06-16 21:24:45</td>\n",
       "      <td>2014-06-22 03:26:40</td>\n",
       "      <td>2014-08-25T00:00:00.000Z</td>\n",
       "      <td>7561.0</td>\n",
       "      <td>8.930759</td>\n",
       "      <td>3.912023</td>\n",
       "      <td>8.931548</td>\n",
       "      <td>True</td>\n",
       "      <td>survey personality stress rating</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301G7MYOAJ2YU4YTD9HY8W55XQD356</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.092967</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2014-10-01 12:07:38</td>\n",
       "      <td>2014-10-22 03:41:33</td>\n",
       "      <td>2014-11-04T00:00:00.000Z</td>\n",
       "      <td>29733.0</td>\n",
       "      <td>10.300013</td>\n",
       "      <td>3.912023</td>\n",
       "      <td>10.300216</td>\n",
       "      <td>True</td>\n",
       "      <td>survey brief short situation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301G7MYOAJ2YU4YTD9HY8W57OW9359</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>15.906404</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>['Location is US']</td>\n",
       "      <td>2015-10-13 17:02:18</td>\n",
       "      <td>2015-10-25 21:01:08</td>\n",
       "      <td>2015-10-25T00:00:00.000Z</td>\n",
       "      <td>17518.0</td>\n",
       "      <td>9.770984</td>\n",
       "      <td>5.298317</td>\n",
       "      <td>9.771196</td>\n",
       "      <td>True</td>\n",
       "      <td>decisions online reward bonus fun interesting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3ZY19HV01BIMKUJC8R23XWPE2U4GSE</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.039658</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>['HIT approval rate (%) is not less than 90']</td>\n",
       "      <td>2015-10-25 01:22:08</td>\n",
       "      <td>2015-10-26 02:30:03</td>\n",
       "      <td>2015-10-26T00:00:00.000Z</td>\n",
       "      <td>1507.0</td>\n",
       "      <td>7.317876</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>7.321806</td>\n",
       "      <td>True</td>\n",
       "      <td>feedback image interface UI design easy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3ZY19HV01BIUAL70JGMVTT0E150GSD</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>9.107489</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>['Total approved HITs is not less than 50', 'H...</td>\n",
       "      <td>2015-10-19 17:14:05</td>\n",
       "      <td>2015-10-19 17:44:52</td>\n",
       "      <td>2015-10-21T00:00:00.000Z</td>\n",
       "      <td>30.0</td>\n",
       "      <td>3.401197</td>\n",
       "      <td>3.688879</td>\n",
       "      <td>3.577016</td>\n",
       "      <td>True</td>\n",
       "      <td>survey demographics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3ZY19HV01BMN1HMYRKAG7N9SYLVGSY</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.151299</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>['Masters has been granted none Request Qualif...</td>\n",
       "      <td>2016-01-05 12:40:03</td>\n",
       "      <td>2016-01-05 19:11:34</td>\n",
       "      <td>2016-01-08T00:00:00.000Z</td>\n",
       "      <td>391.0</td>\n",
       "      <td>5.968708</td>\n",
       "      <td>2.708050</td>\n",
       "      <td>5.982844</td>\n",
       "      <td>True</td>\n",
       "      <td>psychology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4YFZK2ZCCXSZ64ZJNTR0</th>\n",
       "      <td>271</td>\n",
       "      <td>176</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>533.747917</td>\n",
       "      <td>45.166667</td>\n",
       "      <td>41.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>23.016661</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2014-09-08 17:45:33</td>\n",
       "      <td>2014-09-08 18:15:21</td>\n",
       "      <td>2014-09-10T00:00:00.000Z</td>\n",
       "      <td>29.0</td>\n",
       "      <td>3.367296</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>3.552964</td>\n",
       "      <td>True</td>\n",
       "      <td>image tag picture tagging photo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>J1ZZNQGNTW1YZVD8FWTZ</th>\n",
       "      <td>5474</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>1934</td>\n",
       "      <td>37.801095</td>\n",
       "      <td>4.099866</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>782.0</td>\n",
       "      <td>20.336540</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2014-09-15 15:13:09</td>\n",
       "      <td>2014-09-29 15:19:57</td>\n",
       "      <td>2014-09-29T00:00:00.000Z</td>\n",
       "      <td>20166.0</td>\n",
       "      <td>9.911753</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>9.912047</td>\n",
       "      <td>True</td>\n",
       "      <td>data collection contact info phone email shopp...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>259502 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                max_hits  first_hits  last_hits  num_obs  \\\n",
       "group_id                                                                   \n",
       "301G7MYOAJ2BOPC8GAIX74AGQGQ350         1           1          0        2   \n",
       "301G7MYOAJ2FYU5YANHEGT95DZ835P        11           9          0        3   \n",
       "301G7MYOAJ2GKVIZE6OLR130JML53R         1           1          0        2   \n",
       "301G7MYOAJ2YU4YTD9HY8W55XQD356         1           1          0        4   \n",
       "301G7MYOAJ2YU4YTD9HY8W57OW9359         1           1          0       60   \n",
       "...                                  ...         ...        ...      ...   \n",
       "3ZY19HV01BIMKUJC8R23XWPE2U4GSE         1           1          0        2   \n",
       "3ZY19HV01BIUAL70JGMVTT0E150GSD         1           1          0        6   \n",
       "3ZY19HV01BMN1HMYRKAG7N9SYLVGSY         1           1          0        2   \n",
       "4YFZK2ZCCXSZ64ZJNTR0                 271         176          0        8   \n",
       "J1ZZNQGNTW1YZVD8FWTZ                5474          64          0     1934   \n",
       "\n",
       "                                avg_hitrate  avg_hits_completed  \\\n",
       "group_id                                                          \n",
       "301G7MYOAJ2BOPC8GAIX74AGQGQ350     0.043450            1.000000   \n",
       "301G7MYOAJ2FYU5YANHEGT95DZ835P    66.000000           11.000000   \n",
       "301G7MYOAJ2GKVIZE6OLR130JML53R     0.007929            1.000000   \n",
       "301G7MYOAJ2YU4YTD9HY8W55XQD356     0.092967            1.000000   \n",
       "301G7MYOAJ2YU4YTD9HY8W57OW9359    15.906404            1.000000   \n",
       "...                                     ...                 ...   \n",
       "3ZY19HV01BIMKUJC8R23XWPE2U4GSE     0.039658            1.000000   \n",
       "3ZY19HV01BIUAL70JGMVTT0E150GSD     9.107489            1.000000   \n",
       "3ZY19HV01BMN1HMYRKAG7N9SYLVGSY     0.151299            1.000000   \n",
       "4YFZK2ZCCXSZ64ZJNTR0             533.747917           45.166667   \n",
       "J1ZZNQGNTW1YZVD8FWTZ              37.801095            4.099866   \n",
       "\n",
       "                                med_hits_completed  min_hits_completed  \\\n",
       "group_id                                                                 \n",
       "301G7MYOAJ2BOPC8GAIX74AGQGQ350                 1.0                 1.0   \n",
       "301G7MYOAJ2FYU5YANHEGT95DZ835P                11.0                11.0   \n",
       "301G7MYOAJ2GKVIZE6OLR130JML53R                 1.0                 1.0   \n",
       "301G7MYOAJ2YU4YTD9HY8W55XQD356                 1.0                 1.0   \n",
       "301G7MYOAJ2YU4YTD9HY8W57OW9359                 1.0                 1.0   \n",
       "...                                            ...                 ...   \n",
       "3ZY19HV01BIMKUJC8R23XWPE2U4GSE                 1.0                 1.0   \n",
       "3ZY19HV01BIUAL70JGMVTT0E150GSD                 1.0                 1.0   \n",
       "3ZY19HV01BMN1HMYRKAG7N9SYLVGSY                 1.0                 1.0   \n",
       "4YFZK2ZCCXSZ64ZJNTR0                          41.0                18.0   \n",
       "J1ZZNQGNTW1YZVD8FWTZ                           3.0                 1.0   \n",
       "\n",
       "                                max_hits_completed  hits_completed_sd  ...  \\\n",
       "group_id                                                               ...   \n",
       "301G7MYOAJ2BOPC8GAIX74AGQGQ350                 1.0                NaN  ...   \n",
       "301G7MYOAJ2FYU5YANHEGT95DZ835P                11.0                NaN  ...   \n",
       "301G7MYOAJ2GKVIZE6OLR130JML53R                 1.0                NaN  ...   \n",
       "301G7MYOAJ2YU4YTD9HY8W55XQD356                 1.0           0.000000  ...   \n",
       "301G7MYOAJ2YU4YTD9HY8W57OW9359                 1.0           0.000000  ...   \n",
       "...                                            ...                ...  ...   \n",
       "3ZY19HV01BIMKUJC8R23XWPE2U4GSE                 1.0                NaN  ...   \n",
       "3ZY19HV01BIUAL70JGMVTT0E150GSD                 1.0           0.000000  ...   \n",
       "3ZY19HV01BMN1HMYRKAG7N9SYLVGSY                 1.0                NaN  ...   \n",
       "4YFZK2ZCCXSZ64ZJNTR0                          88.0          23.016661  ...   \n",
       "J1ZZNQGNTW1YZVD8FWTZ                         782.0          20.336540  ...   \n",
       "\n",
       "                                                                   qualifications  \\\n",
       "group_id                                                                            \n",
       "301G7MYOAJ2BOPC8GAIX74AGQGQ350  ['Total approved HITs is not less than 100', '...   \n",
       "301G7MYOAJ2FYU5YANHEGT95DZ835P                                                NaN   \n",
       "301G7MYOAJ2GKVIZE6OLR130JML53R                                                NaN   \n",
       "301G7MYOAJ2YU4YTD9HY8W55XQD356                                                NaN   \n",
       "301G7MYOAJ2YU4YTD9HY8W57OW9359                                 ['Location is US']   \n",
       "...                                                                           ...   \n",
       "3ZY19HV01BIMKUJC8R23XWPE2U4GSE      ['HIT approval rate (%) is not less than 90']   \n",
       "3ZY19HV01BIUAL70JGMVTT0E150GSD  ['Total approved HITs is not less than 50', 'H...   \n",
       "3ZY19HV01BMN1HMYRKAG7N9SYLVGSY  ['Masters has been granted none Request Qualif...   \n",
       "4YFZK2ZCCXSZ64ZJNTR0                                                          NaN   \n",
       "J1ZZNQGNTW1YZVD8FWTZ                                                          NaN   \n",
       "\n",
       "                                         first_seen            last_seen  \\\n",
       "group_id                                                                   \n",
       "301G7MYOAJ2BOPC8GAIX74AGQGQ350  2016-01-07 16:25:08  2016-01-08 15:21:00   \n",
       "301G7MYOAJ2FYU5YANHEGT95DZ835P  2015-05-23 21:50:08  2015-05-23 22:00:02   \n",
       "301G7MYOAJ2GKVIZE6OLR130JML53R  2014-06-16 21:24:45  2014-06-22 03:26:40   \n",
       "301G7MYOAJ2YU4YTD9HY8W55XQD356  2014-10-01 12:07:38  2014-10-22 03:41:33   \n",
       "301G7MYOAJ2YU4YTD9HY8W57OW9359  2015-10-13 17:02:18  2015-10-25 21:01:08   \n",
       "...                                             ...                  ...   \n",
       "3ZY19HV01BIMKUJC8R23XWPE2U4GSE  2015-10-25 01:22:08  2015-10-26 02:30:03   \n",
       "3ZY19HV01BIUAL70JGMVTT0E150GSD  2015-10-19 17:14:05  2015-10-19 17:44:52   \n",
       "3ZY19HV01BMN1HMYRKAG7N9SYLVGSY  2016-01-05 12:40:03  2016-01-05 19:11:34   \n",
       "4YFZK2ZCCXSZ64ZJNTR0            2014-09-08 17:45:33  2014-09-08 18:15:21   \n",
       "J1ZZNQGNTW1YZVD8FWTZ            2014-09-15 15:13:09  2014-09-29 15:19:57   \n",
       "\n",
       "                                         expiration_date  duration_old  \\\n",
       "group_id                                                                 \n",
       "301G7MYOAJ2BOPC8GAIX74AGQGQ350  2016-01-27T00:00:00.000Z        1375.0   \n",
       "301G7MYOAJ2FYU5YANHEGT95DZ835P  2015-05-27T00:00:00.000Z           9.0   \n",
       "301G7MYOAJ2GKVIZE6OLR130JML53R  2014-08-25T00:00:00.000Z        7561.0   \n",
       "301G7MYOAJ2YU4YTD9HY8W55XQD356  2014-11-04T00:00:00.000Z       29733.0   \n",
       "301G7MYOAJ2YU4YTD9HY8W57OW9359  2015-10-25T00:00:00.000Z       17518.0   \n",
       "...                                                  ...           ...   \n",
       "3ZY19HV01BIMKUJC8R23XWPE2U4GSE  2015-10-26T00:00:00.000Z        1507.0   \n",
       "3ZY19HV01BIUAL70JGMVTT0E150GSD  2015-10-21T00:00:00.000Z          30.0   \n",
       "3ZY19HV01BMN1HMYRKAG7N9SYLVGSY  2016-01-08T00:00:00.000Z         391.0   \n",
       "4YFZK2ZCCXSZ64ZJNTR0            2014-09-10T00:00:00.000Z          29.0   \n",
       "J1ZZNQGNTW1YZVD8FWTZ            2014-09-29T00:00:00.000Z       20166.0   \n",
       "\n",
       "                                log_duration_old  log_reward  log_duration  \\\n",
       "group_id                                                                     \n",
       "301G7MYOAJ2BOPC8GAIX74AGQGQ350          7.226209    4.007333      7.230479   \n",
       "301G7MYOAJ2FYU5YANHEGT95DZ835P          2.197225    0.000000      2.700242   \n",
       "301G7MYOAJ2GKVIZE6OLR130JML53R          8.930759    3.912023      8.931548   \n",
       "301G7MYOAJ2YU4YTD9HY8W55XQD356         10.300013    3.912023     10.300216   \n",
       "301G7MYOAJ2YU4YTD9HY8W57OW9359          9.770984    5.298317      9.771196   \n",
       "...                                          ...         ...           ...   \n",
       "3ZY19HV01BIMKUJC8R23XWPE2U4GSE          7.317876    1.609438      7.321806   \n",
       "3ZY19HV01BIUAL70JGMVTT0E150GSD          3.401197    3.688879      3.577016   \n",
       "3ZY19HV01BMN1HMYRKAG7N9SYLVGSY          5.968708    2.708050      5.982844   \n",
       "4YFZK2ZCCXSZ64ZJNTR0                    3.367296    1.609438      3.552964   \n",
       "J1ZZNQGNTW1YZVD8FWTZ                    9.911753    1.609438      9.912047   \n",
       "\n",
       "                                valid_duration  \\\n",
       "group_id                                         \n",
       "301G7MYOAJ2BOPC8GAIX74AGQGQ350            True   \n",
       "301G7MYOAJ2FYU5YANHEGT95DZ835P            True   \n",
       "301G7MYOAJ2GKVIZE6OLR130JML53R            True   \n",
       "301G7MYOAJ2YU4YTD9HY8W55XQD356            True   \n",
       "301G7MYOAJ2YU4YTD9HY8W57OW9359            True   \n",
       "...                                        ...   \n",
       "3ZY19HV01BIMKUJC8R23XWPE2U4GSE            True   \n",
       "3ZY19HV01BIUAL70JGMVTT0E150GSD            True   \n",
       "3ZY19HV01BMN1HMYRKAG7N9SYLVGSY            True   \n",
       "4YFZK2ZCCXSZ64ZJNTR0                      True   \n",
       "J1ZZNQGNTW1YZVD8FWTZ                      True   \n",
       "\n",
       "                                                                        kw_parsed  \n",
       "group_id                                                                           \n",
       "301G7MYOAJ2BOPC8GAIX74AGQGQ350                                           politics  \n",
       "301G7MYOAJ2FYU5YANHEGT95DZ835P                                         categorize  \n",
       "301G7MYOAJ2GKVIZE6OLR130JML53R                   survey personality stress rating  \n",
       "301G7MYOAJ2YU4YTD9HY8W55XQD356                       survey brief short situation  \n",
       "301G7MYOAJ2YU4YTD9HY8W57OW9359      decisions online reward bonus fun interesting  \n",
       "...                                                                           ...  \n",
       "3ZY19HV01BIMKUJC8R23XWPE2U4GSE            feedback image interface UI design easy  \n",
       "3ZY19HV01BIUAL70JGMVTT0E150GSD                                survey demographics  \n",
       "3ZY19HV01BMN1HMYRKAG7N9SYLVGSY                                         psychology  \n",
       "4YFZK2ZCCXSZ64ZJNTR0                              image tag picture tagging photo  \n",
       "J1ZZNQGNTW1YZVD8FWTZ            data collection contact info phone email shopp...  \n",
       "\n",
       "[259502 rows x 37 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ipeirotis_cleaned = cleanGroupData(merged_df_ipeirotis, 'ipeirotis')\n",
    "ipeirotis_cleaned.to_pickle('./data/ipeirotis_cleaned.pkl')\n",
    "ipeirotis_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "849adde4-8d91-4a9a-b2fe-589bfcd99535",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid durations marked\n",
      "# null log_reward: 0\n",
      "# null log_duration: 0\n",
      "Total number of obs: 363167\n",
      "New # observations after dropping null rewards/durations: 355469\n",
      "Number of HIT batches once invalid durations are dropped: 355469\n",
      "And once invalid rewards are dropped: 355469\n",
      "Dropping obs with reward < 0 or reward > 500.0\n",
      "Dropping obs with duration_new < 0 or duration_new > 90000.0\n",
      "Number of obs remaining: 292746\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_hits</th>\n",
       "      <th>first_hits</th>\n",
       "      <th>last_hits</th>\n",
       "      <th>num_obs</th>\n",
       "      <th>avg_hitrate</th>\n",
       "      <th>avg_hits_completed</th>\n",
       "      <th>med_hits_completed</th>\n",
       "      <th>min_hits_completed</th>\n",
       "      <th>max_hits_completed</th>\n",
       "      <th>hits_completed_sd</th>\n",
       "      <th>...</th>\n",
       "      <th>title</th>\n",
       "      <th>requester</th>\n",
       "      <th>expiration_date</th>\n",
       "      <th>hit_info_str</th>\n",
       "      <th>reward</th>\n",
       "      <th>time_allotted</th>\n",
       "      <th>time_left</th>\n",
       "      <th>log_reward</th>\n",
       "      <th>log_duration</th>\n",
       "      <th>valid_duration</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>group_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>00004bd33574f0bbb5415bc39a5e50cd</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Change Sciences Missed Submission</td>\n",
       "      <td>Change Sciences Group</td>\n",
       "      <td>Jul 7, 2016</td>\n",
       "      <td>A1DIWKR9NEY82N|$1.50|Change Sciences Missed Su...</td>\n",
       "      <td>150.0</td>\n",
       "      <td>60</td>\n",
       "      <td>23 hours 37 minutes</td>\n",
       "      <td>5.010635</td>\n",
       "      <td>7.544332</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000057992d4dccafb2c5481d655ae2e5</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Urgent - Higher Pay - Review media transcripti...</td>\n",
       "      <td>Speechpad</td>\n",
       "      <td>Oct 12, 2016</td>\n",
       "      <td>A1AQ7EJ5P7ME65|$1.75|Urgent - Higher Pay - Rev...</td>\n",
       "      <td>175.0</td>\n",
       "      <td>60</td>\n",
       "      <td>6 days 23 hours</td>\n",
       "      <td>5.164786</td>\n",
       "      <td>5.480639</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0000990eeaa355136a2ef1bdc9b1484a</th>\n",
       "      <td>65</td>\n",
       "      <td>53</td>\n",
       "      <td>65</td>\n",
       "      <td>12</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.57735</td>\n",
       "      <td>...</td>\n",
       "      <td>Labeling Tweets 24</td>\n",
       "      <td>Siddharth Suri</td>\n",
       "      <td>Aug 22, 2016</td>\n",
       "      <td>A3RXXNTGSUSTQ9|$0.10|Labeling Tweets 24</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5</td>\n",
       "      <td>5 hours 34 minutes</td>\n",
       "      <td>2.302585</td>\n",
       "      <td>5.799093</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0000f33788d8874bec0c72d6bdb73924</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Urgent - Higher Pay - Review media transcripti...</td>\n",
       "      <td>Speechpad</td>\n",
       "      <td>Aug 26, 2016</td>\n",
       "      <td>A1AQ7EJ5P7ME65|$0.41|Urgent - Higher Pay - Rev...</td>\n",
       "      <td>41.0</td>\n",
       "      <td>60</td>\n",
       "      <td>6 days 23 hours</td>\n",
       "      <td>3.713572</td>\n",
       "      <td>5.192957</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00011eb8afef8299e0e2ad1886808edc</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>26Retrieve Property Numbers 2016 ML 12.007</td>\n",
       "      <td>Obsidian</td>\n",
       "      <td>Jan 19, 2017</td>\n",
       "      <td>A3MX44TDYCA6JW|$0.07|26Retrieve Property Numbe...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7</td>\n",
       "      <td>2 hours 30 minutes</td>\n",
       "      <td>1.945910</td>\n",
       "      <td>4.094345</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fffdae03eb029f2d8e60eabaa971adc2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Transcribe on-line orders  A2540323  (Audio le...</td>\n",
       "      <td>Speechpad</td>\n",
       "      <td>Feb 3, 2017</td>\n",
       "      <td>A1AQ7EJ5P7ME65|$0.02|Transcribe on-line orders...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>60</td>\n",
       "      <td>6 days 23 hours</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>5.480639</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ffff1d8b216a25a0619474b6a465dde5</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Urgent - Higher Pay - Review media transcripti...</td>\n",
       "      <td>Speechpad</td>\n",
       "      <td>Mar 16, 2017</td>\n",
       "      <td>A1AQ7EJ5P7ME65|$3.69|Urgent - Higher Pay - Rev...</td>\n",
       "      <td>369.0</td>\n",
       "      <td>60</td>\n",
       "      <td>6 days 23 hours</td>\n",
       "      <td>5.910797</td>\n",
       "      <td>4.787492</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ffff9f464f1e1d0a8c9e8588ce435e5e</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Converse with Mobile Weather App</td>\n",
       "      <td>MTurkIRL</td>\n",
       "      <td>Mar 16, 2017</td>\n",
       "      <td>A2883M4WUQRXJ1|$0.15|Converse with Mobile Weat...</td>\n",
       "      <td>15.0</td>\n",
       "      <td>10</td>\n",
       "      <td>6 days 23 hours</td>\n",
       "      <td>2.708050</td>\n",
       "      <td>8.560253</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ffffc1d9b78826955e9687d8c6ca714a</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>98</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.57735</td>\n",
       "      <td>...</td>\n",
       "      <td>Identify the brands featured in banner ads - 2...</td>\n",
       "      <td>Ad Tagger</td>\n",
       "      <td>Dec 13, 2016</td>\n",
       "      <td>A361N9XL4OF4FG|$0.60|Identify the brands featu...</td>\n",
       "      <td>60.0</td>\n",
       "      <td>60</td>\n",
       "      <td>6 days 23 hours</td>\n",
       "      <td>4.094345</td>\n",
       "      <td>7.975908</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ffffc57feb6f5ee5ef5d95a54548bcc5</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>[audio] Audio sample quality assurance #21821 ...</td>\n",
       "      <td>Bunny Inc.</td>\n",
       "      <td>Feb 24, 2017</td>\n",
       "      <td>A18U2D0C5M86ZA|$0.02|[audio] Audio sample qual...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8</td>\n",
       "      <td>23 hours 29 minutes</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>4.787492</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>292746 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  max_hits  first_hits  last_hits  num_obs  \\\n",
       "group_id                                                                     \n",
       "00004bd33574f0bbb5415bc39a5e50cd         1           0          0       63   \n",
       "000057992d4dccafb2c5481d655ae2e5         1           0          0        9   \n",
       "0000990eeaa355136a2ef1bdc9b1484a        65          53         65       12   \n",
       "0000f33788d8874bec0c72d6bdb73924         1           0          0        7   \n",
       "00011eb8afef8299e0e2ad1886808edc         1           0          0        3   \n",
       "...                                    ...         ...        ...      ...   \n",
       "fffdae03eb029f2d8e60eabaa971adc2         1           0          0        9   \n",
       "ffff1d8b216a25a0619474b6a465dde5         1           0          0        4   \n",
       "ffff9f464f1e1d0a8c9e8588ce435e5e         1           0          0      172   \n",
       "ffffc1d9b78826955e9687d8c6ca714a         6           6          1       98   \n",
       "ffffc57feb6f5ee5ef5d95a54548bcc5         1           0          0        5   \n",
       "\n",
       "                                  avg_hitrate  avg_hits_completed  \\\n",
       "group_id                                                            \n",
       "00004bd33574f0bbb5415bc39a5e50cd     2.000000            1.000000   \n",
       "000057992d4dccafb2c5481d655ae2e5     2.000000            1.000000   \n",
       "0000990eeaa355136a2ef1bdc9b1484a     2.666667            1.333333   \n",
       "0000f33788d8874bec0c72d6bdb73924     2.000000            1.000000   \n",
       "00011eb8afef8299e0e2ad1886808edc     2.000000            1.000000   \n",
       "...                                       ...                 ...   \n",
       "fffdae03eb029f2d8e60eabaa971adc2     2.000000            1.000000   \n",
       "ffff1d8b216a25a0619474b6a465dde5     2.000000            1.000000   \n",
       "ffff9f464f1e1d0a8c9e8588ce435e5e     2.000000            1.000000   \n",
       "ffffc1d9b78826955e9687d8c6ca714a     3.333333            1.666667   \n",
       "ffffc57feb6f5ee5ef5d95a54548bcc5     2.000000            1.000000   \n",
       "\n",
       "                                  med_hits_completed  min_hits_completed  \\\n",
       "group_id                                                                   \n",
       "00004bd33574f0bbb5415bc39a5e50cd                 1.0                 1.0   \n",
       "000057992d4dccafb2c5481d655ae2e5                 1.0                 1.0   \n",
       "0000990eeaa355136a2ef1bdc9b1484a                 1.0                 1.0   \n",
       "0000f33788d8874bec0c72d6bdb73924                 1.0                 1.0   \n",
       "00011eb8afef8299e0e2ad1886808edc                 1.0                 1.0   \n",
       "...                                              ...                 ...   \n",
       "fffdae03eb029f2d8e60eabaa971adc2                 1.0                 1.0   \n",
       "ffff1d8b216a25a0619474b6a465dde5                 1.0                 1.0   \n",
       "ffff9f464f1e1d0a8c9e8588ce435e5e                 1.0                 1.0   \n",
       "ffffc1d9b78826955e9687d8c6ca714a                 2.0                 1.0   \n",
       "ffffc57feb6f5ee5ef5d95a54548bcc5                 1.0                 1.0   \n",
       "\n",
       "                                  max_hits_completed  hits_completed_sd  ...  \\\n",
       "group_id                                                                 ...   \n",
       "00004bd33574f0bbb5415bc39a5e50cd                 1.0                NaN  ...   \n",
       "000057992d4dccafb2c5481d655ae2e5                 1.0                NaN  ...   \n",
       "0000990eeaa355136a2ef1bdc9b1484a                 2.0            0.57735  ...   \n",
       "0000f33788d8874bec0c72d6bdb73924                 1.0                NaN  ...   \n",
       "00011eb8afef8299e0e2ad1886808edc                 1.0                NaN  ...   \n",
       "...                                              ...                ...  ...   \n",
       "fffdae03eb029f2d8e60eabaa971adc2                 1.0                NaN  ...   \n",
       "ffff1d8b216a25a0619474b6a465dde5                 1.0                NaN  ...   \n",
       "ffff9f464f1e1d0a8c9e8588ce435e5e                 1.0                NaN  ...   \n",
       "ffffc1d9b78826955e9687d8c6ca714a                 2.0            0.57735  ...   \n",
       "ffffc57feb6f5ee5ef5d95a54548bcc5                 1.0                NaN  ...   \n",
       "\n",
       "                                                                              title  \\\n",
       "group_id                                                                              \n",
       "00004bd33574f0bbb5415bc39a5e50cd                  Change Sciences Missed Submission   \n",
       "000057992d4dccafb2c5481d655ae2e5  Urgent - Higher Pay - Review media transcripti...   \n",
       "0000990eeaa355136a2ef1bdc9b1484a                                 Labeling Tweets 24   \n",
       "0000f33788d8874bec0c72d6bdb73924  Urgent - Higher Pay - Review media transcripti...   \n",
       "00011eb8afef8299e0e2ad1886808edc         26Retrieve Property Numbers 2016 ML 12.007   \n",
       "...                                                                             ...   \n",
       "fffdae03eb029f2d8e60eabaa971adc2  Transcribe on-line orders  A2540323  (Audio le...   \n",
       "ffff1d8b216a25a0619474b6a465dde5  Urgent - Higher Pay - Review media transcripti...   \n",
       "ffff9f464f1e1d0a8c9e8588ce435e5e                   Converse with Mobile Weather App   \n",
       "ffffc1d9b78826955e9687d8c6ca714a  Identify the brands featured in banner ads - 2...   \n",
       "ffffc57feb6f5ee5ef5d95a54548bcc5  [audio] Audio sample quality assurance #21821 ...   \n",
       "\n",
       "                                              requester  expiration_date  \\\n",
       "group_id                                                                   \n",
       "00004bd33574f0bbb5415bc39a5e50cd  Change Sciences Group      Jul 7, 2016   \n",
       "000057992d4dccafb2c5481d655ae2e5              Speechpad     Oct 12, 2016   \n",
       "0000990eeaa355136a2ef1bdc9b1484a         Siddharth Suri     Aug 22, 2016   \n",
       "0000f33788d8874bec0c72d6bdb73924              Speechpad     Aug 26, 2016   \n",
       "00011eb8afef8299e0e2ad1886808edc               Obsidian     Jan 19, 2017   \n",
       "...                                                 ...              ...   \n",
       "fffdae03eb029f2d8e60eabaa971adc2              Speechpad      Feb 3, 2017   \n",
       "ffff1d8b216a25a0619474b6a465dde5              Speechpad     Mar 16, 2017   \n",
       "ffff9f464f1e1d0a8c9e8588ce435e5e               MTurkIRL     Mar 16, 2017   \n",
       "ffffc1d9b78826955e9687d8c6ca714a              Ad Tagger     Dec 13, 2016   \n",
       "ffffc57feb6f5ee5ef5d95a54548bcc5             Bunny Inc.     Feb 24, 2017   \n",
       "\n",
       "                                                                       hit_info_str  \\\n",
       "group_id                                                                              \n",
       "00004bd33574f0bbb5415bc39a5e50cd  A1DIWKR9NEY82N|$1.50|Change Sciences Missed Su...   \n",
       "000057992d4dccafb2c5481d655ae2e5  A1AQ7EJ5P7ME65|$1.75|Urgent - Higher Pay - Rev...   \n",
       "0000990eeaa355136a2ef1bdc9b1484a            A3RXXNTGSUSTQ9|$0.10|Labeling Tweets 24   \n",
       "0000f33788d8874bec0c72d6bdb73924  A1AQ7EJ5P7ME65|$0.41|Urgent - Higher Pay - Rev...   \n",
       "00011eb8afef8299e0e2ad1886808edc  A3MX44TDYCA6JW|$0.07|26Retrieve Property Numbe...   \n",
       "...                                                                             ...   \n",
       "fffdae03eb029f2d8e60eabaa971adc2  A1AQ7EJ5P7ME65|$0.02|Transcribe on-line orders...   \n",
       "ffff1d8b216a25a0619474b6a465dde5  A1AQ7EJ5P7ME65|$3.69|Urgent - Higher Pay - Rev...   \n",
       "ffff9f464f1e1d0a8c9e8588ce435e5e  A2883M4WUQRXJ1|$0.15|Converse with Mobile Weat...   \n",
       "ffffc1d9b78826955e9687d8c6ca714a  A361N9XL4OF4FG|$0.60|Identify the brands featu...   \n",
       "ffffc57feb6f5ee5ef5d95a54548bcc5  A18U2D0C5M86ZA|$0.02|[audio] Audio sample qual...   \n",
       "\n",
       "                                  reward  time_allotted            time_left  \\\n",
       "group_id                                                                       \n",
       "00004bd33574f0bbb5415bc39a5e50cd   150.0             60  23 hours 37 minutes   \n",
       "000057992d4dccafb2c5481d655ae2e5   175.0             60      6 days 23 hours   \n",
       "0000990eeaa355136a2ef1bdc9b1484a    10.0              5   5 hours 34 minutes   \n",
       "0000f33788d8874bec0c72d6bdb73924    41.0             60      6 days 23 hours   \n",
       "00011eb8afef8299e0e2ad1886808edc     7.0              7   2 hours 30 minutes   \n",
       "...                                  ...            ...                  ...   \n",
       "fffdae03eb029f2d8e60eabaa971adc2     2.0             60      6 days 23 hours   \n",
       "ffff1d8b216a25a0619474b6a465dde5   369.0             60      6 days 23 hours   \n",
       "ffff9f464f1e1d0a8c9e8588ce435e5e    15.0             10      6 days 23 hours   \n",
       "ffffc1d9b78826955e9687d8c6ca714a    60.0             60      6 days 23 hours   \n",
       "ffffc57feb6f5ee5ef5d95a54548bcc5     2.0              8  23 hours 29 minutes   \n",
       "\n",
       "                                  log_reward  log_duration valid_duration  \n",
       "group_id                                                                   \n",
       "00004bd33574f0bbb5415bc39a5e50cd    5.010635      7.544332              1  \n",
       "000057992d4dccafb2c5481d655ae2e5    5.164786      5.480639              1  \n",
       "0000990eeaa355136a2ef1bdc9b1484a    2.302585      5.799093              1  \n",
       "0000f33788d8874bec0c72d6bdb73924    3.713572      5.192957              1  \n",
       "00011eb8afef8299e0e2ad1886808edc    1.945910      4.094345              1  \n",
       "...                                      ...           ...            ...  \n",
       "fffdae03eb029f2d8e60eabaa971adc2    0.693147      5.480639              1  \n",
       "ffff1d8b216a25a0619474b6a465dde5    5.910797      4.787492              1  \n",
       "ffff9f464f1e1d0a8c9e8588ce435e5e    2.708050      8.560253              1  \n",
       "ffffc1d9b78826955e9687d8c6ca714a    4.094345      7.975908              1  \n",
       "ffffc57feb6f5ee5ef5d95a54548bcc5    0.693147      4.787492              1  \n",
       "\n",
       "[292746 rows x 30 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textlab_30_cleaned = cleanGroupData(merged_df_textlab30, 'textlab_30')\n",
    "textlab_30_cleaned.to_pickle('./data/textlab_30_cleaned.pkl')\n",
    "textlab_30_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5f84e983-6018-4433-9e80-a8814e0d8a1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid durations marked\n",
      "# null log_reward: 0\n",
      "# null log_duration: 0\n",
      "Total number of obs: 110313\n",
      "New # observations after dropping null rewards/durations: 107930\n",
      "Number of HIT batches once invalid durations are dropped: 107930\n",
      "And once invalid rewards are dropped: 107930\n",
      "Dropping obs with reward < 0 or reward > 500.0\n",
      "Dropping obs with duration_new < 0 or duration_new > 90000.0\n",
      "Number of obs remaining: 93775\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_hits</th>\n",
       "      <th>first_hits</th>\n",
       "      <th>last_hits</th>\n",
       "      <th>num_obs</th>\n",
       "      <th>avg_hitrate</th>\n",
       "      <th>avg_hits_completed</th>\n",
       "      <th>med_hits_completed</th>\n",
       "      <th>min_hits_completed</th>\n",
       "      <th>max_hits_completed</th>\n",
       "      <th>hits_completed_sd</th>\n",
       "      <th>...</th>\n",
       "      <th>time_allotted</th>\n",
       "      <th>title</th>\n",
       "      <th>keywords</th>\n",
       "      <th>requester_id</th>\n",
       "      <th>description</th>\n",
       "      <th>expiration_date</th>\n",
       "      <th>log_reward</th>\n",
       "      <th>log_duration</th>\n",
       "      <th>valid_duration</th>\n",
       "      <th>kw_parsed</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>group_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>301G7MYOAJ1RQHRCTOCVAOHMWTZ35U</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>30</td>\n",
       "      <td>Recycling Attitudes and Intentions Questionnaire</td>\n",
       "      <td>survey|recycling|opinions</td>\n",
       "      <td>A2R9VUC7LO7HJU</td>\n",
       "      <td>Complete a questionnaire related to waste recy...</td>\n",
       "      <td>Jun 24, 2017</td>\n",
       "      <td>2.708050</td>\n",
       "      <td>4.499810</td>\n",
       "      <td>1</td>\n",
       "      <td>survey recycling opinions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301G7MYOAJ397EAIS94FMNLGU7035W</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>Image Annotation Verification</td>\n",
       "      <td>image annotation|image tagging|directions|navi...</td>\n",
       "      <td>A1W518UWEFCTSE</td>\n",
       "      <td>Verify that the description of an image is acc...</td>\n",
       "      <td>Jun 7, 2017</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>6.016157</td>\n",
       "      <td>1</td>\n",
       "      <td>image annotation image tagging directions navi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301G7MYOAJ39FPP8WA9R6K95M9335Z</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>15</td>\n",
       "      <td>Consumer survey about sales promotions</td>\n",
       "      <td>Sales promotions|consumer survey|academic study</td>\n",
       "      <td>A39EQL8PB8SVTQ</td>\n",
       "      <td>Academic study interested in customer feelings...</td>\n",
       "      <td>Aug 25, 2017</td>\n",
       "      <td>4.248495</td>\n",
       "      <td>5.347108</td>\n",
       "      <td>1</td>\n",
       "      <td>Sales promotions consumer survey academic study</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301G7MYOAJ3OHAOZV8UWUP9UZHM53Y</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>50</td>\n",
       "      <td>Investigation of Attitudes Towards Groups(~ 25...</td>\n",
       "      <td>survey|demographics</td>\n",
       "      <td>A2FS313FG0JGW3</td>\n",
       "      <td>You will be asked to complete a variety of que...</td>\n",
       "      <td>Jul 4, 2017</td>\n",
       "      <td>4.317488</td>\n",
       "      <td>3.688879</td>\n",
       "      <td>1</td>\n",
       "      <td>survey demographics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301G7MYOAJ54ES5MA4KIU09DOJ653Q</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>60</td>\n",
       "      <td>Quick Interesting Survey: Social attitudes(~ 2...</td>\n",
       "      <td>quick survey|short survey|opinions|attitudes|b...</td>\n",
       "      <td>A79USK145OBJJ</td>\n",
       "      <td>This is a quick 2 minute survey on your attitudes</td>\n",
       "      <td>Jul 20, 2017</td>\n",
       "      <td>2.995732</td>\n",
       "      <td>2.995732</td>\n",
       "      <td>1</td>\n",
       "      <td>quick survey short survey opinions attitudes b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3ZY19HV01BONLIR1KK5SXUJQHSGGS1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>22</td>\n",
       "      <td>Copy Edit English Text</td>\n",
       "      <td>grammatical error correction|proofreading|revi...</td>\n",
       "      <td>A3AYV6BR7VCGW0</td>\n",
       "      <td>Proofreading English Text:  Correct spelling a...</td>\n",
       "      <td>Jul 9, 2017</td>\n",
       "      <td>3.784190</td>\n",
       "      <td>11.017809</td>\n",
       "      <td>1</td>\n",
       "      <td>grammatical error correction proofreading revi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3ZY19HV01BONLIR1KK5SXUJQHSIGS3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>26</td>\n",
       "      <td>Copy Edit English Text</td>\n",
       "      <td>grammatical error correction|proofreading|revi...</td>\n",
       "      <td>A3AYV6BR7VCGW0</td>\n",
       "      <td>Proofreading English Text:  Correct spelling a...</td>\n",
       "      <td>Jul 11, 2017</td>\n",
       "      <td>3.951244</td>\n",
       "      <td>9.596962</td>\n",
       "      <td>1</td>\n",
       "      <td>grammatical error correction proofreading revi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3ZY19HV01BONLIR1KK5SXUJQIWEGS8</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>39</td>\n",
       "      <td>Copy Edit English Text</td>\n",
       "      <td>grammatical error correction|proofreading|revi...</td>\n",
       "      <td>A3AYV6BR7VCGW0</td>\n",
       "      <td>Proofreading English Text:  Correct spelling a...</td>\n",
       "      <td>Aug 1, 2017</td>\n",
       "      <td>4.356709</td>\n",
       "      <td>9.885324</td>\n",
       "      <td>1</td>\n",
       "      <td>grammatical error correction proofreading revi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3ZY19HV01BPM76GKCNBV9R7GD76SG1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>248</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>60</td>\n",
       "      <td>What Are People Thinking? - 2 Minute Survey</td>\n",
       "      <td>survey|demographics|articles|reading|opinion</td>\n",
       "      <td>A3JG43JLET2NUM</td>\n",
       "      <td>What are people think. 2 minute survey on topi...</td>\n",
       "      <td>Jul 27, 2017</td>\n",
       "      <td>2.302585</td>\n",
       "      <td>8.687779</td>\n",
       "      <td>1</td>\n",
       "      <td>survey demographics articles reading opinion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3ZY19HV01BSBSMWQ8SJ63FS1C9KSG5</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3187</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>300</td>\n",
       "      <td>Meaningfulness in Life &amp; Work Stress Part 3(~ ...</td>\n",
       "      <td>Work Stress; Time Management; Values; Attitudes</td>\n",
       "      <td>A14BIFHITSA2R9</td>\n",
       "      <td>A survey of employed individuals assessing wor...</td>\n",
       "      <td>Oct 18, 2017</td>\n",
       "      <td>5.857933</td>\n",
       "      <td>10.375364</td>\n",
       "      <td>1</td>\n",
       "      <td>Work Stress; Time Management; Values; Attitudes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>93775 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                max_hits  first_hits  last_hits  num_obs  \\\n",
       "group_id                                                                   \n",
       "301G7MYOAJ1RQHRCTOCVAOHMWTZ35U         1           0          0       10   \n",
       "301G7MYOAJ397EAIS94FMNLGU7035W         1           0          0        4   \n",
       "301G7MYOAJ39FPP8WA9R6K95M9335Z         1           0          0       22   \n",
       "301G7MYOAJ3OHAOZV8UWUP9UZHM53Y         1           0          0        5   \n",
       "301G7MYOAJ54ES5MA4KIU09DOJ653Q         1           0          0        3   \n",
       "...                                  ...         ...        ...      ...   \n",
       "3ZY19HV01BONLIR1KK5SXUJQHSGGS1         1           0          0       20   \n",
       "3ZY19HV01BONLIR1KK5SXUJQHSIGS3         1           0          0       17   \n",
       "3ZY19HV01BONLIR1KK5SXUJQIWEGS8         1           0          0       31   \n",
       "3ZY19HV01BPM76GKCNBV9R7GD76SG1         1           0          0      248   \n",
       "3ZY19HV01BSBSMWQ8SJ63FS1C9KSG5         1           0          0     3187   \n",
       "\n",
       "                                avg_hitrate  avg_hits_completed  \\\n",
       "group_id                                                          \n",
       "301G7MYOAJ1RQHRCTOCVAOHMWTZ35U          6.0                 1.0   \n",
       "301G7MYOAJ397EAIS94FMNLGU7035W          6.0                 1.0   \n",
       "301G7MYOAJ39FPP8WA9R6K95M9335Z          6.0                 1.0   \n",
       "301G7MYOAJ3OHAOZV8UWUP9UZHM53Y          6.0                 1.0   \n",
       "301G7MYOAJ54ES5MA4KIU09DOJ653Q          6.0                 1.0   \n",
       "...                                     ...                 ...   \n",
       "3ZY19HV01BONLIR1KK5SXUJQHSGGS1          6.0                 1.0   \n",
       "3ZY19HV01BONLIR1KK5SXUJQHSIGS3          6.0                 1.0   \n",
       "3ZY19HV01BONLIR1KK5SXUJQIWEGS8          6.0                 1.0   \n",
       "3ZY19HV01BPM76GKCNBV9R7GD76SG1          6.0                 1.0   \n",
       "3ZY19HV01BSBSMWQ8SJ63FS1C9KSG5          6.0                 1.0   \n",
       "\n",
       "                                med_hits_completed  min_hits_completed  \\\n",
       "group_id                                                                 \n",
       "301G7MYOAJ1RQHRCTOCVAOHMWTZ35U                 1.0                 1.0   \n",
       "301G7MYOAJ397EAIS94FMNLGU7035W                 1.0                 1.0   \n",
       "301G7MYOAJ39FPP8WA9R6K95M9335Z                 1.0                 1.0   \n",
       "301G7MYOAJ3OHAOZV8UWUP9UZHM53Y                 1.0                 1.0   \n",
       "301G7MYOAJ54ES5MA4KIU09DOJ653Q                 1.0                 1.0   \n",
       "...                                            ...                 ...   \n",
       "3ZY19HV01BONLIR1KK5SXUJQHSGGS1                 1.0                 1.0   \n",
       "3ZY19HV01BONLIR1KK5SXUJQHSIGS3                 1.0                 1.0   \n",
       "3ZY19HV01BONLIR1KK5SXUJQIWEGS8                 1.0                 1.0   \n",
       "3ZY19HV01BPM76GKCNBV9R7GD76SG1                 1.0                 1.0   \n",
       "3ZY19HV01BSBSMWQ8SJ63FS1C9KSG5                 1.0                 1.0   \n",
       "\n",
       "                                max_hits_completed  hits_completed_sd  ...  \\\n",
       "group_id                                                               ...   \n",
       "301G7MYOAJ1RQHRCTOCVAOHMWTZ35U                 1.0                NaN  ...   \n",
       "301G7MYOAJ397EAIS94FMNLGU7035W                 1.0                NaN  ...   \n",
       "301G7MYOAJ39FPP8WA9R6K95M9335Z                 1.0                NaN  ...   \n",
       "301G7MYOAJ3OHAOZV8UWUP9UZHM53Y                 1.0                NaN  ...   \n",
       "301G7MYOAJ54ES5MA4KIU09DOJ653Q                 1.0                NaN  ...   \n",
       "...                                            ...                ...  ...   \n",
       "3ZY19HV01BONLIR1KK5SXUJQHSGGS1                 1.0                NaN  ...   \n",
       "3ZY19HV01BONLIR1KK5SXUJQHSIGS3                 1.0                NaN  ...   \n",
       "3ZY19HV01BONLIR1KK5SXUJQIWEGS8                 1.0                NaN  ...   \n",
       "3ZY19HV01BPM76GKCNBV9R7GD76SG1                 1.0                NaN  ...   \n",
       "3ZY19HV01BSBSMWQ8SJ63FS1C9KSG5                 1.0                NaN  ...   \n",
       "\n",
       "                               time_allotted  \\\n",
       "group_id                                       \n",
       "301G7MYOAJ1RQHRCTOCVAOHMWTZ35U            30   \n",
       "301G7MYOAJ397EAIS94FMNLGU7035W             2   \n",
       "301G7MYOAJ39FPP8WA9R6K95M9335Z            15   \n",
       "301G7MYOAJ3OHAOZV8UWUP9UZHM53Y            50   \n",
       "301G7MYOAJ54ES5MA4KIU09DOJ653Q            60   \n",
       "...                                      ...   \n",
       "3ZY19HV01BONLIR1KK5SXUJQHSGGS1            22   \n",
       "3ZY19HV01BONLIR1KK5SXUJQHSIGS3            26   \n",
       "3ZY19HV01BONLIR1KK5SXUJQIWEGS8            39   \n",
       "3ZY19HV01BPM76GKCNBV9R7GD76SG1            60   \n",
       "3ZY19HV01BSBSMWQ8SJ63FS1C9KSG5           300   \n",
       "\n",
       "                                                                            title  \\\n",
       "group_id                                                                            \n",
       "301G7MYOAJ1RQHRCTOCVAOHMWTZ35U   Recycling Attitudes and Intentions Questionnaire   \n",
       "301G7MYOAJ397EAIS94FMNLGU7035W                      Image Annotation Verification   \n",
       "301G7MYOAJ39FPP8WA9R6K95M9335Z             Consumer survey about sales promotions   \n",
       "301G7MYOAJ3OHAOZV8UWUP9UZHM53Y  Investigation of Attitudes Towards Groups(~ 25...   \n",
       "301G7MYOAJ54ES5MA4KIU09DOJ653Q  Quick Interesting Survey: Social attitudes(~ 2...   \n",
       "...                                                                           ...   \n",
       "3ZY19HV01BONLIR1KK5SXUJQHSGGS1                             Copy Edit English Text   \n",
       "3ZY19HV01BONLIR1KK5SXUJQHSIGS3                             Copy Edit English Text   \n",
       "3ZY19HV01BONLIR1KK5SXUJQIWEGS8                             Copy Edit English Text   \n",
       "3ZY19HV01BPM76GKCNBV9R7GD76SG1        What Are People Thinking? - 2 Minute Survey   \n",
       "3ZY19HV01BSBSMWQ8SJ63FS1C9KSG5  Meaningfulness in Life & Work Stress Part 3(~ ...   \n",
       "\n",
       "                                                                         keywords  \\\n",
       "group_id                                                                            \n",
       "301G7MYOAJ1RQHRCTOCVAOHMWTZ35U                          survey|recycling|opinions   \n",
       "301G7MYOAJ397EAIS94FMNLGU7035W  image annotation|image tagging|directions|navi...   \n",
       "301G7MYOAJ39FPP8WA9R6K95M9335Z    Sales promotions|consumer survey|academic study   \n",
       "301G7MYOAJ3OHAOZV8UWUP9UZHM53Y                                survey|demographics   \n",
       "301G7MYOAJ54ES5MA4KIU09DOJ653Q  quick survey|short survey|opinions|attitudes|b...   \n",
       "...                                                                           ...   \n",
       "3ZY19HV01BONLIR1KK5SXUJQHSGGS1  grammatical error correction|proofreading|revi...   \n",
       "3ZY19HV01BONLIR1KK5SXUJQHSIGS3  grammatical error correction|proofreading|revi...   \n",
       "3ZY19HV01BONLIR1KK5SXUJQIWEGS8  grammatical error correction|proofreading|revi...   \n",
       "3ZY19HV01BPM76GKCNBV9R7GD76SG1       survey|demographics|articles|reading|opinion   \n",
       "3ZY19HV01BSBSMWQ8SJ63FS1C9KSG5    Work Stress; Time Management; Values; Attitudes   \n",
       "\n",
       "                                  requester_id  \\\n",
       "group_id                                         \n",
       "301G7MYOAJ1RQHRCTOCVAOHMWTZ35U  A2R9VUC7LO7HJU   \n",
       "301G7MYOAJ397EAIS94FMNLGU7035W  A1W518UWEFCTSE   \n",
       "301G7MYOAJ39FPP8WA9R6K95M9335Z  A39EQL8PB8SVTQ   \n",
       "301G7MYOAJ3OHAOZV8UWUP9UZHM53Y  A2FS313FG0JGW3   \n",
       "301G7MYOAJ54ES5MA4KIU09DOJ653Q   A79USK145OBJJ   \n",
       "...                                        ...   \n",
       "3ZY19HV01BONLIR1KK5SXUJQHSGGS1  A3AYV6BR7VCGW0   \n",
       "3ZY19HV01BONLIR1KK5SXUJQHSIGS3  A3AYV6BR7VCGW0   \n",
       "3ZY19HV01BONLIR1KK5SXUJQIWEGS8  A3AYV6BR7VCGW0   \n",
       "3ZY19HV01BPM76GKCNBV9R7GD76SG1  A3JG43JLET2NUM   \n",
       "3ZY19HV01BSBSMWQ8SJ63FS1C9KSG5  A14BIFHITSA2R9   \n",
       "\n",
       "                                                                      description  \\\n",
       "group_id                                                                            \n",
       "301G7MYOAJ1RQHRCTOCVAOHMWTZ35U  Complete a questionnaire related to waste recy...   \n",
       "301G7MYOAJ397EAIS94FMNLGU7035W  Verify that the description of an image is acc...   \n",
       "301G7MYOAJ39FPP8WA9R6K95M9335Z  Academic study interested in customer feelings...   \n",
       "301G7MYOAJ3OHAOZV8UWUP9UZHM53Y  You will be asked to complete a variety of que...   \n",
       "301G7MYOAJ54ES5MA4KIU09DOJ653Q  This is a quick 2 minute survey on your attitudes   \n",
       "...                                                                           ...   \n",
       "3ZY19HV01BONLIR1KK5SXUJQHSGGS1  Proofreading English Text:  Correct spelling a...   \n",
       "3ZY19HV01BONLIR1KK5SXUJQHSIGS3  Proofreading English Text:  Correct spelling a...   \n",
       "3ZY19HV01BONLIR1KK5SXUJQIWEGS8  Proofreading English Text:  Correct spelling a...   \n",
       "3ZY19HV01BPM76GKCNBV9R7GD76SG1  What are people think. 2 minute survey on topi...   \n",
       "3ZY19HV01BSBSMWQ8SJ63FS1C9KSG5  A survey of employed individuals assessing wor...   \n",
       "\n",
       "                                expiration_date  log_reward  log_duration  \\\n",
       "group_id                                                                    \n",
       "301G7MYOAJ1RQHRCTOCVAOHMWTZ35U     Jun 24, 2017    2.708050      4.499810   \n",
       "301G7MYOAJ397EAIS94FMNLGU7035W      Jun 7, 2017    1.098612      6.016157   \n",
       "301G7MYOAJ39FPP8WA9R6K95M9335Z     Aug 25, 2017    4.248495      5.347108   \n",
       "301G7MYOAJ3OHAOZV8UWUP9UZHM53Y      Jul 4, 2017    4.317488      3.688879   \n",
       "301G7MYOAJ54ES5MA4KIU09DOJ653Q     Jul 20, 2017    2.995732      2.995732   \n",
       "...                                         ...         ...           ...   \n",
       "3ZY19HV01BONLIR1KK5SXUJQHSGGS1      Jul 9, 2017    3.784190     11.017809   \n",
       "3ZY19HV01BONLIR1KK5SXUJQHSIGS3     Jul 11, 2017    3.951244      9.596962   \n",
       "3ZY19HV01BONLIR1KK5SXUJQIWEGS8      Aug 1, 2017    4.356709      9.885324   \n",
       "3ZY19HV01BPM76GKCNBV9R7GD76SG1     Jul 27, 2017    2.302585      8.687779   \n",
       "3ZY19HV01BSBSMWQ8SJ63FS1C9KSG5     Oct 18, 2017    5.857933     10.375364   \n",
       "\n",
       "                                valid_duration  \\\n",
       "group_id                                         \n",
       "301G7MYOAJ1RQHRCTOCVAOHMWTZ35U               1   \n",
       "301G7MYOAJ397EAIS94FMNLGU7035W               1   \n",
       "301G7MYOAJ39FPP8WA9R6K95M9335Z               1   \n",
       "301G7MYOAJ3OHAOZV8UWUP9UZHM53Y               1   \n",
       "301G7MYOAJ54ES5MA4KIU09DOJ653Q               1   \n",
       "...                                        ...   \n",
       "3ZY19HV01BONLIR1KK5SXUJQHSGGS1               1   \n",
       "3ZY19HV01BONLIR1KK5SXUJQHSIGS3               1   \n",
       "3ZY19HV01BONLIR1KK5SXUJQIWEGS8               1   \n",
       "3ZY19HV01BPM76GKCNBV9R7GD76SG1               1   \n",
       "3ZY19HV01BSBSMWQ8SJ63FS1C9KSG5               1   \n",
       "\n",
       "                                                                        kw_parsed  \n",
       "group_id                                                                           \n",
       "301G7MYOAJ1RQHRCTOCVAOHMWTZ35U                          survey recycling opinions  \n",
       "301G7MYOAJ397EAIS94FMNLGU7035W  image annotation image tagging directions navi...  \n",
       "301G7MYOAJ39FPP8WA9R6K95M9335Z    Sales promotions consumer survey academic study  \n",
       "301G7MYOAJ3OHAOZV8UWUP9UZHM53Y                                survey demographics  \n",
       "301G7MYOAJ54ES5MA4KIU09DOJ653Q  quick survey short survey opinions attitudes b...  \n",
       "...                                                                           ...  \n",
       "3ZY19HV01BONLIR1KK5SXUJQHSGGS1  grammatical error correction proofreading revi...  \n",
       "3ZY19HV01BONLIR1KK5SXUJQHSIGS3  grammatical error correction proofreading revi...  \n",
       "3ZY19HV01BONLIR1KK5SXUJQIWEGS8  grammatical error correction proofreading revi...  \n",
       "3ZY19HV01BPM76GKCNBV9R7GD76SG1       survey demographics articles reading opinion  \n",
       "3ZY19HV01BSBSMWQ8SJ63FS1C9KSG5    Work Stress; Time Management; Values; Attitudes  \n",
       "\n",
       "[93775 rows x 32 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textlab_10_cleaned = cleanGroupData(merged_df_textlab10, 'textlab_10')\n",
    "textlab_10_cleaned.to_pickle('./data/textlab_10_cleaned.pkl')\n",
    "textlab_10_cleaned"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8374a35f",
   "metadata": {},
   "source": [
    "### （三）LDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a0352e2-6a8d-44fb-980f-ff25063abeee",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### 1、计算doc2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "2f1770a9-cc5c-457c-9aa1-cd6797bcd124",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 结果向量维度\n",
    "VEC_DIM = 50\n",
    "\n",
    "doc2vec_path = os.path.join(\".\",\"doc2vec_output\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd5e30e1-4038-4bdd-a7ed-2794b5cd8b33",
   "metadata": {},
   "source": [
    "#### 2、计算语料库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "05b3f720-6ef9-481b-8963-ef4c18ad6247",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateCorpora(full_df, data_name):\n",
    "    if data_name == \"ipeirotis\":\n",
    "        full_df[\"title\"] = full_df[\"title\"].astype(str)\n",
    "        full_df[\"description\"] = full_df[\"description\"].astype(str)\n",
    "    elif data_name == \"textlab_30\":\n",
    "        full_df[\"title\"] = full_df[\"title\"].astype(str)\n",
    "    elif data_name == \"textlab_10\":\n",
    "        full_df[\"title\"] = full_df[\"title\"].astype(str)\n",
    "        full_df[\"description\"] = full_df[\"description\"].astype(str)\n",
    "\n",
    "    # 创建doc2vec模型，将文档转换为固定长度的向量\n",
    "    # min_count用来忽略出现次数小于此值的单词\n",
    "    title_model = gensim.models.doc2vec.Doc2Vec(vector_size=VEC_DIM,min_count=2)\n",
    "    if data_name != \"textlab_30\":\n",
    "        desc_model = gensim.models.doc2vec.Doc2Vec(vector_size=VEC_DIM,min_count=2)\n",
    "        kw_model = gensim.models.doc2vec.Doc2Vec(vector_size=VEC_DIM,min_count=2)\n",
    "\n",
    "    # 提取文本\n",
    "    titles = full_df[\"title\"]\n",
    "    if data_name != \"textlab_30\":\n",
    "        descriptions = full_df[\"description\"]\n",
    "        keywords = full_df[\"kw_parsed\"]\n",
    "\n",
    "    # 加载 stopwords 来过滤文本中的无意义词汇， 提升文本处理效率\n",
    "    stoplist = nltk.corpus.stopwords.words(\"english\")\n",
    "\n",
    "    # 预处理并生成语料库\n",
    "    def preprocess(text):\n",
    "        # 将原始文本快速转换为小写、去符号的单词列表，输出为小写、无标点、无数字的单词列表，如['this', 'is', 'sample', 'text']\n",
    "        word_list = gensim.utils.simple_preprocess(text)\n",
    "        word_list = [word for word in word_list if (word not in stoplist) and (len(word) > 2)]\n",
    "        return word_list\n",
    "\n",
    "    def generateCorpus(doc_series):\n",
    "        # 将原始文档集合转换为TaggedDocument格式的列表，每个文档包含preprocessing预处理后的分词结果和标签\n",
    "        corpus = [gensim.models.doc2vec.TaggedDocument(preprocess(doc), [doc_id])\n",
    "              for doc_id,doc in doc_series.items()]\n",
    "        return corpus\n",
    "\n",
    "    title_corpus = generateCorpus(titles)\n",
    "    if data_name != \"textlab_30\":\n",
    "        desc_corpus = generateCorpus(descriptions)\n",
    "        kw_corpus = generateCorpus(keywords)\n",
    "    joblib.dump(title_corpus, os.path.join(doc2vec_path,data_name + \"_titles_doc2vec_corpus.pkl\"))\n",
    "    if data_name != \"textlab_30\":\n",
    "        joblib.dump(desc_corpus, os.path.join(doc2vec_path,data_name + \"_desc_doc2vec_corpus.pkl\"))\n",
    "        joblib.dump(kw_corpus, os.path.join(doc2vec_path,data_name + \"_kw_doc2vec_corpus.pkl\"))\n",
    "    print(\"Corpora exported\")\n",
    "\n",
    "    # 构建词汇\n",
    "    # 分析所有文档中的单词，统计词频，过滤低频词。同时初始化单词向量和文档向量的存储结构，为后续的神经网络训练建立词表索引。\n",
    "    title_model.build_vocab(title_corpus)\n",
    "    if data_name != \"textlab_30\":\n",
    "        desc_model.build_vocab(desc_corpus)\n",
    "        kw_model.build_vocab(kw_corpus)\n",
    "\n",
    "    # 保存模型\n",
    "    title_model.save(os.path.join(doc2vec_path, data_name + \"_titles_doc2vec.pkl\"))\n",
    "    if data_name != \"textlab_30\":\n",
    "        desc_model.save(os.path.join(doc2vec_path, data_name + \"_desc_doc2vec.pkl\"))\n",
    "        kw_model.save(os.path.join(doc2vec_path, data_name + \"_kw_doc2vec.pkl\"))\n",
    "    print(\"Models saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "ca01efd2-a53d-464e-bd37-031a19a7b511",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpora exported\n",
      "Models saved\n",
      "Corpora exported\n",
      "Models saved\n",
      "Corpora exported\n",
      "Models saved\n"
     ]
    }
   ],
   "source": [
    "generateCorpora(ipeirotis_cleaned, 'ipeirotis')\n",
    "generateCorpora(textlab_30_cleaned, 'textlab_30')\n",
    "generateCorpora(textlab_10_cleaned, 'textlab_10')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e906e15e-d62c-4fb1-ac4e-fb8481ba6919",
   "metadata": {},
   "source": [
    "#### 3、训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "a32a7224-84ec-4ac8-9190-82cbcfa7aea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadModel(pickle_filename):\n",
    "    # 加载 .pkl 文件为gensim doc2vec项目\n",
    "    return gensim.models.doc2vec.Doc2Vec.load(pickle_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "42fd1eb7-95ac-4b8b-ba5c-9bc69d12329e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainModels(data_name):\n",
    "    # 返回系统中的cpu总数\n",
    "    num_cpus = multiprocessing.cpu_count()\n",
    "\n",
    "    # 加载模型文件\n",
    "    title_model = loadModel(os.path.join(doc2vec_path,data_name + \"_titles_doc2vec.pkl\"))\n",
    "    if data_name != \"textlab_30\":\n",
    "        desc_model = loadModel(os.path.join(doc2vec_path,data_name + \"_desc_doc2vec.pkl\"))\n",
    "        kw_model = loadModel(os.path.join(doc2vec_path,data_name + \"_kw_doc2vec.pkl\"))\n",
    "\n",
    "    title_corpus = joblib.load(os.path.join(doc2vec_path,data_name + \"_titles_doc2vec_corpus.pkl\"))\n",
    "    if data_name != \"textlab_30\":\n",
    "        desc_corpus = joblib.load(os.path.join(doc2vec_path,data_name + \"_desc_doc2vec_corpus.pkl\"))\n",
    "        kw_corpus = joblib.load(os.path.join(doc2vec_path,data_name + \"_kw_doc2vec_corpus.pkl\"))\n",
    "\n",
    "    # 训练模型并存储\n",
    "    print(\"Training title model\")\n",
    "    title_model.train(title_corpus, total_examples=title_model.corpus_count,\n",
    "        epochs=title_model.epochs)\n",
    "    title_model.save(os.path.join(doc2vec_path,data_name + \"_titles_doc2vec_trained.pkl\"))\n",
    "    if data_name != \"textlab_30\":\n",
    "        print(\"Training description model\")\n",
    "        desc_model.train(desc_corpus, total_examples=desc_model.corpus_count,\n",
    "            epochs=desc_model.epochs)\n",
    "        desc_model.save(os.path.join(doc2vec_path,data_name + \"_desc_doc2vec_trained.pkl\"))\n",
    "        print(\"Training keyword model\")\n",
    "        kw_model.train(kw_corpus, total_examples=kw_model.corpus_count,\n",
    "            epochs=kw_model.epochs)\n",
    "        kw_model.save(os.path.join(doc2vec_path,data_name + \"_kw_doc2vec_trained.pkl\"))\n",
    "    print(\"Trained models saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "6c5e4171-8fbb-4243-8103-5117bb1ae637",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training title model\n",
      "Training description model\n",
      "Training keyword model\n",
      "Trained models saved\n",
      "Training title model\n",
      "Trained models saved\n",
      "Training title model\n",
      "Training description model\n",
      "Training keyword model\n",
      "Trained models saved\n"
     ]
    }
   ],
   "source": [
    "trainModels('ipeirotis')\n",
    "trainModels('textlab_30')\n",
    "trainModels('textlab_10')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27ff95cb-82aa-479c-a157-6269be90df79",
   "metadata": {},
   "source": [
    "#### 4、获取目标向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "ba7c4871-3593-471c-bc6e-fd05e337379f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inferVectors(data_name):\n",
    "    # 加载模型\n",
    "    titles_trained = loadModel(os.path.join(doc2vec_path,data_name + \"_titles_doc2vec_trained.pkl\"))\n",
    "    if data_name != \"textlab_30\":\n",
    "        desc_trained = loadModel(os.path.join(doc2vec_path,data_name + \"_desc_doc2vec_trained.pkl\"))\n",
    "        kw_trained = loadModel(os.path.join(doc2vec_path, data_name + \"_kw_doc2vec_trained.pkl\"))\n",
    "\n",
    "    # 加载语料库\n",
    "    title_corpus = joblib.load(os.path.join(doc2vec_path,data_name + \"_titles_doc2vec_corpus.pkl\"))\n",
    "    if data_name != \"textlab_30\":\n",
    "        desc_corpus = joblib.load(os.path.join(doc2vec_path,data_name + \"_desc_doc2vec_corpus.pkl\"))\n",
    "        kw_corpus = joblib.load(os.path.join(doc2vec_path,data_name + \"_kw_doc2vec_corpus.pkl\"))\n",
    "\n",
    "    # 从语料库中获取目标向量\n",
    "    print(\"Inferring title vectors\")\n",
    "    title_corpus_vecs = [titles_trained.infer_vector(corpus_doc.words) for corpus_doc in title_corpus]\n",
    "    if data_name != \"textlab_30\":\n",
    "        print(\"Inferring description vectors\")\n",
    "        desc_corpus_vecs = [desc_trained.infer_vector(corpus_doc.words) for corpus_doc in desc_corpus]\n",
    "        print(\"Inferring keyword vectors\")\n",
    "        kw_corpus_vecs = [kw_trained.infer_vector(corpus_doc.words) for corpus_doc in kw_corpus]\n",
    "    title_col_headers = [\"doc2vec_title_\" + str(dim) for dim in range(VEC_DIM)]\n",
    "    if data_name != \"textlab_30\":\n",
    "        desc_col_headers = [\"doc2vec_desc_\" + str(dim) for dim in range(VEC_DIM)]\n",
    "        kw_col_headers = [\"doc2vec_kw_\" + str(dim) for dim in range(VEC_DIM)]\n",
    "    title_vec_df = pd.DataFrame(title_corpus_vecs, columns=title_col_headers)\n",
    "    if data_name != \"textlab_30\":\n",
    "        desc_vec_df = pd.DataFrame(desc_corpus_vecs, columns=desc_col_headers)\n",
    "        kw_vec_df = pd.DataFrame(kw_corpus_vecs, columns=kw_col_headers)\n",
    "    if data_name == \"textlab_30\":\n",
    "        df = title_vec_df\n",
    "    else:\n",
    "        df = pd.concat([title_vec_df, desc_vec_df, kw_vec_df], axis=1)\n",
    "    df.to_pickle(os.path.join(doc2vec_path,data_name + \"_doc2vec.pkl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "d6c46e02-4cc4-4c94-a576-8fb64d9643fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inferring title vectors\n",
      "Inferring description vectors\n",
      "Inferring keyword vectors\n",
      "Inferring title vectors\n",
      "Inferring title vectors\n",
      "Inferring description vectors\n",
      "Inferring keyword vectors\n"
     ]
    }
   ],
   "source": [
    "inferVectors('ipeirotis')\n",
    "inferVectors('textlab_30')\n",
    "inferVectors('textlab_10')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f51ed891-ae97-45af-bc98-de04d70749bc",
   "metadata": {},
   "source": [
    "#### 5、计算LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "7233dd27-8bb4-4da6-97f4-e7bb9a8a3f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# string.punctuation获取所有的英文标点符号\n",
    "# {key: None for key in string.punctuation}\t生成字典：键为标点符号，值为 None（表示删除）\n",
    "# str.maketrans() 将字典转换为字符映射表——将所有标点符号转换为None，即删除\n",
    "# 该方法相比正则表达式运行速度更快\n",
    "remove_punct = str.maketrans({key: None for key in string.punctuation})\n",
    "# 使用的内核数量\n",
    "num_workers = 7\n",
    "\n",
    "cleaned_path = os.path.join('.', 'data')\n",
    "lda_path = os.path.join('.', 'lda_data')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20d1152c-cc1c-4edc-84e0-45315ea19703",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### 6、计算语料库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "baa56803-d703-41da-b224-77ba500ddcc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateCorpora2(dataset):\n",
    "    if dataset == \"ipeirotis\":\n",
    "        ## 加载 Ipeirotis 数据\n",
    "        full_df = pd.read_pickle(os.path.join(cleaned_path,\"ipeirotis_cleaned.pkl\"))\n",
    "        full_df[\"title\"] = full_df[\"title\"].astype(str)\n",
    "        full_df[\"description\"] = full_df[\"description\"].astype(str)\n",
    "    elif dataset == \"textlab_30\":\n",
    "        ## 加载 TextLab 30-minute 数据\n",
    "        full_df = pd.read_pickle(os.path.join(cleaned_path,\"textlab_30_cleaned.pkl\"))\n",
    "        full_df[\"title\"] = full_df[\"title\"].astype(str)\n",
    "    elif dataset == \"textlab_10\":\n",
    "        ## 加载 the TextLab 10-minute 数据\n",
    "        full_df = pd.read_pickle(os.path.join(cleaned_path,\"textlab_10_cleaned.pkl\"))\n",
    "        # 保证所有描述都是字符串(-__-)\n",
    "        full_df[\"description\"] = full_df[\"description\"].astype(str)\n",
    "        full_df[\"title\"] = full_df[\"title\"].astype(str)\n",
    "\n",
    "    stoplist = stopwords.words('english')\n",
    "    # 扩展英文停用词列表，添加html标签和制表符\n",
    "    stoplist.extend([\"<p>\",\"</p>\",\"<p></p>\",\"</p><p>\",\"<i>\",\"</i>\",\"\\t\"])\n",
    "\n",
    "    # 提取文本\n",
    "    title_df = full_df[\"title\"]\n",
    "    if dataset != \"textlab_30\":\n",
    "        desc_df = full_df[\"description\"]\n",
    "        kw_df = full_df[\"kw_parsed\"]\n",
    "    # 移除标点符号，使用之前创建的remove_punct映射表\n",
    "    title_df = title_df.str.translate(remove_punct)\n",
    "    if dataset != \"textlab_30\":\n",
    "        desc_df = desc_df.str.translate(remove_punct)\n",
    "        kw_df = kw_df.str.translate(remove_punct)\n",
    "\n",
    "    # 创建文本列表\n",
    "    # 列表的列表，每个子列表是单词列表\n",
    "    '''\n",
    "    title_docs = [\n",
    "    ['hello', 'world', 'nlp'],\n",
    "    ['world', 'computer', 'science'],\n",
    "    ['nlp', 'deep', 'learning']\n",
    "    ]\n",
    "    '''\n",
    "    def seriesToDocList(doc_series):\n",
    "        docs = [[cur_word for cur_word in cur_doc.lower().split() if cur_word not in stoplist] for cur_doc in doc_series]\n",
    "        docs = [[cur_word for cur_word in cur_doc if len(cur_word) > 2] for cur_doc in docs]\n",
    "        return docs\n",
    "    title_docs = seriesToDocList(title_df)\n",
    "    if dataset != \"textlab_30\":\n",
    "        desc_docs = seriesToDocList(desc_df)\n",
    "        kw_docs = seriesToDocList(kw_df)\n",
    "    print(\"Doc lists created\")\n",
    "\n",
    "    # 创建 gensim 字典\n",
    "    # 包含所有唯一的单词（词项）\n",
    "    # 每个单词的整数ID（从0开始自动分配）\n",
    "    # 词频统计信息\n",
    "    title_dict = gensim.corpora.Dictionary(title_docs)\n",
    "    if dataset != \"textlab_30\":\n",
    "        desc_dict = gensim.corpora.Dictionary(desc_docs)\n",
    "        kw_dict = gensim.corpora.Dictionary(kw_docs)\n",
    "\n",
    "    # 保存为 .dict \n",
    "    title_dict.save(os.path.join(lda_path, dataset + \"_title.dict\"))\n",
    "    if dataset != \"textlab_30\":\n",
    "        desc_dict.save(os.path.join(lda_path, dataset + \"_desc.dict\"))\n",
    "        kw_dict.save(os.path.join(lda_path, dataset + \"_kw.dict\"))\n",
    "    print(\"Dictionaries saved\")\n",
    "\n",
    "    # 创建 gensim 语料库\n",
    "    # 将原始文档集合转换为词袋模型BOW表示的语料库\n",
    "    '''\n",
    "    [\n",
    "    [(0, 1), (1, 1), (2, 1)],  # 'hello':0, 'world':1, 'nlp':2\n",
    "    [(1, 1), (3, 1), (4, 1)],  # 'world':1, 'computer':3, 'science':4\n",
    "    [(2, 1), (5, 1), (6, 1)]   # 'nlp':2, 'deep':5, 'learning':6\n",
    "    ]\n",
    "    '''\n",
    "    title_corpus = [title_dict.doc2bow(doc) for doc in title_docs]\n",
    "    if dataset != \"textlab_30\":\n",
    "        desc_corpus = [desc_dict.doc2bow(doc) for doc in desc_docs]\n",
    "        kw_corpus = [kw_dict.doc2bow(doc) for doc in kw_docs]\n",
    "\n",
    "    # 序列化语料库\n",
    "    # 将文件保存为Matrix Market（MM）文件，后续可以直接通过MmCorpus（）读取\n",
    "    title_corpus_path = os.path.join(lda_path, dataset + \"_title_corpus.mm\")\n",
    "    gensim.corpora.MmCorpus.serialize(title_corpus_path, title_corpus)\n",
    "    if dataset != \"textlab_30\":\n",
    "        desc_corpus_path = os.path.join(lda_path, dataset + \"_desc_corpus.mm\")\n",
    "        gensim.corpora.MmCorpus.serialize(desc_corpus_path, desc_corpus)\n",
    "        kw_corpus_path = os.path.join(lda_path, dataset + \"_kw_corpus.mm\")\n",
    "        gensim.corpora.MmCorpus.serialize(kw_corpus_path, kw_corpus)\n",
    "    print(\"Corpora serialized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "1ecf53ff-e341-48b2-a6c2-c0ff0c0a4265",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doc lists created\n",
      "Dictionaries saved\n",
      "Corpora serialized\n",
      "Doc lists created\n",
      "Dictionaries saved\n",
      "Corpora serialized\n",
      "Doc lists created\n",
      "Dictionaries saved\n",
      "Corpora serialized\n"
     ]
    }
   ],
   "source": [
    "generateCorpora2('ipeirotis')\n",
    "generateCorpora2('textlab_30')\n",
    "generateCorpora2('textlab_10')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a244711f-cd2b-4edb-a915-f8928bc87df5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### 7、计算LDA矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "9a472cf8-2681-443b-801e-b7ec8b13f8dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "K_vals = [5,10,15,20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "636b3033-e351-4379-8dbd-65eb322ceaf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeLDA(K, data_prefix):\n",
    "    doc_dict = gensim.corpora.dictionary.Dictionary.load(os.path.join(lda_path, data_prefix + \".dict\"))\n",
    "    doc_corpus = gensim.corpora.mmcorpus.MmCorpus(os.path.join(lda_path, data_prefix + \"_corpus.mm\"))\n",
    "    lda = gensim.models.ldamulticore.LdaMulticore(corpus=doc_corpus,\n",
    "      id2word=doc_dict, num_topics=K, workers=7)\n",
    "    lda_filename = os.path.join(lda_path, data_prefix + \"_lda_\" + str(K) + \".pkl\")\n",
    "    lda.save(lda_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "86975666-f95d-4c7d-b9c5-24ab7770030f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTopicDistributions(K, data_prefix):\n",
    "    # 获得每一批次hit的主要分布\n",
    "    prefix_var = data_prefix.split(\"_\")[-1]\n",
    "    lda_filename = os.path.join(lda_path, data_prefix + \"_lda_\" + str(K) + \".pkl\")\n",
    "    lda = gensim.models.ldamulticore.LdaMulticore.load(lda_filename)\n",
    "    corpus_filename = os.path.join(lda_path, data_prefix + \"_corpus.mm\")\n",
    "    corpus = gensim.corpora.mmcorpus.MmCorpus(corpus_filename)\n",
    "    # 将集合传递给lda对象\n",
    "    corpus_dist = lda[corpus]\n",
    "    print(\"Distributions computed\")\n",
    "    corpus_dict = [{elt[0]:elt[1] for elt in doc_dist} for doc_dist in corpus_dist]\n",
    "    print(\"Dict created\")\n",
    "    corpus_arr = [[doc_dict[key] if (key in doc_dict) else 0.0 for key in range(K)] for doc_dict in corpus_dict]\n",
    "    print(\"Array created\")\n",
    "    column_names = [prefix_var + \"topic_\" + str(K) + \"_\" + str(n) for n in range(K)]\n",
    "    corpus_df = pd.DataFrame(corpus_arr,columns=column_names)\n",
    "    print(\"DF created\")\n",
    "    dist_file = os.path.join(lda_path, data_prefix + \"_lda_dists_\" + str(K) + \".pkl\")\n",
    "    corpus_df.to_pickle(dist_file)\n",
    "    print(corpus_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "2cebf51f-b750-47ea-88d6-b9d216d1d500",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distributions computed\n",
      "Dict created\n",
      "Array created\n",
      "DF created\n",
      "   titletopic_5_0  titletopic_5_1  titletopic_5_2  titletopic_5_3  \\\n",
      "0        0.066776        0.066799        0.732476        0.066704   \n",
      "1        0.100106        0.100514        0.100079        0.100013   \n",
      "2        0.050032        0.050156        0.799029        0.050017   \n",
      "3        0.067019        0.067713        0.731760        0.066713   \n",
      "4        0.022341        0.022351        0.279558        0.652325   \n",
      "\n",
      "   titletopic_5_4  \n",
      "0        0.067246  \n",
      "1        0.599287  \n",
      "2        0.050766  \n",
      "3        0.066795  \n",
      "4        0.023425  \n",
      "Distributions computed\n",
      "Dict created\n",
      "Array created\n",
      "DF created\n",
      "   desctopic_5_0  desctopic_5_1  desctopic_5_2  desctopic_5_3  desctopic_5_4\n",
      "0       0.033456       0.036550       0.033896       0.033608       0.862491\n",
      "1       0.050655       0.798681       0.050180       0.050133       0.050351\n",
      "2       0.020041       0.020076       0.918800       0.020799       0.020285\n",
      "3       0.020080       0.020450       0.320732       0.020368       0.618370\n",
      "4       0.000000       0.000000       0.753646       0.000000       0.224488\n",
      "Distributions computed\n",
      "Dict created\n",
      "Array created\n",
      "DF created\n",
      "   kwtopic_5_0  kwtopic_5_1  kwtopic_5_2  kwtopic_5_3  kwtopic_5_4\n",
      "0     0.597680     0.100051     0.100055     0.100258     0.101956\n",
      "1     0.100012     0.599825     0.100030     0.100004     0.100129\n",
      "2     0.696206     0.182993     0.040154     0.040390     0.040257\n",
      "3     0.041598     0.040063     0.040264     0.040429     0.837646\n",
      "4     0.030180     0.028697     0.028792     0.029653     0.882677\n",
      "Distributions computed\n",
      "Dict created\n",
      "Array created\n",
      "DF created\n",
      "   titletopic_10_0  titletopic_10_1  titletopic_10_2  titletopic_10_3  \\\n",
      "0         0.033350         0.033352         0.033343         0.033343   \n",
      "1         0.050001         0.050003         0.549990         0.050001   \n",
      "2         0.025006         0.025007         0.025001         0.025001   \n",
      "3         0.699921         0.033340         0.033339         0.033339   \n",
      "4         0.348633         0.319887         0.011124         0.011128   \n",
      "\n",
      "   titletopic_10_4  titletopic_10_5  titletopic_10_6  titletopic_10_7  \\\n",
      "0         0.387729         0.033344         0.033347         0.345491   \n",
      "1         0.050001         0.050001         0.050001         0.050001   \n",
      "2         0.025000         0.025001         0.025001         0.774974   \n",
      "3         0.033340         0.033346         0.033350         0.033344   \n",
      "4         0.011124         0.146267         0.118456         0.011128   \n",
      "\n",
      "   titletopic_10_8  titletopic_10_9  \n",
      "0         0.033344         0.033357  \n",
      "1         0.050001         0.050001  \n",
      "2         0.025001         0.025008  \n",
      "3         0.033340         0.033342  \n",
      "4         0.011128         0.011125  \n",
      "Distributions computed\n",
      "Dict created\n",
      "Array created\n",
      "DF created\n",
      "   desctopic_10_0  desctopic_10_1  desctopic_10_2  desctopic_10_3  \\\n",
      "0        0.016680        0.016694        0.016680        0.016680   \n",
      "1        0.025001        0.025001        0.025000        0.774983   \n",
      "2        0.010005        0.010005        0.010016        0.010007   \n",
      "3        0.010002        0.010002        0.010004        0.010003   \n",
      "4        0.000000        0.000000        0.000000        0.137536   \n",
      "\n",
      "   desctopic_10_4  desctopic_10_5  desctopic_10_6  desctopic_10_7  \\\n",
      "0        0.016679        0.016680        0.016680        0.849862   \n",
      "1        0.025001        0.025010        0.025001        0.025001   \n",
      "2        0.010006        0.010007        0.010005        0.010011   \n",
      "3        0.010001        0.010005        0.010002        0.392585   \n",
      "4        0.040604        0.303665        0.000000        0.142901   \n",
      "\n",
      "   desctopic_10_8  desctopic_10_9  \n",
      "0        0.016687        0.016680  \n",
      "1        0.025001        0.025001  \n",
      "2        0.235078        0.684859  \n",
      "3        0.527392        0.010004  \n",
      "4        0.308518        0.052423  \n",
      "Distributions computed\n",
      "Dict created\n",
      "Array created\n",
      "DF created\n",
      "   kwtopic_10_0  kwtopic_10_1  kwtopic_10_2  kwtopic_10_3  kwtopic_10_4  \\\n",
      "0      0.050017      0.050002      0.549965      0.050002      0.050001   \n",
      "1      0.050000      0.549996      0.050000      0.050000      0.050000   \n",
      "2      0.020005      0.020003      0.622789      0.020001      0.020002   \n",
      "3      0.020004      0.020001      0.020009      0.020001      0.020002   \n",
      "4      0.014295      0.014289      0.346841      0.014291      0.014293   \n",
      "\n",
      "   kwtopic_10_5  kwtopic_10_6  kwtopic_10_7  kwtopic_10_8  kwtopic_10_9  \n",
      "0      0.050004      0.050006      0.050001      0.050001      0.050001  \n",
      "1      0.050001      0.050001      0.050000      0.050000      0.050000  \n",
      "2      0.020003      0.020002      0.217192      0.020001      0.020001  \n",
      "3      0.819977      0.020002      0.020002      0.020001      0.020001  \n",
      "4      0.538826      0.014291      0.014293      0.014291      0.014290  \n",
      "Distributions computed\n",
      "Dict created\n",
      "Array created\n",
      "DF created\n",
      "   titletopic_15_0  titletopic_15_1  titletopic_15_2  titletopic_15_3  \\\n",
      "0         0.022233         0.022233         0.022233         0.022233   \n",
      "1         0.033334         0.033334         0.033334         0.033334   \n",
      "2         0.016667         0.016667         0.016667         0.016667   \n",
      "3         0.022225         0.022225         0.022225         0.022225   \n",
      "4         0.000000         0.000000         0.000000         0.000000   \n",
      "\n",
      "   titletopic_15_4  titletopic_15_5  titletopic_15_6  titletopic_15_7  \\\n",
      "0         0.022233         0.022233         0.022233         0.022233   \n",
      "1         0.033334         0.033334         0.033334         0.033334   \n",
      "2         0.016667         0.016667         0.016667         0.016667   \n",
      "3         0.022225         0.022225         0.022225         0.022225   \n",
      "4         0.281660         0.000000         0.000000         0.622017   \n",
      "\n",
      "   titletopic_15_8  titletopic_15_9  titletopic_15_10  titletopic_15_11  \\\n",
      "0         0.022233         0.022233          0.022233          0.688745   \n",
      "1         0.033334         0.033334          0.033334          0.033334   \n",
      "2         0.016667         0.016667          0.016667          0.766665   \n",
      "3         0.022225         0.022225          0.022225          0.688852   \n",
      "4         0.000000         0.000000          0.000000          0.000000   \n",
      "\n",
      "   titletopic_15_12  titletopic_15_13  titletopic_15_14  \n",
      "0          0.022233          0.022233          0.022233  \n",
      "1          0.533331          0.033334          0.033334  \n",
      "2          0.016667          0.016667          0.016667  \n",
      "3          0.022225          0.022225          0.022225  \n",
      "4          0.000000          0.000000          0.000000  \n",
      "Distributions computed\n",
      "Dict created\n",
      "Array created\n",
      "DF created\n",
      "   desctopic_15_0  desctopic_15_1  desctopic_15_2  desctopic_15_3  \\\n",
      "0        0.011114        0.471796        0.383725        0.011114   \n",
      "1        0.016667        0.016667        0.016667        0.016667   \n",
      "2        0.000000        0.468122        0.000000        0.000000   \n",
      "3        0.000000        0.906657        0.000000        0.000000   \n",
      "4        0.000000        0.000000        0.000000        0.000000   \n",
      "\n",
      "   desctopic_15_4  desctopic_15_5  desctopic_15_6  desctopic_15_7  \\\n",
      "0        0.011114        0.011114        0.011114        0.011114   \n",
      "1        0.016667        0.016667        0.016667        0.016667   \n",
      "2        0.000000        0.000000        0.000000        0.000000   \n",
      "3        0.000000        0.000000        0.000000        0.000000   \n",
      "4        0.000000        0.032801        0.000000        0.000000   \n",
      "\n",
      "   desctopic_15_8  desctopic_15_9  desctopic_15_10  desctopic_15_11  \\\n",
      "0        0.011114        0.011114         0.011114         0.011114   \n",
      "1        0.016667        0.016667         0.016667         0.766664   \n",
      "2        0.000000        0.000000         0.000000         0.000000   \n",
      "3        0.000000        0.000000         0.000000         0.000000   \n",
      "4        0.000000        0.000000         0.000000         0.000000   \n",
      "\n",
      "   desctopic_15_12  desctopic_15_13  desctopic_15_14  \n",
      "0         0.011114         0.011114         0.011114  \n",
      "1         0.016667         0.016667         0.016667  \n",
      "2         0.445158         0.000000         0.000000  \n",
      "3         0.000000         0.000000         0.000000  \n",
      "4         0.936212         0.000000         0.000000  \n",
      "Distributions computed\n",
      "Dict created\n",
      "Array created\n",
      "DF created\n",
      "   kwtopic_15_0  kwtopic_15_1  kwtopic_15_2  kwtopic_15_3  kwtopic_15_4  \\\n",
      "0      0.033334      0.033334      0.033334      0.033334      0.033334   \n",
      "1      0.033334      0.033334      0.033334      0.033334      0.033334   \n",
      "2      0.013334      0.013334      0.013334      0.013334      0.013334   \n",
      "3      0.013334      0.013334      0.013334      0.013334      0.013334   \n",
      "4      0.000000      0.000000      0.000000      0.000000      0.000000   \n",
      "\n",
      "   kwtopic_15_5  kwtopic_15_6  kwtopic_15_7  kwtopic_15_8  kwtopic_15_9  \\\n",
      "0      0.033334      0.033334      0.033334      0.033334      0.033334   \n",
      "1      0.033334      0.033334      0.033334      0.033334      0.533331   \n",
      "2      0.013334      0.282921      0.013334      0.013334      0.013334   \n",
      "3      0.013334      0.013334      0.013334      0.813325      0.013334   \n",
      "4      0.666777      0.000000      0.000000      0.000000      0.000000   \n",
      "\n",
      "   kwtopic_15_10  kwtopic_15_11  kwtopic_15_12  kwtopic_15_13  kwtopic_15_14  \n",
      "0       0.033334       0.033334       0.033334       0.033334       0.533325  \n",
      "1       0.033334       0.033334       0.033334       0.033334       0.033334  \n",
      "2       0.013334       0.013334       0.013334       0.543737       0.013334  \n",
      "3       0.013334       0.013334       0.013334       0.013334       0.013334  \n",
      "4       0.000000       0.000000       0.000000       0.209395       0.000000  \n",
      "Distributions computed\n",
      "Dict created\n",
      "Array created\n",
      "DF created\n",
      "   titletopic_20_0  titletopic_20_1  titletopic_20_2  titletopic_20_3  \\\n",
      "0         0.016668         0.016668         0.016668         0.016668   \n",
      "1         0.025000         0.025000         0.025000         0.025000   \n",
      "2         0.012500         0.012500         0.012500         0.012500   \n",
      "3         0.016668         0.016668         0.016668         0.016668   \n",
      "4         0.000000         0.000000         0.000000         0.000000   \n",
      "\n",
      "   titletopic_20_4  titletopic_20_5  titletopic_20_6  titletopic_20_7  \\\n",
      "0         0.016668         0.683311         0.016668         0.016668   \n",
      "1         0.025000         0.025000         0.025000         0.025000   \n",
      "2         0.012500         0.762499         0.012500         0.012500   \n",
      "3         0.016668         0.683299         0.016668         0.016668   \n",
      "4         0.000000         0.000000         0.000000         0.000000   \n",
      "\n",
      "   titletopic_20_8  titletopic_20_9  titletopic_20_10  titletopic_20_11  \\\n",
      "0         0.016668         0.016668          0.016668          0.016668   \n",
      "1         0.025000         0.025000          0.025000          0.524996   \n",
      "2         0.012500         0.012500          0.012500          0.012500   \n",
      "3         0.016668         0.016668          0.016668          0.016668   \n",
      "4         0.245705         0.000000          0.000000          0.550144   \n",
      "\n",
      "   titletopic_20_12  titletopic_20_13  titletopic_20_14  titletopic_20_15  \\\n",
      "0          0.016668          0.016668          0.016668          0.016668   \n",
      "1          0.025000          0.025000          0.025000          0.025000   \n",
      "2          0.012500          0.012500          0.012500          0.012500   \n",
      "3          0.016668          0.016668          0.016668          0.016668   \n",
      "4          0.000000          0.000000          0.000000          0.000000   \n",
      "\n",
      "   titletopic_20_16  titletopic_20_17  titletopic_20_18  titletopic_20_19  \n",
      "0          0.016668          0.016668          0.016668          0.016668  \n",
      "1          0.025000          0.025000          0.025000          0.025000  \n",
      "2          0.012500          0.012500          0.012500          0.012500  \n",
      "3          0.016668          0.016668          0.016668          0.016668  \n",
      "4          0.000000          0.000000          0.109626          0.000000  \n",
      "Distributions computed\n",
      "Dict created\n",
      "Array created\n",
      "DF created\n",
      "   desctopic_20_0  desctopic_20_1  desctopic_20_2  desctopic_20_3  \\\n",
      "0          0.0000        0.000000        0.000000         0.00000   \n",
      "1          0.0125        0.012500        0.012500         0.01250   \n",
      "2          0.0000        0.787394        0.000000         0.00000   \n",
      "3          0.0000        0.000000        0.000000         0.10909   \n",
      "4          0.0000        0.000000        0.805437         0.00000   \n",
      "\n",
      "   desctopic_20_4  desctopic_20_5  desctopic_20_6  desctopic_20_7  \\\n",
      "0          0.0000          0.0000          0.0000        0.000000   \n",
      "1          0.0125          0.0125          0.0125        0.012500   \n",
      "2          0.0000          0.0000          0.0000        0.000000   \n",
      "3          0.0000          0.0000          0.0000        0.000000   \n",
      "4          0.0000          0.0000          0.0000        0.116158   \n",
      "\n",
      "   desctopic_20_8  desctopic_20_9  desctopic_20_10  desctopic_20_11  \\\n",
      "0          0.0000          0.0000           0.0000          0.00000   \n",
      "1          0.0125          0.0125           0.0125          0.01250   \n",
      "2          0.0000          0.0000           0.0000          0.12254   \n",
      "3          0.0000          0.0000           0.0000          0.00000   \n",
      "4          0.0000          0.0000           0.0000          0.00000   \n",
      "\n",
      "   desctopic_20_12  desctopic_20_13  desctopic_20_14  desctopic_20_15  \\\n",
      "0         0.000000           0.0000         0.000000         0.287044   \n",
      "1         0.012500           0.0125         0.762499         0.012500   \n",
      "2         0.000000           0.0000         0.000000         0.000000   \n",
      "3         0.408763           0.0000         0.000000         0.397136   \n",
      "4         0.000000           0.0000         0.000000         0.048024   \n",
      "\n",
      "   desctopic_20_16  desctopic_20_17  desctopic_20_18  desctopic_20_19  \n",
      "0           0.0000           0.0000         0.562909           0.0000  \n",
      "1           0.0125           0.0125         0.012500           0.0125  \n",
      "2           0.0000           0.0000         0.000000           0.0000  \n",
      "3           0.0000           0.0000         0.000000           0.0000  \n",
      "4           0.0000           0.0000         0.000000           0.0000  \n",
      "Distributions computed\n",
      "Dict created\n",
      "Array created\n",
      "DF created\n",
      "   kwtopic_20_0  kwtopic_20_1  kwtopic_20_2  kwtopic_20_3  kwtopic_20_4  \\\n",
      "0      0.025000      0.025000      0.025000      0.025000      0.025000   \n",
      "1      0.025000      0.025000      0.025000      0.025000      0.025000   \n",
      "2      0.010001      0.010001      0.010001      0.230096      0.010001   \n",
      "3      0.010000      0.010000      0.010000      0.010000      0.010000   \n",
      "4      0.000000      0.000000      0.000000      0.000000      0.000000   \n",
      "\n",
      "   kwtopic_20_5  kwtopic_20_6  kwtopic_20_7  kwtopic_20_8  kwtopic_20_9  \\\n",
      "0      0.025000      0.025000      0.025000      0.025000      0.025000   \n",
      "1      0.025000      0.025000      0.025000      0.524998      0.025000   \n",
      "2      0.298687      0.010001      0.010001      0.010001      0.010001   \n",
      "3      0.010000      0.010000      0.010000      0.010000      0.010000   \n",
      "4      0.254181      0.000000      0.000000      0.000000      0.000000   \n",
      "\n",
      "   kwtopic_20_10  kwtopic_20_11  kwtopic_20_12  kwtopic_20_13  kwtopic_20_14  \\\n",
      "0       0.025000       0.524997       0.025000       0.025000       0.025000   \n",
      "1       0.025000       0.025000       0.025000       0.025000       0.025000   \n",
      "2       0.010001       0.301208       0.010001       0.010001       0.010001   \n",
      "3       0.010000       0.010000       0.010000       0.010000       0.010000   \n",
      "4       0.000000       0.000000       0.000000       0.000000       0.000000   \n",
      "\n",
      "   kwtopic_20_15  kwtopic_20_16  kwtopic_20_17  kwtopic_20_18  kwtopic_20_19  \n",
      "0       0.025000       0.025000       0.025000       0.025000       0.025000  \n",
      "1       0.025000       0.025000       0.025000       0.025000       0.025000  \n",
      "2       0.010001       0.010001       0.010001       0.010001       0.010001  \n",
      "3       0.010000       0.809994       0.010000       0.010000       0.010000  \n",
      "4       0.000000       0.617235       0.000000       0.000000       0.000000  \n",
      "Distributions computed\n",
      "Dict created\n",
      "Array created\n",
      "DF created\n",
      "   titletopic_5_0  titletopic_5_1  titletopic_5_2  titletopic_5_3  \\\n",
      "0        0.040489        0.439692        0.199686        0.040568   \n",
      "1        0.942662        0.014318        0.014353        0.014362   \n",
      "2        0.066691        0.067583        0.066717        0.732290   \n",
      "3        0.942585        0.014346        0.014352        0.014375   \n",
      "4        0.038673        0.841598        0.039449        0.038729   \n",
      "\n",
      "   titletopic_5_4  \n",
      "0        0.279565  \n",
      "1        0.014305  \n",
      "2        0.066719  \n",
      "3        0.014342  \n",
      "4        0.041551  \n",
      "Distributions computed\n",
      "Dict created\n",
      "Array created\n",
      "DF created\n",
      "   titletopic_10_0  titletopic_10_1  titletopic_10_2  titletopic_10_3  \\\n",
      "0         0.442338         0.020087         0.020087         0.020087   \n",
      "1         0.505449         0.000000         0.000000         0.000000   \n",
      "2         0.033345         0.033345         0.033345         0.033345   \n",
      "3         0.518380         0.000000         0.424319         0.000000   \n",
      "4         0.745340         0.018217         0.018217         0.018227   \n",
      "\n",
      "   titletopic_10_4  titletopic_10_5  titletopic_10_6  titletopic_10_7  \\\n",
      "0         0.396966         0.020087         0.020087         0.020087   \n",
      "1         0.000000         0.437364         0.000000         0.000000   \n",
      "2         0.033345         0.033346         0.699895         0.033345   \n",
      "3         0.000000         0.000000         0.000000         0.000000   \n",
      "4         0.018222         0.018217         0.018224         0.018217   \n",
      "\n",
      "   titletopic_10_8  titletopic_10_9  \n",
      "0         0.020087         0.020087  \n",
      "1         0.000000         0.000000  \n",
      "2         0.033345         0.033346  \n",
      "3         0.000000         0.000000  \n",
      "4         0.108904         0.018217  \n",
      "Distributions computed\n",
      "Dict created\n",
      "Array created\n",
      "DF created\n",
      "   titletopic_15_0  titletopic_15_1  titletopic_15_2  titletopic_15_3  \\\n",
      "0         0.138950         0.013363         0.013363         0.013363   \n",
      "1         0.000000         0.000000         0.000000         0.000000   \n",
      "2         0.022228         0.022228         0.022228         0.022228   \n",
      "3         0.000000         0.000000         0.000000         0.000000   \n",
      "4         0.692024         0.011392         0.011392         0.011392   \n",
      "\n",
      "   titletopic_15_4  titletopic_15_5  titletopic_15_6  titletopic_15_7  \\\n",
      "0         0.013363         0.013363         0.013363         0.013363   \n",
      "1         0.334393         0.000000         0.000000         0.000000   \n",
      "2         0.022228         0.022228         0.022228         0.022228   \n",
      "3         0.502048         0.000000         0.000000         0.000000   \n",
      "4         0.011392         0.011392         0.011392         0.011392   \n",
      "\n",
      "   titletopic_15_8  titletopic_15_9  titletopic_15_10  titletopic_15_11  \\\n",
      "0         0.013363         0.013363          0.013363          0.687334   \n",
      "1         0.000000         0.518861          0.000000          0.000000   \n",
      "2         0.022228         0.022228          0.022228          0.688809   \n",
      "3         0.000000         0.435830          0.000000          0.000000   \n",
      "4         0.011392         0.011392          0.011392          0.011392   \n",
      "\n",
      "   titletopic_15_12  titletopic_15_13  titletopic_15_14  \n",
      "0          0.013363          0.013363          0.013363  \n",
      "1          0.089480          0.000000          0.000000  \n",
      "2          0.022228          0.022228          0.022228  \n",
      "3          0.000000          0.000000          0.000000  \n",
      "4          0.159886          0.011392          0.011392  \n",
      "Distributions computed\n",
      "Dict created\n",
      "Array created\n",
      "DF created\n",
      "   titletopic_20_0  titletopic_20_1  titletopic_20_2  titletopic_20_3  \\\n",
      "0         0.010038         0.204437         0.010038         0.010038   \n",
      "1         0.123147         0.000000         0.000000         0.000000   \n",
      "2         0.016669         0.016669         0.016669         0.016669   \n",
      "3         0.000000         0.000000         0.000000         0.000000   \n",
      "4         0.000000         0.000000         0.000000         0.841510   \n",
      "\n",
      "   titletopic_20_4  titletopic_20_5  titletopic_20_6  titletopic_20_7  \\\n",
      "0         0.010038         0.010038         0.010038         0.010038   \n",
      "1         0.000000         0.000000         0.000000         0.000000   \n",
      "2         0.349954         0.016669         0.016669         0.016669   \n",
      "3         0.000000         0.000000         0.000000         0.000000   \n",
      "4         0.000000         0.000000         0.000000         0.000000   \n",
      "\n",
      "   titletopic_20_8  titletopic_20_9  titletopic_20_10  titletopic_20_11  \\\n",
      "0         0.010038         0.010038          0.216471          0.010038   \n",
      "1         0.000000         0.000000          0.000000          0.000000   \n",
      "2         0.016669         0.016669          0.350000          0.016669   \n",
      "3         0.000000         0.000000          0.000000          0.000000   \n",
      "4         0.000000         0.000000          0.000000          0.000000   \n",
      "\n",
      "   titletopic_20_12  titletopic_20_13  titletopic_20_14  titletopic_20_15  \\\n",
      "0          0.209878          0.010038          0.010038          0.010038   \n",
      "1          0.000000          0.000000          0.000000          0.000000   \n",
      "2          0.016669          0.016669          0.016669          0.016669   \n",
      "3          0.000000          0.000000          0.082162          0.000000   \n",
      "4          0.000000          0.000000          0.000000          0.000000   \n",
      "\n",
      "   titletopic_20_16  titletopic_20_17  titletopic_20_18  titletopic_20_19  \n",
      "0          0.010038          0.010038          0.208602          0.010038  \n",
      "1          0.000000          0.000000          0.000000          0.812363  \n",
      "2          0.016669          0.016669          0.016669          0.016669  \n",
      "3          0.000000          0.000000          0.000000          0.853389  \n",
      "4          0.000000          0.000000          0.000000          0.000000  \n",
      "Distributions computed\n",
      "Dict created\n",
      "Array created\n",
      "DF created\n",
      "   titletopic_5_0  titletopic_5_1  titletopic_5_2  titletopic_5_3  \\\n",
      "0        0.278274        0.251740        0.041275        0.388489   \n",
      "1        0.051339        0.051008        0.305629        0.540949   \n",
      "2        0.040209        0.837394        0.040058        0.042033   \n",
      "3        0.033665        0.033697        0.033589        0.865280   \n",
      "4        0.028697        0.028868        0.028781        0.884908   \n",
      "\n",
      "   titletopic_5_4  \n",
      "0        0.040223  \n",
      "1        0.051075  \n",
      "2        0.040306  \n",
      "3        0.033769  \n",
      "4        0.028746  \n",
      "Distributions computed\n",
      "Dict created\n",
      "Array created\n",
      "DF created\n",
      "   desctopic_5_0  desctopic_5_1  desctopic_5_2  desctopic_5_3  desctopic_5_4\n",
      "0       0.022835       0.276440       0.022358       0.655505       0.022862\n",
      "1       0.317102       0.275468       0.040533       0.040342       0.326554\n",
      "2       0.000000       0.000000       0.205352       0.270206       0.507991\n",
      "3       0.041042       0.040186       0.041261       0.041909       0.835602\n",
      "4       0.836334       0.040206       0.040404       0.041195       0.041862\n",
      "Distributions computed\n",
      "Dict created\n",
      "Array created\n",
      "DF created\n",
      "   kwtopic_5_0  kwtopic_5_1  kwtopic_5_2  kwtopic_5_3  kwtopic_5_4\n",
      "0     0.050192     0.797783     0.051470     0.050319     0.050235\n",
      "1     0.547170     0.363856     0.029305     0.029688     0.029981\n",
      "2     0.028763     0.029507     0.883421     0.029653     0.028656\n",
      "3     0.066875     0.067366     0.731994     0.066982     0.066784\n",
      "4     0.015475     0.937524     0.015973     0.015593     0.015435\n",
      "Distributions computed\n",
      "Dict created\n",
      "Array created\n",
      "DF created\n",
      "   titletopic_10_0  titletopic_10_1  titletopic_10_2  titletopic_10_3  \\\n",
      "0         0.020011         0.020010         0.020011         0.020010   \n",
      "1         0.025019         0.025017         0.025021         0.025018   \n",
      "2         0.020025         0.020026         0.274406         0.020025   \n",
      "3         0.016668         0.016669         0.016668         0.016669   \n",
      "4         0.014287         0.014287         0.014287         0.014287   \n",
      "\n",
      "   titletopic_10_4  titletopic_10_5  titletopic_10_6  titletopic_10_7  \\\n",
      "0         0.020010         0.020011         0.020009         0.020009   \n",
      "1         0.025021         0.322864         0.025016         0.025017   \n",
      "2         0.020033         0.020028         0.020026         0.020026   \n",
      "3         0.016669         0.016669         0.016669         0.016669   \n",
      "4         0.014287         0.014287         0.014287         0.014287   \n",
      "\n",
      "   titletopic_10_8  titletopic_10_9  \n",
      "0         0.819910         0.020010  \n",
      "1         0.025026         0.476980  \n",
      "2         0.565380         0.020025  \n",
      "3         0.849981         0.016669  \n",
      "4         0.871419         0.014287  \n",
      "Distributions computed\n",
      "Dict created\n",
      "Array created\n",
      "DF created\n",
      "   desctopic_10_0  desctopic_10_1  desctopic_10_2  desctopic_10_3  \\\n",
      "0        0.011125        0.011124        0.011125        0.011124   \n",
      "1        0.020014        0.020015        0.412880        0.224201   \n",
      "2        0.000000        0.000000        0.281223        0.000000   \n",
      "3        0.020003        0.542272        0.020007        0.020001   \n",
      "4        0.020002        0.020001        0.020004        0.020001   \n",
      "\n",
      "   desctopic_10_4  desctopic_10_5  desctopic_10_6  desctopic_10_7  \\\n",
      "0        0.011124        0.011125        0.650922        0.011124   \n",
      "1        0.020010        0.020012        0.020011        0.020010   \n",
      "2        0.000000        0.000000        0.479169        0.157210   \n",
      "3        0.020002        0.020002        0.297705        0.020003   \n",
      "4        0.020001        0.020002        0.819984        0.020003   \n",
      "\n",
      "   desctopic_10_8  desctopic_10_9  \n",
      "0        0.011124        0.260085  \n",
      "1        0.020012        0.222835  \n",
      "2        0.058339        0.000000  \n",
      "3        0.020002        0.020003  \n",
      "4        0.020002        0.020001  \n",
      "Distributions computed\n",
      "Dict created\n",
      "Array created\n",
      "DF created\n",
      "   kwtopic_10_0  kwtopic_10_1  kwtopic_10_2  kwtopic_10_3  kwtopic_10_4  \\\n",
      "0      0.774943      0.025006      0.025005      0.025012      0.025005   \n",
      "1      0.014303      0.014298      0.014299      0.338224      0.014300   \n",
      "2      0.014292      0.014293      0.014291      0.693868      0.014290   \n",
      "3      0.699979      0.033336      0.033336      0.033340      0.033334   \n",
      "4      0.930755      0.000000      0.000000      0.000000      0.000000   \n",
      "\n",
      "   kwtopic_10_5  kwtopic_10_6  kwtopic_10_7  kwtopic_10_8  kwtopic_10_9  \n",
      "0      0.025005      0.025006      0.025007      0.025005      0.025006  \n",
      "1      0.014298      0.014300      0.014301      0.429431      0.132247  \n",
      "2      0.014290      0.014291      0.191802      0.014290      0.014291  \n",
      "3      0.033334      0.033335      0.033337      0.033334      0.033335  \n",
      "4      0.000000      0.000000      0.000000      0.000000      0.000000  \n",
      "Distributions computed\n",
      "Dict created\n",
      "Array created\n",
      "DF created\n",
      "   titletopic_15_0  titletopic_15_1  titletopic_15_2  titletopic_15_3  \\\n",
      "0         0.013337         0.013337         0.013337         0.013338   \n",
      "1         0.016670         0.016670         0.016670         0.016670   \n",
      "2         0.013352         0.013352         0.013352         0.013352   \n",
      "3         0.011113         0.011113         0.011113         0.011113   \n",
      "4         0.000000         0.000000         0.000000         0.000000   \n",
      "\n",
      "   titletopic_15_4  titletopic_15_5  titletopic_15_6  titletopic_15_7  \\\n",
      "0         0.013337         0.013337         0.013338         0.013337   \n",
      "1         0.016670         0.016670         0.016670         0.016670   \n",
      "2         0.013352         0.013352         0.475301         0.013352   \n",
      "3         0.011113         0.011113         0.011113         0.011113   \n",
      "4         0.000000         0.000000         0.866662         0.000000   \n",
      "\n",
      "   titletopic_15_8  titletopic_15_9  titletopic_15_10  titletopic_15_11  \\\n",
      "0         0.013337         0.813275          0.013337          0.013337   \n",
      "1         0.016670         0.766614          0.016670          0.016670   \n",
      "2         0.013352         0.013352          0.351121          0.013352   \n",
      "3         0.011113         0.011113          0.011113          0.011113   \n",
      "4         0.000000         0.000000          0.000000          0.000000   \n",
      "\n",
      "   titletopic_15_12  titletopic_15_13  titletopic_15_14  \n",
      "0          0.013337          0.013337          0.013337  \n",
      "1          0.016670          0.016670          0.016670  \n",
      "2          0.013352          0.013352          0.013352  \n",
      "3          0.844416          0.011113          0.011113  \n",
      "4          0.000000          0.000000          0.000000  \n",
      "Distributions computed\n",
      "Dict created\n",
      "Array created\n",
      "DF created\n",
      "   desctopic_15_0  desctopic_15_1  desctopic_15_2  desctopic_15_3  \\\n",
      "0        0.000000        0.000000        0.000000        0.000000   \n",
      "1        0.357951        0.013340        0.013340        0.013340   \n",
      "2        0.000000        0.000000        0.000000        0.000000   \n",
      "3        0.013334        0.013334        0.013334        0.013334   \n",
      "4        0.013334        0.013334        0.013334        0.013334   \n",
      "\n",
      "   desctopic_15_4  desctopic_15_5  desctopic_15_6  desctopic_15_7  \\\n",
      "0        0.000000        0.000000        0.000000        0.000000   \n",
      "1        0.013340        0.013340        0.214038        0.013340   \n",
      "2        0.125792        0.000000        0.000000        0.130816   \n",
      "3        0.013334        0.013334        0.013334        0.813325   \n",
      "4        0.813326        0.013334        0.013334        0.013334   \n",
      "\n",
      "   desctopic_15_8  desctopic_15_9  desctopic_15_10  desctopic_15_11  \\\n",
      "0        0.000000        0.000000         0.000000         0.000000   \n",
      "1        0.013340        0.013340         0.013340         0.013340   \n",
      "2        0.000000        0.000000         0.711362         0.000000   \n",
      "3        0.013334        0.013334         0.013334         0.013334   \n",
      "4        0.013334        0.013334         0.013334         0.013334   \n",
      "\n",
      "   desctopic_15_12  desctopic_15_13  desctopic_15_14  \n",
      "0         0.000000         0.000000         0.896271  \n",
      "1         0.013340         0.013340         0.267928  \n",
      "2         0.000000         0.000000         0.000000  \n",
      "3         0.013334         0.013334         0.013334  \n",
      "4         0.013334         0.013334         0.013334  \n",
      "Distributions computed\n",
      "Dict created\n",
      "Array created\n",
      "DF created\n",
      "   kwtopic_15_0  kwtopic_15_1  kwtopic_15_2  kwtopic_15_3  kwtopic_15_4  \\\n",
      "0      0.016673      0.016673      0.365513      0.417731      0.016674   \n",
      "1      0.000000      0.000000      0.314493      0.000000      0.000000   \n",
      "2      0.000000      0.000000      0.866641      0.000000      0.000000   \n",
      "3      0.022222      0.022222      0.022222      0.022222      0.022222   \n",
      "4      0.000000      0.000000      0.928203      0.000000      0.000000   \n",
      "\n",
      "   kwtopic_15_5  kwtopic_15_6  kwtopic_15_7  kwtopic_15_8  kwtopic_15_9  \\\n",
      "0      0.016674      0.016673      0.016674      0.016673      0.016674   \n",
      "1      0.000000      0.000000      0.000000      0.000000      0.000000   \n",
      "2      0.000000      0.000000      0.000000      0.000000      0.000000   \n",
      "3      0.688888      0.022222      0.022222      0.022222      0.022222   \n",
      "4      0.000000      0.000000      0.000000      0.000000      0.000000   \n",
      "\n",
      "   kwtopic_15_10  kwtopic_15_11  kwtopic_15_12  kwtopic_15_13  kwtopic_15_14  \n",
      "0       0.016673       0.016674       0.016673       0.016673       0.016673  \n",
      "1       0.000000       0.288009       0.000000       0.283075       0.000000  \n",
      "2       0.000000       0.000000       0.000000       0.000000       0.000000  \n",
      "3       0.022222       0.022222       0.022222       0.022222       0.022222  \n",
      "4       0.000000       0.000000       0.000000       0.000000       0.000000  \n",
      "Distributions computed\n",
      "Dict created\n",
      "Array created\n",
      "DF created\n",
      "   titletopic_20_0  titletopic_20_1  titletopic_20_2  titletopic_20_3  \\\n",
      "0         0.010012         0.010012         0.010012         0.010012   \n",
      "1         0.012501         0.012501         0.012501         0.012501   \n",
      "2         0.010005         0.010005         0.010005         0.010005   \n",
      "3         0.000000         0.000000         0.000000         0.000000   \n",
      "4         0.000000         0.000000         0.000000         0.000000   \n",
      "\n",
      "   titletopic_20_4  titletopic_20_5  titletopic_20_6  titletopic_20_7  \\\n",
      "0         0.010012         0.010012         0.202923         0.010012   \n",
      "1         0.012501         0.012501         0.012501         0.012501   \n",
      "2         0.010005         0.010005         0.010005         0.010005   \n",
      "3         0.841657         0.000000         0.000000         0.000000   \n",
      "4         0.000000         0.000000         0.000000         0.000000   \n",
      "\n",
      "   titletopic_20_8  titletopic_20_9  titletopic_20_10  titletopic_20_11  \\\n",
      "0         0.010012         0.213623          0.010012          0.010012   \n",
      "1         0.012501         0.012501          0.012501          0.012501   \n",
      "2         0.585540         0.010005          0.010005          0.010005   \n",
      "3         0.000000         0.000000          0.000000          0.000000   \n",
      "4         0.000000         0.000000          0.000000          0.000000   \n",
      "\n",
      "   titletopic_20_12  titletopic_20_13  titletopic_20_14  titletopic_20_15  \\\n",
      "0          0.010012          0.010012          0.010012          0.010012   \n",
      "1          0.012501          0.012501          0.012501          0.012501   \n",
      "2          0.010005          0.010005          0.010005          0.010005   \n",
      "3          0.000000          0.000000          0.000000          0.000000   \n",
      "4          0.000000          0.000000          0.000000          0.000000   \n",
      "\n",
      "   titletopic_20_16  titletopic_20_17  titletopic_20_18  titletopic_20_19  \n",
      "0          0.010012          0.010012          0.010012          0.413248  \n",
      "1          0.012501          0.012501          0.762472          0.012501  \n",
      "2          0.010005          0.010005          0.010005          0.234365  \n",
      "3          0.000000          0.000000          0.000000          0.000000  \n",
      "4          0.000000          0.000000          0.000000          0.864284  \n",
      "Distributions computed\n",
      "Dict created\n",
      "Array created\n",
      "DF created\n",
      "   desctopic_20_0  desctopic_20_1  desctopic_20_2  desctopic_20_3  \\\n",
      "0        0.000000        0.000000        0.000000        0.000000   \n",
      "1        0.010002        0.010002        0.409914        0.010002   \n",
      "2        0.000000        0.000000        0.000000        0.000000   \n",
      "3        0.010000        0.010000        0.010000        0.010000   \n",
      "4        0.010000        0.010000        0.010000        0.010000   \n",
      "\n",
      "   desctopic_20_4  desctopic_20_5  desctopic_20_6  desctopic_20_7  \\\n",
      "0        0.000000         0.00000        0.000000        0.000000   \n",
      "1        0.010002         0.20212        0.010002        0.010002   \n",
      "2        0.000000         0.00000        0.000000        0.000000   \n",
      "3        0.010000         0.01000        0.010000        0.010000   \n",
      "4        0.010000         0.01000        0.010000        0.010000   \n",
      "\n",
      "   desctopic_20_8  desctopic_20_9  desctopic_20_10  desctopic_20_11  \\\n",
      "0        0.000000        0.000000         0.638586         0.000000   \n",
      "1        0.010002        0.010002         0.010002         0.010002   \n",
      "2        0.000000        0.000000         0.000000         0.057619   \n",
      "3        0.010000        0.010000         0.010000         0.010000   \n",
      "4        0.010000        0.010000         0.809993         0.010000   \n",
      "\n",
      "   desctopic_20_12  desctopic_20_13  desctopic_20_14  desctopic_20_15  \\\n",
      "0         0.000000         0.000000         0.000000         0.261329   \n",
      "1         0.010002         0.217936         0.010002         0.010002   \n",
      "2         0.000000         0.000000         0.000000         0.473307   \n",
      "3         0.010000         0.010000         0.010000         0.010000   \n",
      "4         0.010000         0.010000         0.010000         0.010000   \n",
      "\n",
      "   desctopic_20_16  desctopic_20_17  desctopic_20_18  desctopic_20_19  \n",
      "0         0.000000         0.000000         0.000000         0.000000  \n",
      "1         0.010002         0.010002         0.010002         0.010002  \n",
      "2         0.000000         0.000000         0.435039         0.000000  \n",
      "3         0.010000         0.010000         0.809992         0.010000  \n",
      "4         0.010000         0.010000         0.010000         0.010000  \n",
      "Distributions computed\n",
      "Dict created\n",
      "Array created\n",
      "DF created\n",
      "   kwtopic_20_0  kwtopic_20_1  kwtopic_20_2  kwtopic_20_3  kwtopic_20_4  \\\n",
      "0      0.012502      0.012502      0.012502      0.339635      0.435336   \n",
      "1      0.000000      0.000000      0.000000      0.000000      0.864264   \n",
      "2      0.000000      0.193036      0.000000      0.528339      0.000000   \n",
      "3      0.016667      0.016667      0.016667      0.683333      0.016667   \n",
      "4      0.000000      0.000000      0.000000      0.926921      0.000000   \n",
      "\n",
      "   kwtopic_20_5  kwtopic_20_6  kwtopic_20_7  kwtopic_20_8  kwtopic_20_9  \\\n",
      "0      0.012502      0.012502      0.012502      0.012502      0.012502   \n",
      "1      0.000000      0.000000      0.000000      0.000000      0.000000   \n",
      "2      0.000000      0.157143      0.000000      0.000000      0.000000   \n",
      "3      0.016667      0.016667      0.016667      0.016667      0.016667   \n",
      "4      0.000000      0.000000      0.000000      0.000000      0.000000   \n",
      "\n",
      "   kwtopic_20_10  kwtopic_20_11  kwtopic_20_12  kwtopic_20_13  kwtopic_20_14  \\\n",
      "0       0.012502       0.012502       0.012502       0.012502       0.012502   \n",
      "1       0.000000       0.000000       0.000000       0.000000       0.000000   \n",
      "2       0.000000       0.000000       0.000000       0.000000       0.000000   \n",
      "3       0.016667       0.016667       0.016667       0.016667       0.016667   \n",
      "4       0.000000       0.000000       0.000000       0.000000       0.000000   \n",
      "\n",
      "   kwtopic_20_15  kwtopic_20_16  kwtopic_20_17  kwtopic_20_18  kwtopic_20_19  \n",
      "0       0.012502       0.012502       0.012502       0.012502       0.012502  \n",
      "1       0.000000       0.000000       0.000000       0.000000       0.000000  \n",
      "2       0.000000       0.000000       0.000000       0.000000       0.000000  \n",
      "3       0.016667       0.016667       0.016667       0.016667       0.016667  \n",
      "4       0.000000       0.000000       0.000000       0.000000       0.000000  \n"
     ]
    }
   ],
   "source": [
    "for dataset in all_datasets:\n",
    "    if dataset == \"textlab_10\":\n",
    "        data_prefixes = [\"textlab_10_title\",\"textlab_10_desc\",\"textlab_10_kw\"]\n",
    "    elif dataset == \"textlab_30\":\n",
    "        data_prefixes = [\"textlab_30_title\"]\n",
    "    elif dataset == \"ipeirotis\":\n",
    "        data_prefixes = [\"ipeirotis_title\",\"ipeirotis_desc\",\"ipeirotis_kw\"]\n",
    "\n",
    "    for K in K_vals:\n",
    "        for data_prefix in data_prefixes:\n",
    "            computeLDA(K, data_prefix)\n",
    "            getTopicDistributions(K, data_prefix)\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e46f6815-3949-4215-b4b2-7d836b67a293",
   "metadata": {},
   "source": [
    "### （四）进行机器学习前的准备工作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "b694fba3-6ad9-4118-bd6f-1fd8f56e247f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from scipy.sparse import hstack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "a62e6e17-54d7-4088-abfa-0ca9efa637ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictive_path = os.path.join('.', 'predictive_feats')\n",
    "ml_input_path = os.path.join('.', 'ml_input')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c9b8d7-a640-439a-ada9-e86f2ed605dd",
   "metadata": {},
   "source": [
    "#### 1、数据加载与数据集分割"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "6db85448-e0fd-43cf-8f33-98946bed3c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadCleanedData(dataset):\n",
    "    if dataset == \"textlab_30\":\n",
    "        hit_df = pd.read_pickle(os.path.join(cleaned_path, \"textlab_30_cleaned.pkl\"))\n",
    "        hit_df[\"title\"] = hit_df[\"title\"].astype(str)\n",
    "    elif dataset == \"textlab_10\":\n",
    "        hit_df = pd.read_pickle(os.path.join(cleaned_path, \"textlab_10_cleaned.pkl\"))\n",
    "        hit_df[\"description\"] = hit_df[\"description\"].astype(str)\n",
    "        hit_df[\"title\"] = hit_df[\"title\"].astype(str)\n",
    "    elif dataset == \"ipeirotis\":\n",
    "        hit_df = pd.read_pickle(os.path.join(cleaned_path, \"ipeirotis_cleaned.pkl\"))\n",
    "        hit_df[\"description\"] = hit_df[\"description\"].astype(str)\n",
    "        hit_df[\"title\"] = hit_df[\"title\"].astype(str)\n",
    "    \n",
    "    # 计算报酬与均值的差\n",
    "    hit_df[\"req_mean_reward\"] = hit_df.groupby(\"requester_id\")[\"reward\"].transform(\"mean\")\n",
    "    hit_df[\"log_req_mean_reward\"] = hit_df[\"req_mean_reward\"].apply(np.log)\n",
    "    hit_df[\"meandiff_lreward\"] = hit_df[\"log_reward\"] - hit_df[\"log_req_mean_reward\"]\n",
    "\n",
    "    # 计算回应时间与均值的差\n",
    "    hit_df[\"req_mean_dur\"] = hit_df.groupby(\"requester_id\")[\"duration\"].transform(\"mean\")\n",
    "    hit_df[\"log_req_mean_dur\"] = hit_df[\"req_mean_dur\"].apply(np.log)\n",
    "    hit_df[\"meandiff_ldur\"] = hit_df[\"log_duration\"] - hit_df[\"log_req_mean_dur\"]\n",
    "    return hit_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "b862fb00-5bb6-4254-8bf1-692489394410",
   "metadata": {},
   "outputs": [],
   "source": [
    "def partitionData(hit_df):\n",
    "    ## 为测试集和训练集的分割生成索引\n",
    "    hit_df[\"group_num\"] = range(0,len(hit_df))\n",
    "\n",
    "    # 将数据集均分为 A 和 B，详见：\n",
    "    #http://stackoverflow.com/questions/24147278/how-do-i-create-test-and-train-samples-from-one-dataframe-with-pandas\n",
    "    test_prop = 0.5\n",
    "    all_indices = hit_df[\"group_num\"].tolist()\n",
    "    A_ind, B_ind = train_test_split(all_indices, test_size=test_prop, random_state=48)\n",
    "    print(\"# A obs: \" + str(len(A_ind)))\n",
    "    print(\"# B obs: \" + str(len(B_ind)))\n",
    "\n",
    "    # 将两个数据集中的每一个再次细分训练集和测试集\n",
    "    # 此处测试集用作学习文本特征\n",
    "    validation_prop = 0.2\n",
    "    A_train_ind, A_val_ind = train_test_split(A_ind, test_size=validation_prop, random_state=49)\n",
    "    B_train_ind, B_val_ind = train_test_split(B_ind, test_size=validation_prop, random_state=50)\n",
    "\n",
    "    print(\"# A_train obs: \" + str(len(A_train_ind)))\n",
    "    print(\"# A_val obs: \" + str(len(A_val_ind)))\n",
    "    print(\"# B_train obs: \" + str(len(B_train_ind)))\n",
    "    print(\"# B_val obs: \" + str(len(B_val_ind)))\n",
    "    return {'A':A_ind,'B':B_ind,'A_train':A_train_ind,'A_val':A_val_ind,'B_train':B_train_ind,'B_val':B_val_ind}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da1cc8e-ddc3-4f81-b4de-1726a341cf0b",
   "metadata": {},
   "source": [
    "#### 2、数值特征提取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "4a219644-bfa0-4667-80cb-eca6aec43a4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:9: SyntaxWarning: invalid escape sequence '\\?'\n",
      "<>:57: SyntaxWarning: invalid escape sequence '\\|'\n",
      "<>:9: SyntaxWarning: invalid escape sequence '\\?'\n",
      "<>:57: SyntaxWarning: invalid escape sequence '\\|'\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\2253851036.py:9: SyntaxWarning: invalid escape sequence '\\?'\n",
      "  \"improve\":\"improve\",\"five\":\"five|5\",\"questionmark\":\"\\?\",\"exclamation\":\"!\"}\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\2253851036.py:57: SyntaxWarning: invalid escape sequence '\\|'\n",
      "  list_sep = \"\\|\"\n"
     ]
    }
   ],
   "source": [
    "def generateNumericFeatures(hit_df, dataset, mode, partition):\n",
    "    # Vars 为特征提取准备\n",
    "    # indicative_map.将关键词简化或映射到正则表达式\n",
    "    # \"only\" 表示仅限于某个组\n",
    "    indicative_map = {\"easy\":\"easy\",\"transcribe\":\"transcr\",\n",
    "                      \"writing\":\"writ\",\"audio\":\"audio\",\"image\":\"image|picture\",\"video\":\"video\",\"bonus\":\"bonus\",\n",
    "                     \"copy\":\"copy\",\"search\":\"search\",\"identify\":\"ident\",\"text\":\"text\",\n",
    "                     \"date\":\"date\",\"fun\":\"fun\",\"simple\":\"simpl\",\"summarize\":\"summar\",\"only\":\"only\",\n",
    "                     \"improve\":\"improve\",\"five\":\"five|5\",\"questionmark\":\"\\?\",\"exclamation\":\"!\"}\n",
    "\n",
    "    # 从 .csv 文件里加载特征\n",
    "    desc_top = {}\n",
    "    title_top = {}\n",
    "    kw_top = {}\n",
    "    # 提取字符串中引号内的内容，(.+)匹配任意长度字符\n",
    "    feature_reg = r'\\\"(.+)\\\"'\n",
    "    def updateFeatureDict(feature_list, feature_source):\n",
    "        for feature_num, cur_feature in enumerate(feature_list):\n",
    "            if feature_num >= 100:\n",
    "                # 仅保留前 100 特征\n",
    "                break\n",
    "            feature_str = re.findall(feature_reg, cur_feature)[0]\n",
    "            feature_suffix = feature_source + str(feature_num)\n",
    "            # endswith检查字符串是否以指定后缀结束\n",
    "            if cur_feature.endswith(\"description\"):\n",
    "                desc_top[feature_suffix] = feature_str\n",
    "            elif cur_feature.endswith(\"title\"):\n",
    "                title_top[feature_suffix] = feature_str\n",
    "            else:\n",
    "                kw_top[feature_suffix] = feature_str\n",
    "                \n",
    "    # mode_order只有 \"ab\" 或 \"ba\"\n",
    "    mode_order = mode[-2:]\n",
    "    rew_feat_df = pd.read_csv(os.path.join(predictive_path, \n",
    "            \"./predictive_\" + dataset + \"_gram\" + mode_order + \"_rew.csv\"))\n",
    "    rew_feat_list = rew_feat_df[\"feature\"].tolist()\n",
    "    updateFeatureDict(rew_feat_list, \"r\")\n",
    "\n",
    "    dur_feat_df = pd.read_csv(os.path.join(predictive_path, \n",
    "            \"./predictive_\" + dataset + \"_gram\" + mode_order + \"_dur.csv\"))\n",
    "    dur_feat_list = dur_feat_df[\"feature\"].tolist()\n",
    "    updateFeatureDict(dur_feat_list, \"d\")\n",
    "\n",
    "    print(\"Number of description features: \" + str(len(desc_top)))\n",
    "    print(\"Number of title features: \" + str(len(title_top)))\n",
    "    print(\"Number of keyword features: \" + str(len(kw_top)))\n",
    "\n",
    "    gadiraju_map = {\"find\":\"find\", \"check\":\"check\", \"match\":\"match\", \"choose\":\"choose\", \"categorize\":\"categor\",\n",
    "                    \"suggest\":\"suggest\",\"translate\":\"translat\",\"survey\":\"survey\",\"click\":\"click\",\"link\":\"link\",\n",
    "                   \"read\":\"read\"}\n",
    "    gadiraju_categories = {'IF':['find'], 'VV':[\"check\",\"match\"], 'IA':['choose','categorize'],\n",
    "                            'CC':['suggest','translate'], 'S':['survey'], 'CA':['click','link','read']}\n",
    "    \n",
    "\n",
    "    # 将其两个字典组合\n",
    "    indicative_map.update(gadiraju_map)\n",
    "    # 设定正则表达式\n",
    "    if dataset == \"textlab_10\":\n",
    "        list_sep = \"\\|\"\n",
    "    else:\n",
    "        list_sep = \"',\"\n",
    "\n",
    "    ## 实际计算\n",
    "    # 将时间统计解析到分钟\n",
    "    parseTimes(hit_df, dataset)\n",
    "    # 为特征构建一个新的dataframe\n",
    "    feature_df = hit_df[[\"duration\",\"log_duration\",\"reward\",\"log_reward\",\n",
    "                         \"meandiff_lreward\",\"meandiff_ldur\",\"time_allotted\"]].copy()\n",
    "    computeSimpleFeatures(hit_df, feature_df, dataset, list_sep)\n",
    "    computeIndicatorFeatures(hit_df, feature_df, dataset, indicative_map, \n",
    "        gadiraju_categories, desc_top, title_top, kw_top)\n",
    "    if dataset == \"ipeirotis\":\n",
    "        computeQualificationFeatures(hit_df, feature_df, list_sep)\n",
    "    mergeLDA(feature_df, dataset)\n",
    "    mergeDoc2Vec(feature_df, dataset)\n",
    "    checkNulls(feature_df)\n",
    "    fixNulls(feature_df)\n",
    "\n",
    "    # 创建用来训练检验的数据集\n",
    "    if mode.endswith(\"ab\"):\n",
    "        train_df = feature_df.iloc[partition['A']]\n",
    "        test_df = feature_df.iloc[partition['B']]\n",
    "    else:\n",
    "        train_df = feature_df.iloc[partition['B']]\n",
    "        test_df = feature_df.iloc[partition['A']]\n",
    "    # 这里定义一下后面将要舍弃的非特征列\n",
    "    drop_cols = [\"group_id\",\"reward\",\"log_reward\",\"duration\",\"log_duration\",\"meandiff_lreward\",\n",
    "             \"meandiff_ldur\"]\n",
    "\n",
    "    ## 数据训练\n",
    "    # Training data: y1(rewards)\n",
    "    train_labels_rew = train_df[\"log_reward\"]\n",
    "    train_rewards_filename = os.path.join(ml_input_path, \n",
    "        \"./train_rew_\" + dataset + \"_\" + str(mode) + \".pkl\")\n",
    "    train_labels_rew.to_pickle(train_rewards_filename)\n",
    "    print(\"Train rewards saved to \" + train_rewards_filename)\n",
    "\n",
    "    ## Training data: y2(duration)\n",
    "    train_labels_dur = train_df[\"log_duration\"]\n",
    "    train_durations_filename = os.path.join(ml_input_path,\n",
    "        \"./train_dur_\" + dataset + \"_\" + str(mode) + \".pkl\")\n",
    "    train_labels_dur.to_pickle(train_durations_filename)\n",
    "    print(\"Train durations saved to \" + train_durations_filename)\n",
    "\n",
    "    ## Training data: 数字特征\n",
    "    train_features_filename = os.path.join(ml_input_path,\n",
    "        \"./train_feats_\" + dataset + \"_\" + str(mode) + \".pkl\")\n",
    "\n",
    "    # 去掉不需要的列\n",
    "    for col_name in drop_cols:\n",
    "        if col_name in train_df:\n",
    "            train_df.drop([col_name],axis=1,inplace=True)\n",
    "    joblib.dump(train_df.columns, os.path.join(ml_input_path,\n",
    "        \"./feat_names_\" + dataset + \"_\" + str(mode) + \".pkl\"))\n",
    "    train_df.to_pickle(train_features_filename)\n",
    "    print(\"Train features saved to \" + train_features_filename)\n",
    "    print(\"Training data saved\")\n",
    "\n",
    "    ## 数据测试\n",
    "    ## Test data: y1(rewards)\n",
    "    test_labels_rew = test_df[\"log_reward\"]\n",
    "    test_rewards_filename = os.path.join(ml_input_path,\n",
    "        \"./test_rew_\" + dataset + \"_\" + str(mode) + \".pkl\")\n",
    "    test_labels_rew.to_pickle(test_rewards_filename)\n",
    "    print(\"Test rewards saved to \" + test_rewards_filename)\n",
    "    ## Test data: y2(duration)\n",
    "    test_labels_dur = test_df[\"log_duration\"]\n",
    "    test_durations_filename = os.path.join(ml_input_path,\n",
    "        \"./test_dur_\" + dataset + \"_\" + str(mode) + \".pkl\")\n",
    "    test_labels_dur.to_pickle(test_durations_filename)\n",
    "    print(\"Test durations saved to \" + test_durations_filename)\n",
    "\n",
    "    ## Test data: 数字特征\n",
    "    test_features_filename = os.path.join(ml_input_path,\n",
    "        \"./test_feats_\" + dataset + \"_\" + str(mode) + \".pkl\")\n",
    "\n",
    "    for col_name in drop_cols:\n",
    "        if col_name in test_df:\n",
    "            test_df.drop([col_name],axis=1,inplace=True)\n",
    "    test_df.to_pickle(test_features_filename)\n",
    "    print(\"Test features saved to \" + test_features_filename)\n",
    "    print(\"Test data saved\")\n",
    "\n",
    "    print(\"Training data dimensions: \" + str(train_df.shape))\n",
    "    print(\"Test data dimensions: \" + str(test_df.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "2ef786e0-44c4-4628-aef9-c4e1f79b41a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parseTimes(hit_df, dataset):\n",
    "    ## 将字符串时间数据(e.g., \"30 minutes\") 转换为整型\n",
    "    min_reg = r'([0-9]+) (?:minute)|(?:minutes)'\n",
    "    hr_reg = r'([0-9]+) (?:hour)|(?:hours)'\n",
    "    day_reg = r'([0-9]+) (?:day)|(?:days)'\n",
    "    week_reg = r'([0-9]+) (?:week)|(?:weeks)'\n",
    "\n",
    "    def convertToMins(cur_time):\n",
    "        if type(cur_time) == int:\n",
    "            return cur_time\n",
    "        total_mins = 0\n",
    "        # 分钟\n",
    "        min_match = re.findall(min_reg, cur_time)\n",
    "        num_mins = int(min_match[0]) if min_match else 0\n",
    "        total_mins += num_mins\n",
    "        # 小时\n",
    "        hr_match = re.findall(hr_reg, cur_time)\n",
    "        num_hrs = int(hr_match[0]) if hr_match else 0\n",
    "        total_mins += 60*num_hrs\n",
    "        # 天\n",
    "        day_match = re.findall(day_reg, cur_time)\n",
    "        num_days = int(day_match[0]) if day_match else 0\n",
    "        total_mins += 60*24*num_days\n",
    "        # 周\n",
    "        week_match = re.findall(week_reg, cur_time)\n",
    "        num_weeks = int(week_match[0]) if week_match else 0\n",
    "        total_mins += 60*24*7*num_weeks\n",
    "        return total_mins\n",
    "\n",
    "    if dataset == \"textlab_10\" or dataset == \"textlab_30\":\n",
    "        # 将 time_allotted 和 time_left 列进行解析\n",
    "        hit_df[\"time_allotted\"] = hit_df[\"time_allotted\"].apply(convertToMins)\n",
    "        hit_df[\"time_left\"] = hit_df[\"time_left\"].apply(convertToMins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "88796554-2d70-46f1-aaf8-9f2cd9b5e18c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeSimpleFeatures(hit_df, feature_df, dataset, list_sep):\n",
    "    ## 基础特征\n",
    "    # NOTE: num_obs 不应为 textlab 使用, 这会透露 textlab_10 和 textlab_30 的时间\n",
    "    # ipeirotis 的 min_time_gap 和 max_time_gap 可以给出更完美的预测 \n",
    "    # avg_time_gap 、 med_time_gap 和 time_gap_sd 也是如此\n",
    "    vars_to_import = [\"first_hits\",\"last_hits\",\"avg_hitrate\",\"avg_hits_completed\",\n",
    "                     \"med_hits_completed\",\"min_hits_completed\",\"max_hits_completed\",\n",
    "                     \"num_zeros\"]\n",
    "    if dataset != \"ipeirotis\":\n",
    "        vars_to_import.append(\"time_left\")\n",
    "    if dataset == \"ipeirotis\":\n",
    "        vars_to_import.append(\"num_obs\")\n",
    "    for cur_var in vars_to_import:\n",
    "        feature_df[cur_var] = hit_df[cur_var]\n",
    "        \n",
    "    # 填充缺失值\n",
    "    feature_df[\"avg_hits_completed\"] = feature_df[\"avg_hits_completed\"].fillna(0)\n",
    "    feature_df[\"med_hits_completed\"] = feature_df[\"med_hits_completed\"].fillna(0)\n",
    "    feature_df[\"min_hits_completed\"] = feature_df[\"min_hits_completed\"].fillna(0)\n",
    "    feature_df[\"max_hits_completed\"] = feature_df[\"max_hits_completed\"].fillna(0)\n",
    "\n",
    "    if dataset != \"textlab_30\":\n",
    "        # textlab_30 中没有 max_hits\n",
    "        feature_df[\"max_hits\"] = hit_df[\"max_hits\"].astype(int)\n",
    "\n",
    "    ## 提取部分数据长度\n",
    "    feature_df[\"title_len\"] = hit_df[\"title\"].apply(len)\n",
    "    if dataset != \"textlab_30\":\n",
    "        feature_df[\"desc_len\"] = hit_df[\"description\"].apply(len)\n",
    "        feature_df[\"keywords_len\"] = hit_df[\"keywords\"].apply(lambda x: len(x) if pd.notnull(x) else 0)\n",
    "        feature_df[\"num_keywords\"] = (hit_df[\"keywords\"].str.count(list_sep) + 1).fillna(0).astype(int)\n",
    "\n",
    "    # 为数据中的任务发布者计数\n",
    "    hit_df[\"req_count\"] = 0\n",
    "    feature_df[\"req_count\"] = hit_df.groupby(\"requester_id\")[\"req_count\"].transform(\"count\")\n",
    "\n",
    "    ## 词汇数量\n",
    "    feature_df[\"title_words\"] = (hit_df[\"title\"].str.split()).apply(len)\n",
    "    if dataset != \"textlab_30\":\n",
    "        feature_df[\"desc_words\"] = (hit_df[\"description\"].str.split()).apply(len)\n",
    "\n",
    "    return feature_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "f30e2b3e-222c-453c-a499-0e057588ccef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeIndicatorFeatures(hit_df, feature_df, dataset, indicative_map,\n",
    "    gadiraju_categories, desc_top, title_top, kw_top):\n",
    "    ## 提示词: 针对 title+descriptions+keywords 使用小写版本\n",
    "    hit_df[\"title_lower\"] = hit_df[\"title\"].str.lower()\n",
    "    if dataset != \"textlab_30\":\n",
    "        hit_df[\"desc_lower\"] = hit_df[\"description\"].str.lower()\n",
    "        # 关键字有时候不同，因为有的为空值\n",
    "        hit_df[\"kw_lower\"] = hit_df[\"keywords\"].str.lower()\n",
    "\n",
    "    ## Use indicative words as a proxy for full ngramming\n",
    "    for var_num, var_suffix in enumerate(indicative_map):\n",
    "        print(\"Computing feature #\" + str(var_num) + \": \" + var_suffix)\n",
    "        str_to_search = indicative_map[var_suffix]\n",
    "        title_var = \"title_\" + var_suffix\n",
    "        feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
    "        if dataset != \"textlab_30\":\n",
    "            desc_var = \"desc_\" + var_suffix\n",
    "            feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
    "            kw_var = \"kw_\" + var_suffix\n",
    "            feature_df[kw_var] = (hit_df[\"kw_lower\"].str.count(str_to_search).fillna(0)).astype(int)\n",
    "\n",
    "    ## New as of 2018-06-19: Export a separate dataset with the Gadiraju\n",
    "    ## categories for each HIT group\n",
    "    gadiraju_df = pd.DataFrame()\n",
    "    for cur_category in gadiraju_categories:\n",
    "        suffixes = gadiraju_categories[cur_category]\n",
    "        # Titles\n",
    "        title_var = \"title_\" + cur_category\n",
    "        title_feature_vars = [\"title_\" + suffix for suffix in suffixes]\n",
    "        title_subset_df = feature_df[title_feature_vars]\n",
    "        gadiraju_df[title_var] = title_subset_df.sum(axis=1)\n",
    "        if dataset != \"textlab_30\":\n",
    "            # Descriptions\n",
    "            desc_var = \"desc_\" + cur_category\n",
    "            desc_feature_vars = [\"desc_\" + suffix for suffix in suffixes]\n",
    "            desc_subset_df = feature_df[desc_feature_vars]\n",
    "            gadiraju_df[desc_var] = desc_subset_df.sum(axis=1)\n",
    "            # Keywords\n",
    "            kw_var = \"kw_\" + cur_category\n",
    "            kw_feature_vars = [\"kw_\" + suffix for suffix in suffixes]\n",
    "            kw_subset_df = feature_df[kw_feature_vars]\n",
    "            gadiraju_df[kw_var] = kw_subset_df.sum(axis=1)\n",
    "\n",
    "    # 将 group_id 作为第一列\n",
    "    gadiraju_df.insert(0, \"group_id\", feature_df.index)\n",
    "    # 提取\n",
    "    gadiraju_filepath = os.path.join(ml_input_path, \"gadiraju_categories_\" + dataset + \".csv\")\n",
    "    gadiraju_df.to_csv(gadiraju_filepath, index=False)\n",
    "\n",
    "    ## 前 400 个学习特征 (200 rewards ，200 duration)\n",
    "    for var_suffix in title_top:\n",
    "        str_to_search = title_top[var_suffix]\n",
    "        title_var = \"title_\" + var_suffix.replace(\" \",\"_\")\n",
    "        feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
    "    if dataset != \"textlab_30\":\n",
    "        for var_suffix in desc_top:\n",
    "            str_to_search = desc_top[var_suffix]\n",
    "            desc_var = \"desc_\" + var_suffix.replace(\" \",\"_\")\n",
    "            feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
    "        for var_suffix in kw_top:\n",
    "            str_to_search = kw_top[var_suffix]\n",
    "            kw_var = \"kw_\" + var_suffix.replace(\" \",\"_\")\n",
    "            feature_df[kw_var] = (hit_df[\"kw_lower\"].str.count(str_to_search).fillna(0)).astype(int)\n",
    "\n",
    "    ## 其它员工\n",
    "    ## 0/1 会出现 \"5 minute task\" 这种短语\n",
    "    seconds_reg = r'([0-9]+)\\s?(?:s|sec|second|secs|seconds)'\n",
    "    minutes_reg = r'([0-9]+)\\s?(?:m|min|minute|mins|minutes)'\n",
    "    hours_reg = r'([0-9]+)\\s?(?h|hr|hour|hrs|hours)'\n",
    "    # extract()方法从每个字符串中提取与正则模式匹配的部分，expand=False返回Series，expand=True返回DataFrame\n",
    "    feature_df[\"minutes_title\"] = hit_df[\"title_lower\"].str.extract(minutes_reg,expand=False).fillna(0).astype(int)\n",
    "    if dataset != \"textlab_30\":\n",
    "        feature_df[\"minutes_desc\"] = hit_df[\"desc_lower\"].str.extract(minutes_reg,expand=False).fillna(0).astype(int)\n",
    "        feature_df[\"minutes_kw\"] = hit_df[\"kw_lower\"].str.extract(minutes_reg,expand=False).fillna(0).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "1a35a93d-b2b5-4d4f-b55e-a3d650a27d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeQualificationFeatures(hit_df, feature_df, list_sep):\n",
    "    # 设定正则表达式\n",
    "    qual_granted = r'\\'.+ has been granted\\''\n",
    "    qual_not_granted = r'\\'.+ has not been granted\\''\n",
    "    qual_loc = r'\\'Location is (..)\\''\n",
    "    qual_loc_mult = r'\\'Location is one of: (.+)\\''\n",
    "    qual_rej_rate_lt = r'\\'HIT rejection rate \\(%\\) is less than ([0-9]+)\\''\n",
    "    qual_rej_num_lt = r'\\'Total rejected HITs is (?:less than|not greater than) ([0-9]+)\\''\n",
    "    qual_appr_rate_gt = r'\\'HIT approval rate \\(%\\) is (?:greater than|not less than) ([0-9]+)\\''\n",
    "    qual_appr_num_gt = r'\\'Total approved HITs is (?:greater than|not less than) ([0-9]+)\\''\n",
    "    qual_adult_content = r'\\'Adult Content Qualification is 1\\''\n",
    "\n",
    "    # 解析 qualifications list\n",
    "    # 无效的hit填充缺失值0\n",
    "    feature_df[\"qual_len\"] = hit_df[\"qualifications\"].apply(lambda x: len(x) if pd.notnull(x) else 0)\n",
    "    feature_df[\"num_quals\"] = (hit_df[\"qualifications\"].str.count(list_sep) + 1).fillna(0).astype(int)\n",
    "    ## 自定义 quals\n",
    "    feature_df[\"custom_not_granted\"] = hit_df[\"qualifications\"].str.count(qual_not_granted).fillna(0).astype(int)\n",
    "    feature_df[\"custom_granted\"] = hit_df[\"qualifications\"].str.count(qual_granted).fillna(0).astype(int)\n",
    "\n",
    "    ## Location qualifications\n",
    "    # expand=False 确保数据被压缩为 Series 而不是 DF\n",
    "    hit_df[\"locs\"] = hit_df[\"qualifications\"].str.extract(qual_loc,expand=False).fillna('')\n",
    "    hit_df[\"locs_mult\"] = hit_df[\"qualifications\"].str.extract(qual_loc_mult,expand=False).fillna('')\n",
    "    # any_loc = 0 or 1, any location qualifications\n",
    "    feature_df[\"any_loc\"] = ((hit_df[\"locs\"] + hit_df[\"locs_mult\"]) != \"\").astype(int)\n",
    "    # us_only = 0 or 1 if location qualification is US only\n",
    "    feature_df[\"us_only\"] = ((hit_df[\"locs\"] + \"|\" + hit_df[\"locs_mult\"]).str.contains(\"US\")).astype(int)\n",
    "\n",
    "    ## Rejection / acceptance qualifications\n",
    "    # rej_rate_lt =拒绝 pct 小于 X 的线程\n",
    "    # (-1 = no restrictions, 0-100 = required rejection pct)\n",
    "    feature_df[\"appr_rate_gt\"] = hit_df[\"qualifications\"].str.extract(qual_appr_rate_gt,expand=False).fillna(-1).astype(int)\n",
    "    feature_df[\"appr_num_gt\"] = hit_df[\"qualifications\"].str.extract(qual_appr_num_gt,expand=False).fillna(-1).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "3f80cda8-0917-4cc6-a8c3-4986fe6c34d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mergeLDA(feature_df, dataset):\n",
    "    # 首先，为特征数据集创建一个暂时索引\n",
    "    if \"level_0\" not in feature_df.columns:\n",
    "        feature_df.reset_index(inplace=True)\n",
    "    # 合并主题分布\n",
    "    for K in [5,10,15,20]:\n",
    "        title_topic_filename = os.path.join(lda_path,\n",
    "            dataset + \"_title_lda_dists_\" + str(K) + \".pkl\")\n",
    "        title_topic_df = pd.read_pickle(title_topic_filename)\n",
    "        feature_df = feature_df.merge(title_topic_df, how='left', left_index=True, right_index=True)\n",
    "        if dataset != \"textlab_30\":\n",
    "            desc_topic_filename = os.path.join(lda_path,\n",
    "                dataset + \"_desc_lda_dists_\" + str(K) + \".pkl\")\n",
    "            desc_topic_df = pd.read_pickle(desc_topic_filename)\n",
    "            feature_df = feature_df.merge(desc_topic_df, how='left', left_index=True, right_index=True)\n",
    "            kw_topic_filename = os.path.join(lda_path,\n",
    "                dataset + \"_kw_lda_dists_\" + str(K) + \".pkl\")\n",
    "            kw_topic_df = pd.read_pickle(kw_topic_filename)\n",
    "            feature_df = feature_df.merge(kw_topic_df, how='left', left_index=True, right_index=True)\n",
    "    print(\"LDA features merged in\")\n",
    "\n",
    "    ## New 2018-08-20: 将主题分布导出为一个独立的 .csv 文件\n",
    "    vars_to_keep = [\"group_id\",\"titletopic_5_0\",\"titletopic_5_1\",\n",
    "        \"titletopic_5_2\",\"titletopic_5_3\",\"titletopic_5_4\"]\n",
    "    if dataset != \"textlab_30\":\n",
    "        vars_to_keep.extend([\"desctopic_5_0\",\"desctopic_5_1\",\"desctopic_5_2\",\n",
    "            \"desctopic_5_3\",\"desctopic_5_4\"])\n",
    "        vars_to_keep.extend([\"kwtopic_5_0\",\"kwtopic_5_1\",\"kwtopic_5_2\",\n",
    "            \"kwtopic_5_3\",\"kwtopic_5_4\"])\n",
    "\n",
    "    full_topic_df = feature_df[vars_to_keep]\n",
    "    full_topic_filepath = os.path.join(ml_input_path, \"topic_dists_\" + dataset + \".csv\")\n",
    "    full_topic_df.to_csv(full_topic_filepath, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "c6d55fbc-ae87-483e-aff2-26da0e372c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mergeDoc2Vec(feature_df, dataset):\n",
    "    # 合并 doc2vec 向量\n",
    "    doc2vec_df = pd.read_pickle(os.path.join(doc2vec_path, dataset + \"_doc2vec.pkl\"))\n",
    "    feature_df = feature_df.merge(doc2vec_df, how='left', left_index=True, right_index=True)\n",
    "    print(\"Doc2Vec features merged in\")\n",
    "    print(feature_df.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "7b95c22f-1396-46b6-90f2-54df9f007896",
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkNulls(feature_df):\n",
    "    # 为确保所有特征都没有空值和无穷值，进行有效性检验\n",
    "    for cur_var in feature_df.columns:\n",
    "        if cur_var == \"group_id\":\n",
    "            continue\n",
    "        #print(\"Checking \" + cur_var)\n",
    "        num_nans = sum(np.isnan(feature_df[cur_var]))\n",
    "        num_inf = sum(np.isinf(feature_df[cur_var]))\n",
    "        if num_nans > 0 or num_inf > 0:\n",
    "            print(cur_var + \": \" + str(num_nans) + \" nans, \" + str(num_inf) + \" infs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "bd4f673a-dff1-4983-bd44-d936cc467df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fixNulls(feature_df):\n",
    "    # avg_hitrate has 9 nans, 7 infs in ipeirotis data, and 8007 NaNs in textlab_30.\n",
    "    # 这里通过将空值和无穷值替换为最大值来进行填充\n",
    "    non_inf = feature_df[~np.isinf(feature_df[\"avg_hitrate\"])]\n",
    "    mean_hitrate = non_inf[\"avg_hitrate\"].mean()\n",
    "    max_hitrate = non_inf[\"avg_hitrate\"].max()\n",
    "    print(\"Mean hitrate: \" + str(mean_hitrate))\n",
    "    print(\"Max hitrate: \" + str(max_hitrate))\n",
    "    feature_df[\"avg_hitrate\"] = feature_df[\"avg_hitrate\"].fillna(mean_hitrate)\n",
    "    feature_df[\"avg_hitrate\"] = feature_df[\"avg_hitrate\"].replace(np.inf, max_hitrate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c93aa13-e90b-4a6a-a241-a74b663133c5",
   "metadata": {},
   "source": [
    "#### 3、N-GRAM特征提取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "fe45bc17-f09a-49cc-bc04-b25dedad83fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateGramFeatures(hit_df, dataset, mode, partition):\n",
    "    # 对于文本机器学习，需要注意不能把 CountVectorizer 拟合到仅在测试集出现的单词上\n",
    "    vars_to_keep = [\"log_reward\",\"log_duration\",\"title\",\"meandiff_lreward\",\"meandiff_ldur\"]\n",
    "    if dataset == \"ipeirotis\":\n",
    "        # TextLab 的爬取没有 qualifications 列, 但是 Ipeirotis' 有\n",
    "        vars_to_keep.append(\"qualifications\")\n",
    "    if dataset == \"textlab_10\" or dataset == \"ipeirotis\":\n",
    "        # textlab_30 没有 descriptions 和 keywords\n",
    "        vars_to_keep.append(\"description\")\n",
    "        vars_to_keep.append(\"kw_parsed\")\n",
    "\n",
    "    feature_df = hit_df[vars_to_keep]\n",
    "\n",
    "    if dataset == \"textlab_10\" or dataset == \"ipeirotis\":\n",
    "        feature_df[\"description\"] = feature_df[\"description\"].astype(str)\n",
    "        feature_df[\"kw_parsed\"] = feature_df[\"kw_parsed\"].astype(str)\n",
    "    if dataset == \"ipeirotis\":\n",
    "        feature_df[\"qualifications\"] = feature_df[\"qualifications\"].astype(str)\n",
    "\n",
    "    # 保证文本向量为字符串格式\n",
    "    feature_df[\"title\"] = feature_df[\"title\"].astype(str)\n",
    "    # 在训练 countvectorizer 之前， 将A/B数据集分到不同的dataframe中\n",
    "    if mode.endswith(\"ab\"):\n",
    "        train_df = feature_df.iloc[partition['A_train']]\n",
    "        test_df = feature_df.iloc[partition['A_val']]\n",
    "    else:\n",
    "        train_df = feature_df.iloc[partition['B_train']]\n",
    "        test_df = feature_df.iloc[partition['B_val']]\n",
    "\n",
    "    # Training Counts\n",
    "    if dataset == \"textlab_10\" or dataset == \"ipeirotis\":\n",
    "        ## 矢量化 descriptions\n",
    "        # CountVectorizer用于将文本数据模型转换为词袋模型的数值表示，ngram_range(1,3)是提取1到3个单词的组合，max_df=0.9指忽略在超过90%的文档里出现的词，即过滤高频无意义词\n",
    "        count_vec_desc = CountVectorizer(ngram_range=(1,3),stop_words='english',max_df=0.9)\n",
    "        # 将包含文本数据的Pandas Series转换为稀疏矩阵（n_samples, n_features），表示每个文档的词频\n",
    "        train_desc_counts = count_vec_desc.fit_transform(train_df[\"description\"])\n",
    "        print(\"Descriptions vectorized for train data\")\n",
    "        ## 矢量化关键字\n",
    "        count_vec_kw = CountVectorizer(stop_words='english',max_df=0.9)\n",
    "        train_kw_counts = count_vec_kw.fit_transform(train_df[\"kw_parsed\"])\n",
    "        print(\"Keywords vectorized for train data\")\n",
    "    ## 矢量化 titles\n",
    "    count_vec_title = CountVectorizer(ngram_range=(1,3),stop_words='english',max_df=0.9)\n",
    "    train_title_counts = count_vec_title.fit_transform(train_df[\"title\"])\n",
    "    print(\"Titles vectorized for train data\")\n",
    "\n",
    "    if dataset == \"textlab_10\" or dataset == \"ipeirotis\":\n",
    "        print(train_desc_counts.shape)\n",
    "        print(train_kw_counts.shape)\n",
    "    print(train_title_counts.shape)\n",
    "\n",
    "    # 导出特征名\n",
    "    if dataset == \"textlab_10\" or dataset == \"ipeirotis\":\n",
    "        # get_feature_names_out()用于获取countvectorizer生成的词汇表（特征名列表），输出结果为按字母顺序排序的包含所有保留词汇的numpy数组\n",
    "        desc_feature_name_arr = count_vec_desc.get_feature_names_out()\n",
    "        desc_feature_name_arr = [\"\\\"\" + str(feat_name) + \"\\\" in description\" for feat_name in desc_feature_name_arr]\n",
    "        kw_feature_name_arr = count_vec_kw.get_feature_names_out()\n",
    "        kw_feature_name_arr = [\"\\\"\" + str(feat_name) + \"\\\" in keywords\" for feat_name in kw_feature_name_arr]\n",
    "    title_feature_name_arr = count_vec_title.get_feature_names_out()\n",
    "    title_feature_name_arr = [\"\\\"\" + str(feat_name) + \"\\\" in title\" for feat_name in title_feature_name_arr]\n",
    "\n",
    "    feature_name_arr = title_feature_name_arr\n",
    "    if dataset == \"textlab_10\" or dataset == \"ipeirotis\":\n",
    "        feature_name_arr = feature_name_arr + desc_feature_name_arr + kw_feature_name_arr\n",
    "    feature_filename = os.path.join(ml_input_path, \"feat_names_\" + dataset + \"_\" + mode + \".pkl\")\n",
    "    joblib.dump(feature_name_arr, feature_filename)\n",
    "    print(\"Feature names saved to \" + feature_filename)\n",
    "\n",
    "    ## Validation counts\n",
    "    if dataset == \"textlab_10\" or dataset == \"ipeirotis\":\n",
    "        # 必须将transform用于测试集。fit_transform会基于测试数据重新构建词汇表或计算统计量，导致测试集信息泄露到模型中。\n",
    "        # transform则沿用相同的参数和词汇表进行转换，且如果在测试阶段出现新词，transform会忽略这些词，确保矩阵的列数与训练集一致。\n",
    "        val_desc_counts = count_vec_desc.transform(test_df[\"description\"])\n",
    "        print(\"Validation set descriptions vectorized\")\n",
    "        val_kw_counts = count_vec_kw.transform(test_df[\"kw_parsed\"])\n",
    "        print(\"Validation set keywords vectorized\")\n",
    "    val_title_counts = count_vec_title.transform(test_df[\"title\"])\n",
    "    print(\"Validation set titles vectorized\")\n",
    "\n",
    "    if dataset == \"textlab_10\" or dataset == \"ipeirotis\":\n",
    "        print(val_desc_counts.shape)\n",
    "        print(val_kw_counts.shape)\n",
    "    print(val_title_counts.shape)\n",
    "\n",
    "    # Careful in this part:\n",
    "    # train = A and test = B if [mode==\"numab\"]\n",
    "    # train = A_train and test = A_validation if [mode==\"textab\"]\n",
    "    # train = B and test = A if [mode==\"numba\"]\n",
    "    # train = B_train and test = B_validation if [mode==\"textba\"]\n",
    "\n",
    "    #################\n",
    "    ### 训练数据 ###\n",
    "    #################\n",
    "\n",
    "    ### 导出标签，因为后续导出特征会删除标签节省内存，这里用来保存顺序\n",
    "\n",
    "    ## Training data: y1(rewards)\n",
    "    train_labels_rew = train_df[\"log_reward\"]\n",
    "    train_rewards_filename = os.path.join(ml_input_path,\n",
    "        \"./train_rew_\" + dataset + \"_\" + str(mode) + \".pkl\")\n",
    "    train_labels_rew.to_pickle(train_rewards_filename)\n",
    "    print(\"Train rewards saved to \" + train_rewards_filename)\n",
    "    ## Training data: y2(duration)\n",
    "    train_labels_dur = train_df[\"log_duration\"]\n",
    "    train_durations_filename = os.path.join(ml_input_path,\n",
    "        \"./train_dur_\" + dataset + \"_\" + str(mode) + \".pkl\")\n",
    "    train_labels_dur.to_pickle(train_durations_filename)\n",
    "    print(\"Train durations saved to \" + train_durations_filename)\n",
    "\n",
    "    ### 导出标签\n",
    "    ## Training data: text features\n",
    "    train_text_features_filename = os.path.join(ml_input_path,\n",
    "        \"./train_txtfeats_\" + dataset + \"_\" + str(mode) + \".pkl\")\n",
    "    if dataset == \"textlab_10\" or dataset == \"ipeirotis\":\n",
    "        train_text_features = hstack([train_desc_counts,train_title_counts,train_kw_counts])\n",
    "    else:\n",
    "        train_text_features = train_title_counts\n",
    "    joblib.dump(train_text_features, train_text_features_filename)\n",
    "    print(\"Train text features saved to \" + train_text_features_filename)\n",
    "    print(\"Training data saved\")\n",
    "\n",
    "    #################\n",
    "    ### 测试数据 ###\n",
    "    #################\n",
    "\n",
    "    ## Test data: y1(rewards)\n",
    "    test_labels_rew = test_df[\"log_reward\"]\n",
    "    test_rewards_filename = os.path.join(ml_input_path,\n",
    "        \"./test_rew_\" + dataset + \"_\" + str(mode) + \".pkl\")\n",
    "    test_labels_rew.to_pickle(test_rewards_filename)\n",
    "    print(\"Test rewards saved to \" + test_rewards_filename)\n",
    "    ## Test data: y2(duration)\n",
    "    test_labels_dur = test_df[\"log_duration\"]\n",
    "    test_durations_filename = os.path.join(ml_input_path,\n",
    "        \"./test_dur_\" + dataset + \"_\" + str(mode) + \".pkl\")\n",
    "    test_labels_dur.to_pickle(test_durations_filename)\n",
    "    print(\"Test durations saved to \" + test_durations_filename)\n",
    "\n",
    "    ## Validation data: text features\n",
    "    test_text_features_filename = os.path.join(ml_input_path,\n",
    "        \"./test_txtfeats_\" + dataset + \"_\" + str(mode) + \".pkl\")\n",
    "    if dataset == \"textlab_10\" or dataset == \"ipeirotis\":\n",
    "        val_text_features = hstack([val_desc_counts,val_title_counts,val_kw_counts])\n",
    "    else:\n",
    "        val_text_features = val_title_counts\n",
    "    joblib.dump(val_text_features, test_text_features_filename)\n",
    "    print(\"Test text features saved to \" + test_text_features_filename)\n",
    "\n",
    "    print(\"Validation data saved\")\n",
    "\n",
    "    print(\"Textual features exported\")\n",
    "    print(\"*** Train data: ***\")\n",
    "    print(\"Features: \" + str(train_text_features.shape))\n",
    "    print(\"Reward labels: \" + str(train_labels_rew.shape))\n",
    "    print(\"Duration labels: \" + str(train_labels_dur.shape))\n",
    "    print(\"*** Validation data: ***\")\n",
    "    print(\"Features: \" + str(val_text_features.shape))\n",
    "    print(\"Reward labels: \" + str(test_labels_rew.shape))\n",
    "    print(\"Duration labels: \" + str(test_labels_dur.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "68341505-3909-404e-998f-52379c477063",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepareML(dataset, mode):\n",
    "    cleaned_df = loadCleanedData(dataset)\n",
    "    # 数据分类标签：{A, B, A_train, A_val, B_train, B_val} \n",
    "    data_partition = partitionData(cleaned_df)\n",
    "    if mode.startswith(\"full\"):\n",
    "        generateNumericFeatures(cleaned_df, dataset, mode, data_partition)\n",
    "    else:\n",
    "        generateGramFeatures(cleaned_df, dataset, mode, data_partition)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79561e44-256f-414c-a871-d8e0e8c11d07",
   "metadata": {},
   "source": [
    "### （五）机器学习运行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "c3481596-c336-4513-986a-b8ca430e007b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Random Forest Regression\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "da70b03d-47b7-455a-b09b-3e28cba6e592",
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_output_path = os.path.join('.', 'ml_output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "fded3b53-219e-4125-ade6-5fe2e5e5544b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def timeit(method):\n",
    "    def timed(*args, **kw):\n",
    "        # 记录开始时间\n",
    "        ts = time.time()\n",
    "        result = method(*args, **kw)\n",
    "        # 记录结束时间\n",
    "        te = time.time()\n",
    "        print(method.__name__ + \": \" + str(te-ts) + \" seconds\")\n",
    "        return result\n",
    "    return timed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "df95e535-9948-4026-a9b2-cb3da9d745d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 快速运行分类器并保存结果\n",
    "@timeit\n",
    "def fitAndPredict(X_train, y_train, X_test, y_test, classifier, dataset_name, y_name):\n",
    "    print(\"Running \" + dataset_name + \"_\" + y_name)\n",
    "    #使用这个函数去比较不同回归下的R方（传入不同的分类器）\n",
    "    fitted_reg = classifier.fit(X_train, y_train)\n",
    "    print(dataset_name + \"_\" + y_name + \" fit complete\")\n",
    "\n",
    "    # 将合适的模型保存\n",
    "    fitted_filename = os.path.join(ml_output_path, \"fitted_\" + dataset_name + \"_\" + y_name + \".pkl\")\n",
    "    joblib.dump(fitted_reg, fitted_filename)\n",
    "    print(\"Fitted model saved\")\n",
    "    # 计算并保存预测值\n",
    "    y_predicted = fitted_reg.predict(X_test)\n",
    "    joblib.dump(y_predicted, os.path.join(ml_output_path, \"predictions_\" + dataset_name + \"_\" + y_name + \".pkl\"))\n",
    "    # 计算并返回预测精度\n",
    "    pred_score = fitted_reg.score(X_test, y_test)\n",
    "    joblib.dump(pred_score, os.path.join(ml_output_path, \"pred_score_\" + dataset_name + \"_\" + y_name + \".pkl\"))\n",
    "    return pred_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "e7258076-f984-4a7b-ac63-8cf43dfa39f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def runML(dataset, mode):\n",
    "    rewname = mode + \"_rew\"\n",
    "    durname = mode + \"_dur\"\n",
    "    text_trees = 40\n",
    "    numeric_trees = 600\n",
    "    \n",
    "    # The input files needed for *text* ML are:\n",
    "    # (1a) train_txtfeats_<dataset>_<mode>.pkl, train_rew_<dataset>_<mode>.pkl, and train_dur_<dataset>_<mode>.pkl\n",
    "    # (1b) test_txtfeats_<dataset>_<mode>.pkl, test_rew_<dataset>_<mode>.pkl, and test_dur_<dataset>_<mode>.pkl\n",
    "    # \n",
    "    # Upon completion of *text* ML, the program will output:\n",
    "    # (1c) fitted_rfr_rewtext.pkl, predictions_rfr_rewtext.pkl, and pred_score_rfr_rewtext.pkl\n",
    "    # (1d) fitted_rfr_durtext.pkl, predictions_rfr_durtext.pkl, and pred_score_rfr_durtext.pkl\n",
    "    #\n",
    "    # The input files needed for *numeric* ML are:\n",
    "    # (2a) train_feats_<dataset>_<mode>.pkl, train_rew_<dataset>_<mode>.pkl, and train_dur_<dataset>_<mode>.pkl\n",
    "    # (2b) test_feats_<dataset>_<mode>.pkl, test_rew_<dataset>_<mode>.pkl, and test_dur_<dataset>_<mode>.pkl.\n",
    "    #\n",
    "    # Upon completion of *numeric* ML, the program will output:\n",
    "    # (2c) fitted_<dataset>_<mode>_rew.pkl, predictions_<dataset>_<mode>_rew.pkl, and pred_score_<dataset>_<mode>_rew.pkl\n",
    "    # (2d) fitted_<dataset>_<mode>_dur.pkl, predictions_<dataset>_<mode>_dur.pkl, and pred_score_<dataset>_<mode>_dur.pkl\n",
    "    #\n",
    "    \n",
    "    ### Load training and test data\n",
    "    if mode.startswith(\"gram\"):\n",
    "        ## X_train text features\n",
    "        X_train = joblib.load(os.path.join(ml_input_path, \n",
    "            \"train_txtfeats_\" + dataset + \"_\" + str(mode) + \".pkl\"))\n",
    "    else:\n",
    "        ## X_train numeric features\n",
    "        X_train_df = pd.read_pickle(os.path.join(ml_input_path, \n",
    "            \"train_feats_\" + dataset + \"_\" + str(mode) + \".pkl\"))\n",
    "        X_train = X_train_df.values\n",
    "    ## y_train_rew\n",
    "    y_train_rew_df = pd.read_pickle(os.path.join(ml_input_path, \n",
    "        \"train_rew_\" + dataset + \"_\" + mode + \".pkl\"))\n",
    "    y_train_rew = y_train_rew_df.values\n",
    "    ## y_train_dur\n",
    "    y_train_dur_df = pd.read_pickle(os.path.join(ml_input_path, \n",
    "        \"train_dur_\" + dataset + \"_\" + mode + \".pkl\"))\n",
    "    y_train_dur = y_train_dur_df.values\n",
    "    print(\"Training data loaded\")\n",
    "    \n",
    "    if mode.startswith(\"gram\"):\n",
    "        ## X_test text features\n",
    "        X_test = joblib.load(os.path.join(ml_input_path, \n",
    "            \"test_txtfeats_\" + dataset + \"_\" + mode + \".pkl\"))\n",
    "    else:\n",
    "        ## X_test numeric features\n",
    "        X_test_df = pd.read_pickle(os.path.join(ml_input_path, \n",
    "            \"test_feats_\" + dataset + \"_\" + mode + \".pkl\"))\n",
    "        X_test = X_test_df.values\n",
    "    ## y_test_rew\n",
    "    y_test_rew_df = pd.read_pickle(os.path.join(ml_input_path,\n",
    "        \"test_rew_\" + dataset + \"_\" + mode + \".pkl\"))\n",
    "    y_test_rew = y_test_rew_df.values\n",
    "    ## y_test_dur\n",
    "    y_test_dur_df = pd.read_pickle(os.path.join(ml_input_path, \n",
    "        \"test_dur_\" + dataset + \"_\" + mode + \".pkl\"))\n",
    "    y_test_dur = y_test_dur_df.values\n",
    "    print(\"Test data loaded\")\n",
    "\n",
    "    # 现在使用fitAndPredict() 去比较不同方法的knn效果好但是计算速度慢，gbr效果差但是计算速度快，rfr效果是目前最好的，但是运行速度还是慢，不过可以并行运行。\n",
    "    if mode.startswith(\"gram\"):\n",
    "        ## Text feature ML\n",
    "        # y = reward\n",
    "        print(\"----- [Running *reward* ML with text features] -----\")\n",
    "        # n_jobs=-1表示使用所有cpu核心并行计算，oob_score=False表示不计算袋外误差oob，n_estimators表示设定的树的数量，verbose=2表示保存详细的训练过程日志\n",
    "        reward_rfr = RandomForestRegressor(n_jobs=-1,oob_score=False,\n",
    "            n_estimators=text_trees,verbose=2)\n",
    "        reward_r2 = fitAndPredict(X_train,y_train_rew,X_test,y_test_rew,\n",
    "            reward_rfr,dataset,rewname)\n",
    "        print(reward_r2)\n",
    "        # y = duration\n",
    "        print(\"----- [Running *duration* ML with text features] -----\")\n",
    "        duration_rfr = RandomForestRegressor(n_jobs=-1,oob_score=False,\n",
    "            n_estimators=text_trees,verbose=2)\n",
    "        duration_r2 = fitAndPredict(X_train,y_train_dur,X_test,y_test_dur,\n",
    "            duration_rfr,dataset,durname)\n",
    "        print(duration_r2)\n",
    "\n",
    "    else:\n",
    "        ## Numeric feature ML\n",
    "        print(\"----- [Running *reward* ML with numeric features] -----\")\n",
    "        reward_rfr = RandomForestRegressor(n_jobs=-1,oob_score=True,\n",
    "            n_estimators=numeric_trees,verbose=2)\n",
    "        reward_r2 = fitAndPredict(X_train,y_train_rew,X_test,y_test_rew,\n",
    "            reward_rfr,dataset,rewname)\n",
    "        print(reward_r2) \n",
    "        print(\"----- [Running *duration* ML with numeric features] -----\")\n",
    "        duration_rfr = RandomForestRegressor(n_jobs=-1,oob_score=True,\n",
    "            n_estimators=numeric_trees,verbose=2)\n",
    "        duration_r2 = fitAndPredict(X_train,y_train_dur,X_test,y_test_dur,\n",
    "            duration_rfr,dataset,durname)\n",
    "        print(duration_r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d44294-f1e7-43a9-a873-8322851b3143",
   "metadata": {},
   "source": [
    "### （六）计算贡献度较大的特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "6e044af2-784f-4270-9d2b-6cfba9658f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeMostPredictive(dataset, mode):\n",
    "    for depvar in [\"dur\",\"rew\"]:\n",
    "        print(\"Generating most predictive features for \" + depvar)\n",
    "        fitted_filepath = os.path.join(ml_output_path, \"fitted_\" + dataset + \"_\" + mode + \"_\" + depvar + \".pkl\")\n",
    "        rfr = joblib.load(fitted_filepath)\n",
    "        feature_names_filepath = os.path.join(ml_input_path, \"feat_names_\" + dataset + \"_\" + mode + \".pkl\")\n",
    "        feature_names = joblib.load(feature_names_filepath)\n",
    "        num_features = len(feature_names)\n",
    "        print(\"Number of features: \" + str(num_features))\n",
    "\n",
    "        feature_dict = {feat_index: feat_name for feat_index, feat_name in list(enumerate(feature_names))}\n",
    "        # importances 是包含了每个特征的gini系数的大数组，表示每个特征对模型预测的贡献度\n",
    "        # 注意这里使用hstack方法堆叠了desc和title的特征，所以在解释这个数组时需要查看len（desc_features）上所有索引来寻找title features\n",
    "        importances = rfr.feature_importances_\n",
    "        # 获取特征重要性分数的排序索引\n",
    "        sorted_imp = importances.argsort()\n",
    "        # reversed()方法返回序列值反转后的迭代器\n",
    "        sorted_imp = list(reversed(sorted_imp))\n",
    "        \n",
    "        ## For numeric features\n",
    "        #imp_arr = [(ind, feature_dict[ind], importances[ind]) for ind in sorted_imp]\n",
    "        #print(imp_arr)\n",
    "        \n",
    "        ## For text features\n",
    "        sorted_feature_names = [feature_names[ind] for ind in sorted_imp]\n",
    "        sorted_importances = [importances[ind] for ind in sorted_imp]\n",
    "        importance_df = pd.DataFrame({'feature':sorted_feature_names,'gini':sorted_importances})\n",
    "        csv_filepath = os.path.join(predictive_path,\"predictive_\" + dataset + \"_\" + mode + \"_\" + depvar + \".csv\")\n",
    "        importance_df.head(300).to_csv(csv_filepath)\n",
    "        print(\"Features outputted to: \" + csv_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "dc32b170-7676-483f-847d-05ca309691aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>feature</th>\n",
       "      <th>gini</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>\"picture 112071\" in description</td>\n",
       "      <td>0.037437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>\"audio recording a2580296\" in title</td>\n",
       "      <td>0.030065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>\"app\" in description</td>\n",
       "      <td>0.026277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>\"going gray purpose\" in title</td>\n",
       "      <td>0.024129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>\"endorser\" in description</td>\n",
       "      <td>0.015902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>295</td>\n",
       "      <td>\"apptituda\" in title</td>\n",
       "      <td>0.000247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>296</td>\n",
       "      <td>\"af88 400c\" in title</td>\n",
       "      <td>0.000247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>297</td>\n",
       "      <td>\"webcam 20sec qualify\" in title</td>\n",
       "      <td>0.000247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>298</td>\n",
       "      <td>\"transcribe video a2582963\" in title</td>\n",
       "      <td>0.000243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>299</td>\n",
       "      <td>\"5d4c\" in title</td>\n",
       "      <td>0.000242</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0                               feature      gini\n",
       "0             0       \"picture 112071\" in description  0.037437\n",
       "1             1   \"audio recording a2580296\" in title  0.030065\n",
       "2             2                  \"app\" in description  0.026277\n",
       "3             3         \"going gray purpose\" in title  0.024129\n",
       "4             4             \"endorser\" in description  0.015902\n",
       "..          ...                                   ...       ...\n",
       "295         295                  \"apptituda\" in title  0.000247\n",
       "296         296                  \"af88 400c\" in title  0.000247\n",
       "297         297       \"webcam 20sec qualify\" in title  0.000247\n",
       "298         298  \"transcribe video a2582963\" in title  0.000243\n",
       "299         299                       \"5d4c\" in title  0.000242\n",
       "\n",
       "[300 rows x 3 columns]"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_df = pd.read_csv('./predictive_feats/predictive_textlab_10_gramab_dur.csv')\n",
    "temp_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb2a0bd8-f4ed-4445-9965-514cc63f3f4a",
   "metadata": {},
   "source": [
    "### （七）双重机器学习估计"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "93a10c8d-3baf-445f-978d-4451f4aa96c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimates_path = os.path.join('.', 'estimates')"
   ]
  },
  {
   "attachments": {
    "9c632afe-ded7-4c9d-861a-1a055ab9fe73.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "20be1f2c-95a1-4c0c-b562-b1d420163ab1",
   "metadata": {},
   "source": [
    "![image.png](attachment:9c632afe-ded7-4c9d-861a-1a055ab9fe73.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "05fa57c5-2305-41e9-9817-36c87ac5b648",
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeThetaCheck(lrew_resid, ldur_resid):\n",
    "    inv_term = 1/(sum(lrew_resid**2)/len(lrew_resid))\n",
    "    numer_term = sum(lrew_resid * ldur_resid)/len(lrew_resid)\n",
    "    theta_check = inv_term * numer_term\n",
    "    return theta_check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "b2ac47e2-326d-4488-9b81-831462c9efac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeEta(dataset):\n",
    "\n",
    "    ########################\n",
    "    ### Part I: 估计 ###\n",
    "    ########################\n",
    "\n",
    "    print(\"doubleMLEstimate()\")\n",
    "    # 获取两次机器学习结果预测的y值，计算残差后带入到双重机器学习的估计器中\n",
    "\n",
    "    # (LOTS OF STUFF IN THIS SECTION WILL LOOK WEIRD BECAUSE OF THE CHANGE FROM TRAIN/TEST to A/B)\n",
    "\n",
    "    # (Set to True if you're also doing the alternative specification with\n",
    "    # mean-differenced rewards and durations)\n",
    "    mean_differenced = False\n",
    "\n",
    "    # Load best reward predictions\n",
    "    predicted_lrew_ab = joblib.load(os.path.join(ml_output_path,\n",
    "        \"predictions_\" + dataset + \"_fullab_rew.pkl\"))\n",
    "    print(\"Loaded predicted_lrew_ab: \" + str(predicted_lrew_ab.shape))\n",
    "    predicted_lrew_ba = joblib.load(os.path.join(ml_output_path,\n",
    "        \"predictions_\" + dataset + \"_fullba_rew.pkl\"))\n",
    "    print(\"Loaded predicted_lrew_ba: \" + str(predicted_lrew_ba.shape))\n",
    "    ## Load actual rewards\n",
    "    lrew_ab = pd.read_pickle(os.path.join(ml_input_path,\n",
    "        \"train_rew_\" + dataset + \"_fullab.pkl\"))\n",
    "    print(\"Loaded lrew_ab: \" + str(lrew_ab.shape))\n",
    "    lrew_ba = pd.read_pickle(os.path.join(ml_input_path,\n",
    "        \"train_rew_\" + dataset + \"_fullba.pkl\"))\n",
    "    print(\"Loaded lrew_ba: \" + str(lrew_ba.shape))\n",
    "    ## Load actual mean-differenced rewards\n",
    "    #mdlrew_train = pd.read_pickle(\"./train_mdrewards.pkl\")\n",
    "    #mdlrew_test = pd.read_pickle(\"./test_mdrewards.pkl\")\n",
    "\n",
    "    ## Load best duration predictions\n",
    "    predicted_ldur_ab = joblib.load(os.path.join(ml_output_path,\n",
    "        \"predictions_\" + dataset + \"_fullab_dur.pkl\"))\n",
    "    predicted_ldur_ba = joblib.load(os.path.join(ml_output_path,\n",
    "        \"predictions_\" + dataset + \"_fullba_dur.pkl\"))\n",
    "    ## Load actual durations\n",
    "    ldur_ab = pd.read_pickle(os.path.join(ml_input_path,\n",
    "        \"train_dur_\" + dataset + \"_fullab.pkl\"))\n",
    "    ldur_ba = pd.read_pickle(os.path.join(ml_input_path,\n",
    "        \"train_dur_\" + dataset + \"_fullba.pkl\"))\n",
    "\n",
    "    ## Compute reward residuals = V_hat\n",
    "    # 这部分看起来奇怪是因为最近预测的集合是集合A（原始训练集），集合A的残差是lrew_train - predicted_lrew。这点对集合B也一样\n",
    "    lrew_resid_ab = lrew_ba - predicted_lrew_ab\n",
    "    lrew_resid_ab.rename(\"lrew_resid\",inplace=True)\n",
    "    lrew_resid_ba = lrew_ab - predicted_lrew_ba\n",
    "    lrew_resid_ba.rename(\"lrew_resid_ba\",inplace=True)\n",
    "    ## Compute mean-differenced log(reward) residuals\n",
    "    #mdlrew_resid = mdlrew_test - predicted_mdlrew\n",
    "    #mdlrew_resid.rename(\"mdlrew_resid\",inplace=True)\n",
    "    #mdlrew_resid_flip = mdlrew_train - predicted_mdlrew_flip\n",
    "    #mdlrew_resid_flip.rename(\"mdlrew_resid_flip\",inplace=True)\n",
    "\n",
    "    ## Compute log(duration) residuals = W_hat\n",
    "    ldur_resid_ab = ldur_ba - predicted_ldur_ab\n",
    "    ldur_resid_ab.rename(\"ldur_resid\",inplace=True)\n",
    "    ldur_resid_ba = ldur_ab - predicted_ldur_ba\n",
    "    ldur_resid_ba.rename(\"ldur_resid_ba\",inplace=True)\n",
    "    ## Compute mean-differenced log(duration) residuals\n",
    "    #mdldur_resid = mdldur_test - predicted_mdldur\n",
    "    #mdldur_resid.rename(\"mdldur_resid\",inplace=True)\n",
    "    #mdldur_resid_flip = mdldur_train - predicted_mdldur_flip\n",
    "    #mdldur_resid_flip.rename(\"mdldur_resid_flip\",inplace=True)\n",
    "    ## Compute log(normalized duration) residuals\n",
    "    #lndur_resid = lndur - predicted_lndur\n",
    "    #lndur_resid.rename(\"lndur_resid\",inplace=True)\n",
    "\n",
    "    ## Theta_check(log(reward) -> log(duration))\n",
    "    theta_check_ab = computeThetaCheck(lrew_resid_ab, ldur_resid_ab)\n",
    "    print(\"Standard theta_check: \" + str(theta_check_ab))\n",
    "    theta_check_ba = computeThetaCheck(lrew_resid_ba, ldur_resid_ba)\n",
    "    print(\"Standard theta_check (flipped data): \" + str(theta_check_ba))\n",
    "    avg_theta_check = (theta_check_ab + theta_check_ba)/2\n",
    "    print(\"Averaged theta_check: \" + str(avg_theta_check))\n",
    "\n",
    "    ## Theta_check(md(log(reward)) -> md(log(duration)))\n",
    "    #theta_check_md = computeThetaCheck(mdlrew_resid, mdldur_resid)\n",
    "    #print(\"Mean-differenced theta_check: \" + str(theta_check_md))\n",
    "    #theta_check_md_flip = computeThetaCheck(mdlrew_resid_flip, mdldur_resid_flip)\n",
    "    #print(\"Mean-differenced theta_check (flipped data): \" + str(theta_check_md_flip))\n",
    "    #avg_theta_check_md = (theta_check_md + theta_check_md_flip) / 2\n",
    "    #print(\"Averaged mean-differenced theta_check: \" + str(avg_theta_check_md))\n",
    "\n",
    "    # Theta_check(log(reward) -> log(normduration))\n",
    "    #theta_check_ndur = computeThetaCheck(lrew_resid, lndur_resid)\n",
    "    #print(\"Standard theta_check with normalized durations: \" + str(theta_check_ndur))\n",
    "\n",
    "    # Theta_check(md(log(reward)) -> log(normduration))\n",
    "    #theta_check_md_ndur = computeThetaCheck(mdlrew_resid, lndur_resid)\n",
    "    #print(\"Mean-differenced theta_check with normalized durations: \" + str(theta_check_md_ndur))\n",
    "\n",
    "    ###############################\n",
    "    ### Part II: 导出文件 ###\n",
    "    ###############################\n",
    "\n",
    "    # 将计算出来的双重机器学习估计值，即预测值和残差值合并回原有数据集\n",
    "    residual_vars = [lrew_resid_ab, ldur_resid_ab]\n",
    "    residual_vars_flip = [lrew_resid_ba,ldur_resid_ba]\n",
    "    if mean_differenced:\n",
    "        residual_vars = residual_vars + [mdlrew_resid, mdldur_resid]\n",
    "        #residual_vars_flip = residual_vars_flip + [mdlrew_resid_flip, mdldur_resid_flip]\n",
    "    residual_df = pd.concat(residual_vars, axis=1)\n",
    "    residual_df_flip = pd.concat(residual_vars_flip, axis=1)\n",
    "    #residual_df = pd.concat([mdlrew_resid, mdldur_resid], axis=1)\n",
    "\n",
    "    # Merge predicted vals back into the test data DFs\n",
    "    residual_df[\"predicted_lrew\"] = predicted_lrew_ab\n",
    "    residual_df_flip[\"predicted_lrew_ba\"] = predicted_lrew_ba\n",
    "    if mean_differenced:\n",
    "        residual_df[\"predicted_mdlrew\"] = predicted_mdlrew\n",
    "        #residual_df_flip[\"predicted_mdlrew_flip\"] = predicted_mdlrew_flip\n",
    "    residual_df[\"predicted_ldur\"] = predicted_ldur_ab\n",
    "    residual_df_flip[\"predicted_ldur_ba\"] = predicted_ldur_ba\n",
    "    if mean_differenced:\n",
    "        residual_df[\"predicted_mdldur\"] = predicted_mdldur\n",
    "        residual_df_flip[\"predicted_mdldur_flip\"] = predicted_mdldur_flip\n",
    "    #residual_df[\"predicted_lndur\"] = predicted_lndur\n",
    "\n",
    "    if dataset == \"ipeirotis\":\n",
    "        ## Now merge *this* residual_df back into the full dataset\n",
    "        full_df = pd.read_pickle(os.path.join(cleaned_path,\"ipeirotis_cleaned.pkl\"))\n",
    "    if dataset == \"textlab_30\":\n",
    "        ## Or the full 400k obs TextLab 30-minute dataset\n",
    "        full_df = pd.read_pickle(os.path.join(cleaned_path,\"textlab_30_cleaned.pkl\"))\n",
    "    if dataset == \"textlab_10\":\n",
    "        ## Or 100k obs TextLab 10-minute dataset\n",
    "        full_df = pd.read_pickle(os.path.join(cleaned_path,\"textlab_10_cleaned.pkl\"))\n",
    "    # 只有删除desc和kw才能让pandas写入dta\n",
    "    if dataset != \"textlab_30\":\n",
    "        full_df.drop(\"description\",axis=1,inplace=True)\n",
    "        full_df.drop(\"keywords\",axis=1,inplace=True)\n",
    "        full_df.drop(\"kw_parsed\",axis=1,inplace=True)\n",
    "    #full_df.drop(\"qualifications\",axis=1,inplace=True)\n",
    "    # And reset the index, so it's 0, 1, 2, ... instead of the group ids\n",
    "    #full_df.index = full_df.index.astype(int)\n",
    "    full_df.reset_index(inplace=True)\n",
    "\n",
    "    # Merge the \"normal\" training-test split residuals in\n",
    "    full_df_merged = full_df.merge(residual_df,how='left',left_index=True,right_index=True,indicator=True)\n",
    "    full_df_merged[\"_merge\"] = full_df_merged[\"_merge\"].replace('both',1)\n",
    "    full_df_merged[\"_merge\"] = full_df_merged[\"_merge\"].replace('left_only',0)\n",
    "    full_df_merged[\"_merge\"] = full_df_merged[\"_merge\"].replace('right_only',0)\n",
    "    full_df_merged.rename(index=str,columns={'_merge':'A_B'},inplace=True)\n",
    "    # print(full_df_merged)\n",
    "    full_df_merged[\"A_B\"] = full_df_merged[\"A_B\"].astype(int)\n",
    "    full_df_merged.index = full_df_merged.index.astype(int)\n",
    "\n",
    "    flip_vars = [\"lrew_resid_ba\",\"ldur_resid_ba\",\"predicted_lrew_ba\",\n",
    "                 \"predicted_ldur_ba\"]\n",
    "    if mean_differenced:\n",
    "        flip_vars = flip_vars + [\"mdlrew_resid_flip\",\"mdldur_resid_flip\",\n",
    "                                \"predicted_mdlrew_flip\",\"predicted_mdldur_flip\"]\n",
    "\n",
    "    # And merge the flipped residuals in\n",
    "    full_df_merged = full_df_merged.merge(residual_df_flip,how='left',left_index=True,right_index=True,indicator=True)\n",
    "    full_df_merged[\"_merge\"] = full_df_merged[\"_merge\"].replace('both',2)\n",
    "    full_df_merged[\"_merge\"] = full_df_merged[\"_merge\"].replace('left_only',0)\n",
    "    full_df_merged[\"_merge\"] = full_df_merged[\"_merge\"].replace('right_only',0)\n",
    "    full_df_merged[\"_merge\"] = full_df_merged[\"_merge\"].astype(int)\n",
    "    full_df_merged[\"A_B\"] = full_df_merged[\"A_B\"] + full_df_merged[\"_merge\"]\n",
    "    full_df_merged.drop(\"_merge\",axis=1,inplace=True)\n",
    "\n",
    "    # Now fill the (non-flipped) NaN values with the flipped values\n",
    "    full_df_merged[\"lrew_resid\"] = full_df_merged[\"lrew_resid\"].fillna(full_df_merged[\"lrew_resid_ba\"])\n",
    "    #full_df_merged[\"mdlrew_resid\"] = full_df_merged[\"mdlrew_resid\"].fillna(full_df_merged[\"mdlrew_resid_flip\"])\n",
    "    full_df_merged[\"ldur_resid\"] = full_df_merged[\"ldur_resid\"].fillna(full_df_merged[\"ldur_resid_ba\"])\n",
    "    #full_df_merged[\"mdldur_resid\"] = full_df_merged[\"mdldur_resid\"].fillna(full_df_merged[\"mdldur_resid_flip\"])\n",
    "    full_df_merged[\"predicted_lrew\"] = full_df_merged[\"predicted_lrew\"].fillna(full_df_merged[\"predicted_lrew_ba\"])\n",
    "    #full_df_merged[\"predicted_mdlrew\"] = full_df_merged[\"predicted_mdlrew\"].fillna(full_df_merged[\"predicted_mdlrew_flip\"])\n",
    "    full_df_merged[\"predicted_ldur\"] = full_df_merged[\"predicted_ldur\"].fillna(full_df_merged[\"predicted_ldur_ba\"])\n",
    "    #full_df_merged[\"predicted_mdldur\"] = full_df_merged[\"predicted_mdldur\"].fillna(full_df_merged[\"predicted_mdldur_flip\"])\n",
    "\n",
    "    full_df_merged.drop(flip_vars,axis=1,inplace=True)\n",
    "\n",
    "    #####################\n",
    "    ### The export!!! ###\n",
    "    #####################\n",
    "\n",
    "    # Load the R^2 terms from the ML runs\n",
    "    format_str = \"{0:.4f}\"\n",
    "    lrew_r2 = format_str.format(joblib.load(os.path.join(ml_output_path,\n",
    "        \"pred_score_\" + dataset + \"_fullab_rew.pkl\")))\n",
    "    lrew_r2_flip = format_str.format(joblib.load(os.path.join(ml_output_path,\n",
    "        \"pred_score_\" + dataset + \"_fullba_rew.pkl\")))\n",
    "    ldur_r2 = format_str.format(joblib.load(os.path.join(ml_output_path,\n",
    "        \"pred_score_\" + dataset + \"_fullab_dur.pkl\")))\n",
    "    ldur_r2_flip = format_str.format(joblib.load(os.path.join(ml_output_path,\n",
    "        \"pred_score_\" + dataset + \"_fullba_dur.pkl\")))\n",
    "    if mean_differenced:\n",
    "        mdlrew_r2 = format_str.format(joblib.load(os.path.join(ml_output_path,\n",
    "            \"pred_score_rfr_mdlrew.pkl\")))\n",
    "        #mdlrew_r2_flip = format_str.format(joblib.load(\"pred_score_rfr_mdlrewflip.pkl\"))\n",
    "        mdldur_r2 = format_str.format(joblib.load(os.path.join(ml_output_path,\n",
    "            \"pred_score_rfr_mdldur.pkl\")))\n",
    "        #mdldur_r2_flip = format_str.format(joblib.load(\"pred_score_rfr_mdldurflip.pkl\"))\n",
    "\n",
    "    # Export dataset of residuals to Stata\n",
    "    label_map = {}\n",
    "    label_map[\"lrew_resid\"] = \"log(reward) residuals. Rsq_0 = \" + lrew_r2 + \", Rsq_1 = \" + lrew_r2_flip\n",
    "    label_map[\"ldur_resid\"] = \"log(duration) residuals. Rsq_0 = \" + ldur_r2 + \", Rsq_1 = \" + ldur_r2_flip\n",
    "    if mean_differenced:\n",
    "        label_map[\"mdlrew_resid\"] = \"Mean-differenced log(reward) residuals. Rsq_0 = \" + mdlrew_r2 + \", Rsq_1 = \" + mdlrew_r2_flip\n",
    "        label_map[\"mdldur_resid\"] = \"Mean-differenced log(duration) residuals. Rsq_0 = \" + mdldur_r2 + \", Rsq_1 = \" + mdldur_r2_flip\n",
    "    label_map[\"A_B\"] = \"0 if not used, 1 if in Set A (first train data), 2 if in Set B (first test data)\"\n",
    "    residuals_filepath = os.path.join(estimates_path, \"residuals_full_\" + dataset + \".dta\")\n",
    "    if \"level_0\" in full_df_merged.columns:\n",
    "        full_df_merged.drop(\"level_0\",axis=1,inplace=True)\n",
    "    if \"qualifications\" in full_df_merged.columns:\n",
    "        full_df_merged.drop(\"qualifications\",axis=1,inplace=True)\n",
    "    full_df_merged.to_stata(residuals_filepath, variable_labels=label_map)\n",
    "    print(\"Exported Stata file \" + residuals_filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e400104-0aa1-486d-9444-a9df172ebd45",
   "metadata": {},
   "source": [
    "### （九）正式计算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "dccbd023-2283-4fc2-80f6-8dd5aa73c850",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** A->B n-gram ML run\n",
      "# A obs: 129751\n",
      "# B obs: 129751\n",
      "# A_train obs: 103800\n",
      "# A_val obs: 25951\n",
      "# B_train obs: 103800\n",
      "# B_val obs: 25951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\1619589998.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  feature_df[\"description\"] = feature_df[\"description\"].astype(str)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\1619589998.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  feature_df[\"kw_parsed\"] = feature_df[\"kw_parsed\"].astype(str)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\1619589998.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  feature_df[\"qualifications\"] = feature_df[\"qualifications\"].astype(str)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\1619589998.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  feature_df[\"title\"] = feature_df[\"title\"].astype(str)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descriptions vectorized for train data\n",
      "Keywords vectorized for train data\n",
      "Titles vectorized for train data\n",
      "(103800, 419295)\n",
      "(103800, 8952)\n",
      "(103800, 282599)\n",
      "Feature names saved to .\\ml_input\\feat_names_ipeirotis_gramab.pkl\n",
      "Validation set descriptions vectorized\n",
      "Validation set keywords vectorized\n",
      "Validation set titles vectorized\n",
      "(25951, 419295)\n",
      "(25951, 8952)\n",
      "(25951, 282599)\n",
      "Train rewards saved to .\\ml_input\\./train_rew_ipeirotis_gramab.pkl\n",
      "Train durations saved to .\\ml_input\\./train_dur_ipeirotis_gramab.pkl\n",
      "Train text features saved to .\\ml_input\\./train_txtfeats_ipeirotis_gramab.pkl\n",
      "Training data saved\n",
      "Test rewards saved to .\\ml_input\\./test_rew_ipeirotis_gramab.pkl\n",
      "Test durations saved to .\\ml_input\\./test_dur_ipeirotis_gramab.pkl\n",
      "Test text features saved to .\\ml_input\\./test_txtfeats_ipeirotis_gramab.pkl\n",
      "Validation data saved\n",
      "Textual features exported\n",
      "*** Train data: ***\n",
      "Features: (103800, 710846)\n",
      "Reward labels: (103800,)\n",
      "Duration labels: (103800,)\n",
      "*** Validation data: ***\n",
      "Features: (25951, 710846)\n",
      "Reward labels: (25951,)\n",
      "Duration labels: (25951,)\n",
      "Training data loaded\n",
      "Test data loaded\n",
      "----- [Running *reward* ML with text features] -----\n",
      "Running ipeirotis_gramab_rew\n",
      "building tree 1 of 40\n",
      "building tree 2 of 40\n",
      "building tree 3 of 40\n",
      "building tree 4 of 40\n",
      "building tree 5 of 40\n",
      "building tree 6 of 40\n",
      "building tree 7 of 40\n",
      "building tree 8 of 40\n",
      "building tree 9 of 40\n",
      "building tree 10 of 40\n",
      "building tree 11 of 40\n",
      "building tree 12 of 40\n",
      "building tree 13 of 40\n",
      "building tree 14 of 40\n",
      "building tree 15 of 40\n",
      "building tree 16 of 40\n",
      "building tree 17 of 40\n",
      "building tree 18 of 40\n",
      "building tree 19 of 40\n",
      "building tree 20 of 40\n",
      "building tree 21 of 40\n",
      "building tree 22 of 40\n",
      "building tree 23 of 40\n",
      "building tree 24 of 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 24 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 25 of 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed: 15.2min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 26 of 40\n",
      "building tree 27 of 40\n",
      "building tree 28 of 40\n",
      "building tree 29 of 40\n",
      "building tree 30 of 40\n",
      "building tree 31 of 40\n",
      "building tree 32 of 40\n",
      "building tree 33 of 40\n",
      "building tree 34 of 40\n",
      "building tree 35 of 40\n",
      "building tree 36 of 40\n",
      "building tree 37 of 40\n",
      "building tree 38 of 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  14 out of  40 | elapsed: 15.5min remaining: 28.7min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 39 of 40\n",
      "building tree 40 of 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  35 out of  40 | elapsed: 24.6min remaining:  3.5min\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed: 24.6min finished\n",
      "[Parallel(n_jobs=24)]: Using backend ThreadingBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=24)]: Done   1 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=24)]: Done  14 out of  40 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=24)]: Done  35 out of  40 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=24)]: Done  40 out of  40 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=24)]: Using backend ThreadingBackend with 24 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ipeirotis_gramab_rew fit complete\n",
      "Fitted model saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=24)]: Done   1 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=24)]: Done  14 out of  40 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=24)]: Done  35 out of  40 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=24)]: Done  40 out of  40 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 24 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitAndPredict: 1478.6810615062714 seconds\n",
      "0.7661512227220669\n",
      "----- [Running *duration* ML with text features] -----\n",
      "Running ipeirotis_gramab_dur\n",
      "building tree 1 of 40\n",
      "building tree 2 of 40\n",
      "building tree 3 of 40\n",
      "building tree 4 of 40\n",
      "building tree 5 of 40\n",
      "building tree 6 of 40\n",
      "building tree 7 of 40\n",
      "building tree 8 of 40\n",
      "building tree 9 of 40\n",
      "building tree 10 of 40\n",
      "building tree 11 of 40\n",
      "building tree 12 of 40\n",
      "building tree 13 of 40\n",
      "building tree 14 of 40\n",
      "building tree 15 of 40\n",
      "building tree 16 of 40\n",
      "building tree 17 of 40\n",
      "building tree 18 of 40\n",
      "building tree 19 of 40\n",
      "building tree 20 of 40\n",
      "building tree 21 of 40\n",
      "building tree 22 of 40\n",
      "building tree 23 of 40\n",
      "building tree 24 of 40\n",
      "building tree 25 of 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed: 30.1min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 26 of 40\n",
      "building tree 27 of 40\n",
      "building tree 28 of 40\n",
      "building tree 29 of 40\n",
      "building tree 30 of 40\n",
      "building tree 31 of 40\n",
      "building tree 32 of 40\n",
      "building tree 33 of 40\n",
      "building tree 34 of 40\n",
      "building tree 35 of 40\n",
      "building tree 36 of 40\n",
      "building tree 37 of 40\n",
      "building tree 38 of 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  14 out of  40 | elapsed: 31.1min remaining: 57.8min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 39 of 40\n",
      "building tree 40 of 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  35 out of  40 | elapsed: 49.5min remaining:  7.1min\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed: 49.9min finished\n",
      "[Parallel(n_jobs=24)]: Using backend ThreadingBackend with 24 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ipeirotis_gramab_dur fit complete\n",
      "Fitted model saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=24)]: Done   1 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=24)]: Done  14 out of  40 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=24)]: Done  35 out of  40 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=24)]: Done  40 out of  40 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=24)]: Using backend ThreadingBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=24)]: Done   1 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=24)]: Done  14 out of  40 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=24)]: Done  35 out of  40 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=24)]: Done  40 out of  40 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitAndPredict: 2991.8724117279053 seconds\n",
      "0.4042878636049796\n",
      "*** A->B computing most predictive features\n",
      "Generating most predictive features for dur\n",
      "Number of features: 710846\n",
      "Features outputted to: .\\predictive_feats\\predictive_ipeirotis_gramab_dur.csv\n",
      "Generating most predictive features for rew\n",
      "Number of features: 710846\n",
      "Features outputted to: .\\predictive_feats\\predictive_ipeirotis_gramab_rew.csv\n",
      "*** A->B full ML run\n",
      "# A obs: 129751\n",
      "# B obs: 129751\n",
      "# A_train obs: 103800\n",
      "# A_val obs: 25951\n",
      "# B_train obs: 103800\n",
      "# B_val obs: 25951\n",
      "Number of description features: 93\n",
      "Number of title features: 75\n",
      "Number of keyword features: 32\n",
      "Computing feature #0: easy\n",
      "Computing feature #1: transcribe\n",
      "Computing feature #2: writing\n",
      "Computing feature #3: audio\n",
      "Computing feature #4: image\n",
      "Computing feature #5: video\n",
      "Computing feature #6: bonus\n",
      "Computing feature #7: copy\n",
      "Computing feature #8: search\n",
      "Computing feature #9: identify\n",
      "Computing feature #10: text\n",
      "Computing feature #11: date\n",
      "Computing feature #12: fun\n",
      "Computing feature #13: simple\n",
      "Computing feature #14: summarize\n",
      "Computing feature #15: only\n",
      "Computing feature #16: improve\n",
      "Computing feature #17: five\n",
      "Computing feature #18: questionmark\n",
      "Computing feature #19: exclamation\n",
      "Computing feature #20: find\n",
      "Computing feature #21: check\n",
      "Computing feature #22: match\n",
      "Computing feature #23: choose\n",
      "Computing feature #24: categorize\n",
      "Computing feature #25: suggest\n",
      "Computing feature #26: translate\n",
      "Computing feature #27: survey\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[kw_var] = (hit_df[\"kw_lower\"].str.count(str_to_search).fillna(0)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing feature #28: click\n",
      "Computing feature #29: link\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[kw_var] = (hit_df[\"kw_lower\"].str.count(str_to_search).fillna(0)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[kw_var] = (hit_df[\"kw_lower\"].str.count(str_to_search).fillna(0)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[kw_var] = (hit_df[\"kw_lower\"].str.count(str_to_search).fillna(0)).astype(int)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing feature #30: read\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[kw_var] = (hit_df[\"kw_lower\"].str.count(str_to_search).fillna(0)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[kw_var] = (hit_df[\"kw_lower\"].str.count(str_to_search).fillna(0)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[kw_var] = (hit_df[\"kw_lower\"].str.count(str_to_search).fillna(0)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[kw_var] = (hit_df[\"kw_lower\"].str.count(str_to_search).fillna(0)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[kw_var] = (hit_df[\"kw_lower\"].str.count(str_to_search).fillna(0)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[kw_var] = (hit_df[\"kw_lower\"].str.count(str_to_search).fillna(0)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[kw_var] = (hit_df[\"kw_lower\"].str.count(str_to_search).fillna(0)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[kw_var] = (hit_df[\"kw_lower\"].str.count(str_to_search).fillna(0)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[kw_var] = (hit_df[\"kw_lower\"].str.count(str_to_search).fillna(0)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[kw_var] = (hit_df[\"kw_lower\"].str.count(str_to_search).fillna(0)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[kw_var] = (hit_df[\"kw_lower\"].str.count(str_to_search).fillna(0)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[kw_var] = (hit_df[\"kw_lower\"].str.count(str_to_search).fillna(0)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[kw_var] = (hit_df[\"kw_lower\"].str.count(str_to_search).fillna(0)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[kw_var] = (hit_df[\"kw_lower\"].str.count(str_to_search).fillna(0)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[kw_var] = (hit_df[\"kw_lower\"].str.count(str_to_search).fillna(0)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[kw_var] = (hit_df[\"kw_lower\"].str.count(str_to_search).fillna(0)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[kw_var] = (hit_df[\"kw_lower\"].str.count(str_to_search).fillna(0)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[kw_var] = (hit_df[\"kw_lower\"].str.count(str_to_search).fillna(0)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[kw_var] = (hit_df[\"kw_lower\"].str.count(str_to_search).fillna(0)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[kw_var] = (hit_df[\"kw_lower\"].str.count(str_to_search).fillna(0)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[kw_var] = (hit_df[\"kw_lower\"].str.count(str_to_search).fillna(0)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[kw_var] = (hit_df[\"kw_lower\"].str.count(str_to_search).fillna(0)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[kw_var] = (hit_df[\"kw_lower\"].str.count(str_to_search).fillna(0)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[kw_var] = (hit_df[\"kw_lower\"].str.count(str_to_search).fillna(0)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[kw_var] = (hit_df[\"kw_lower\"].str.count(str_to_search).fillna(0)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[kw_var] = (hit_df[\"kw_lower\"].str.count(str_to_search).fillna(0)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[kw_var] = (hit_df[\"kw_lower\"].str.count(str_to_search).fillna(0)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[kw_var] = (hit_df[\"kw_lower\"].str.count(str_to_search).fillna(0)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[kw_var] = (hit_df[\"kw_lower\"].str.count(str_to_search).fillna(0)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[kw_var] = (hit_df[\"kw_lower\"].str.count(str_to_search).fillna(0)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[kw_var] = (hit_df[\"kw_lower\"].str.count(str_to_search).fillna(0)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[kw_var] = (hit_df[\"kw_lower\"].str.count(str_to_search).fillna(0)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[\"minutes_title\"] = hit_df[\"title_lower\"].str.extract(minutes_reg,expand=False).fillna(0).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:72: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[\"minutes_desc\"] = hit_df[\"desc_lower\"].str.extract(minutes_reg,expand=False).fillna(0).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:73: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[\"minutes_kw\"] = hit_df[\"kw_lower\"].str.extract(minutes_reg,expand=False).fillna(0).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\1226819826.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[\"qual_len\"] = hit_df[\"qualifications\"].apply(lambda x: len(x) if pd.notnull(x) else 0)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\1226819826.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[\"num_quals\"] = (hit_df[\"qualifications\"].str.count(list_sep) + 1).fillna(0).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\1226819826.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[\"custom_not_granted\"] = hit_df[\"qualifications\"].str.count(qual_not_granted).fillna(0).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\1226819826.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[\"custom_granted\"] = hit_df[\"qualifications\"].str.count(qual_granted).fillna(0).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\1226819826.py:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[\"any_loc\"] = ((hit_df[\"locs\"] + hit_df[\"locs_mult\"]) != \"\").astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\1226819826.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[\"us_only\"] = ((hit_df[\"locs\"] + \"|\" + hit_df[\"locs_mult\"]).str.contains(\"US\")).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\1226819826.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[\"appr_rate_gt\"] = hit_df[\"qualifications\"].str.extract(qual_appr_rate_gt,expand=False).fillna(-1).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\1226819826.py:34: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[\"appr_num_gt\"] = hit_df[\"qualifications\"].str.extract(qual_appr_num_gt,expand=False).fillna(-1).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3226286950.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df.reset_index(inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDA features merged in\n",
      "Doc2Vec features merged in\n",
      "                              group_id      duration  log_duration  reward  \\\n",
      "259497  3ZY19HV01BIMKUJC8R23XWPE2U4GSE   1512.933333      7.321806       5   \n",
      "259498  3ZY19HV01BIUAL70JGMVTT0E150GSD     35.766667      3.577016      40   \n",
      "259499  3ZY19HV01BMN1HMYRKAG7N9SYLVGSY    396.566667      5.982844      15   \n",
      "259500            4YFZK2ZCCXSZ64ZJNTR0     34.916667      3.552964       5   \n",
      "259501            J1ZZNQGNTW1YZVD8FWTZ  20171.916667      9.912047       5   \n",
      "\n",
      "        log_reward  meandiff_lreward  meandiff_ldur  time_allotted  \\\n",
      "259497    1.609438         -0.405465      -0.990035           1500   \n",
      "259498    3.688879          0.000000      -4.468027           3600   \n",
      "259499    2.708050         -0.815037      -2.454863           3600   \n",
      "259500    1.609438          0.000000       0.000000           1200   \n",
      "259501    1.609438          0.000000       1.182741           3600   \n",
      "\n",
      "        first_hits  last_hits  ...  doc2vec_kw_40  doc2vec_kw_41  \\\n",
      "259497           1          0  ...       0.001703      -0.022494   \n",
      "259498           1          0  ...       0.035416      -0.013044   \n",
      "259499           1          0  ...       0.022562       0.000857   \n",
      "259500         176          0  ...       0.063211      -0.022357   \n",
      "259501          64          0  ...      -0.270207       0.080985   \n",
      "\n",
      "        doc2vec_kw_42  doc2vec_kw_43  doc2vec_kw_44  doc2vec_kw_45  \\\n",
      "259497      -0.020022       0.004839      -0.071768      -0.070872   \n",
      "259498      -0.014742       0.012896       0.005869      -0.008734   \n",
      "259499       0.000976       0.029591      -0.004299      -0.003275   \n",
      "259500       0.006728       0.023312      -0.023521      -0.012213   \n",
      "259501       0.120046      -0.101056       0.053459       0.055652   \n",
      "\n",
      "        doc2vec_kw_46  doc2vec_kw_47  doc2vec_kw_48  doc2vec_kw_49  \n",
      "259497      -0.044790      -0.019276       0.009722      -0.045072  \n",
      "259498      -0.024511       0.014906       0.013756      -0.021019  \n",
      "259499      -0.022727      -0.010653       0.012825      -0.016798  \n",
      "259500      -0.056970      -0.005674      -0.018408      -0.048212  \n",
      "259501       0.396261       0.026271       0.192404       0.170060  \n",
      "\n",
      "[5 rows x 479 columns]\n",
      "avg_hitrate: 10 nans, 0 infs\n",
      "Mean hitrate: 62.771909907471965\n",
      "Max hitrate: 78241.55253860554\n",
      "Train rewards saved to .\\ml_input\\./train_rew_ipeirotis_fullab.pkl\n",
      "Train durations saved to .\\ml_input\\./train_dur_ipeirotis_fullab.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\2253851036.py:109: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_df.drop([col_name],axis=1,inplace=True)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\2253851036.py:109: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_df.drop([col_name],axis=1,inplace=True)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\2253851036.py:109: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_df.drop([col_name],axis=1,inplace=True)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\2253851036.py:109: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_df.drop([col_name],axis=1,inplace=True)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\2253851036.py:109: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_df.drop([col_name],axis=1,inplace=True)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\2253851036.py:109: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_df.drop([col_name],axis=1,inplace=True)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\2253851036.py:109: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_df.drop([col_name],axis=1,inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train features saved to .\\ml_input\\./train_feats_ipeirotis_fullab.pkl\n",
      "Training data saved\n",
      "Test rewards saved to .\\ml_input\\./test_rew_ipeirotis_fullab.pkl\n",
      "Test durations saved to .\\ml_input\\./test_dur_ipeirotis_fullab.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\2253851036.py:136: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df.drop([col_name],axis=1,inplace=True)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\2253851036.py:136: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df.drop([col_name],axis=1,inplace=True)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\2253851036.py:136: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df.drop([col_name],axis=1,inplace=True)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\2253851036.py:136: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df.drop([col_name],axis=1,inplace=True)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\2253851036.py:136: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df.drop([col_name],axis=1,inplace=True)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\2253851036.py:136: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df.drop([col_name],axis=1,inplace=True)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\2253851036.py:136: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df.drop([col_name],axis=1,inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test features saved to .\\ml_input\\./test_feats_ipeirotis_fullab.pkl\n",
      "Test data saved\n",
      "Training data dimensions: (129751, 322)\n",
      "Test data dimensions: (129751, 322)\n",
      "Training data loaded\n",
      "Test data loaded\n",
      "----- [Running *reward* ML with numeric features] -----\n",
      "Running ipeirotis_fullab_rew\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 24 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 600building tree 2 of 600\n",
      "\n",
      "building tree 3 of 600\n",
      "building tree 4 of 600\n",
      "building tree 5 of 600\n",
      "building tree 6 of 600\n",
      "building tree 7 of 600\n",
      "building tree 8 of 600\n",
      "building tree 9 of 600\n",
      "building tree 10 of 600\n",
      "building tree 11 of 600\n",
      "building tree 12 of 600\n",
      "building tree 13 of 600\n",
      "building tree 14 of 600\n",
      "building tree 15 of 600\n",
      "building tree 16 of 600\n",
      "building tree 17 of 600\n",
      "building tree 18 of 600\n",
      "building tree 19 of 600\n",
      "building tree 20 of 600\n",
      "building tree 21 of 600\n",
      "building tree 22 of 600\n",
      "building tree 23 of 600\n",
      "building tree 24 of 600\n",
      "building tree 25 of 600\n",
      "building tree 26 of 600\n",
      "building tree 27 of 600\n",
      "building tree 28 of 600\n",
      "building tree 29 of 600\n",
      "building tree 30 of 600\n",
      "building tree 31 of 600\n",
      "building tree 32 of 600\n",
      "building tree 33 of 600\n",
      "building tree 34 of 600\n",
      "building tree 35 of 600\n",
      "building tree 36 of 600\n",
      "building tree 37 of 600\n",
      "building tree 38 of 600\n",
      "building tree 39 of 600\n",
      "building tree 40 of 600\n",
      "building tree 41 of 600\n",
      "building tree 42 of 600\n",
      "building tree 43 of 600\n",
      "building tree 44 of 600\n",
      "building tree 45 of 600\n",
      "building tree 46 of 600\n",
      "building tree 47 of 600\n",
      "building tree 48 of 600\n",
      "building tree 49 of 600\n",
      "building tree 50 of 600\n",
      "building tree 51 of 600\n",
      "building tree 52 of 600\n",
      "building tree 53 of 600\n",
      "building tree 54 of 600\n",
      "building tree 55 of 600\n",
      "building tree 56 of 600\n",
      "building tree 57 of 600\n",
      "building tree 58 of 600\n",
      "building tree 59 of 600\n",
      "building tree 60 of 600\n",
      "building tree 61 of 600\n",
      "building tree 62 of 600\n",
      "building tree 63 of 600\n",
      "building tree 64 of 600\n",
      "building tree 65 of 600\n",
      "building tree 66 of 600\n",
      "building tree 67 of 600\n",
      "building tree 68 of 600\n",
      "building tree 69 of 600building tree 70 of 600\n",
      "\n",
      "building tree 71 of 600\n",
      "building tree 72 of 600\n",
      "building tree 73 of 600\n",
      "building tree 74 of 600\n",
      "building tree 75 of 600\n",
      "building tree 76 of 600\n",
      "building tree 77 of 600\n",
      "building tree 78 of 600\n",
      "building tree 79 of 600\n",
      "building tree 80 of 600\n",
      "building tree 81 of 600\n",
      "building tree 82 of 600\n",
      "building tree 83 of 600\n",
      "building tree 84 of 600\n",
      "building tree 85 of 600\n",
      "building tree 86 of 600\n",
      "building tree 87 of 600\n",
      "building tree 88 of 600\n",
      "building tree 89 of 600\n",
      "building tree 90 of 600\n",
      "building tree 91 of 600\n",
      "building tree 92 of 600\n",
      "building tree 93 of 600\n",
      "building tree 94 of 600\n",
      "building tree 95 of 600\n",
      "building tree 96 of 600\n",
      "building tree 97 of 600\n",
      "building tree 98 of 600\n",
      "building tree 99 of 600\n",
      "building tree 100 of 600\n",
      "building tree 101 of 600\n",
      "building tree 102 of 600\n",
      "building tree 103 of 600\n",
      "building tree 104 of 600\n",
      "building tree 105 of 600\n",
      "building tree 106 of 600\n",
      "building tree 107 of 600\n",
      "building tree 108 of 600\n",
      "building tree 109 of 600\n",
      "building tree 110 of 600\n",
      "building tree 111 of 600\n",
      "building tree 112 of 600\n",
      "building tree 113 of 600\n",
      "building tree 114 of 600\n",
      "building tree 115 of 600\n",
      "building tree 116 of 600\n",
      "building tree 117 of 600\n",
      "building tree 118 of 600\n",
      "building tree 119 of 600\n",
      "building tree 120 of 600\n",
      "building tree 121 of 600\n",
      "building tree 122 of 600\n",
      "building tree 123 of 600\n",
      "building tree 124 of 600\n",
      "building tree 125 of 600\n",
      "building tree 126 of 600\n",
      "building tree 127 of 600\n",
      "building tree 128 of 600\n",
      "building tree 129 of 600\n",
      "building tree 130 of 600\n",
      "building tree 131 of 600\n",
      "building tree 132 of 600\n",
      "building tree 133 of 600\n",
      "building tree 134 of 600\n",
      "building tree 135 of 600\n",
      "building tree 136 of 600\n",
      "building tree 137 of 600\n",
      "building tree 138 of 600\n",
      "building tree 139 of 600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 114 tasks      | elapsed:   16.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 140 of 600\n",
      "building tree 141 of 600\n",
      "building tree 142 of 600\n",
      "building tree 143 of 600\n",
      "building tree 144 of 600\n",
      "building tree 145 of 600\n",
      "building tree 146 of 600\n",
      "building tree 147 of 600\n",
      "building tree 148 of 600\n",
      "building tree 149 of 600\n",
      "building tree 150 of 600\n",
      "building tree 151 of 600\n",
      "building tree 152 of 600\n",
      "building tree 153 of 600\n",
      "building tree 154 of 600\n",
      "building tree 155 of 600\n",
      "building tree 156 of 600\n",
      "building tree 157 of 600\n",
      "building tree 158 of 600\n",
      "building tree 159 of 600\n",
      "building tree 160 of 600\n",
      "building tree 161 of 600\n",
      "building tree 162 of 600\n",
      "building tree 163 of 600\n",
      "building tree 164 of 600\n",
      "building tree 165 of 600\n",
      "building tree 166 of 600\n",
      "building tree 167 of 600\n",
      "building tree 168 of 600\n",
      "building tree 169 of 600\n",
      "building tree 170 of 600\n",
      "building tree 171 of 600\n",
      "building tree 172 of 600\n",
      "building tree 173 of 600\n",
      "building tree 174 of 600\n",
      "building tree 175 of 600\n",
      "building tree 176 of 600\n",
      "building tree 177 of 600\n",
      "building tree 178 of 600\n",
      "building tree 179 of 600\n",
      "building tree 180 of 600\n",
      "building tree 181 of 600\n",
      "building tree 182 of 600\n",
      "building tree 183 of 600\n",
      "building tree 184 of 600\n",
      "building tree 185 of 600\n",
      "building tree 186 of 600\n",
      "building tree 187 of 600\n",
      "building tree 188 of 600\n",
      "building tree 189 of 600\n",
      "building tree 190 of 600\n",
      "building tree 191 of 600\n",
      "building tree 192 of 600\n",
      "building tree 193 of 600\n",
      "building tree 194 of 600\n",
      "building tree 195 of 600\n",
      "building tree 196 of 600\n",
      "building tree 197 of 600\n",
      "building tree 198 of 600\n",
      "building tree 199 of 600\n",
      "building tree 200 of 600\n",
      "building tree 201 of 600\n",
      "building tree 202 of 600\n",
      "building tree 203 of 600\n",
      "building tree 204 of 600\n",
      "building tree 205 of 600\n",
      "building tree 206 of 600\n",
      "building tree 207 of 600\n",
      "building tree 208 of 600\n",
      "building tree 209 of 600\n",
      "building tree 210 of 600\n",
      "building tree 211 of 600\n",
      "building tree 212 of 600\n",
      "building tree 213 of 600\n",
      "building tree 214 of 600\n",
      "building tree 215 of 600\n",
      "building tree 216 of 600\n",
      "building tree 217 of 600\n",
      "building tree 218 of 600\n",
      "building tree 219 of 600\n",
      "building tree 220 of 600\n",
      "building tree 221 of 600\n",
      "building tree 222 of 600\n",
      "building tree 223 of 600\n",
      "building tree 224 of 600\n",
      "building tree 225 of 600\n",
      "building tree 226 of 600\n",
      "building tree 227 of 600\n",
      "building tree 228 of 600\n",
      "building tree 229 of 600\n",
      "building tree 230 of 600\n",
      "building tree 231 of 600\n",
      "building tree 232 of 600\n",
      "building tree 233 of 600\n",
      "building tree 234 of 600\n",
      "building tree 235 of 600\n",
      "building tree 236 of 600\n",
      "building tree 237 of 600\n",
      "building tree 238 of 600\n",
      "building tree 239 of 600\n",
      "building tree 240 of 600\n",
      "building tree 241 of 600\n",
      "building tree 242 of 600\n",
      "building tree 243 of 600\n",
      "building tree 244 of 600\n",
      "building tree 245 of 600\n",
      "building tree 246 of 600\n",
      "building tree 247 of 600\n",
      "building tree 248 of 600\n",
      "building tree 249 of 600\n",
      "building tree 250 of 600\n",
      "building tree 251 of 600\n",
      "building tree 252 of 600\n",
      "building tree 253 of 600\n",
      "building tree 254 of 600\n",
      "building tree 255 of 600\n",
      "building tree 256 of 600\n",
      "building tree 257 of 600\n",
      "building tree 258 of 600\n",
      "building tree 259 of 600\n",
      "building tree 260 of 600\n",
      "building tree 261 of 600\n",
      "building tree 262 of 600\n",
      "building tree 263 of 600\n",
      "building tree 264 of 600\n",
      "building tree 265 of 600\n",
      "building tree 266 of 600\n",
      "building tree 267 of 600\n",
      "building tree 268 of 600\n",
      "building tree 269 of 600\n",
      "building tree 270 of 600\n",
      "building tree 271 of 600\n",
      "building tree 272 of 600\n",
      "building tree 273 of 600\n",
      "building tree 274 of 600\n",
      "building tree 275 of 600\n",
      "building tree 276 of 600\n",
      "building tree 277 of 600\n",
      "building tree 278 of 600\n",
      "building tree 279 of 600\n",
      "building tree 280 of 600\n",
      "building tree 281 of 600\n",
      "building tree 282 of 600\n",
      "building tree 283 of 600\n",
      "building tree 284 of 600\n",
      "building tree 285 of 600\n",
      "building tree 286 of 600\n",
      "building tree 287 of 600\n",
      "building tree 288 of 600\n",
      "building tree 289 of 600\n",
      "building tree 290 of 600\n",
      "building tree 291 of 600\n",
      "building tree 292 of 600\n",
      "building tree 293 of 600\n",
      "building tree 294 of 600\n",
      "building tree 295 of 600\n",
      "building tree 296 of 600\n",
      "building tree 297 of 600\n",
      "building tree 298 of 600\n",
      "building tree 299 of 600\n",
      "building tree 300 of 600\n",
      "building tree 301 of 600\n",
      "building tree 302 of 600\n",
      "building tree 303 of 600\n",
      "building tree 304 of 600\n",
      "building tree 305 of 600\n",
      "building tree 306 of 600\n",
      "building tree 307 of 600\n",
      "building tree 308 of 600\n",
      "building tree 309 of 600\n",
      "building tree 310 of 600\n",
      "building tree 311 of 600\n",
      "building tree 312 of 600\n",
      "building tree 313 of 600\n",
      "building tree 314 of 600\n",
      "building tree 315 of 600\n",
      "building tree 316 of 600\n",
      "building tree 317 of 600\n",
      "building tree 318 of 600\n",
      "building tree 319 of 600\n",
      "building tree 320 of 600\n",
      "building tree 321 of 600\n",
      "building tree 322 of 600\n",
      "building tree 323 of 600\n",
      "building tree 324 of 600\n",
      "building tree 325 of 600\n",
      "building tree 326 of 600\n",
      "building tree 327 of 600\n",
      "building tree 328 of 600\n",
      "building tree 329 of 600\n",
      "building tree 330 of 600\n",
      "building tree 331 of 600\n",
      "building tree 332 of 600\n",
      "building tree 333 of 600\n",
      "building tree 334 of 600\n",
      "building tree 335 of 600\n",
      "building tree 336 of 600\n",
      "building tree 337 of 600\n",
      "building tree 338 of 600\n",
      "building tree 339 of 600\n",
      "building tree 340 of 600\n",
      "building tree 341 of 600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 317 tasks      | elapsed:   45.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 342 of 600\n",
      "building tree 343 of 600\n",
      "building tree 344 of 600\n",
      "building tree 345 of 600\n",
      "building tree 346 of 600\n",
      "building tree 347 of 600\n",
      "building tree 348 of 600\n",
      "building tree 349 of 600\n",
      "building tree 350 of 600\n",
      "building tree 351 of 600\n",
      "building tree 352 of 600\n",
      "building tree 353 of 600\n",
      "building tree 354 of 600\n",
      "building tree 355 of 600\n",
      "building tree 356 of 600\n",
      "building tree 357 of 600\n",
      "building tree 358 of 600\n",
      "building tree 359 of 600\n",
      "building tree 360 of 600\n",
      "building tree 361 of 600\n",
      "building tree 362 of 600\n",
      "building tree 363 of 600\n",
      "building tree 364 of 600\n",
      "building tree 365 of 600\n",
      "building tree 366 of 600\n",
      "building tree 367 of 600\n",
      "building tree 368 of 600\n",
      "building tree 369 of 600\n",
      "building tree 370 of 600\n",
      "building tree 371 of 600\n",
      "building tree 372 of 600\n",
      "building tree 373 of 600\n",
      "building tree 374 of 600\n",
      "building tree 375 of 600\n",
      "building tree 376 of 600\n",
      "building tree 377 of 600\n",
      "building tree 378 of 600\n",
      "building tree 379 of 600\n",
      "building tree 380 of 600\n",
      "building tree 381 of 600\n",
      "building tree 382 of 600\n",
      "building tree 383 of 600\n",
      "building tree 384 of 600\n",
      "building tree 385 of 600\n",
      "building tree 386 of 600\n",
      "building tree 387 of 600\n",
      "building tree 388 of 600\n",
      "building tree 389 of 600\n",
      "building tree 390 of 600\n",
      "building tree 391 of 600\n",
      "building tree 392 of 600\n",
      "building tree 393 of 600\n",
      "building tree 394 of 600\n",
      "building tree 395 of 600\n",
      "building tree 396 of 600\n",
      "building tree 397 of 600\n",
      "building tree 398 of 600\n",
      "building tree 399 of 600\n",
      "building tree 400 of 600\n",
      "building tree 401 of 600\n",
      "building tree 402 of 600\n",
      "building tree 403 of 600\n",
      "building tree 404 of 600\n",
      "building tree 405 of 600\n",
      "building tree 406 of 600\n",
      "building tree 407 of 600\n",
      "building tree 408 of 600\n",
      "building tree 409 of 600\n",
      "building tree 410 of 600\n",
      "building tree 411 of 600\n",
      "building tree 412 of 600\n",
      "building tree 413 of 600\n",
      "building tree 414 of 600\n",
      "building tree 415 of 600\n",
      "building tree 416 of 600\n",
      "building tree 417 of 600\n",
      "building tree 418 of 600\n",
      "building tree 419 of 600\n",
      "building tree 420 of 600\n",
      "building tree 421 of 600\n",
      "building tree 422 of 600\n",
      "building tree 423 of 600\n",
      "building tree 424 of 600\n",
      "building tree 425 of 600\n",
      "building tree 426 of 600\n",
      "building tree 427 of 600\n",
      "building tree 428 of 600\n",
      "building tree 429 of 600\n",
      "building tree 430 of 600\n",
      "building tree 431 of 600\n",
      "building tree 432 of 600\n",
      "building tree 433 of 600\n",
      "building tree 434 of 600\n",
      "building tree 435 of 600\n",
      "building tree 436 of 600\n",
      "building tree 437 of 600\n",
      "building tree 438 of 600\n",
      "building tree 439 of 600\n",
      "building tree 440 of 600\n",
      "building tree 441 of 600\n",
      "building tree 442 of 600\n",
      "building tree 443 of 600\n",
      "building tree 444 of 600\n",
      "building tree 445 of 600\n",
      "building tree 446 of 600\n",
      "building tree 447 of 600\n",
      "building tree 448 of 600\n",
      "building tree 449 of 600\n",
      "building tree 450 of 600\n",
      "building tree 451 of 600\n",
      "building tree 452 of 600\n",
      "building tree 453 of 600\n",
      "building tree 454 of 600\n",
      "building tree 455 of 600\n",
      "building tree 456 of 600\n",
      "building tree 457 of 600\n",
      "building tree 458 of 600\n",
      "building tree 459 of 600\n",
      "building tree 460 of 600\n",
      "building tree 461 of 600\n",
      "building tree 462 of 600\n",
      "building tree 463 of 600\n",
      "building tree 464 of 600\n",
      "building tree 465 of 600\n",
      "building tree 466 of 600\n",
      "building tree 467 of 600\n",
      "building tree 468 of 600\n",
      "building tree 469 of 600\n",
      "building tree 470 of 600\n",
      "building tree 471 of 600\n",
      "building tree 472 of 600\n",
      "building tree 473 of 600\n",
      "building tree 474 of 600\n",
      "building tree 475 of 600\n",
      "building tree 476 of 600\n",
      "building tree 477 of 600\n",
      "building tree 478 of 600\n",
      "building tree 479 of 600\n",
      "building tree 480 of 600\n",
      "building tree 481 of 600\n",
      "building tree 482 of 600\n",
      "building tree 483 of 600\n",
      "building tree 484 of 600\n",
      "building tree 485 of 600\n",
      "building tree 486 of 600\n",
      "building tree 487 of 600\n",
      "building tree 488 of 600\n",
      "building tree 489 of 600\n",
      "building tree 490 of 600\n",
      "building tree 491 of 600\n",
      "building tree 492 of 600\n",
      "building tree 493 of 600\n",
      "building tree 494 of 600\n",
      "building tree 495 of 600\n",
      "building tree 496 of 600\n",
      "building tree 497 of 600\n",
      "building tree 498 of 600\n",
      "building tree 499 of 600\n",
      "building tree 500 of 600\n",
      "building tree 501 of 600\n",
      "building tree 502 of 600\n",
      "building tree 503 of 600\n",
      "building tree 504 of 600\n",
      "building tree 505 of 600\n",
      "building tree 506 of 600\n",
      "building tree 507 of 600\n",
      "building tree 508 of 600\n",
      "building tree 509 of 600\n",
      "building tree 510 of 600\n",
      "building tree 511 of 600\n",
      "building tree 512 of 600\n",
      "building tree 513 of 600\n",
      "building tree 514 of 600\n",
      "building tree 515 of 600\n",
      "building tree 516 of 600\n",
      "building tree 517 of 600\n",
      "building tree 518 of 600\n",
      "building tree 519 of 600\n",
      "building tree 520 of 600\n",
      "building tree 521 of 600\n",
      "building tree 522 of 600\n",
      "building tree 523 of 600\n",
      "building tree 524 of 600\n",
      "building tree 525 of 600\n",
      "building tree 526 of 600\n",
      "building tree 527 of 600\n",
      "building tree 528 of 600\n",
      "building tree 529 of 600\n",
      "building tree 530 of 600\n",
      "building tree 531 of 600\n",
      "building tree 532 of 600\n",
      "building tree 533 of 600\n",
      "building tree 534 of 600\n",
      "building tree 535 of 600\n",
      "building tree 536 of 600\n",
      "building tree 537 of 600\n",
      "building tree 538 of 600\n",
      "building tree 539 of 600\n",
      "building tree 540 of 600\n",
      "building tree 541 of 600\n",
      "building tree 542 of 600\n",
      "building tree 543 of 600\n",
      "building tree 544 of 600\n",
      "building tree 545 of 600\n",
      "building tree 546 of 600\n",
      "building tree 547 of 600\n",
      "building tree 548 of 600\n",
      "building tree 549 of 600\n",
      "building tree 550 of 600\n",
      "building tree 551 of 600\n",
      "building tree 552 of 600\n",
      "building tree 553 of 600\n",
      "building tree 554 of 600\n",
      "building tree 555 of 600\n",
      "building tree 556 of 600\n",
      "building tree 557 of 600\n",
      "building tree 558 of 600\n",
      "building tree 559 of 600\n",
      "building tree 560 of 600\n",
      "building tree 561 of 600\n",
      "building tree 562 of 600\n",
      "building tree 563 of 600\n",
      "building tree 564 of 600\n",
      "building tree 565 of 600\n",
      "building tree 566 of 600\n",
      "building tree 567 of 600\n",
      "building tree 568 of 600\n",
      "building tree 569 of 600\n",
      "building tree 570 of 600\n",
      "building tree 571 of 600\n",
      "building tree 572 of 600\n",
      "building tree 573 of 600\n",
      "building tree 574 of 600\n",
      "building tree 575 of 600\n",
      "building tree 576 of 600\n",
      "building tree 577 of 600\n",
      "building tree 578 of 600\n",
      "building tree 579 of 600\n",
      "building tree 580 of 600\n",
      "building tree 581 of 600\n",
      "building tree 582 of 600\n",
      "building tree 583 of 600\n",
      "building tree 584 of 600\n",
      "building tree 585 of 600\n",
      "building tree 586 of 600\n",
      "building tree 587 of 600\n",
      "building tree 588 of 600\n",
      "building tree 589 of 600\n",
      "building tree 590 of 600\n",
      "building tree 591 of 600\n",
      "building tree 592 of 600\n",
      "building tree 593 of 600\n",
      "building tree 594 of 600\n",
      "building tree 595 of 600\n",
      "building tree 596 of 600\n",
      "building tree 597 of 600\n",
      "building tree 598 of 600\n",
      "building tree 599 of 600\n",
      "building tree 600 of 600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 600 out of 600 | elapsed:  1.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ipeirotis_fullab_rew fit complete\n",
      "Fitted model saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=24)]: Using backend ThreadingBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=24)]: Done 114 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=24)]: Done 317 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=24)]: Done 600 out of 600 | elapsed:    1.9s finished\n",
      "[Parallel(n_jobs=24)]: Using backend ThreadingBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=24)]: Done 114 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=24)]: Done 317 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=24)]: Done 600 out of 600 | elapsed:    1.9s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 24 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitAndPredict: 121.61769008636475 seconds\n",
      "0.7745966437571489\n",
      "----- [Running *duration* ML with numeric features] -----\n",
      "Running ipeirotis_fullab_dur\n",
      "building tree 1 of 600\n",
      "building tree 2 of 600\n",
      "building tree 3 of 600\n",
      "building tree 4 of 600\n",
      "building tree 5 of 600\n",
      "building tree 6 of 600\n",
      "building tree 7 of 600\n",
      "building tree 8 of 600\n",
      "building tree 9 of 600\n",
      "building tree 10 of 600\n",
      "building tree 11 of 600\n",
      "building tree 12 of 600\n",
      "building tree 13 of 600\n",
      "building tree 14 of 600\n",
      "building tree 15 of 600\n",
      "building tree 16 of 600\n",
      "building tree 17 of 600\n",
      "building tree 18 of 600\n",
      "building tree 19 of 600\n",
      "building tree 20 of 600\n",
      "building tree 21 of 600\n",
      "building tree 22 of 600\n",
      "building tree 23 of 600\n",
      "building tree 24 of 600\n",
      "building tree 25 of 600\n",
      "building tree 26 of 600\n",
      "building tree 27 of 600\n",
      "building tree 28 of 600\n",
      "building tree 29 of 600\n",
      "building tree 30 of 600\n",
      "building tree 31 of 600\n",
      "building tree 32 of 600\n",
      "building tree 33 of 600\n",
      "building tree 34 of 600\n",
      "building tree 35 of 600\n",
      "building tree 36 of 600\n",
      "building tree 37 of 600\n",
      "building tree 38 of 600\n",
      "building tree 39 of 600\n",
      "building tree 40 of 600\n",
      "building tree 41 of 600\n",
      "building tree 42 of 600\n",
      "building tree 43 of 600\n",
      "building tree 44 of 600\n",
      "building tree 45 of 600\n",
      "building tree 46 of 600\n",
      "building tree 47 of 600\n",
      "building tree 48 of 600\n",
      "building tree 49 of 600\n",
      "building tree 50 of 600\n",
      "building tree 51 of 600\n",
      "building tree 52 of 600\n",
      "building tree 53 of 600\n",
      "building tree 54 of 600\n",
      "building tree 55 of 600\n",
      "building tree 56 of 600\n",
      "building tree 57 of 600\n",
      "building tree 58 of 600\n",
      "building tree 59 of 600\n",
      "building tree 60 of 600\n",
      "building tree 61 of 600\n",
      "building tree 62 of 600\n",
      "building tree 63 of 600\n",
      "building tree 64 of 600\n",
      "building tree 65 of 600\n",
      "building tree 66 of 600\n",
      "building tree 67 of 600\n",
      "building tree 68 of 600\n",
      "building tree 69 of 600\n",
      "building tree 70 of 600\n",
      "building tree 71 of 600\n",
      "building tree 72 of 600\n",
      "building tree 73 of 600\n",
      "building tree 74 of 600\n",
      "building tree 75 of 600\n",
      "building tree 76 of 600\n",
      "building tree 77 of 600\n",
      "building tree 78 of 600\n",
      "building tree 79 of 600\n",
      "building tree 80 of 600\n",
      "building tree 81 of 600\n",
      "building tree 82 of 600\n",
      "building tree 83 of 600\n",
      "building tree 84 of 600\n",
      "building tree 85 of 600\n",
      "building tree 86 of 600\n",
      "building tree 87 of 600\n",
      "building tree 88 of 600\n",
      "building tree 89 of 600\n",
      "building tree 90 of 600\n",
      "building tree 91 of 600\n",
      "building tree 92 of 600\n",
      "building tree 93 of 600\n",
      "building tree 94 of 600\n",
      "building tree 95 of 600\n",
      "building tree 96 of 600\n",
      "building tree 97 of 600\n",
      "building tree 98 of 600\n",
      "building tree 99 of 600\n",
      "building tree 100 of 600\n",
      "building tree 101 of 600\n",
      "building tree 102 of 600\n",
      "building tree 103 of 600\n",
      "building tree 104 of 600\n",
      "building tree 105 of 600\n",
      "building tree 106 of 600\n",
      "building tree 107 of 600\n",
      "building tree 108 of 600\n",
      "building tree 109 of 600\n",
      "building tree 110 of 600\n",
      "building tree 111 of 600\n",
      "building tree 112 of 600\n",
      "building tree 113 of 600\n",
      "building tree 114 of 600\n",
      "building tree 115 of 600\n",
      "building tree 116 of 600\n",
      "building tree 117 of 600\n",
      "building tree 118 of 600\n",
      "building tree 119 of 600\n",
      "building tree 120 of 600\n",
      "building tree 121 of 600\n",
      "building tree 122 of 600\n",
      "building tree 123 of 600\n",
      "building tree 124 of 600\n",
      "building tree 125 of 600\n",
      "building tree 126 of 600\n",
      "building tree 127 of 600\n",
      "building tree 128 of 600\n",
      "building tree 129 of 600\n",
      "building tree 130 of 600\n",
      "building tree 131 of 600\n",
      "building tree 132 of 600\n",
      "building tree 133 of 600\n",
      "building tree 134 of 600\n",
      "building tree 135 of 600\n",
      "building tree 136 of 600\n",
      "building tree 137 of 600\n",
      "building tree 138 of 600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 114 tasks      | elapsed:   18.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 139 of 600\n",
      "building tree 140 of 600\n",
      "building tree 141 of 600\n",
      "building tree 142 of 600\n",
      "building tree 143 of 600\n",
      "building tree 144 of 600\n",
      "building tree 145 of 600\n",
      "building tree 146 of 600\n",
      "building tree 147 of 600\n",
      "building tree 148 of 600\n",
      "building tree 149 of 600\n",
      "building tree 150 of 600\n",
      "building tree 151 of 600\n",
      "building tree 152 of 600\n",
      "building tree 153 of 600\n",
      "building tree 154 of 600\n",
      "building tree 155 of 600\n",
      "building tree 156 of 600\n",
      "building tree 157 of 600\n",
      "building tree 158 of 600\n",
      "building tree 159 of 600\n",
      "building tree 160 of 600\n",
      "building tree 161 of 600\n",
      "building tree 162 of 600\n",
      "building tree 163 of 600\n",
      "building tree 164 of 600\n",
      "building tree 165 of 600\n",
      "building tree 166 of 600\n",
      "building tree 167 of 600\n",
      "building tree 168 of 600\n",
      "building tree 169 of 600\n",
      "building tree 170 of 600\n",
      "building tree 171 of 600\n",
      "building tree 172 of 600\n",
      "building tree 173 of 600\n",
      "building tree 174 of 600\n",
      "building tree 175 of 600\n",
      "building tree 176 of 600\n",
      "building tree 177 of 600\n",
      "building tree 178 of 600\n",
      "building tree 179 of 600\n",
      "building tree 180 of 600\n",
      "building tree 181 of 600\n",
      "building tree 182 of 600\n",
      "building tree 183 of 600\n",
      "building tree 184 of 600\n",
      "building tree 185 of 600\n",
      "building tree 186 of 600\n",
      "building tree 187 of 600\n",
      "building tree 188 of 600\n",
      "building tree 189 of 600\n",
      "building tree 190 of 600\n",
      "building tree 191 of 600\n",
      "building tree 192 of 600\n",
      "building tree 193 of 600\n",
      "building tree 194 of 600\n",
      "building tree 195 of 600\n",
      "building tree 196 of 600\n",
      "building tree 197 of 600\n",
      "building tree 198 of 600\n",
      "building tree 199 of 600\n",
      "building tree 200 of 600\n",
      "building tree 201 of 600\n",
      "building tree 202 of 600\n",
      "building tree 203 of 600\n",
      "building tree 204 of 600\n",
      "building tree 205 of 600\n",
      "building tree 206 of 600\n",
      "building tree 207 of 600\n",
      "building tree 208 of 600\n",
      "building tree 209 of 600\n",
      "building tree 210 of 600\n",
      "building tree 211 of 600\n",
      "building tree 212 of 600\n",
      "building tree 213 of 600\n",
      "building tree 214 of 600\n",
      "building tree 215 of 600\n",
      "building tree 216 of 600\n",
      "building tree 217 of 600\n",
      "building tree 218 of 600\n",
      "building tree 219 of 600\n",
      "building tree 220 of 600\n",
      "building tree 221 of 600\n",
      "building tree 222 of 600\n",
      "building tree 223 of 600\n",
      "building tree 224 of 600\n",
      "building tree 225 of 600\n",
      "building tree 226 of 600\n",
      "building tree 227 of 600\n",
      "building tree 228 of 600\n",
      "building tree 229 of 600\n",
      "building tree 230 of 600\n",
      "building tree 231 of 600\n",
      "building tree 232 of 600\n",
      "building tree 233 of 600\n",
      "building tree 234 of 600\n",
      "building tree 235 of 600\n",
      "building tree 236 of 600\n",
      "building tree 237 of 600\n",
      "building tree 238 of 600\n",
      "building tree 239 of 600\n",
      "building tree 240 of 600\n",
      "building tree 241 of 600\n",
      "building tree 242 of 600\n",
      "building tree 243 of 600\n",
      "building tree 244 of 600\n",
      "building tree 245 of 600\n",
      "building tree 246 of 600\n",
      "building tree 247 of 600\n",
      "building tree 248 of 600\n",
      "building tree 249 of 600\n",
      "building tree 250 of 600\n",
      "building tree 251 of 600\n",
      "building tree 252 of 600\n",
      "building tree 253 of 600\n",
      "building tree 254 of 600\n",
      "building tree 255 of 600\n",
      "building tree 256 of 600\n",
      "building tree 257 of 600\n",
      "building tree 258 of 600\n",
      "building tree 259 of 600\n",
      "building tree 260 of 600\n",
      "building tree 261 of 600\n",
      "building tree 262 of 600\n",
      "building tree 263 of 600\n",
      "building tree 264 of 600\n",
      "building tree 265 of 600\n",
      "building tree 266 of 600\n",
      "building tree 267 of 600\n",
      "building tree 268 of 600\n",
      "building tree 269 of 600\n",
      "building tree 270 of 600\n",
      "building tree 271 of 600\n",
      "building tree 272 of 600\n",
      "building tree 273 of 600\n",
      "building tree 274 of 600\n",
      "building tree 275 of 600\n",
      "building tree 276 of 600\n",
      "building tree 277 of 600\n",
      "building tree 278 of 600\n",
      "building tree 279 of 600\n",
      "building tree 280 of 600\n",
      "building tree 281 of 600\n",
      "building tree 282 of 600\n",
      "building tree 283 of 600\n",
      "building tree 284 of 600\n",
      "building tree 285 of 600\n",
      "building tree 286 of 600\n",
      "building tree 287 of 600\n",
      "building tree 288 of 600\n",
      "building tree 289 of 600\n",
      "building tree 290 of 600\n",
      "building tree 291 of 600\n",
      "building tree 292 of 600\n",
      "building tree 293 of 600\n",
      "building tree 294 of 600\n",
      "building tree 295 of 600\n",
      "building tree 296 of 600\n",
      "building tree 297 of 600\n",
      "building tree 298 of 600\n",
      "building tree 299 of 600\n",
      "building tree 300 of 600\n",
      "building tree 301 of 600\n",
      "building tree 302 of 600\n",
      "building tree 303 of 600\n",
      "building tree 304 of 600\n",
      "building tree 305 of 600\n",
      "building tree 306 of 600\n",
      "building tree 307 of 600\n",
      "building tree 308 of 600\n",
      "building tree 309 of 600\n",
      "building tree 310 of 600\n",
      "building tree 311 of 600\n",
      "building tree 312 of 600\n",
      "building tree 313 of 600\n",
      "building tree 314 of 600\n",
      "building tree 315 of 600\n",
      "building tree 316 of 600\n",
      "building tree 317 of 600\n",
      "building tree 318 of 600\n",
      "building tree 319 of 600\n",
      "building tree 320 of 600\n",
      "building tree 321 of 600\n",
      "building tree 322 of 600\n",
      "building tree 323 of 600\n",
      "building tree 324 of 600\n",
      "building tree 325 of 600building tree 326 of 600\n",
      "\n",
      "building tree 327 of 600\n",
      "building tree 328 of 600\n",
      "building tree 329 of 600\n",
      "building tree 330 of 600\n",
      "building tree 331 of 600\n",
      "building tree 332 of 600building tree 333 of 600\n",
      "\n",
      "building tree 334 of 600\n",
      "building tree 335 of 600\n",
      "building tree 336 of 600\n",
      "building tree 337 of 600\n",
      "building tree 338 of 600\n",
      "building tree 339 of 600\n",
      "building tree 340 of 600\n",
      "building tree 341 of 600\n",
      "building tree 342 of 600\n",
      "building tree 343 of 600\n",
      "building tree 344 of 600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 317 tasks      | elapsed:   48.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 345 of 600\n",
      "building tree 346 of 600\n",
      "building tree 347 of 600\n",
      "building tree 348 of 600\n",
      "building tree 349 of 600\n",
      "building tree 350 of 600\n",
      "building tree 351 of 600\n",
      "building tree 352 of 600\n",
      "building tree 353 of 600\n",
      "building tree 354 of 600\n",
      "building tree 355 of 600\n",
      "building tree 356 of 600\n",
      "building tree 357 of 600\n",
      "building tree 358 of 600\n",
      "building tree 359 of 600\n",
      "building tree 360 of 600\n",
      "building tree 361 of 600\n",
      "building tree 362 of 600\n",
      "building tree 363 of 600\n",
      "building tree 364 of 600\n",
      "building tree 365 of 600\n",
      "building tree 366 of 600\n",
      "building tree 367 of 600\n",
      "building tree 368 of 600\n",
      "building tree 369 of 600\n",
      "building tree 370 of 600\n",
      "building tree 371 of 600\n",
      "building tree 372 of 600\n",
      "building tree 373 of 600\n",
      "building tree 374 of 600\n",
      "building tree 375 of 600\n",
      "building tree 376 of 600\n",
      "building tree 377 of 600\n",
      "building tree 378 of 600\n",
      "building tree 379 of 600\n",
      "building tree 380 of 600\n",
      "building tree 381 of 600\n",
      "building tree 382 of 600\n",
      "building tree 383 of 600\n",
      "building tree 384 of 600\n",
      "building tree 385 of 600\n",
      "building tree 386 of 600\n",
      "building tree 387 of 600\n",
      "building tree 388 of 600\n",
      "building tree 389 of 600\n",
      "building tree 390 of 600\n",
      "building tree 391 of 600\n",
      "building tree 392 of 600\n",
      "building tree 393 of 600\n",
      "building tree 394 of 600\n",
      "building tree 395 of 600\n",
      "building tree 396 of 600\n",
      "building tree 397 of 600\n",
      "building tree 398 of 600\n",
      "building tree 399 of 600\n",
      "building tree 400 of 600\n",
      "building tree 401 of 600\n",
      "building tree 402 of 600\n",
      "building tree 403 of 600\n",
      "building tree 404 of 600\n",
      "building tree 405 of 600\n",
      "building tree 406 of 600\n",
      "building tree 407 of 600\n",
      "building tree 408 of 600\n",
      "building tree 409 of 600\n",
      "building tree 410 of 600\n",
      "building tree 411 of 600\n",
      "building tree 412 of 600\n",
      "building tree 413 of 600\n",
      "building tree 414 of 600\n",
      "building tree 415 of 600\n",
      "building tree 416 of 600\n",
      "building tree 417 of 600\n",
      "building tree 418 of 600\n",
      "building tree 419 of 600\n",
      "building tree 420 of 600\n",
      "building tree 421 of 600\n",
      "building tree 422 of 600\n",
      "building tree 423 of 600\n",
      "building tree 424 of 600\n",
      "building tree 425 of 600\n",
      "building tree 426 of 600\n",
      "building tree 427 of 600\n",
      "building tree 428 of 600\n",
      "building tree 429 of 600\n",
      "building tree 430 of 600\n",
      "building tree 431 of 600\n",
      "building tree 432 of 600\n",
      "building tree 433 of 600\n",
      "building tree 434 of 600\n",
      "building tree 435 of 600\n",
      "building tree 436 of 600\n",
      "building tree 437 of 600\n",
      "building tree 438 of 600\n",
      "building tree 439 of 600\n",
      "building tree 440 of 600\n",
      "building tree 441 of 600\n",
      "building tree 442 of 600\n",
      "building tree 443 of 600\n",
      "building tree 444 of 600\n",
      "building tree 445 of 600\n",
      "building tree 446 of 600\n",
      "building tree 447 of 600\n",
      "building tree 448 of 600\n",
      "building tree 449 of 600\n",
      "building tree 450 of 600\n",
      "building tree 451 of 600\n",
      "building tree 452 of 600\n",
      "building tree 453 of 600\n",
      "building tree 454 of 600building tree 455 of 600\n",
      "\n",
      "building tree 456 of 600\n",
      "building tree 457 of 600\n",
      "building tree 458 of 600\n",
      "building tree 459 of 600\n",
      "building tree 460 of 600\n",
      "building tree 461 of 600\n",
      "building tree 462 of 600\n",
      "building tree 463 of 600\n",
      "building tree 464 of 600\n",
      "building tree 465 of 600\n",
      "building tree 466 of 600\n",
      "building tree 467 of 600\n",
      "building tree 468 of 600\n",
      "building tree 469 of 600\n",
      "building tree 470 of 600\n",
      "building tree 471 of 600\n",
      "building tree 472 of 600\n",
      "building tree 473 of 600\n",
      "building tree 474 of 600\n",
      "building tree 475 of 600\n",
      "building tree 476 of 600\n",
      "building tree 477 of 600\n",
      "building tree 478 of 600\n",
      "building tree 479 of 600\n",
      "building tree 480 of 600\n",
      "building tree 481 of 600\n",
      "building tree 482 of 600\n",
      "building tree 483 of 600\n",
      "building tree 484 of 600\n",
      "building tree 485 of 600\n",
      "building tree 486 of 600\n",
      "building tree 487 of 600\n",
      "building tree 488 of 600\n",
      "building tree 489 of 600\n",
      "building tree 490 of 600\n",
      "building tree 491 of 600\n",
      "building tree 492 of 600\n",
      "building tree 493 of 600\n",
      "building tree 494 of 600\n",
      "building tree 495 of 600\n",
      "building tree 496 of 600\n",
      "building tree 497 of 600\n",
      "building tree 498 of 600\n",
      "building tree 499 of 600\n",
      "building tree 500 of 600\n",
      "building tree 501 of 600\n",
      "building tree 502 of 600\n",
      "building tree 503 of 600\n",
      "building tree 504 of 600\n",
      "building tree 505 of 600\n",
      "building tree 506 of 600\n",
      "building tree 507 of 600\n",
      "building tree 508 of 600\n",
      "building tree 509 of 600\n",
      "building tree 510 of 600\n",
      "building tree 511 of 600\n",
      "building tree 512 of 600\n",
      "building tree 513 of 600\n",
      "building tree 514 of 600\n",
      "building tree 515 of 600\n",
      "building tree 516 of 600\n",
      "building tree 517 of 600\n",
      "building tree 518 of 600\n",
      "building tree 519 of 600\n",
      "building tree 520 of 600\n",
      "building tree 521 of 600\n",
      "building tree 522 of 600\n",
      "building tree 523 of 600\n",
      "building tree 524 of 600\n",
      "building tree 525 of 600\n",
      "building tree 526 of 600\n",
      "building tree 527 of 600\n",
      "building tree 528 of 600\n",
      "building tree 529 of 600\n",
      "building tree 530 of 600\n",
      "building tree 531 of 600\n",
      "building tree 532 of 600\n",
      "building tree 533 of 600\n",
      "building tree 534 of 600\n",
      "building tree 535 of 600\n",
      "building tree 536 of 600\n",
      "building tree 537 of 600\n",
      "building tree 538 of 600\n",
      "building tree 539 of 600\n",
      "building tree 540 of 600\n",
      "building tree 541 of 600\n",
      "building tree 542 of 600\n",
      "building tree 543 of 600\n",
      "building tree 544 of 600\n",
      "building tree 545 of 600\n",
      "building tree 546 of 600\n",
      "building tree 547 of 600\n",
      "building tree 548 of 600\n",
      "building tree 549 of 600\n",
      "building tree 550 of 600\n",
      "building tree 551 of 600\n",
      "building tree 552 of 600\n",
      "building tree 553 of 600\n",
      "building tree 554 of 600\n",
      "building tree 555 of 600\n",
      "building tree 556 of 600\n",
      "building tree 557 of 600\n",
      "building tree 558 of 600\n",
      "building tree 559 of 600\n",
      "building tree 560 of 600\n",
      "building tree 561 of 600\n",
      "building tree 562 of 600\n",
      "building tree 563 of 600\n",
      "building tree 564 of 600\n",
      "building tree 565 of 600\n",
      "building tree 566 of 600\n",
      "building tree 567 of 600\n",
      "building tree 568 of 600\n",
      "building tree 569 of 600\n",
      "building tree 570 of 600\n",
      "building tree 571 of 600\n",
      "building tree 572 of 600\n",
      "building tree 573 of 600\n",
      "building tree 574 of 600\n",
      "building tree 575 of 600\n",
      "building tree 576 of 600\n",
      "building tree 577 of 600\n",
      "building tree 578 of 600\n",
      "building tree 579 of 600\n",
      "building tree 580 of 600\n",
      "building tree 581 of 600\n",
      "building tree 582 of 600\n",
      "building tree 583 of 600\n",
      "building tree 584 of 600\n",
      "building tree 585 of 600\n",
      "building tree 586 of 600\n",
      "building tree 587 of 600\n",
      "building tree 588 of 600\n",
      "building tree 589 of 600\n",
      "building tree 590 of 600\n",
      "building tree 591 of 600\n",
      "building tree 592 of 600\n",
      "building tree 593 of 600\n",
      "building tree 594 of 600\n",
      "building tree 595 of 600\n",
      "building tree 596 of 600\n",
      "building tree 597 of 600\n",
      "building tree 598 of 600\n",
      "building tree 599 of 600\n",
      "building tree 600 of 600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 600 out of 600 | elapsed:  1.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ipeirotis_fullab_dur fit complete\n",
      "Fitted model saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=24)]: Using backend ThreadingBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=24)]: Done 114 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=24)]: Done 317 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=24)]: Done 600 out of 600 | elapsed:    1.9s finished\n",
      "[Parallel(n_jobs=24)]: Using backend ThreadingBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=24)]: Done 114 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=24)]: Done 317 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=24)]: Done 600 out of 600 | elapsed:    1.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitAndPredict: 129.6943142414093 seconds\n",
      "0.8972814317031571\n",
      "*** A->B n-gram ML run\n",
      "# A obs: 146373\n",
      "# B obs: 146373\n",
      "# A_train obs: 117098\n",
      "# A_val obs: 29275\n",
      "# B_train obs: 117098\n",
      "# B_val obs: 29275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\1619589998.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  feature_df[\"title\"] = feature_df[\"title\"].astype(str)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Titles vectorized for train data\n",
      "(117098, 418949)\n",
      "Feature names saved to .\\ml_input\\feat_names_textlab_30_gramab.pkl\n",
      "Validation set titles vectorized\n",
      "(29275, 418949)\n",
      "Train rewards saved to .\\ml_input\\./train_rew_textlab_30_gramab.pkl\n",
      "Train durations saved to .\\ml_input\\./train_dur_textlab_30_gramab.pkl\n",
      "Train text features saved to .\\ml_input\\./train_txtfeats_textlab_30_gramab.pkl\n",
      "Training data saved\n",
      "Test rewards saved to .\\ml_input\\./test_rew_textlab_30_gramab.pkl\n",
      "Test durations saved to .\\ml_input\\./test_dur_textlab_30_gramab.pkl\n",
      "Test text features saved to .\\ml_input\\./test_txtfeats_textlab_30_gramab.pkl\n",
      "Validation data saved\n",
      "Textual features exported\n",
      "*** Train data: ***\n",
      "Features: (117098, 418949)\n",
      "Reward labels: (117098,)\n",
      "Duration labels: (117098,)\n",
      "*** Validation data: ***\n",
      "Features: (29275, 418949)\n",
      "Reward labels: (29275,)\n",
      "Duration labels: (29275,)\n",
      "Training data loaded\n",
      "Test data loaded\n",
      "----- [Running *reward* ML with text features] -----\n",
      "Running textlab_30_gramab_rew\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 24 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 40building tree 2 of 40\n",
      "building tree 3 of 40\n",
      "\n",
      "building tree 4 of 40\n",
      "building tree 5 of 40\n",
      "building tree 6 of 40\n",
      "building tree 7 of 40\n",
      "building tree 8 of 40\n",
      "building tree 9 of 40\n",
      "building tree 10 of 40\n",
      "building tree 11 of 40\n",
      "building tree 12 of 40\n",
      "building tree 13 of 40\n",
      "building tree 14 of 40\n",
      "building tree 15 of 40\n",
      "building tree 16 of 40\n",
      "building tree 17 of 40\n",
      "building tree 18 of 40\n",
      "building tree 19 of 40\n",
      "building tree 20 of 40\n",
      "building tree 21 of 40\n",
      "building tree 22 of 40\n",
      "building tree 23 of 40\n",
      "building tree 24 of 40\n",
      "building tree 25 of 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:  6.5min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 26 of 40\n",
      "building tree 27 of 40\n",
      "building tree 28 of 40\n",
      "building tree 29 of 40\n",
      "building tree 30 of 40\n",
      "building tree 31 of 40\n",
      "building tree 32 of 40\n",
      "building tree 33 of 40\n",
      "building tree 34 of 40\n",
      "building tree 35 of 40\n",
      "building tree 36 of 40\n",
      "building tree 37 of 40\n",
      "building tree 38 of 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  14 out of  40 | elapsed:  6.7min remaining: 12.5min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 39 of 40\n",
      "building tree 40 of 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  35 out of  40 | elapsed: 10.7min remaining:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed: 10.8min finished\n",
      "[Parallel(n_jobs=24)]: Using backend ThreadingBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=24)]: Done   1 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=24)]: Done  14 out of  40 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=24)]: Done  35 out of  40 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=24)]: Done  40 out of  40 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=24)]: Using backend ThreadingBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=24)]: Done   1 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=24)]: Done  14 out of  40 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "textlab_30_gramab_rew fit complete\n",
      "Fitted model saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=24)]: Done  35 out of  40 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=24)]: Done  40 out of  40 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 24 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitAndPredict: 647.8112711906433 seconds\n",
      "0.8658655199892127\n",
      "----- [Running *duration* ML with text features] -----\n",
      "Running textlab_30_gramab_dur\n",
      "building tree 1 of 40\n",
      "building tree 2 of 40\n",
      "building tree 3 of 40\n",
      "building tree 4 of 40\n",
      "building tree 5 of 40\n",
      "building tree 6 of 40\n",
      "building tree 7 of 40\n",
      "building tree 8 of 40\n",
      "building tree 9 of 40\n",
      "building tree 10 of 40\n",
      "building tree 11 of 40\n",
      "building tree 12 of 40\n",
      "building tree 13 of 40\n",
      "building tree 14 of 40\n",
      "building tree 15 of 40\n",
      "building tree 16 of 40\n",
      "building tree 17 of 40\n",
      "building tree 18 of 40\n",
      "building tree 19 of 40\n",
      "building tree 20 of 40\n",
      "building tree 21 of 40\n",
      "building tree 22 of 40\n",
      "building tree 23 of 40\n",
      "building tree 24 of 40\n",
      "building tree 25 of 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed: 13.0min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 26 of 40\n",
      "building tree 27 of 40\n",
      "building tree 28 of 40\n",
      "building tree 29 of 40\n",
      "building tree 30 of 40\n",
      "building tree 31 of 40\n",
      "building tree 32 of 40\n",
      "building tree 33 of 40\n",
      "building tree 34 of 40\n",
      "building tree 35 of 40\n",
      "building tree 36 of 40\n",
      "building tree 37 of 40\n",
      "building tree 38 of 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  14 out of  40 | elapsed: 13.4min remaining: 24.8min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 39 of 40\n",
      "building tree 40 of 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  35 out of  40 | elapsed: 21.7min remaining:  3.1min\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed: 21.8min finished\n",
      "[Parallel(n_jobs=24)]: Using backend ThreadingBackend with 24 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "textlab_30_gramab_dur fit complete\n",
      "Fitted model saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=24)]: Done   1 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=24)]: Done  14 out of  40 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=24)]: Done  35 out of  40 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=24)]: Done  40 out of  40 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=24)]: Using backend ThreadingBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=24)]: Done   1 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=24)]: Done  14 out of  40 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=24)]: Done  35 out of  40 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=24)]: Done  40 out of  40 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitAndPredict: 1310.1504600048065 seconds\n",
      "0.2694385474524966\n",
      "*** A->B computing most predictive features\n",
      "Generating most predictive features for dur\n",
      "Number of features: 418949\n",
      "Features outputted to: .\\predictive_feats\\predictive_textlab_30_gramab_dur.csv\n",
      "Generating most predictive features for rew\n",
      "Number of features: 418949\n",
      "Features outputted to: .\\predictive_feats\\predictive_textlab_30_gramab_rew.csv\n",
      "*** A->B full ML run\n",
      "# A obs: 146373\n",
      "# B obs: 146373\n",
      "# A_train obs: 117098\n",
      "# A_val obs: 29275\n",
      "# B_train obs: 117098\n",
      "# B_val obs: 29275\n",
      "Number of description features: 0\n",
      "Number of title features: 200\n",
      "Number of keyword features: 0\n",
      "Computing feature #0: easy\n",
      "Computing feature #1: transcribe\n",
      "Computing feature #2: writing\n",
      "Computing feature #3: audio\n",
      "Computing feature #4: image\n",
      "Computing feature #5: video\n",
      "Computing feature #6: bonus\n",
      "Computing feature #7: copy\n",
      "Computing feature #8: search\n",
      "Computing feature #9: identify\n",
      "Computing feature #10: text\n",
      "Computing feature #11: date\n",
      "Computing feature #12: fun\n",
      "Computing feature #13: simple\n",
      "Computing feature #14: summarize\n",
      "Computing feature #15: only\n",
      "Computing feature #16: improve\n",
      "Computing feature #17: five\n",
      "Computing feature #18: questionmark\n",
      "Computing feature #19: exclamation\n",
      "Computing feature #20: find\n",
      "Computing feature #21: check\n",
      "Computing feature #22: match\n",
      "Computing feature #23: choose\n",
      "Computing feature #24: categorize\n",
      "Computing feature #25: suggest\n",
      "Computing feature #26: translate\n",
      "Computing feature #27: survey\n",
      "Computing feature #28: click\n",
      "Computing feature #29: link\n",
      "Computing feature #30: read\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[\"minutes_title\"] = hit_df[\"title_lower\"].str.extract(minutes_reg,expand=False).fillna(0).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3226286950.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df.reset_index(inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDA features merged in\n",
      "Doc2Vec features merged in\n",
      "                                group_id  duration  log_duration  reward  \\\n",
      "292741  fffdae03eb029f2d8e60eabaa971adc2     240.0      5.480639     2.0   \n",
      "292742  ffff1d8b216a25a0619474b6a465dde5     120.0      4.787492   369.0   \n",
      "292743  ffff9f464f1e1d0a8c9e8588ce435e5e    5220.0      8.560253    15.0   \n",
      "292744  ffffc1d9b78826955e9687d8c6ca714a    2910.0      7.975908    60.0   \n",
      "292745  ffffc57feb6f5ee5ef5d95a54548bcc5     120.0      4.787492     2.0   \n",
      "\n",
      "        log_reward  meandiff_lreward  meandiff_ldur  time_allotted  \\\n",
      "292741    0.693147         -4.308529      -1.490776             60   \n",
      "292742    5.910797          0.909121      -2.183924             60   \n",
      "292743    2.708050         -0.105361      -0.034272             10   \n",
      "292744    4.094345          0.017075      -0.527354             60   \n",
      "292745    0.693147          0.000000      -0.406011              8   \n",
      "\n",
      "        first_hits  last_hits  ...  doc2vec_title_40  doc2vec_title_41  \\\n",
      "292741           0          0  ...          0.008363         -0.006260   \n",
      "292742           0          0  ...          0.046744         -0.016521   \n",
      "292743           0          0  ...          0.067740          0.000037   \n",
      "292744           6          1  ...          0.025640         -0.020772   \n",
      "292745           0          0  ...          0.052734          0.001159   \n",
      "\n",
      "        doc2vec_title_42  doc2vec_title_43  doc2vec_title_44  \\\n",
      "292741          0.010535         -0.010594          0.009250   \n",
      "292742         -0.011025         -0.000218          0.015323   \n",
      "292743          0.011005         -0.037205          0.072878   \n",
      "292744         -0.032470         -0.069878          0.104790   \n",
      "292745          0.001235         -0.012121          0.068618   \n",
      "\n",
      "        doc2vec_title_45  doc2vec_title_46  doc2vec_title_47  \\\n",
      "292741         -0.006053          0.009979          0.002506   \n",
      "292742          0.004408          0.012567         -0.036121   \n",
      "292743          0.005271          0.011413          0.006818   \n",
      "292744          0.038554         -0.040410         -0.041124   \n",
      "292745          0.000113         -0.031259         -0.027557   \n",
      "\n",
      "        doc2vec_title_48  doc2vec_title_49  \n",
      "292741          0.000179          0.002364  \n",
      "292742          0.005923         -0.054891  \n",
      "292743         -0.020776         -0.017559  \n",
      "292744          0.127619         -0.027586  \n",
      "292745          0.045267         -0.019086  \n",
      "\n",
      "[5 rows x 302 columns]\n",
      "avg_hitrate: 8007 nans, 0 infs\n",
      "Mean hitrate: 12.96194478684621\n",
      "Max hitrate: 42614.0\n",
      "Train rewards saved to .\\ml_input\\./train_rew_textlab_30_fullab.pkl\n",
      "Train durations saved to .\\ml_input\\./train_dur_textlab_30_fullab.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\2253851036.py:109: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_df.drop([col_name],axis=1,inplace=True)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\2253851036.py:109: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_df.drop([col_name],axis=1,inplace=True)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\2253851036.py:109: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_df.drop([col_name],axis=1,inplace=True)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\2253851036.py:109: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_df.drop([col_name],axis=1,inplace=True)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\2253851036.py:109: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_df.drop([col_name],axis=1,inplace=True)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\2253851036.py:109: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_df.drop([col_name],axis=1,inplace=True)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\2253851036.py:109: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_df.drop([col_name],axis=1,inplace=True)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\2253851036.py:136: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df.drop([col_name],axis=1,inplace=True)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\2253851036.py:136: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df.drop([col_name],axis=1,inplace=True)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\2253851036.py:136: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df.drop([col_name],axis=1,inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train features saved to .\\ml_input\\./train_feats_textlab_30_fullab.pkl\n",
      "Training data saved\n",
      "Test rewards saved to .\\ml_input\\./test_rew_textlab_30_fullab.pkl\n",
      "Test durations saved to .\\ml_input\\./test_dur_textlab_30_fullab.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\2253851036.py:136: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df.drop([col_name],axis=1,inplace=True)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\2253851036.py:136: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df.drop([col_name],axis=1,inplace=True)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\2253851036.py:136: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df.drop([col_name],axis=1,inplace=True)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\2253851036.py:136: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df.drop([col_name],axis=1,inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test features saved to .\\ml_input\\./test_feats_textlab_30_fullab.pkl\n",
      "Test data saved\n",
      "Training data dimensions: (146373, 245)\n",
      "Test data dimensions: (146373, 245)\n",
      "Training data loaded\n",
      "Test data loaded\n",
      "----- [Running *reward* ML with numeric features] -----\n",
      "Running textlab_30_fullab_rew\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 24 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 600building tree 2 of 600\n",
      "building tree 3 of 600\n",
      "\n",
      "building tree 4 of 600\n",
      "building tree 5 of 600\n",
      "building tree 6 of 600\n",
      "building tree 7 of 600\n",
      "building tree 8 of 600\n",
      "building tree 9 of 600\n",
      "building tree 10 of 600\n",
      "building tree 11 of 600\n",
      "building tree 12 of 600\n",
      "building tree 13 of 600\n",
      "building tree 14 of 600\n",
      "building tree 15 of 600\n",
      "building tree 16 of 600\n",
      "building tree 17 of 600\n",
      "building tree 18 of 600\n",
      "building tree 19 of 600\n",
      "building tree 20 of 600\n",
      "building tree 21 of 600\n",
      "building tree 22 of 600\n",
      "building tree 23 of 600\n",
      "building tree 24 of 600\n",
      "building tree 25 of 600\n",
      "building tree 26 of 600\n",
      "building tree 27 of 600\n",
      "building tree 28 of 600\n",
      "building tree 29 of 600\n",
      "building tree 30 of 600\n",
      "building tree 31 of 600\n",
      "building tree 32 of 600\n",
      "building tree 33 of 600\n",
      "building tree 34 of 600\n",
      "building tree 35 of 600\n",
      "building tree 36 of 600\n",
      "building tree 37 of 600\n",
      "building tree 38 of 600\n",
      "building tree 39 of 600\n",
      "building tree 40 of 600\n",
      "building tree 41 of 600\n",
      "building tree 42 of 600\n",
      "building tree 43 of 600\n",
      "building tree 44 of 600\n",
      "building tree 45 of 600\n",
      "building tree 46 of 600\n",
      "building tree 47 of 600\n",
      "building tree 48 of 600\n",
      "building tree 49 of 600\n",
      "building tree 50 of 600\n",
      "building tree 51 of 600\n",
      "building tree 52 of 600\n",
      "building tree 53 of 600\n",
      "building tree 54 of 600\n",
      "building tree 55 of 600\n",
      "building tree 56 of 600\n",
      "building tree 57 of 600\n",
      "building tree 58 of 600\n",
      "building tree 59 of 600\n",
      "building tree 60 of 600\n",
      "building tree 61 of 600\n",
      "building tree 62 of 600\n",
      "building tree 63 of 600\n",
      "building tree 64 of 600\n",
      "building tree 65 of 600\n",
      "building tree 66 of 600\n",
      "building tree 67 of 600\n",
      "building tree 68 of 600\n",
      "building tree 69 of 600\n",
      "building tree 70 of 600\n",
      "building tree 71 of 600\n",
      "building tree 72 of 600\n",
      "building tree 73 of 600\n",
      "building tree 74 of 600\n",
      "building tree 75 of 600\n",
      "building tree 76 of 600\n",
      "building tree 77 of 600\n",
      "building tree 78 of 600\n",
      "building tree 79 of 600\n",
      "building tree 80 of 600\n",
      "building tree 81 of 600\n",
      "building tree 82 of 600\n",
      "building tree 83 of 600\n",
      "building tree 84 of 600\n",
      "building tree 85 of 600\n",
      "building tree 86 of 600\n",
      "building tree 87 of 600\n",
      "building tree 88 of 600\n",
      "building tree 89 of 600\n",
      "building tree 90 of 600\n",
      "building tree 91 of 600\n",
      "building tree 92 of 600\n",
      "building tree 93 of 600\n",
      "building tree 94 of 600\n",
      "building tree 95 of 600\n",
      "building tree 96 of 600\n",
      "building tree 97 of 600\n",
      "building tree 98 of 600\n",
      "building tree 99 of 600\n",
      "building tree 100 of 600\n",
      "building tree 101 of 600\n",
      "building tree 102 of 600\n",
      "building tree 103 of 600\n",
      "building tree 104 of 600\n",
      "building tree 105 of 600\n",
      "building tree 106 of 600\n",
      "building tree 107 of 600\n",
      "building tree 108 of 600\n",
      "building tree 109 of 600\n",
      "building tree 110 of 600\n",
      "building tree 111 of 600\n",
      "building tree 112 of 600\n",
      "building tree 113 of 600\n",
      "building tree 114 of 600\n",
      "building tree 115 of 600\n",
      "building tree 116 of 600building tree 117 of 600\n",
      "\n",
      "building tree 118 of 600\n",
      "building tree 119 of 600\n",
      "building tree 120 of 600\n",
      "building tree 121 of 600\n",
      "building tree 122 of 600\n",
      "building tree 123 of 600\n",
      "building tree 124 of 600\n",
      "building tree 125 of 600\n",
      "building tree 126 of 600\n",
      "building tree 127 of 600\n",
      "building tree 128 of 600\n",
      "building tree 129 of 600\n",
      "building tree 130 of 600\n",
      "building tree 131 of 600\n",
      "building tree 132 of 600\n",
      "building tree 133 of 600\n",
      "building tree 134 of 600\n",
      "building tree 135 of 600\n",
      "building tree 136 of 600\n",
      "building tree 137 of 600\n",
      "building tree 138 of 600\n",
      "building tree 139 of 600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 114 tasks      | elapsed:   12.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 140 of 600\n",
      "building tree 141 of 600\n",
      "building tree 142 of 600\n",
      "building tree 143 of 600\n",
      "building tree 144 of 600\n",
      "building tree 145 of 600\n",
      "building tree 146 of 600\n",
      "building tree 147 of 600\n",
      "building tree 148 of 600\n",
      "building tree 149 of 600\n",
      "building tree 150 of 600\n",
      "building tree 151 of 600\n",
      "building tree 152 of 600\n",
      "building tree 153 of 600\n",
      "building tree 154 of 600\n",
      "building tree 155 of 600\n",
      "building tree 156 of 600\n",
      "building tree 157 of 600\n",
      "building tree 158 of 600\n",
      "building tree 159 of 600\n",
      "building tree 160 of 600\n",
      "building tree 161 of 600\n",
      "building tree 162 of 600\n",
      "building tree 163 of 600\n",
      "building tree 164 of 600\n",
      "building tree 165 of 600\n",
      "building tree 166 of 600\n",
      "building tree 167 of 600\n",
      "building tree 168 of 600\n",
      "building tree 169 of 600\n",
      "building tree 170 of 600\n",
      "building tree 171 of 600\n",
      "building tree 172 of 600\n",
      "building tree 173 of 600\n",
      "building tree 174 of 600\n",
      "building tree 175 of 600\n",
      "building tree 176 of 600\n",
      "building tree 177 of 600\n",
      "building tree 178 of 600\n",
      "building tree 179 of 600\n",
      "building tree 180 of 600\n",
      "building tree 181 of 600\n",
      "building tree 182 of 600\n",
      "building tree 183 of 600\n",
      "building tree 184 of 600\n",
      "building tree 185 of 600\n",
      "building tree 186 of 600\n",
      "building tree 187 of 600\n",
      "building tree 188 of 600\n",
      "building tree 189 of 600\n",
      "building tree 190 of 600\n",
      "building tree 191 of 600\n",
      "building tree 192 of 600\n",
      "building tree 193 of 600\n",
      "building tree 194 of 600\n",
      "building tree 195 of 600\n",
      "building tree 196 of 600\n",
      "building tree 197 of 600\n",
      "building tree 198 of 600\n",
      "building tree 199 of 600\n",
      "building tree 200 of 600\n",
      "building tree 201 of 600\n",
      "building tree 202 of 600\n",
      "building tree 203 of 600\n",
      "building tree 204 of 600\n",
      "building tree 205 of 600\n",
      "building tree 206 of 600\n",
      "building tree 207 of 600\n",
      "building tree 208 of 600\n",
      "building tree 209 of 600\n",
      "building tree 210 of 600\n",
      "building tree 211 of 600\n",
      "building tree 212 of 600\n",
      "building tree 213 of 600\n",
      "building tree 214 of 600\n",
      "building tree 215 of 600\n",
      "building tree 216 of 600\n",
      "building tree 217 of 600\n",
      "building tree 218 of 600\n",
      "building tree 219 of 600\n",
      "building tree 220 of 600\n",
      "building tree 221 of 600\n",
      "building tree 222 of 600\n",
      "building tree 223 of 600\n",
      "building tree 224 of 600\n",
      "building tree 225 of 600\n",
      "building tree 226 of 600\n",
      "building tree 227 of 600\n",
      "building tree 228 of 600\n",
      "building tree 229 of 600\n",
      "building tree 230 of 600\n",
      "building tree 231 of 600\n",
      "building tree 232 of 600\n",
      "building tree 233 of 600\n",
      "building tree 234 of 600\n",
      "building tree 235 of 600\n",
      "building tree 236 of 600\n",
      "building tree 237 of 600\n",
      "building tree 238 of 600\n",
      "building tree 239 of 600\n",
      "building tree 240 of 600\n",
      "building tree 241 of 600\n",
      "building tree 242 of 600\n",
      "building tree 243 of 600\n",
      "building tree 244 of 600\n",
      "building tree 245 of 600\n",
      "building tree 246 of 600\n",
      "building tree 247 of 600\n",
      "building tree 248 of 600\n",
      "building tree 249 of 600\n",
      "building tree 250 of 600\n",
      "building tree 251 of 600\n",
      "building tree 252 of 600\n",
      "building tree 253 of 600\n",
      "building tree 254 of 600\n",
      "building tree 255 of 600\n",
      "building tree 256 of 600\n",
      "building tree 257 of 600\n",
      "building tree 258 of 600\n",
      "building tree 259 of 600\n",
      "building tree 260 of 600\n",
      "building tree 261 of 600\n",
      "building tree 262 of 600\n",
      "building tree 263 of 600\n",
      "building tree 264 of 600\n",
      "building tree 265 of 600\n",
      "building tree 266 of 600\n",
      "building tree 267 of 600\n",
      "building tree 268 of 600\n",
      "building tree 269 of 600\n",
      "building tree 270 of 600\n",
      "building tree 271 of 600\n",
      "building tree 272 of 600\n",
      "building tree 273 of 600\n",
      "building tree 274 of 600\n",
      "building tree 275 of 600\n",
      "building tree 276 of 600\n",
      "building tree 277 of 600\n",
      "building tree 278 of 600\n",
      "building tree 279 of 600\n",
      "building tree 280 of 600\n",
      "building tree 281 of 600\n",
      "building tree 282 of 600\n",
      "building tree 283 of 600\n",
      "building tree 284 of 600\n",
      "building tree 285 of 600\n",
      "building tree 286 of 600\n",
      "building tree 287 of 600\n",
      "building tree 288 of 600\n",
      "building tree 289 of 600\n",
      "building tree 290 of 600\n",
      "building tree 291 of 600\n",
      "building tree 292 of 600\n",
      "building tree 293 of 600\n",
      "building tree 294 of 600\n",
      "building tree 295 of 600\n",
      "building tree 296 of 600\n",
      "building tree 297 of 600\n",
      "building tree 298 of 600\n",
      "building tree 299 of 600\n",
      "building tree 300 of 600\n",
      "building tree 301 of 600\n",
      "building tree 302 of 600\n",
      "building tree 303 of 600\n",
      "building tree 304 of 600\n",
      "building tree 305 of 600\n",
      "building tree 306 of 600\n",
      "building tree 307 of 600\n",
      "building tree 308 of 600\n",
      "building tree 309 of 600\n",
      "building tree 310 of 600\n",
      "building tree 311 of 600\n",
      "building tree 312 of 600\n",
      "building tree 313 of 600\n",
      "building tree 314 of 600\n",
      "building tree 315 of 600\n",
      "building tree 316 of 600\n",
      "building tree 317 of 600\n",
      "building tree 318 of 600\n",
      "building tree 319 of 600\n",
      "building tree 320 of 600\n",
      "building tree 321 of 600\n",
      "building tree 322 of 600\n",
      "building tree 323 of 600\n",
      "building tree 324 of 600\n",
      "building tree 325 of 600\n",
      "building tree 326 of 600\n",
      "building tree 327 of 600\n",
      "building tree 328 of 600\n",
      "building tree 329 of 600\n",
      "building tree 330 of 600\n",
      "building tree 331 of 600\n",
      "building tree 332 of 600\n",
      "building tree 333 of 600\n",
      "building tree 334 of 600\n",
      "building tree 335 of 600\n",
      "building tree 336 of 600\n",
      "building tree 337 of 600\n",
      "building tree 338 of 600\n",
      "building tree 339 of 600\n",
      "building tree 340 of 600\n",
      "building tree 341 of 600\n",
      "building tree 342 of 600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 317 tasks      | elapsed:   33.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 343 of 600\n",
      "building tree 344 of 600\n",
      "building tree 345 of 600\n",
      "building tree 346 of 600\n",
      "building tree 347 of 600\n",
      "building tree 348 of 600\n",
      "building tree 349 of 600\n",
      "building tree 350 of 600\n",
      "building tree 351 of 600\n",
      "building tree 352 of 600\n",
      "building tree 353 of 600\n",
      "building tree 354 of 600\n",
      "building tree 355 of 600\n",
      "building tree 356 of 600\n",
      "building tree 357 of 600\n",
      "building tree 358 of 600\n",
      "building tree 359 of 600\n",
      "building tree 360 of 600\n",
      "building tree 361 of 600\n",
      "building tree 362 of 600\n",
      "building tree 363 of 600\n",
      "building tree 364 of 600\n",
      "building tree 365 of 600\n",
      "building tree 366 of 600\n",
      "building tree 367 of 600\n",
      "building tree 368 of 600\n",
      "building tree 369 of 600\n",
      "building tree 370 of 600\n",
      "building tree 371 of 600\n",
      "building tree 372 of 600\n",
      "building tree 373 of 600\n",
      "building tree 374 of 600\n",
      "building tree 375 of 600\n",
      "building tree 376 of 600\n",
      "building tree 377 of 600\n",
      "building tree 378 of 600\n",
      "building tree 379 of 600\n",
      "building tree 380 of 600\n",
      "building tree 381 of 600\n",
      "building tree 382 of 600\n",
      "building tree 383 of 600\n",
      "building tree 384 of 600\n",
      "building tree 385 of 600\n",
      "building tree 386 of 600\n",
      "building tree 387 of 600\n",
      "building tree 388 of 600\n",
      "building tree 389 of 600\n",
      "building tree 390 of 600\n",
      "building tree 391 of 600\n",
      "building tree 392 of 600\n",
      "building tree 393 of 600\n",
      "building tree 394 of 600\n",
      "building tree 395 of 600\n",
      "building tree 396 of 600\n",
      "building tree 397 of 600\n",
      "building tree 398 of 600\n",
      "building tree 399 of 600\n",
      "building tree 400 of 600\n",
      "building tree 401 of 600\n",
      "building tree 402 of 600\n",
      "building tree 403 of 600\n",
      "building tree 404 of 600\n",
      "building tree 405 of 600\n",
      "building tree 406 of 600\n",
      "building tree 407 of 600\n",
      "building tree 408 of 600\n",
      "building tree 409 of 600\n",
      "building tree 410 of 600\n",
      "building tree 411 of 600\n",
      "building tree 412 of 600\n",
      "building tree 413 of 600\n",
      "building tree 414 of 600\n",
      "building tree 415 of 600\n",
      "building tree 416 of 600\n",
      "building tree 417 of 600\n",
      "building tree 418 of 600\n",
      "building tree 419 of 600\n",
      "building tree 420 of 600\n",
      "building tree 421 of 600\n",
      "building tree 422 of 600\n",
      "building tree 423 of 600\n",
      "building tree 424 of 600\n",
      "building tree 425 of 600\n",
      "building tree 426 of 600\n",
      "building tree 427 of 600\n",
      "building tree 428 of 600\n",
      "building tree 429 of 600\n",
      "building tree 430 of 600\n",
      "building tree 431 of 600\n",
      "building tree 432 of 600\n",
      "building tree 433 of 600\n",
      "building tree 434 of 600\n",
      "building tree 435 of 600\n",
      "building tree 436 of 600\n",
      "building tree 437 of 600\n",
      "building tree 438 of 600\n",
      "building tree 439 of 600\n",
      "building tree 440 of 600\n",
      "building tree 441 of 600\n",
      "building tree 442 of 600\n",
      "building tree 443 of 600\n",
      "building tree 444 of 600\n",
      "building tree 445 of 600\n",
      "building tree 446 of 600\n",
      "building tree 447 of 600\n",
      "building tree 448 of 600\n",
      "building tree 449 of 600\n",
      "building tree 450 of 600\n",
      "building tree 451 of 600\n",
      "building tree 452 of 600\n",
      "building tree 453 of 600\n",
      "building tree 454 of 600\n",
      "building tree 455 of 600\n",
      "building tree 456 of 600\n",
      "building tree 457 of 600\n",
      "building tree 458 of 600\n",
      "building tree 459 of 600\n",
      "building tree 460 of 600\n",
      "building tree 461 of 600\n",
      "building tree 462 of 600\n",
      "building tree 463 of 600\n",
      "building tree 464 of 600\n",
      "building tree 465 of 600\n",
      "building tree 466 of 600\n",
      "building tree 467 of 600\n",
      "building tree 468 of 600\n",
      "building tree 469 of 600\n",
      "building tree 470 of 600\n",
      "building tree 471 of 600\n",
      "building tree 472 of 600\n",
      "building tree 473 of 600\n",
      "building tree 474 of 600\n",
      "building tree 475 of 600\n",
      "building tree 476 of 600\n",
      "building tree 477 of 600\n",
      "building tree 478 of 600\n",
      "building tree 479 of 600\n",
      "building tree 480 of 600\n",
      "building tree 481 of 600\n",
      "building tree 482 of 600\n",
      "building tree 483 of 600\n",
      "building tree 484 of 600\n",
      "building tree 485 of 600\n",
      "building tree 486 of 600\n",
      "building tree 487 of 600\n",
      "building tree 488 of 600\n",
      "building tree 489 of 600\n",
      "building tree 490 of 600\n",
      "building tree 491 of 600\n",
      "building tree 492 of 600\n",
      "building tree 493 of 600\n",
      "building tree 494 of 600\n",
      "building tree 495 of 600\n",
      "building tree 496 of 600\n",
      "building tree 497 of 600\n",
      "building tree 498 of 600\n",
      "building tree 499 of 600\n",
      "building tree 500 of 600\n",
      "building tree 501 of 600\n",
      "building tree 502 of 600\n",
      "building tree 503 of 600\n",
      "building tree 504 of 600\n",
      "building tree 505 of 600\n",
      "building tree 506 of 600\n",
      "building tree 507 of 600\n",
      "building tree 508 of 600\n",
      "building tree 509 of 600\n",
      "building tree 510 of 600\n",
      "building tree 511 of 600\n",
      "building tree 512 of 600\n",
      "building tree 513 of 600\n",
      "building tree 514 of 600\n",
      "building tree 515 of 600\n",
      "building tree 516 of 600\n",
      "building tree 517 of 600\n",
      "building tree 518 of 600\n",
      "building tree 519 of 600\n",
      "building tree 520 of 600\n",
      "building tree 521 of 600\n",
      "building tree 522 of 600\n",
      "building tree 523 of 600\n",
      "building tree 524 of 600\n",
      "building tree 525 of 600\n",
      "building tree 526 of 600\n",
      "building tree 527 of 600\n",
      "building tree 528 of 600\n",
      "building tree 529 of 600\n",
      "building tree 530 of 600\n",
      "building tree 531 of 600\n",
      "building tree 532 of 600\n",
      "building tree 533 of 600\n",
      "building tree 534 of 600\n",
      "building tree 535 of 600\n",
      "building tree 536 of 600\n",
      "building tree 537 of 600\n",
      "building tree 538 of 600\n",
      "building tree 539 of 600\n",
      "building tree 540 of 600\n",
      "building tree 541 of 600\n",
      "building tree 542 of 600\n",
      "building tree 543 of 600\n",
      "building tree 544 of 600\n",
      "building tree 545 of 600\n",
      "building tree 546 of 600\n",
      "building tree 547 of 600\n",
      "building tree 548 of 600building tree 549 of 600\n",
      "\n",
      "building tree 550 of 600\n",
      "building tree 551 of 600\n",
      "building tree 552 of 600\n",
      "building tree 553 of 600\n",
      "building tree 554 of 600\n",
      "building tree 555 of 600\n",
      "building tree 556 of 600\n",
      "building tree 557 of 600\n",
      "building tree 558 of 600\n",
      "building tree 559 of 600\n",
      "building tree 560 of 600\n",
      "building tree 561 of 600\n",
      "building tree 562 of 600\n",
      "building tree 563 of 600\n",
      "building tree 564 of 600\n",
      "building tree 565 of 600\n",
      "building tree 566 of 600\n",
      "building tree 567 of 600\n",
      "building tree 568 of 600\n",
      "building tree 569 of 600\n",
      "building tree 570 of 600\n",
      "building tree 571 of 600\n",
      "building tree 572 of 600\n",
      "building tree 573 of 600\n",
      "building tree 574 of 600\n",
      "building tree 575 of 600\n",
      "building tree 576 of 600\n",
      "building tree 577 of 600\n",
      "building tree 578 of 600\n",
      "building tree 579 of 600\n",
      "building tree 580 of 600\n",
      "building tree 581 of 600\n",
      "building tree 582 of 600\n",
      "building tree 583 of 600\n",
      "building tree 584 of 600\n",
      "building tree 585 of 600\n",
      "building tree 586 of 600\n",
      "building tree 587 of 600\n",
      "building tree 588 of 600\n",
      "building tree 589 of 600\n",
      "building tree 590 of 600\n",
      "building tree 591 of 600\n",
      "building tree 592 of 600\n",
      "building tree 593 of 600\n",
      "building tree 594 of 600\n",
      "building tree 595 of 600\n",
      "building tree 596 of 600\n",
      "building tree 597 of 600\n",
      "building tree 598 of 600\n",
      "building tree 599 of 600\n",
      "building tree 600 of 600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 600 out of 600 | elapsed:  1.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "textlab_30_fullab_rew fit complete\n",
      "Fitted model saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=24)]: Using backend ThreadingBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=24)]: Done 114 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=24)]: Done 317 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=24)]: Done 600 out of 600 | elapsed:    1.7s finished\n",
      "[Parallel(n_jobs=24)]: Using backend ThreadingBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=24)]: Done 114 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=24)]: Done 317 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=24)]: Done 600 out of 600 | elapsed:    1.6s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 24 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitAndPredict: 89.95465922355652 seconds\n",
      "0.8948259642306319\n",
      "----- [Running *duration* ML with numeric features] -----\n",
      "Running textlab_30_fullab_dur\n",
      "building tree 1 of 600\n",
      "building tree 2 of 600\n",
      "building tree 3 of 600\n",
      "building tree 4 of 600\n",
      "building tree 5 of 600\n",
      "building tree 6 of 600\n",
      "building tree 7 of 600\n",
      "building tree 8 of 600\n",
      "building tree 9 of 600\n",
      "building tree 10 of 600\n",
      "building tree 11 of 600\n",
      "building tree 12 of 600\n",
      "building tree 13 of 600\n",
      "building tree 14 of 600\n",
      "building tree 15 of 600\n",
      "building tree 16 of 600\n",
      "building tree 17 of 600\n",
      "building tree 18 of 600\n",
      "building tree 19 of 600\n",
      "building tree 20 of 600\n",
      "building tree 21 of 600\n",
      "building tree 22 of 600\n",
      "building tree 23 of 600\n",
      "building tree 24 of 600\n",
      "building tree 25 of 600\n",
      "building tree 26 of 600\n",
      "building tree 27 of 600\n",
      "building tree 28 of 600\n",
      "building tree 29 of 600\n",
      "building tree 30 of 600\n",
      "building tree 31 of 600\n",
      "building tree 32 of 600\n",
      "building tree 33 of 600\n",
      "building tree 34 of 600\n",
      "building tree 35 of 600\n",
      "building tree 36 of 600\n",
      "building tree 37 of 600\n",
      "building tree 38 of 600\n",
      "building tree 39 of 600\n",
      "building tree 40 of 600\n",
      "building tree 41 of 600\n",
      "building tree 42 of 600\n",
      "building tree 43 of 600\n",
      "building tree 44 of 600\n",
      "building tree 45 of 600\n",
      "building tree 46 of 600\n",
      "building tree 47 of 600\n",
      "building tree 48 of 600\n",
      "building tree 49 of 600building tree 50 of 600\n",
      "\n",
      "building tree 51 of 600\n",
      "building tree 52 of 600\n",
      "building tree 53 of 600\n",
      "building tree 54 of 600\n",
      "building tree 55 of 600\n",
      "building tree 56 of 600\n",
      "building tree 57 of 600\n",
      "building tree 58 of 600\n",
      "building tree 59 of 600\n",
      "building tree 60 of 600\n",
      "building tree 61 of 600\n",
      "building tree 62 of 600\n",
      "building tree 63 of 600\n",
      "building tree 64 of 600\n",
      "building tree 65 of 600\n",
      "building tree 66 of 600\n",
      "building tree 67 of 600\n",
      "building tree 68 of 600\n",
      "building tree 69 of 600\n",
      "building tree 70 of 600\n",
      "building tree 71 of 600\n",
      "building tree 72 of 600\n",
      "building tree 73 of 600building tree 74 of 600\n",
      "\n",
      "building tree 75 of 600\n",
      "building tree 76 of 600\n",
      "building tree 77 of 600\n",
      "building tree 78 of 600\n",
      "building tree 79 of 600\n",
      "building tree 80 of 600\n",
      "building tree 81 of 600\n",
      "building tree 82 of 600\n",
      "building tree 83 of 600\n",
      "building tree 84 of 600\n",
      "building tree 85 of 600\n",
      "building tree 86 of 600\n",
      "building tree 87 of 600\n",
      "building tree 88 of 600\n",
      "building tree 89 of 600\n",
      "building tree 90 of 600\n",
      "building tree 91 of 600\n",
      "building tree 92 of 600\n",
      "building tree 93 of 600\n",
      "building tree 94 of 600\n",
      "building tree 95 of 600\n",
      "building tree 96 of 600\n",
      "building tree 97 of 600\n",
      "building tree 98 of 600\n",
      "building tree 99 of 600\n",
      "building tree 100 of 600\n",
      "building tree 101 of 600\n",
      "building tree 102 of 600\n",
      "building tree 103 of 600\n",
      "building tree 104 of 600\n",
      "building tree 105 of 600\n",
      "building tree 106 of 600\n",
      "building tree 107 of 600\n",
      "building tree 108 of 600\n",
      "building tree 109 of 600\n",
      "building tree 110 of 600\n",
      "building tree 111 of 600\n",
      "building tree 112 of 600\n",
      "building tree 113 of 600\n",
      "building tree 114 of 600\n",
      "building tree 115 of 600\n",
      "building tree 116 of 600\n",
      "building tree 117 of 600\n",
      "building tree 118 of 600\n",
      "building tree 119 of 600\n",
      "building tree 120 of 600\n",
      "building tree 121 of 600\n",
      "building tree 122 of 600\n",
      "building tree 123 of 600\n",
      "building tree 124 of 600\n",
      "building tree 125 of 600\n",
      "building tree 126 of 600\n",
      "building tree 127 of 600\n",
      "building tree 128 of 600\n",
      "building tree 129 of 600\n",
      "building tree 130 of 600\n",
      "building tree 131 of 600\n",
      "building tree 132 of 600\n",
      "building tree 133 of 600\n",
      "building tree 134 of 600\n",
      "building tree 135 of 600\n",
      "building tree 136 of 600\n",
      "building tree 137 of 600\n",
      "building tree 138 of 600\n",
      "building tree 139 of 600\n",
      "building tree 140 of 600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 114 tasks      | elapsed:   15.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 141 of 600\n",
      "building tree 142 of 600\n",
      "building tree 143 of 600\n",
      "building tree 144 of 600\n",
      "building tree 145 of 600\n",
      "building tree 146 of 600\n",
      "building tree 147 of 600\n",
      "building tree 148 of 600\n",
      "building tree 149 of 600\n",
      "building tree 150 of 600\n",
      "building tree 151 of 600\n",
      "building tree 152 of 600\n",
      "building tree 153 of 600\n",
      "building tree 154 of 600\n",
      "building tree 155 of 600\n",
      "building tree 156 of 600\n",
      "building tree 157 of 600\n",
      "building tree 158 of 600\n",
      "building tree 159 of 600\n",
      "building tree 160 of 600\n",
      "building tree 161 of 600\n",
      "building tree 162 of 600\n",
      "building tree 163 of 600\n",
      "building tree 164 of 600\n",
      "building tree 165 of 600\n",
      "building tree 166 of 600\n",
      "building tree 167 of 600\n",
      "building tree 168 of 600\n",
      "building tree 169 of 600\n",
      "building tree 170 of 600\n",
      "building tree 171 of 600\n",
      "building tree 172 of 600\n",
      "building tree 173 of 600\n",
      "building tree 174 of 600\n",
      "building tree 175 of 600\n",
      "building tree 176 of 600\n",
      "building tree 177 of 600\n",
      "building tree 178 of 600\n",
      "building tree 179 of 600\n",
      "building tree 180 of 600\n",
      "building tree 181 of 600\n",
      "building tree 182 of 600\n",
      "building tree 183 of 600\n",
      "building tree 184 of 600\n",
      "building tree 185 of 600\n",
      "building tree 186 of 600\n",
      "building tree 187 of 600\n",
      "building tree 188 of 600\n",
      "building tree 189 of 600\n",
      "building tree 190 of 600\n",
      "building tree 191 of 600\n",
      "building tree 192 of 600\n",
      "building tree 193 of 600\n",
      "building tree 194 of 600\n",
      "building tree 195 of 600\n",
      "building tree 196 of 600\n",
      "building tree 197 of 600\n",
      "building tree 198 of 600\n",
      "building tree 199 of 600\n",
      "building tree 200 of 600\n",
      "building tree 201 of 600\n",
      "building tree 202 of 600\n",
      "building tree 203 of 600\n",
      "building tree 204 of 600\n",
      "building tree 205 of 600\n",
      "building tree 206 of 600\n",
      "building tree 207 of 600\n",
      "building tree 208 of 600\n",
      "building tree 209 of 600\n",
      "building tree 210 of 600\n",
      "building tree 211 of 600\n",
      "building tree 212 of 600\n",
      "building tree 213 of 600\n",
      "building tree 214 of 600\n",
      "building tree 215 of 600\n",
      "building tree 216 of 600\n",
      "building tree 217 of 600\n",
      "building tree 218 of 600\n",
      "building tree 219 of 600\n",
      "building tree 220 of 600\n",
      "building tree 221 of 600\n",
      "building tree 222 of 600\n",
      "building tree 223 of 600\n",
      "building tree 224 of 600\n",
      "building tree 225 of 600\n",
      "building tree 226 of 600\n",
      "building tree 227 of 600\n",
      "building tree 228 of 600\n",
      "building tree 229 of 600\n",
      "building tree 230 of 600\n",
      "building tree 231 of 600\n",
      "building tree 232 of 600\n",
      "building tree 233 of 600\n",
      "building tree 234 of 600\n",
      "building tree 235 of 600\n",
      "building tree 236 of 600\n",
      "building tree 237 of 600\n",
      "building tree 238 of 600\n",
      "building tree 239 of 600\n",
      "building tree 240 of 600\n",
      "building tree 241 of 600\n",
      "building tree 242 of 600\n",
      "building tree 243 of 600\n",
      "building tree 244 of 600\n",
      "building tree 245 of 600\n",
      "building tree 246 of 600\n",
      "building tree 247 of 600\n",
      "building tree 248 of 600\n",
      "building tree 249 of 600\n",
      "building tree 250 of 600\n",
      "building tree 251 of 600\n",
      "building tree 252 of 600\n",
      "building tree 253 of 600\n",
      "building tree 254 of 600\n",
      "building tree 255 of 600\n",
      "building tree 256 of 600\n",
      "building tree 257 of 600\n",
      "building tree 258 of 600\n",
      "building tree 259 of 600\n",
      "building tree 260 of 600\n",
      "building tree 261 of 600\n",
      "building tree 262 of 600\n",
      "building tree 263 of 600\n",
      "building tree 264 of 600\n",
      "building tree 265 of 600\n",
      "building tree 266 of 600\n",
      "building tree 267 of 600\n",
      "building tree 268 of 600\n",
      "building tree 269 of 600\n",
      "building tree 270 of 600\n",
      "building tree 271 of 600\n",
      "building tree 272 of 600\n",
      "building tree 273 of 600\n",
      "building tree 274 of 600\n",
      "building tree 275 of 600\n",
      "building tree 276 of 600\n",
      "building tree 277 of 600\n",
      "building tree 278 of 600\n",
      "building tree 279 of 600\n",
      "building tree 280 of 600\n",
      "building tree 281 of 600\n",
      "building tree 282 of 600\n",
      "building tree 283 of 600\n",
      "building tree 284 of 600\n",
      "building tree 285 of 600\n",
      "building tree 286 of 600\n",
      "building tree 287 of 600\n",
      "building tree 288 of 600\n",
      "building tree 289 of 600\n",
      "building tree 290 of 600\n",
      "building tree 291 of 600\n",
      "building tree 292 of 600\n",
      "building tree 293 of 600\n",
      "building tree 294 of 600\n",
      "building tree 295 of 600\n",
      "building tree 296 of 600\n",
      "building tree 297 of 600\n",
      "building tree 298 of 600\n",
      "building tree 299 of 600\n",
      "building tree 300 of 600\n",
      "building tree 301 of 600\n",
      "building tree 302 of 600\n",
      "building tree 303 of 600\n",
      "building tree 304 of 600\n",
      "building tree 305 of 600\n",
      "building tree 306 of 600\n",
      "building tree 307 of 600\n",
      "building tree 308 of 600\n",
      "building tree 309 of 600\n",
      "building tree 310 of 600\n",
      "building tree 311 of 600\n",
      "building tree 312 of 600\n",
      "building tree 313 of 600\n",
      "building tree 314 of 600\n",
      "building tree 315 of 600\n",
      "building tree 316 of 600\n",
      "building tree 317 of 600\n",
      "building tree 318 of 600\n",
      "building tree 319 of 600\n",
      "building tree 320 of 600\n",
      "building tree 321 of 600\n",
      "building tree 322 of 600\n",
      "building tree 323 of 600\n",
      "building tree 324 of 600\n",
      "building tree 325 of 600\n",
      "building tree 326 of 600\n",
      "building tree 327 of 600\n",
      "building tree 328 of 600\n",
      "building tree 329 of 600\n",
      "building tree 330 of 600\n",
      "building tree 331 of 600\n",
      "building tree 332 of 600\n",
      "building tree 333 of 600\n",
      "building tree 334 of 600building tree 335 of 600\n",
      "\n",
      "building tree 336 of 600\n",
      "building tree 337 of 600\n",
      "building tree 338 of 600\n",
      "building tree 339 of 600\n",
      "building tree 340 of 600\n",
      "building tree 341 of 600\n",
      "building tree 342 of 600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 317 tasks      | elapsed:   41.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 343 of 600\n",
      "building tree 344 of 600\n",
      "building tree 345 of 600\n",
      "building tree 346 of 600\n",
      "building tree 347 of 600\n",
      "building tree 348 of 600\n",
      "building tree 349 of 600\n",
      "building tree 350 of 600\n",
      "building tree 351 of 600\n",
      "building tree 352 of 600\n",
      "building tree 353 of 600\n",
      "building tree 354 of 600\n",
      "building tree 355 of 600\n",
      "building tree 356 of 600\n",
      "building tree 357 of 600\n",
      "building tree 358 of 600\n",
      "building tree 359 of 600\n",
      "building tree 360 of 600\n",
      "building tree 361 of 600\n",
      "building tree 362 of 600\n",
      "building tree 363 of 600\n",
      "building tree 364 of 600\n",
      "building tree 365 of 600\n",
      "building tree 366 of 600\n",
      "building tree 367 of 600\n",
      "building tree 368 of 600\n",
      "building tree 369 of 600\n",
      "building tree 370 of 600\n",
      "building tree 371 of 600\n",
      "building tree 372 of 600\n",
      "building tree 373 of 600\n",
      "building tree 374 of 600\n",
      "building tree 375 of 600\n",
      "building tree 376 of 600\n",
      "building tree 377 of 600\n",
      "building tree 378 of 600\n",
      "building tree 379 of 600\n",
      "building tree 380 of 600\n",
      "building tree 381 of 600\n",
      "building tree 382 of 600\n",
      "building tree 383 of 600\n",
      "building tree 384 of 600\n",
      "building tree 385 of 600\n",
      "building tree 386 of 600\n",
      "building tree 387 of 600\n",
      "building tree 388 of 600\n",
      "building tree 389 of 600\n",
      "building tree 390 of 600\n",
      "building tree 391 of 600\n",
      "building tree 392 of 600\n",
      "building tree 393 of 600\n",
      "building tree 394 of 600\n",
      "building tree 395 of 600\n",
      "building tree 396 of 600\n",
      "building tree 397 of 600\n",
      "building tree 398 of 600\n",
      "building tree 399 of 600\n",
      "building tree 400 of 600\n",
      "building tree 401 of 600\n",
      "building tree 402 of 600\n",
      "building tree 403 of 600\n",
      "building tree 404 of 600\n",
      "building tree 405 of 600\n",
      "building tree 406 of 600\n",
      "building tree 407 of 600\n",
      "building tree 408 of 600\n",
      "building tree 409 of 600\n",
      "building tree 410 of 600\n",
      "building tree 411 of 600\n",
      "building tree 412 of 600\n",
      "building tree 413 of 600\n",
      "building tree 414 of 600\n",
      "building tree 415 of 600\n",
      "building tree 416 of 600\n",
      "building tree 417 of 600\n",
      "building tree 418 of 600\n",
      "building tree 419 of 600\n",
      "building tree 420 of 600\n",
      "building tree 421 of 600\n",
      "building tree 422 of 600\n",
      "building tree 423 of 600\n",
      "building tree 424 of 600\n",
      "building tree 425 of 600\n",
      "building tree 426 of 600\n",
      "building tree 427 of 600\n",
      "building tree 428 of 600\n",
      "building tree 429 of 600\n",
      "building tree 430 of 600\n",
      "building tree 431 of 600\n",
      "building tree 432 of 600\n",
      "building tree 433 of 600\n",
      "building tree 434 of 600\n",
      "building tree 435 of 600\n",
      "building tree 436 of 600\n",
      "building tree 437 of 600\n",
      "building tree 438 of 600\n",
      "building tree 439 of 600\n",
      "building tree 440 of 600\n",
      "building tree 441 of 600\n",
      "building tree 442 of 600\n",
      "building tree 443 of 600\n",
      "building tree 444 of 600\n",
      "building tree 445 of 600\n",
      "building tree 446 of 600\n",
      "building tree 447 of 600\n",
      "building tree 448 of 600\n",
      "building tree 449 of 600\n",
      "building tree 450 of 600\n",
      "building tree 451 of 600\n",
      "building tree 452 of 600\n",
      "building tree 453 of 600\n",
      "building tree 454 of 600\n",
      "building tree 455 of 600\n",
      "building tree 456 of 600\n",
      "building tree 457 of 600\n",
      "building tree 458 of 600\n",
      "building tree 459 of 600\n",
      "building tree 460 of 600\n",
      "building tree 461 of 600\n",
      "building tree 462 of 600\n",
      "building tree 463 of 600\n",
      "building tree 464 of 600\n",
      "building tree 465 of 600\n",
      "building tree 466 of 600\n",
      "building tree 467 of 600\n",
      "building tree 468 of 600\n",
      "building tree 469 of 600\n",
      "building tree 470 of 600\n",
      "building tree 471 of 600\n",
      "building tree 472 of 600\n",
      "building tree 473 of 600\n",
      "building tree 474 of 600\n",
      "building tree 475 of 600\n",
      "building tree 476 of 600\n",
      "building tree 477 of 600\n",
      "building tree 478 of 600\n",
      "building tree 479 of 600\n",
      "building tree 480 of 600\n",
      "building tree 481 of 600\n",
      "building tree 482 of 600\n",
      "building tree 483 of 600\n",
      "building tree 484 of 600\n",
      "building tree 485 of 600\n",
      "building tree 486 of 600\n",
      "building tree 487 of 600\n",
      "building tree 488 of 600\n",
      "building tree 489 of 600\n",
      "building tree 490 of 600\n",
      "building tree 491 of 600\n",
      "building tree 492 of 600\n",
      "building tree 493 of 600\n",
      "building tree 494 of 600\n",
      "building tree 495 of 600\n",
      "building tree 496 of 600\n",
      "building tree 497 of 600\n",
      "building tree 498 of 600\n",
      "building tree 499 of 600\n",
      "building tree 500 of 600\n",
      "building tree 501 of 600\n",
      "building tree 502 of 600\n",
      "building tree 503 of 600\n",
      "building tree 504 of 600\n",
      "building tree 505 of 600\n",
      "building tree 506 of 600\n",
      "building tree 507 of 600\n",
      "building tree 508 of 600\n",
      "building tree 509 of 600\n",
      "building tree 510 of 600\n",
      "building tree 511 of 600\n",
      "building tree 512 of 600\n",
      "building tree 513 of 600\n",
      "building tree 514 of 600\n",
      "building tree 515 of 600\n",
      "building tree 516 of 600\n",
      "building tree 517 of 600\n",
      "building tree 518 of 600\n",
      "building tree 519 of 600\n",
      "building tree 520 of 600\n",
      "building tree 521 of 600\n",
      "building tree 522 of 600\n",
      "building tree 523 of 600\n",
      "building tree 524 of 600\n",
      "building tree 525 of 600\n",
      "building tree 526 of 600\n",
      "building tree 527 of 600\n",
      "building tree 528 of 600\n",
      "building tree 529 of 600\n",
      "building tree 530 of 600\n",
      "building tree 531 of 600\n",
      "building tree 532 of 600\n",
      "building tree 533 of 600\n",
      "building tree 534 of 600\n",
      "building tree 535 of 600\n",
      "building tree 536 of 600\n",
      "building tree 537 of 600\n",
      "building tree 538 of 600\n",
      "building tree 539 of 600\n",
      "building tree 540 of 600\n",
      "building tree 541 of 600\n",
      "building tree 542 of 600\n",
      "building tree 543 of 600\n",
      "building tree 544 of 600\n",
      "building tree 545 of 600\n",
      "building tree 546 of 600\n",
      "building tree 547 of 600\n",
      "building tree 548 of 600\n",
      "building tree 549 of 600\n",
      "building tree 550 of 600\n",
      "building tree 551 of 600\n",
      "building tree 552 of 600\n",
      "building tree 553 of 600\n",
      "building tree 554 of 600\n",
      "building tree 555 of 600\n",
      "building tree 556 of 600\n",
      "building tree 557 of 600\n",
      "building tree 558 of 600\n",
      "building tree 559 of 600\n",
      "building tree 560 of 600\n",
      "building tree 561 of 600\n",
      "building tree 562 of 600\n",
      "building tree 563 of 600\n",
      "building tree 564 of 600\n",
      "building tree 565 of 600\n",
      "building tree 566 of 600\n",
      "building tree 567 of 600\n",
      "building tree 568 of 600\n",
      "building tree 569 of 600\n",
      "building tree 570 of 600\n",
      "building tree 571 of 600\n",
      "building tree 572 of 600\n",
      "building tree 573 of 600\n",
      "building tree 574 of 600\n",
      "building tree 575 of 600\n",
      "building tree 576 of 600\n",
      "building tree 577 of 600\n",
      "building tree 578 of 600\n",
      "building tree 579 of 600\n",
      "building tree 580 of 600\n",
      "building tree 581 of 600\n",
      "building tree 582 of 600\n",
      "building tree 583 of 600\n",
      "building tree 584 of 600\n",
      "building tree 585 of 600\n",
      "building tree 586 of 600\n",
      "building tree 587 of 600\n",
      "building tree 588 of 600\n",
      "building tree 589 of 600\n",
      "building tree 590 of 600\n",
      "building tree 591 of 600\n",
      "building tree 592 of 600\n",
      "building tree 593 of 600\n",
      "building tree 594 of 600\n",
      "building tree 595 of 600\n",
      "building tree 596 of 600\n",
      "building tree 597 of 600\n",
      "building tree 598 of 600\n",
      "building tree 599 of 600\n",
      "building tree 600 of 600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 600 out of 600 | elapsed:  1.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "textlab_30_fullab_dur fit complete\n",
      "Fitted model saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=24)]: Using backend ThreadingBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=24)]: Done 114 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=24)]: Done 317 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=24)]: Done 600 out of 600 | elapsed:    3.0s finished\n",
      "[Parallel(n_jobs=24)]: Using backend ThreadingBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=24)]: Done 114 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=24)]: Done 317 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=24)]: Done 600 out of 600 | elapsed:    2.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitAndPredict: 115.27418088912964 seconds\n",
      "0.43851247094014834\n",
      "*** A->B n-gram ML run\n",
      "# A obs: 46887\n",
      "# B obs: 46888\n",
      "# A_train obs: 37509\n",
      "# A_val obs: 9378\n",
      "# B_train obs: 37510\n",
      "# B_val obs: 9378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\1619589998.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  feature_df[\"description\"] = feature_df[\"description\"].astype(str)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\1619589998.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  feature_df[\"kw_parsed\"] = feature_df[\"kw_parsed\"].astype(str)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\1619589998.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  feature_df[\"title\"] = feature_df[\"title\"].astype(str)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descriptions vectorized for train data\n",
      "Keywords vectorized for train data\n",
      "Titles vectorized for train data\n",
      "(37509, 82701)\n",
      "(37509, 3553)\n",
      "(37509, 134055)\n",
      "Feature names saved to .\\ml_input\\feat_names_textlab_10_gramab.pkl\n",
      "Validation set descriptions vectorized\n",
      "Validation set keywords vectorized\n",
      "Validation set titles vectorized\n",
      "(9378, 82701)\n",
      "(9378, 3553)\n",
      "(9378, 134055)\n",
      "Train rewards saved to .\\ml_input\\./train_rew_textlab_10_gramab.pkl\n",
      "Train durations saved to .\\ml_input\\./train_dur_textlab_10_gramab.pkl\n",
      "Train text features saved to .\\ml_input\\./train_txtfeats_textlab_10_gramab.pkl\n",
      "Training data saved\n",
      "Test rewards saved to .\\ml_input\\./test_rew_textlab_10_gramab.pkl\n",
      "Test durations saved to .\\ml_input\\./test_dur_textlab_10_gramab.pkl\n",
      "Test text features saved to .\\ml_input\\./test_txtfeats_textlab_10_gramab.pkl\n",
      "Validation data saved\n",
      "Textual features exported\n",
      "*** Train data: ***\n",
      "Features: (37509, 220309)\n",
      "Reward labels: (37509,)\n",
      "Duration labels: (37509,)\n",
      "*** Validation data: ***\n",
      "Features: (9378, 220309)\n",
      "Reward labels: (9378,)\n",
      "Duration labels: (9378,)\n",
      "Training data loaded\n",
      "Test data loaded\n",
      "----- [Running *reward* ML with text features] -----\n",
      "Running textlab_10_gramab_rew\n",
      "building tree 1 of 40\n",
      "building tree 2 of 40\n",
      "building tree 3 of 40\n",
      "building tree 4 of 40\n",
      "building tree 5 of 40\n",
      "building tree 6 of 40\n",
      "building tree 7 of 40\n",
      "building tree 8 of 40\n",
      "building tree 9 of 40\n",
      "building tree 10 of 40\n",
      "building tree 11 of 40\n",
      "building tree 12 of 40\n",
      "building tree 13 of 40\n",
      "building tree 14 of 40\n",
      "building tree 15 of 40\n",
      "building tree 16 of 40\n",
      "building tree 17 of 40\n",
      "building tree 18 of 40\n",
      "building tree 19 of 40\n",
      "building tree 20 of 40\n",
      "building tree 21 of 40\n",
      "building tree 22 of 40\n",
      "building tree 23 of 40\n",
      "building tree 24 of 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 24 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 25 of 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:   35.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 26 of 40\n",
      "building tree 27 of 40\n",
      "building tree 28 of 40\n",
      "building tree 29 of 40\n",
      "building tree 30 of 40\n",
      "building tree 31 of 40\n",
      "building tree 32 of 40\n",
      "building tree 33 of 40\n",
      "building tree 34 of 40\n",
      "building tree 35 of 40\n",
      "building tree 36 of 40\n",
      "building tree 37 of 40\n",
      "building tree 38 of 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  14 out of  40 | elapsed:   39.3s remaining:  1.2min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 39 of 40\n",
      "building tree 40 of 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  35 out of  40 | elapsed:  1.1min remaining:    9.6s\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:  1.1min finished\n",
      "[Parallel(n_jobs=24)]: Using backend ThreadingBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=24)]: Done   1 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=24)]: Done  14 out of  40 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=24)]: Done  35 out of  40 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=24)]: Done  40 out of  40 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=24)]: Using backend ThreadingBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=24)]: Done   1 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=24)]: Done  14 out of  40 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=24)]: Done  35 out of  40 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=24)]: Done  40 out of  40 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 24 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "textlab_10_gramab_rew fit complete\n",
      "Fitted model saved\n",
      "fitAndPredict: 68.97812151908875 seconds\n",
      "0.8763084043022822\n",
      "----- [Running *duration* ML with text features] -----\n",
      "Running textlab_10_gramab_dur\n",
      "building tree 1 of 40\n",
      "building tree 2 of 40\n",
      "building tree 3 of 40\n",
      "building tree 4 of 40\n",
      "building tree 5 of 40\n",
      "building tree 6 of 40\n",
      "building tree 7 of 40\n",
      "building tree 8 of 40\n",
      "building tree 9 of 40\n",
      "building tree 10 of 40\n",
      "building tree 11 of 40\n",
      "building tree 12 of 40\n",
      "building tree 13 of 40\n",
      "building tree 14 of 40\n",
      "building tree 15 of 40\n",
      "building tree 16 of 40\n",
      "building tree 17 of 40\n",
      "building tree 18 of 40\n",
      "building tree 19 of 40\n",
      "building tree 20 of 40\n",
      "building tree 21 of 40\n",
      "building tree 22 of 40\n",
      "building tree 23 of 40\n",
      "building tree 24 of 40\n",
      "building tree 25 of 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:  1.3min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 26 of 40\n",
      "building tree 27 of 40\n",
      "building tree 28 of 40\n",
      "building tree 29 of 40\n",
      "building tree 30 of 40\n",
      "building tree 31 of 40\n",
      "building tree 32 of 40\n",
      "building tree 33 of 40\n",
      "building tree 34 of 40\n",
      "building tree 35 of 40\n",
      "building tree 36 of 40\n",
      "building tree 37 of 40\n",
      "building tree 38 of 40\n",
      "building tree 39 of 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  14 out of  40 | elapsed:  1.4min remaining:  2.7min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 40 of 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  35 out of  40 | elapsed:  2.5min remaining:   21.4s\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:  2.6min finished\n",
      "[Parallel(n_jobs=24)]: Using backend ThreadingBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=24)]: Done   1 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=24)]: Done  14 out of  40 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=24)]: Done  35 out of  40 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=24)]: Done  40 out of  40 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=24)]: Using backend ThreadingBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=24)]: Done   1 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=24)]: Done  14 out of  40 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=24)]: Done  35 out of  40 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=24)]: Done  40 out of  40 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "textlab_10_gramab_dur fit complete\n",
      "Fitted model saved\n",
      "fitAndPredict: 153.5969340801239 seconds\n",
      "0.3791504779174041\n",
      "*** A->B computing most predictive features\n",
      "Generating most predictive features for dur\n",
      "Number of features: 220309\n",
      "Features outputted to: .\\predictive_feats\\predictive_textlab_10_gramab_dur.csv\n",
      "Generating most predictive features for rew\n",
      "Number of features: 220309\n",
      "Features outputted to: .\\predictive_feats\\predictive_textlab_10_gramab_rew.csv\n",
      "*** A->B full ML run\n",
      "# A obs: 46887\n",
      "# B obs: 46888\n",
      "# A_train obs: 37509\n",
      "# A_val obs: 9378\n",
      "# B_train obs: 37510\n",
      "# B_val obs: 9378\n",
      "Number of description features: 54\n",
      "Number of title features: 103\n",
      "Number of keyword features: 43\n",
      "Computing feature #0: easy\n",
      "Computing feature #1: transcribe\n",
      "Computing feature #2: writing\n",
      "Computing feature #3: audio\n",
      "Computing feature #4: image\n",
      "Computing feature #5: video\n",
      "Computing feature #6: bonus\n",
      "Computing feature #7: copy\n",
      "Computing feature #8: search\n",
      "Computing feature #9: identify\n",
      "Computing feature #10: text\n",
      "Computing feature #11: date\n",
      "Computing feature #12: fun\n",
      "Computing feature #13: simple\n",
      "Computing feature #14: summarize\n",
      "Computing feature #15: only\n",
      "Computing feature #16: improve\n",
      "Computing feature #17: five\n",
      "Computing feature #18: questionmark\n",
      "Computing feature #19: exclamation\n",
      "Computing feature #20: find\n",
      "Computing feature #21: check\n",
      "Computing feature #22: match\n",
      "Computing feature #23: choose\n",
      "Computing feature #24: categorize\n",
      "Computing feature #25: suggest\n",
      "Computing feature #26: translate\n",
      "Computing feature #27: survey\n",
      "Computing feature #28: click\n",
      "Computing feature #29: link\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[kw_var] = (hit_df[\"kw_lower\"].str.count(str_to_search).fillna(0)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[kw_var] = (hit_df[\"kw_lower\"].str.count(str_to_search).fillna(0)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[kw_var] = (hit_df[\"kw_lower\"].str.count(str_to_search).fillna(0)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing feature #30: read\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[kw_var] = (hit_df[\"kw_lower\"].str.count(str_to_search).fillna(0)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[kw_var] = (hit_df[\"kw_lower\"].str.count(str_to_search).fillna(0)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[kw_var] = (hit_df[\"kw_lower\"].str.count(str_to_search).fillna(0)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[kw_var] = (hit_df[\"kw_lower\"].str.count(str_to_search).fillna(0)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[kw_var] = (hit_df[\"kw_lower\"].str.count(str_to_search).fillna(0)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[kw_var] = (hit_df[\"kw_lower\"].str.count(str_to_search).fillna(0)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[kw_var] = (hit_df[\"kw_lower\"].str.count(str_to_search).fillna(0)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[kw_var] = (hit_df[\"kw_lower\"].str.count(str_to_search).fillna(0)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[kw_var] = (hit_df[\"kw_lower\"].str.count(str_to_search).fillna(0)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[kw_var] = (hit_df[\"kw_lower\"].str.count(str_to_search).fillna(0)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[kw_var] = (hit_df[\"kw_lower\"].str.count(str_to_search).fillna(0)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[kw_var] = (hit_df[\"kw_lower\"].str.count(str_to_search).fillna(0)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[kw_var] = (hit_df[\"kw_lower\"].str.count(str_to_search).fillna(0)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[kw_var] = (hit_df[\"kw_lower\"].str.count(str_to_search).fillna(0)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[kw_var] = (hit_df[\"kw_lower\"].str.count(str_to_search).fillna(0)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[kw_var] = (hit_df[\"kw_lower\"].str.count(str_to_search).fillna(0)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[kw_var] = (hit_df[\"kw_lower\"].str.count(str_to_search).fillna(0)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[kw_var] = (hit_df[\"kw_lower\"].str.count(str_to_search).fillna(0)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[kw_var] = (hit_df[\"kw_lower\"].str.count(str_to_search).fillna(0)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[kw_var] = (hit_df[\"kw_lower\"].str.count(str_to_search).fillna(0)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[kw_var] = (hit_df[\"kw_lower\"].str.count(str_to_search).fillna(0)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[kw_var] = (hit_df[\"kw_lower\"].str.count(str_to_search).fillna(0)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[kw_var] = (hit_df[\"kw_lower\"].str.count(str_to_search).fillna(0)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[kw_var] = (hit_df[\"kw_lower\"].str.count(str_to_search).fillna(0)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[kw_var] = (hit_df[\"kw_lower\"].str.count(str_to_search).fillna(0)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[kw_var] = (hit_df[\"kw_lower\"].str.count(str_to_search).fillna(0)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[kw_var] = (hit_df[\"kw_lower\"].str.count(str_to_search).fillna(0)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[kw_var] = (hit_df[\"kw_lower\"].str.count(str_to_search).fillna(0)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[kw_var] = (hit_df[\"kw_lower\"].str.count(str_to_search).fillna(0)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[kw_var] = (hit_df[\"kw_lower\"].str.count(str_to_search).fillna(0)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[kw_var] = (hit_df[\"kw_lower\"].str.count(str_to_search).fillna(0)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[kw_var] = (hit_df[\"kw_lower\"].str.count(str_to_search).fillna(0)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[kw_var] = (hit_df[\"kw_lower\"].str.count(str_to_search).fillna(0)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[kw_var] = (hit_df[\"kw_lower\"].str.count(str_to_search).fillna(0)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[kw_var] = (hit_df[\"kw_lower\"].str.count(str_to_search).fillna(0)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[kw_var] = (hit_df[\"kw_lower\"].str.count(str_to_search).fillna(0)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[kw_var] = (hit_df[\"kw_lower\"].str.count(str_to_search).fillna(0)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[kw_var] = (hit_df[\"kw_lower\"].str.count(str_to_search).fillna(0)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[kw_var] = (hit_df[\"kw_lower\"].str.count(str_to_search).fillna(0)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[kw_var] = (hit_df[\"kw_lower\"].str.count(str_to_search).fillna(0)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[kw_var] = (hit_df[\"kw_lower\"].str.count(str_to_search).fillna(0)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[kw_var] = (hit_df[\"kw_lower\"].str.count(str_to_search).fillna(0)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[kw_var] = (hit_df[\"kw_lower\"].str.count(str_to_search).fillna(0)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[kw_var] = (hit_df[\"kw_lower\"].str.count(str_to_search).fillna(0)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[\"minutes_title\"] = hit_df[\"title_lower\"].str.extract(minutes_reg,expand=False).fillna(0).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:72: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[\"minutes_desc\"] = hit_df[\"desc_lower\"].str.extract(minutes_reg,expand=False).fillna(0).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:73: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[\"minutes_kw\"] = hit_df[\"kw_lower\"].str.extract(minutes_reg,expand=False).fillna(0).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3226286950.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df.reset_index(inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDA features merged in\n",
      "Doc2Vec features merged in\n",
      "                             group_id  duration  log_duration  reward  \\\n",
      "93770  3ZY19HV01BONLIR1KK5SXUJQHSGGS1   60950.0     11.017809    44.0   \n",
      "93771  3ZY19HV01BONLIR1KK5SXUJQHSIGS3   14720.0      9.596962    52.0   \n",
      "93772  3ZY19HV01BONLIR1KK5SXUJQIWEGS8   19640.0      9.885324    78.0   \n",
      "93773  3ZY19HV01BPM76GKCNBV9R7GD76SG1    5930.0      8.687779    10.0   \n",
      "93774  3ZY19HV01BSBSMWQ8SJ63FS1C9KSG5   32060.0     10.375364   350.0   \n",
      "\n",
      "       log_reward  meandiff_lreward  meandiff_ldur  time_allotted  first_hits  \\\n",
      "93770    3.784190          0.232745       0.775686             22           0   \n",
      "93771    3.951244          0.399799      -0.645160             26           0   \n",
      "93772    4.356709          0.805264      -0.356799             39           0   \n",
      "93773    2.302585         -0.370374       0.813040             60           0   \n",
      "93774    5.857933          0.292848      -0.045906            300           0   \n",
      "\n",
      "       last_hits  ...  doc2vec_kw_40  doc2vec_kw_41  doc2vec_kw_42  \\\n",
      "93770          0  ...       0.057277      -0.015378      -0.007566   \n",
      "93771          0  ...       0.017443      -0.010658      -0.000646   \n",
      "93772          0  ...       0.007987      -0.006276      -0.001892   \n",
      "93773          0  ...       0.046992      -0.037043      -0.037068   \n",
      "93774          0  ...       0.093032      -0.000971       0.027968   \n",
      "\n",
      "       doc2vec_kw_43  doc2vec_kw_44  doc2vec_kw_45  doc2vec_kw_46  \\\n",
      "93770      -0.017273       0.016873       0.014011      -0.060737   \n",
      "93771      -0.006335       0.012017       0.010868      -0.015269   \n",
      "93772      -0.001618       0.004430       0.010374       0.002604   \n",
      "93773      -0.033143       0.034212       0.039987      -0.030635   \n",
      "93774      -0.013535       0.063752       0.025086      -0.066204   \n",
      "\n",
      "       doc2vec_kw_47  doc2vec_kw_48  doc2vec_kw_49  \n",
      "93770      -0.027929       0.024993       0.004436  \n",
      "93771      -0.000832       0.005807      -0.006922  \n",
      "93772      -0.007765      -0.002077      -0.006186  \n",
      "93773      -0.028525       0.029824       0.042585  \n",
      "93774      -0.053561      -0.000151      -0.000190  \n",
      "\n",
      "[5 rows x 471 columns]\n",
      "avg_hitrate: 1822 nans, 0 infs\n",
      "Mean hitrate: 29.57481617676986\n",
      "Max hitrate: 81435.0\n",
      "Train rewards saved to .\\ml_input\\./train_rew_textlab_10_fullab.pkl\n",
      "Train durations saved to .\\ml_input\\./train_dur_textlab_10_fullab.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\2253851036.py:109: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_df.drop([col_name],axis=1,inplace=True)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\2253851036.py:109: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_df.drop([col_name],axis=1,inplace=True)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\2253851036.py:109: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_df.drop([col_name],axis=1,inplace=True)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\2253851036.py:109: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_df.drop([col_name],axis=1,inplace=True)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\2253851036.py:109: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_df.drop([col_name],axis=1,inplace=True)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\2253851036.py:109: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_df.drop([col_name],axis=1,inplace=True)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\2253851036.py:109: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_df.drop([col_name],axis=1,inplace=True)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\2253851036.py:136: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df.drop([col_name],axis=1,inplace=True)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\2253851036.py:136: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df.drop([col_name],axis=1,inplace=True)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\2253851036.py:136: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df.drop([col_name],axis=1,inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train features saved to .\\ml_input\\./train_feats_textlab_10_fullab.pkl\n",
      "Training data saved\n",
      "Test rewards saved to .\\ml_input\\./test_rew_textlab_10_fullab.pkl\n",
      "Test durations saved to .\\ml_input\\./test_dur_textlab_10_fullab.pkl\n",
      "Test features saved to .\\ml_input\\./test_feats_textlab_10_fullab.pkl\n",
      "Test data saved\n",
      "Training data dimensions: (46887, 314)\n",
      "Test data dimensions: (46888, 314)\n",
      "Training data loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\2253851036.py:136: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df.drop([col_name],axis=1,inplace=True)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\2253851036.py:136: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df.drop([col_name],axis=1,inplace=True)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\2253851036.py:136: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df.drop([col_name],axis=1,inplace=True)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\2253851036.py:136: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df.drop([col_name],axis=1,inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data loaded\n",
      "----- [Running *reward* ML with numeric features] -----\n",
      "Running textlab_10_fullab_rew\n",
      "building tree 1 of 600\n",
      "building tree 2 of 600\n",
      "building tree 3 of 600\n",
      "building tree 4 of 600\n",
      "building tree 5 of 600\n",
      "building tree 6 of 600\n",
      "building tree 7 of 600\n",
      "building tree 8 of 600\n",
      "building tree 9 of 600\n",
      "building tree 10 of 600\n",
      "building tree 11 of 600\n",
      "building tree 12 of 600\n",
      "building tree 13 of 600\n",
      "building tree 14 of 600\n",
      "building tree 15 of 600\n",
      "building tree 16 of 600\n",
      "building tree 17 of 600\n",
      "building tree 18 of 600\n",
      "building tree 19 of 600\n",
      "building tree 20 of 600\n",
      "building tree 21 of 600\n",
      "building tree 22 of 600\n",
      "building tree 23 of 600\n",
      "building tree 24 of 600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 24 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 25 of 600\n",
      "building tree 26 of 600\n",
      "building tree 27 of 600\n",
      "building tree 28 of 600\n",
      "building tree 29 of 600\n",
      "building tree 30 of 600\n",
      "building tree 31 of 600\n",
      "building tree 32 of 600\n",
      "building tree 33 of 600\n",
      "building tree 34 of 600\n",
      "building tree 35 of 600\n",
      "building tree 36 of 600\n",
      "building tree 37 of 600\n",
      "building tree 38 of 600\n",
      "building tree 39 of 600\n",
      "building tree 40 of 600\n",
      "building tree 41 of 600\n",
      "building tree 42 of 600\n",
      "building tree 43 of 600\n",
      "building tree 44 of 600\n",
      "building tree 45 of 600\n",
      "building tree 46 of 600\n",
      "building tree 47 of 600\n",
      "building tree 48 of 600\n",
      "building tree 49 of 600\n",
      "building tree 50 of 600\n",
      "building tree 51 of 600\n",
      "building tree 52 of 600\n",
      "building tree 53 of 600\n",
      "building tree 54 of 600\n",
      "building tree 55 of 600\n",
      "building tree 56 of 600\n",
      "building tree 57 of 600\n",
      "building tree 58 of 600\n",
      "building tree 59 of 600\n",
      "building tree 60 of 600\n",
      "building tree 61 of 600\n",
      "building tree 62 of 600\n",
      "building tree 63 of 600\n",
      "building tree 64 of 600\n",
      "building tree 65 of 600\n",
      "building tree 66 of 600\n",
      "building tree 67 of 600\n",
      "building tree 68 of 600\n",
      "building tree 69 of 600\n",
      "building tree 70 of 600\n",
      "building tree 71 of 600\n",
      "building tree 72 of 600\n",
      "building tree 73 of 600\n",
      "building tree 74 of 600\n",
      "building tree 75 of 600\n",
      "building tree 76 of 600\n",
      "building tree 77 of 600\n",
      "building tree 78 of 600\n",
      "building tree 79 of 600\n",
      "building tree 80 of 600\n",
      "building tree 81 of 600\n",
      "building tree 82 of 600\n",
      "building tree 83 of 600\n",
      "building tree 84 of 600\n",
      "building tree 85 of 600\n",
      "building tree 86 of 600\n",
      "building tree 87 of 600\n",
      "building tree 88 of 600\n",
      "building tree 89 of 600\n",
      "building tree 90 of 600\n",
      "building tree 91 of 600\n",
      "building tree 92 of 600\n",
      "building tree 93 of 600\n",
      "building tree 94 of 600\n",
      "building tree 95 of 600\n",
      "building tree 96 of 600\n",
      "building tree 97 of 600\n",
      "building tree 98 of 600\n",
      "building tree 99 of 600\n",
      "building tree 100 of 600\n",
      "building tree 101 of 600\n",
      "building tree 102 of 600\n",
      "building tree 103 of 600\n",
      "building tree 104 of 600\n",
      "building tree 105 of 600\n",
      "building tree 106 of 600\n",
      "building tree 107 of 600\n",
      "building tree 108 of 600\n",
      "building tree 109 of 600\n",
      "building tree 110 of 600\n",
      "building tree 111 of 600\n",
      "building tree 112 of 600\n",
      "building tree 113 of 600\n",
      "building tree 114 of 600\n",
      "building tree 115 of 600\n",
      "building tree 116 of 600\n",
      "building tree 117 of 600\n",
      "building tree 118 of 600\n",
      "building tree 119 of 600\n",
      "building tree 120 of 600\n",
      "building tree 121 of 600\n",
      "building tree 122 of 600\n",
      "building tree 123 of 600\n",
      "building tree 124 of 600\n",
      "building tree 125 of 600\n",
      "building tree 126 of 600\n",
      "building tree 127 of 600\n",
      "building tree 128 of 600\n",
      "building tree 129 of 600\n",
      "building tree 130 of 600\n",
      "building tree 131 of 600\n",
      "building tree 132 of 600\n",
      "building tree 133 of 600\n",
      "building tree 134 of 600\n",
      "building tree 135 of 600\n",
      "building tree 136 of 600\n",
      "building tree 137 of 600\n",
      "building tree 138 of 600\n",
      "building tree 139 of 600\n",
      "building tree 140 of 600\n",
      "building tree 141 of 600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 114 tasks      | elapsed:    2.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 142 of 600\n",
      "building tree 143 of 600\n",
      "building tree 144 of 600\n",
      "building tree 145 of 600\n",
      "building tree 146 of 600\n",
      "building tree 147 of 600\n",
      "building tree 148 of 600\n",
      "building tree 149 of 600\n",
      "building tree 150 of 600\n",
      "building tree 151 of 600\n",
      "building tree 152 of 600\n",
      "building tree 153 of 600\n",
      "building tree 154 of 600\n",
      "building tree 155 of 600\n",
      "building tree 156 of 600\n",
      "building tree 157 of 600\n",
      "building tree 158 of 600\n",
      "building tree 159 of 600\n",
      "building tree 160 of 600\n",
      "building tree 161 of 600\n",
      "building tree 162 of 600\n",
      "building tree 163 of 600\n",
      "building tree 164 of 600\n",
      "building tree 165 of 600\n",
      "building tree 166 of 600\n",
      "building tree 167 of 600\n",
      "building tree 168 of 600\n",
      "building tree 169 of 600\n",
      "building tree 170 of 600\n",
      "building tree 171 of 600\n",
      "building tree 172 of 600\n",
      "building tree 173 of 600\n",
      "building tree 174 of 600\n",
      "building tree 175 of 600\n",
      "building tree 176 of 600\n",
      "building tree 177 of 600\n",
      "building tree 178 of 600\n",
      "building tree 179 of 600\n",
      "building tree 180 of 600\n",
      "building tree 181 of 600\n",
      "building tree 182 of 600\n",
      "building tree 183 of 600\n",
      "building tree 184 of 600\n",
      "building tree 185 of 600\n",
      "building tree 186 of 600\n",
      "building tree 187 of 600\n",
      "building tree 188 of 600\n",
      "building tree 189 of 600\n",
      "building tree 190 of 600\n",
      "building tree 191 of 600\n",
      "building tree 192 of 600\n",
      "building tree 193 of 600\n",
      "building tree 194 of 600\n",
      "building tree 195 of 600\n",
      "building tree 196 of 600\n",
      "building tree 197 of 600\n",
      "building tree 198 of 600\n",
      "building tree 199 of 600\n",
      "building tree 200 of 600\n",
      "building tree 201 of 600\n",
      "building tree 202 of 600\n",
      "building tree 203 of 600\n",
      "building tree 204 of 600\n",
      "building tree 205 of 600\n",
      "building tree 206 of 600\n",
      "building tree 207 of 600\n",
      "building tree 208 of 600\n",
      "building tree 209 of 600\n",
      "building tree 210 of 600\n",
      "building tree 211 of 600\n",
      "building tree 212 of 600\n",
      "building tree 213 of 600\n",
      "building tree 214 of 600\n",
      "building tree 215 of 600\n",
      "building tree 216 of 600\n",
      "building tree 217 of 600\n",
      "building tree 218 of 600\n",
      "building tree 219 of 600\n",
      "building tree 220 of 600\n",
      "building tree 221 of 600\n",
      "building tree 222 of 600\n",
      "building tree 223 of 600\n",
      "building tree 224 of 600\n",
      "building tree 225 of 600\n",
      "building tree 226 of 600\n",
      "building tree 227 of 600\n",
      "building tree 228 of 600\n",
      "building tree 229 of 600\n",
      "building tree 230 of 600\n",
      "building tree 231 of 600\n",
      "building tree 232 of 600\n",
      "building tree 233 of 600\n",
      "building tree 234 of 600\n",
      "building tree 235 of 600\n",
      "building tree 236 of 600\n",
      "building tree 237 of 600\n",
      "building tree 238 of 600\n",
      "building tree 239 of 600\n",
      "building tree 240 of 600\n",
      "building tree 241 of 600\n",
      "building tree 242 of 600\n",
      "building tree 243 of 600\n",
      "building tree 244 of 600\n",
      "building tree 245 of 600\n",
      "building tree 246 of 600\n",
      "building tree 247 of 600\n",
      "building tree 248 of 600\n",
      "building tree 249 of 600\n",
      "building tree 250 of 600\n",
      "building tree 251 of 600\n",
      "building tree 252 of 600\n",
      "building tree 253 of 600\n",
      "building tree 254 of 600\n",
      "building tree 255 of 600\n",
      "building tree 256 of 600\n",
      "building tree 257 of 600\n",
      "building tree 258 of 600\n",
      "building tree 259 of 600\n",
      "building tree 260 of 600\n",
      "building tree 261 of 600\n",
      "building tree 262 of 600\n",
      "building tree 263 of 600\n",
      "building tree 264 of 600\n",
      "building tree 265 of 600\n",
      "building tree 266 of 600\n",
      "building tree 267 of 600\n",
      "building tree 268 of 600\n",
      "building tree 269 of 600\n",
      "building tree 270 of 600\n",
      "building tree 271 of 600\n",
      "building tree 272 of 600\n",
      "building tree 273 of 600\n",
      "building tree 274 of 600\n",
      "building tree 275 of 600\n",
      "building tree 276 of 600\n",
      "building tree 277 of 600\n",
      "building tree 278 of 600\n",
      "building tree 279 of 600\n",
      "building tree 280 of 600\n",
      "building tree 281 of 600\n",
      "building tree 282 of 600\n",
      "building tree 283 of 600\n",
      "building tree 284 of 600\n",
      "building tree 285 of 600\n",
      "building tree 286 of 600\n",
      "building tree 287 of 600\n",
      "building tree 288 of 600\n",
      "building tree 289 of 600\n",
      "building tree 290 of 600\n",
      "building tree 291 of 600\n",
      "building tree 292 of 600\n",
      "building tree 293 of 600\n",
      "building tree 294 of 600\n",
      "building tree 295 of 600\n",
      "building tree 296 of 600\n",
      "building tree 297 of 600\n",
      "building tree 298 of 600\n",
      "building tree 299 of 600\n",
      "building tree 300 of 600\n",
      "building tree 301 of 600\n",
      "building tree 302 of 600\n",
      "building tree 303 of 600\n",
      "building tree 304 of 600\n",
      "building tree 305 of 600\n",
      "building tree 306 of 600\n",
      "building tree 307 of 600\n",
      "building tree 308 of 600\n",
      "building tree 309 of 600\n",
      "building tree 310 of 600\n",
      "building tree 311 of 600\n",
      "building tree 312 of 600\n",
      "building tree 313 of 600\n",
      "building tree 314 of 600\n",
      "building tree 315 of 600\n",
      "building tree 316 of 600\n",
      "building tree 317 of 600\n",
      "building tree 318 of 600\n",
      "building tree 319 of 600\n",
      "building tree 320 of 600\n",
      "building tree 321 of 600\n",
      "building tree 322 of 600\n",
      "building tree 323 of 600\n",
      "building tree 324 of 600\n",
      "building tree 325 of 600\n",
      "building tree 326 of 600\n",
      "building tree 327 of 600\n",
      "building tree 328 of 600\n",
      "building tree 329 of 600\n",
      "building tree 330 of 600\n",
      "building tree 331 of 600\n",
      "building tree 332 of 600\n",
      "building tree 333 of 600\n",
      "building tree 334 of 600\n",
      "building tree 335 of 600\n",
      "building tree 336 of 600\n",
      "building tree 337 of 600\n",
      "building tree 338 of 600\n",
      "building tree 339 of 600\n",
      "building tree 340 of 600\n",
      "building tree 341 of 600\n",
      "building tree 342 of 600\n",
      "building tree 343 of 600\n",
      "building tree 344 of 600\n",
      "building tree 345 of 600\n",
      "building tree 346 of 600\n",
      "building tree 347 of 600\n",
      "building tree 348 of 600\n",
      "building tree 349 of 600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 317 tasks      | elapsed:    7.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 350 of 600\n",
      "building tree 351 of 600\n",
      "building tree 352 of 600\n",
      "building tree 353 of 600\n",
      "building tree 354 of 600\n",
      "building tree 355 of 600\n",
      "building tree 356 of 600\n",
      "building tree 357 of 600\n",
      "building tree 358 of 600\n",
      "building tree 359 of 600\n",
      "building tree 360 of 600\n",
      "building tree 361 of 600\n",
      "building tree 362 of 600\n",
      "building tree 363 of 600\n",
      "building tree 364 of 600\n",
      "building tree 365 of 600\n",
      "building tree 366 of 600\n",
      "building tree 367 of 600\n",
      "building tree 368 of 600\n",
      "building tree 369 of 600\n",
      "building tree 370 of 600\n",
      "building tree 371 of 600\n",
      "building tree 372 of 600\n",
      "building tree 373 of 600\n",
      "building tree 374 of 600\n",
      "building tree 375 of 600\n",
      "building tree 376 of 600\n",
      "building tree 377 of 600\n",
      "building tree 378 of 600\n",
      "building tree 379 of 600\n",
      "building tree 380 of 600\n",
      "building tree 381 of 600\n",
      "building tree 382 of 600\n",
      "building tree 383 of 600\n",
      "building tree 384 of 600\n",
      "building tree 385 of 600\n",
      "building tree 386 of 600\n",
      "building tree 387 of 600\n",
      "building tree 388 of 600\n",
      "building tree 389 of 600\n",
      "building tree 390 of 600\n",
      "building tree 391 of 600\n",
      "building tree 392 of 600\n",
      "building tree 393 of 600\n",
      "building tree 394 of 600\n",
      "building tree 395 of 600\n",
      "building tree 396 of 600\n",
      "building tree 397 of 600\n",
      "building tree 398 of 600\n",
      "building tree 399 of 600\n",
      "building tree 400 of 600\n",
      "building tree 401 of 600\n",
      "building tree 402 of 600\n",
      "building tree 403 of 600\n",
      "building tree 404 of 600\n",
      "building tree 405 of 600\n",
      "building tree 406 of 600\n",
      "building tree 407 of 600\n",
      "building tree 408 of 600\n",
      "building tree 409 of 600\n",
      "building tree 410 of 600\n",
      "building tree 411 of 600\n",
      "building tree 412 of 600\n",
      "building tree 413 of 600\n",
      "building tree 414 of 600\n",
      "building tree 415 of 600\n",
      "building tree 416 of 600\n",
      "building tree 417 of 600\n",
      "building tree 418 of 600\n",
      "building tree 419 of 600\n",
      "building tree 420 of 600\n",
      "building tree 421 of 600\n",
      "building tree 422 of 600\n",
      "building tree 423 of 600\n",
      "building tree 424 of 600\n",
      "building tree 425 of 600\n",
      "building tree 426 of 600\n",
      "building tree 427 of 600\n",
      "building tree 428 of 600\n",
      "building tree 429 of 600\n",
      "building tree 430 of 600\n",
      "building tree 431 of 600\n",
      "building tree 432 of 600\n",
      "building tree 433 of 600\n",
      "building tree 434 of 600\n",
      "building tree 435 of 600\n",
      "building tree 436 of 600\n",
      "building tree 437 of 600\n",
      "building tree 438 of 600\n",
      "building tree 439 of 600\n",
      "building tree 440 of 600\n",
      "building tree 441 of 600\n",
      "building tree 442 of 600\n",
      "building tree 443 of 600\n",
      "building tree 444 of 600\n",
      "building tree 445 of 600\n",
      "building tree 446 of 600\n",
      "building tree 447 of 600\n",
      "building tree 448 of 600\n",
      "building tree 449 of 600\n",
      "building tree 450 of 600\n",
      "building tree 451 of 600\n",
      "building tree 452 of 600\n",
      "building tree 453 of 600\n",
      "building tree 454 of 600\n",
      "building tree 455 of 600\n",
      "building tree 456 of 600\n",
      "building tree 457 of 600\n",
      "building tree 458 of 600\n",
      "building tree 459 of 600\n",
      "building tree 460 of 600\n",
      "building tree 461 of 600\n",
      "building tree 462 of 600\n",
      "building tree 463 of 600\n",
      "building tree 464 of 600\n",
      "building tree 465 of 600\n",
      "building tree 466 of 600\n",
      "building tree 467 of 600\n",
      "building tree 468 of 600\n",
      "building tree 469 of 600\n",
      "building tree 470 of 600\n",
      "building tree 471 of 600\n",
      "building tree 472 of 600\n",
      "building tree 473 of 600\n",
      "building tree 474 of 600\n",
      "building tree 475 of 600\n",
      "building tree 476 of 600\n",
      "building tree 477 of 600\n",
      "building tree 478 of 600\n",
      "building tree 479 of 600\n",
      "building tree 480 of 600\n",
      "building tree 481 of 600\n",
      "building tree 482 of 600\n",
      "building tree 483 of 600\n",
      "building tree 484 of 600\n",
      "building tree 485 of 600\n",
      "building tree 486 of 600\n",
      "building tree 487 of 600\n",
      "building tree 488 of 600\n",
      "building tree 489 of 600\n",
      "building tree 490 of 600\n",
      "building tree 491 of 600\n",
      "building tree 492 of 600\n",
      "building tree 493 of 600\n",
      "building tree 494 of 600\n",
      "building tree 495 of 600\n",
      "building tree 496 of 600\n",
      "building tree 497 of 600\n",
      "building tree 498 of 600\n",
      "building tree 499 of 600\n",
      "building tree 500 of 600\n",
      "building tree 501 of 600\n",
      "building tree 502 of 600\n",
      "building tree 503 of 600\n",
      "building tree 504 of 600\n",
      "building tree 505 of 600\n",
      "building tree 506 of 600\n",
      "building tree 507 of 600\n",
      "building tree 508 of 600\n",
      "building tree 509 of 600\n",
      "building tree 510 of 600\n",
      "building tree 511 of 600\n",
      "building tree 512 of 600\n",
      "building tree 513 of 600\n",
      "building tree 514 of 600\n",
      "building tree 515 of 600\n",
      "building tree 516 of 600\n",
      "building tree 517 of 600\n",
      "building tree 518 of 600\n",
      "building tree 519 of 600\n",
      "building tree 520 of 600\n",
      "building tree 521 of 600\n",
      "building tree 522 of 600\n",
      "building tree 523 of 600\n",
      "building tree 524 of 600\n",
      "building tree 525 of 600\n",
      "building tree 526 of 600\n",
      "building tree 527 of 600\n",
      "building tree 528 of 600\n",
      "building tree 529 of 600\n",
      "building tree 530 of 600\n",
      "building tree 531 of 600\n",
      "building tree 532 of 600\n",
      "building tree 533 of 600\n",
      "building tree 534 of 600\n",
      "building tree 535 of 600\n",
      "building tree 536 of 600\n",
      "building tree 537 of 600\n",
      "building tree 538 of 600\n",
      "building tree 539 of 600\n",
      "building tree 540 of 600\n",
      "building tree 541 of 600\n",
      "building tree 542 of 600\n",
      "building tree 543 of 600\n",
      "building tree 544 of 600\n",
      "building tree 545 of 600\n",
      "building tree 546 of 600\n",
      "building tree 547 of 600\n",
      "building tree 548 of 600\n",
      "building tree 549 of 600\n",
      "building tree 550 of 600\n",
      "building tree 551 of 600\n",
      "building tree 552 of 600\n",
      "building tree 553 of 600\n",
      "building tree 554 of 600\n",
      "building tree 555 of 600\n",
      "building tree 556 of 600\n",
      "building tree 557 of 600\n",
      "building tree 558 of 600\n",
      "building tree 559 of 600\n",
      "building tree 560 of 600\n",
      "building tree 561 of 600\n",
      "building tree 562 of 600\n",
      "building tree 563 of 600\n",
      "building tree 564 of 600\n",
      "building tree 565 of 600\n",
      "building tree 566 of 600\n",
      "building tree 567 of 600\n",
      "building tree 568 of 600\n",
      "building tree 569 of 600\n",
      "building tree 570 of 600\n",
      "building tree 571 of 600\n",
      "building tree 572 of 600\n",
      "building tree 573 of 600\n",
      "building tree 574 of 600\n",
      "building tree 575 of 600\n",
      "building tree 576 of 600\n",
      "building tree 577 of 600\n",
      "building tree 578 of 600\n",
      "building tree 579 of 600\n",
      "building tree 580 of 600\n",
      "building tree 581 of 600\n",
      "building tree 582 of 600\n",
      "building tree 583 of 600\n",
      "building tree 584 of 600\n",
      "building tree 585 of 600\n",
      "building tree 586 of 600\n",
      "building tree 587 of 600\n",
      "building tree 588 of 600\n",
      "building tree 589 of 600\n",
      "building tree 590 of 600\n",
      "building tree 591 of 600\n",
      "building tree 592 of 600\n",
      "building tree 593 of 600\n",
      "building tree 594 of 600\n",
      "building tree 595 of 600\n",
      "building tree 596 of 600\n",
      "building tree 597 of 600\n",
      "building tree 598 of 600\n",
      "building tree 599 of 600\n",
      "building tree 600 of 600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 600 out of 600 | elapsed:   14.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "textlab_10_fullab_rew fit complete\n",
      "Fitted model saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=24)]: Using backend ThreadingBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=24)]: Done 114 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=24)]: Done 317 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=24)]: Done 600 out of 600 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=24)]: Using backend ThreadingBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=24)]: Done 114 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=24)]: Done 317 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=24)]: Done 600 out of 600 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 24 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitAndPredict: 25.128639698028564 seconds\n",
      "0.8986011617442209\n",
      "----- [Running *duration* ML with numeric features] -----\n",
      "Running textlab_10_fullab_dur\n",
      "building tree 1 of 600\n",
      "building tree 2 of 600\n",
      "building tree 3 of 600\n",
      "building tree 4 of 600\n",
      "building tree 5 of 600\n",
      "building tree 6 of 600\n",
      "building tree 7 of 600\n",
      "building tree 8 of 600\n",
      "building tree 9 of 600\n",
      "building tree 10 of 600\n",
      "building tree 11 of 600\n",
      "building tree 12 of 600\n",
      "building tree 13 of 600\n",
      "building tree 14 of 600\n",
      "building tree 15 of 600\n",
      "building tree 16 of 600\n",
      "building tree 17 of 600\n",
      "building tree 18 of 600\n",
      "building tree 19 of 600\n",
      "building tree 20 of 600\n",
      "building tree 21 of 600\n",
      "building tree 22 of 600\n",
      "building tree 23 of 600\n",
      "building tree 24 of 600\n",
      "building tree 25 of 600\n",
      "building tree 26 of 600\n",
      "building tree 27 of 600\n",
      "building tree 28 of 600\n",
      "building tree 29 of 600\n",
      "building tree 30 of 600\n",
      "building tree 31 of 600\n",
      "building tree 32 of 600\n",
      "building tree 33 of 600\n",
      "building tree 34 of 600\n",
      "building tree 35 of 600\n",
      "building tree 36 of 600\n",
      "building tree 37 of 600\n",
      "building tree 38 of 600\n",
      "building tree 39 of 600\n",
      "building tree 40 of 600\n",
      "building tree 41 of 600\n",
      "building tree 42 of 600\n",
      "building tree 43 of 600\n",
      "building tree 44 of 600\n",
      "building tree 45 of 600\n",
      "building tree 46 of 600\n",
      "building tree 47 of 600\n",
      "building tree 48 of 600\n",
      "building tree 49 of 600building tree 50 of 600\n",
      "\n",
      "building tree 51 of 600\n",
      "building tree 52 of 600\n",
      "building tree 53 of 600\n",
      "building tree 54 of 600\n",
      "building tree 55 of 600\n",
      "building tree 56 of 600\n",
      "building tree 57 of 600\n",
      "building tree 58 of 600\n",
      "building tree 59 of 600\n",
      "building tree 60 of 600\n",
      "building tree 61 of 600\n",
      "building tree 62 of 600\n",
      "building tree 63 of 600\n",
      "building tree 64 of 600\n",
      "building tree 65 of 600\n",
      "building tree 66 of 600\n",
      "building tree 67 of 600\n",
      "building tree 68 of 600\n",
      "building tree 69 of 600\n",
      "building tree 70 of 600\n",
      "building tree 71 of 600\n",
      "building tree 72 of 600\n",
      "building tree 73 of 600building tree 74 of 600\n",
      "\n",
      "building tree 75 of 600\n",
      "building tree 76 of 600\n",
      "building tree 77 of 600\n",
      "building tree 78 of 600\n",
      "building tree 79 of 600\n",
      "building tree 80 of 600\n",
      "building tree 81 of 600\n",
      "building tree 82 of 600\n",
      "building tree 83 of 600\n",
      "building tree 84 of 600\n",
      "building tree 85 of 600\n",
      "building tree 86 of 600\n",
      "building tree 87 of 600\n",
      "building tree 88 of 600\n",
      "building tree 89 of 600\n",
      "building tree 90 of 600\n",
      "building tree 91 of 600\n",
      "building tree 92 of 600\n",
      "building tree 93 of 600\n",
      "building tree 94 of 600\n",
      "building tree 95 of 600\n",
      "building tree 96 of 600\n",
      "building tree 97 of 600\n",
      "building tree 98 of 600\n",
      "building tree 99 of 600\n",
      "building tree 100 of 600\n",
      "building tree 101 of 600\n",
      "building tree 102 of 600\n",
      "building tree 103 of 600\n",
      "building tree 104 of 600\n",
      "building tree 105 of 600\n",
      "building tree 106 of 600\n",
      "building tree 107 of 600\n",
      "building tree 108 of 600\n",
      "building tree 109 of 600\n",
      "building tree 110 of 600\n",
      "building tree 111 of 600building tree 112 of 600\n",
      "\n",
      "building tree 113 of 600\n",
      "building tree 114 of 600\n",
      "building tree 115 of 600\n",
      "building tree 116 of 600\n",
      "building tree 117 of 600\n",
      "building tree 118 of 600\n",
      "building tree 119 of 600\n",
      "building tree 120 of 600\n",
      "building tree 121 of 600\n",
      "building tree 122 of 600\n",
      "building tree 123 of 600\n",
      "building tree 124 of 600\n",
      "building tree 125 of 600\n",
      "building tree 126 of 600\n",
      "building tree 127 of 600\n",
      "building tree 128 of 600\n",
      "building tree 129 of 600\n",
      "building tree 130 of 600\n",
      "building tree 131 of 600\n",
      "building tree 132 of 600\n",
      "building tree 133 of 600\n",
      "building tree 134 of 600\n",
      "building tree 135 of 600\n",
      "building tree 136 of 600\n",
      "building tree 137 of 600\n",
      "building tree 138 of 600\n",
      "building tree 139 of 600\n",
      "building tree 140 of 600\n",
      "building tree 141 of 600\n",
      "building tree 142 of 600\n",
      "building tree 143 of 600\n",
      "building tree 144 of 600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 114 tasks      | elapsed:    2.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 145 of 600\n",
      "building tree 146 of 600\n",
      "building tree 147 of 600\n",
      "building tree 148 of 600\n",
      "building tree 149 of 600\n",
      "building tree 150 of 600\n",
      "building tree 151 of 600\n",
      "building tree 152 of 600\n",
      "building tree 153 of 600\n",
      "building tree 154 of 600\n",
      "building tree 155 of 600\n",
      "building tree 156 of 600\n",
      "building tree 157 of 600\n",
      "building tree 158 of 600\n",
      "building tree 159 of 600\n",
      "building tree 160 of 600\n",
      "building tree 161 of 600\n",
      "building tree 162 of 600\n",
      "building tree 163 of 600\n",
      "building tree 164 of 600\n",
      "building tree 165 of 600\n",
      "building tree 166 of 600\n",
      "building tree 167 of 600\n",
      "building tree 168 of 600\n",
      "building tree 169 of 600\n",
      "building tree 170 of 600\n",
      "building tree 171 of 600\n",
      "building tree 172 of 600\n",
      "building tree 173 of 600\n",
      "building tree 174 of 600\n",
      "building tree 175 of 600\n",
      "building tree 176 of 600\n",
      "building tree 177 of 600\n",
      "building tree 178 of 600\n",
      "building tree 179 of 600\n",
      "building tree 180 of 600\n",
      "building tree 181 of 600\n",
      "building tree 182 of 600\n",
      "building tree 183 of 600\n",
      "building tree 184 of 600\n",
      "building tree 185 of 600\n",
      "building tree 186 of 600\n",
      "building tree 187 of 600\n",
      "building tree 188 of 600\n",
      "building tree 189 of 600\n",
      "building tree 190 of 600\n",
      "building tree 191 of 600\n",
      "building tree 192 of 600\n",
      "building tree 193 of 600\n",
      "building tree 194 of 600\n",
      "building tree 195 of 600\n",
      "building tree 196 of 600\n",
      "building tree 197 of 600\n",
      "building tree 198 of 600\n",
      "building tree 199 of 600\n",
      "building tree 200 of 600\n",
      "building tree 201 of 600\n",
      "building tree 202 of 600\n",
      "building tree 203 of 600\n",
      "building tree 204 of 600\n",
      "building tree 205 of 600\n",
      "building tree 206 of 600\n",
      "building tree 207 of 600\n",
      "building tree 208 of 600\n",
      "building tree 209 of 600\n",
      "building tree 210 of 600\n",
      "building tree 211 of 600\n",
      "building tree 212 of 600\n",
      "building tree 213 of 600\n",
      "building tree 214 of 600\n",
      "building tree 215 of 600\n",
      "building tree 216 of 600\n",
      "building tree 217 of 600\n",
      "building tree 218 of 600\n",
      "building tree 219 of 600\n",
      "building tree 220 of 600\n",
      "building tree 221 of 600\n",
      "building tree 222 of 600\n",
      "building tree 223 of 600\n",
      "building tree 224 of 600\n",
      "building tree 225 of 600\n",
      "building tree 226 of 600\n",
      "building tree 227 of 600\n",
      "building tree 228 of 600building tree 229 of 600\n",
      "building tree 230 of 600\n",
      "\n",
      "building tree 231 of 600\n",
      "building tree 232 of 600\n",
      "building tree 233 of 600\n",
      "building tree 234 of 600\n",
      "building tree 235 of 600\n",
      "building tree 236 of 600\n",
      "building tree 237 of 600\n",
      "building tree 238 of 600\n",
      "building tree 239 of 600\n",
      "building tree 240 of 600\n",
      "building tree 241 of 600\n",
      "building tree 242 of 600\n",
      "building tree 243 of 600\n",
      "building tree 244 of 600\n",
      "building tree 245 of 600\n",
      "building tree 246 of 600\n",
      "building tree 247 of 600\n",
      "building tree 248 of 600\n",
      "building tree 249 of 600\n",
      "building tree 250 of 600\n",
      "building tree 251 of 600\n",
      "building tree 252 of 600\n",
      "building tree 253 of 600\n",
      "building tree 254 of 600\n",
      "building tree 255 of 600\n",
      "building tree 256 of 600\n",
      "building tree 257 of 600\n",
      "building tree 258 of 600\n",
      "building tree 259 of 600\n",
      "building tree 260 of 600\n",
      "building tree 261 of 600\n",
      "building tree 262 of 600\n",
      "building tree 263 of 600\n",
      "building tree 264 of 600\n",
      "building tree 265 of 600\n",
      "building tree 266 of 600\n",
      "building tree 267 of 600\n",
      "building tree 268 of 600\n",
      "building tree 269 of 600\n",
      "building tree 270 of 600\n",
      "building tree 271 of 600\n",
      "building tree 272 of 600\n",
      "building tree 273 of 600\n",
      "building tree 274 of 600\n",
      "building tree 275 of 600\n",
      "building tree 276 of 600\n",
      "building tree 277 of 600\n",
      "building tree 278 of 600\n",
      "building tree 279 of 600\n",
      "building tree 280 of 600\n",
      "building tree 281 of 600\n",
      "building tree 282 of 600\n",
      "building tree 283 of 600\n",
      "building tree 284 of 600\n",
      "building tree 285 of 600\n",
      "building tree 286 of 600\n",
      "building tree 287 of 600\n",
      "building tree 288 of 600\n",
      "building tree 289 of 600\n",
      "building tree 290 of 600\n",
      "building tree 291 of 600\n",
      "building tree 292 of 600\n",
      "building tree 293 of 600\n",
      "building tree 294 of 600\n",
      "building tree 295 of 600\n",
      "building tree 296 of 600\n",
      "building tree 297 of 600\n",
      "building tree 298 of 600\n",
      "building tree 299 of 600\n",
      "building tree 300 of 600\n",
      "building tree 301 of 600\n",
      "building tree 302 of 600\n",
      "building tree 303 of 600\n",
      "building tree 304 of 600\n",
      "building tree 305 of 600\n",
      "building tree 306 of 600\n",
      "building tree 307 of 600\n",
      "building tree 308 of 600\n",
      "building tree 309 of 600building tree 310 of 600\n",
      "building tree 311 of 600\n",
      "\n",
      "building tree 312 of 600\n",
      "building tree 313 of 600\n",
      "building tree 314 of 600\n",
      "building tree 315 of 600\n",
      "building tree 316 of 600\n",
      "building tree 317 of 600\n",
      "building tree 318 of 600\n",
      "building tree 319 of 600\n",
      "building tree 320 of 600\n",
      "building tree 321 of 600\n",
      "building tree 322 of 600\n",
      "building tree 323 of 600\n",
      "building tree 324 of 600\n",
      "building tree 325 of 600\n",
      "building tree 326 of 600\n",
      "building tree 327 of 600\n",
      "building tree 328 of 600\n",
      "building tree 329 of 600\n",
      "building tree 330 of 600\n",
      "building tree 331 of 600\n",
      "building tree 332 of 600\n",
      "building tree 333 of 600\n",
      "building tree 334 of 600\n",
      "building tree 335 of 600\n",
      "building tree 336 of 600\n",
      "building tree 337 of 600\n",
      "building tree 338 of 600\n",
      "building tree 339 of 600\n",
      "building tree 340 of 600\n",
      "building tree 341 of 600\n",
      "building tree 342 of 600\n",
      "building tree 343 of 600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 317 tasks      | elapsed:    7.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 344 of 600building tree 345 of 600\n",
      "\n",
      "building tree 346 of 600\n",
      "building tree 347 of 600\n",
      "building tree 348 of 600\n",
      "building tree 349 of 600\n",
      "building tree 350 of 600\n",
      "building tree 351 of 600\n",
      "building tree 352 of 600\n",
      "building tree 353 of 600\n",
      "building tree 354 of 600\n",
      "building tree 355 of 600\n",
      "building tree 356 of 600\n",
      "building tree 357 of 600\n",
      "building tree 358 of 600\n",
      "building tree 359 of 600\n",
      "building tree 360 of 600\n",
      "building tree 361 of 600\n",
      "building tree 362 of 600\n",
      "building tree 363 of 600\n",
      "building tree 364 of 600\n",
      "building tree 365 of 600\n",
      "building tree 366 of 600\n",
      "building tree 367 of 600\n",
      "building tree 368 of 600\n",
      "building tree 369 of 600\n",
      "building tree 370 of 600\n",
      "building tree 371 of 600\n",
      "building tree 372 of 600\n",
      "building tree 373 of 600\n",
      "building tree 374 of 600\n",
      "building tree 375 of 600\n",
      "building tree 376 of 600\n",
      "building tree 377 of 600\n",
      "building tree 378 of 600\n",
      "building tree 379 of 600\n",
      "building tree 380 of 600\n",
      "building tree 381 of 600\n",
      "building tree 382 of 600\n",
      "building tree 383 of 600\n",
      "building tree 384 of 600\n",
      "building tree 385 of 600\n",
      "building tree 386 of 600\n",
      "building tree 387 of 600\n",
      "building tree 388 of 600\n",
      "building tree 389 of 600\n",
      "building tree 390 of 600\n",
      "building tree 391 of 600\n",
      "building tree 392 of 600\n",
      "building tree 393 of 600\n",
      "building tree 394 of 600\n",
      "building tree 395 of 600\n",
      "building tree 396 of 600\n",
      "building tree 397 of 600\n",
      "building tree 398 of 600\n",
      "building tree 399 of 600\n",
      "building tree 400 of 600\n",
      "building tree 401 of 600\n",
      "building tree 402 of 600\n",
      "building tree 403 of 600\n",
      "building tree 404 of 600\n",
      "building tree 405 of 600\n",
      "building tree 406 of 600\n",
      "building tree 407 of 600\n",
      "building tree 408 of 600\n",
      "building tree 409 of 600\n",
      "building tree 410 of 600\n",
      "building tree 411 of 600\n",
      "building tree 412 of 600\n",
      "building tree 413 of 600\n",
      "building tree 414 of 600\n",
      "building tree 415 of 600\n",
      "building tree 416 of 600\n",
      "building tree 417 of 600\n",
      "building tree 418 of 600\n",
      "building tree 419 of 600\n",
      "building tree 420 of 600\n",
      "building tree 421 of 600\n",
      "building tree 422 of 600\n",
      "building tree 423 of 600\n",
      "building tree 424 of 600\n",
      "building tree 425 of 600\n",
      "building tree 426 of 600\n",
      "building tree 427 of 600\n",
      "building tree 428 of 600\n",
      "building tree 429 of 600\n",
      "building tree 430 of 600\n",
      "building tree 431 of 600\n",
      "building tree 432 of 600\n",
      "building tree 433 of 600\n",
      "building tree 434 of 600\n",
      "building tree 435 of 600\n",
      "building tree 436 of 600\n",
      "building tree 437 of 600\n",
      "building tree 438 of 600\n",
      "building tree 439 of 600\n",
      "building tree 440 of 600\n",
      "building tree 441 of 600\n",
      "building tree 442 of 600\n",
      "building tree 443 of 600\n",
      "building tree 444 of 600\n",
      "building tree 445 of 600\n",
      "building tree 446 of 600\n",
      "building tree 447 of 600\n",
      "building tree 448 of 600\n",
      "building tree 449 of 600\n",
      "building tree 450 of 600\n",
      "building tree 451 of 600\n",
      "building tree 452 of 600\n",
      "building tree 453 of 600\n",
      "building tree 454 of 600\n",
      "building tree 455 of 600\n",
      "building tree 456 of 600\n",
      "building tree 457 of 600\n",
      "building tree 458 of 600\n",
      "building tree 459 of 600\n",
      "building tree 460 of 600\n",
      "building tree 461 of 600\n",
      "building tree 462 of 600\n",
      "building tree 463 of 600\n",
      "building tree 464 of 600\n",
      "building tree 465 of 600\n",
      "building tree 466 of 600\n",
      "building tree 467 of 600\n",
      "building tree 468 of 600\n",
      "building tree 469 of 600\n",
      "building tree 470 of 600\n",
      "building tree 471 of 600\n",
      "building tree 472 of 600\n",
      "building tree 473 of 600\n",
      "building tree 474 of 600\n",
      "building tree 475 of 600\n",
      "building tree 476 of 600\n",
      "building tree 477 of 600\n",
      "building tree 478 of 600\n",
      "building tree 479 of 600\n",
      "building tree 480 of 600\n",
      "building tree 481 of 600\n",
      "building tree 482 of 600\n",
      "building tree 483 of 600building tree 484 of 600\n",
      "\n",
      "building tree 485 of 600\n",
      "building tree 486 of 600\n",
      "building tree 487 of 600\n",
      "building tree 488 of 600\n",
      "building tree 489 of 600\n",
      "building tree 490 of 600\n",
      "building tree 491 of 600\n",
      "building tree 492 of 600\n",
      "building tree 493 of 600\n",
      "building tree 494 of 600\n",
      "building tree 495 of 600\n",
      "building tree 496 of 600\n",
      "building tree 497 of 600\n",
      "building tree 498 of 600\n",
      "building tree 499 of 600\n",
      "building tree 500 of 600\n",
      "building tree 501 of 600\n",
      "building tree 502 of 600\n",
      "building tree 503 of 600\n",
      "building tree 504 of 600\n",
      "building tree 505 of 600\n",
      "building tree 506 of 600\n",
      "building tree 507 of 600\n",
      "building tree 508 of 600\n",
      "building tree 509 of 600\n",
      "building tree 510 of 600\n",
      "building tree 511 of 600\n",
      "building tree 512 of 600\n",
      "building tree 513 of 600\n",
      "building tree 514 of 600\n",
      "building tree 515 of 600\n",
      "building tree 516 of 600\n",
      "building tree 517 of 600\n",
      "building tree 518 of 600\n",
      "building tree 519 of 600\n",
      "building tree 520 of 600\n",
      "building tree 521 of 600\n",
      "building tree 522 of 600\n",
      "building tree 523 of 600\n",
      "building tree 524 of 600\n",
      "building tree 525 of 600\n",
      "building tree 526 of 600\n",
      "building tree 527 of 600\n",
      "building tree 528 of 600\n",
      "building tree 529 of 600\n",
      "building tree 530 of 600\n",
      "building tree 531 of 600\n",
      "building tree 532 of 600\n",
      "building tree 533 of 600\n",
      "building tree 534 of 600\n",
      "building tree 535 of 600\n",
      "building tree 536 of 600\n",
      "building tree 537 of 600\n",
      "building tree 538 of 600\n",
      "building tree 539 of 600\n",
      "building tree 540 of 600\n",
      "building tree 541 of 600\n",
      "building tree 542 of 600\n",
      "building tree 543 of 600\n",
      "building tree 544 of 600\n",
      "building tree 545 of 600\n",
      "building tree 546 of 600\n",
      "building tree 547 of 600\n",
      "building tree 548 of 600\n",
      "building tree 549 of 600\n",
      "building tree 550 of 600\n",
      "building tree 551 of 600\n",
      "building tree 552 of 600\n",
      "building tree 553 of 600\n",
      "building tree 554 of 600\n",
      "building tree 555 of 600\n",
      "building tree 556 of 600\n",
      "building tree 557 of 600\n",
      "building tree 558 of 600\n",
      "building tree 559 of 600\n",
      "building tree 560 of 600\n",
      "building tree 561 of 600\n",
      "building tree 562 of 600\n",
      "building tree 563 of 600\n",
      "building tree 564 of 600\n",
      "building tree 565 of 600\n",
      "building tree 566 of 600\n",
      "building tree 567 of 600\n",
      "building tree 568 of 600\n",
      "building tree 569 of 600\n",
      "building tree 570 of 600\n",
      "building tree 571 of 600\n",
      "building tree 572 of 600\n",
      "building tree 573 of 600\n",
      "building tree 574 of 600\n",
      "building tree 575 of 600\n",
      "building tree 576 of 600\n",
      "building tree 577 of 600\n",
      "building tree 578 of 600\n",
      "building tree 579 of 600\n",
      "building tree 580 of 600\n",
      "building tree 581 of 600\n",
      "building tree 582 of 600\n",
      "building tree 583 of 600\n",
      "building tree 584 of 600\n",
      "building tree 585 of 600\n",
      "building tree 586 of 600\n",
      "building tree 587 of 600\n",
      "building tree 588 of 600\n",
      "building tree 589 of 600\n",
      "building tree 590 of 600\n",
      "building tree 591 of 600\n",
      "building tree 592 of 600\n",
      "building tree 593 of 600building tree 594 of 600\n",
      "\n",
      "building tree 595 of 600\n",
      "building tree 596 of 600\n",
      "building tree 597 of 600\n",
      "building tree 598 of 600\n",
      "building tree 599 of 600\n",
      "building tree 600 of 600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 600 out of 600 | elapsed:   14.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "textlab_10_fullab_dur fit complete\n",
      "Fitted model saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=24)]: Using backend ThreadingBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=24)]: Done 114 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=24)]: Done 317 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=24)]: Done 600 out of 600 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=24)]: Using backend ThreadingBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=24)]: Done 114 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=24)]: Done 317 tasks      | elapsed:    0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitAndPredict: 26.265891551971436 seconds\n",
      "0.5086904671748376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=24)]: Done 600 out of 600 | elapsed:    0.3s finished\n"
     ]
    }
   ],
   "source": [
    "# 根据之前的分组计算特征，将其分为训练集和测试集\n",
    "# A->B run with just n-gram features\n",
    "for dataset in all_datasets:\n",
    "    print(\"*** A->B n-gram ML run\")\n",
    "    prepareML(dataset, \"gramab\")\n",
    "    runML(dataset, \"gramab\")\n",
    "    # Compute and save the most predictive features\n",
    "    print(\"*** A->B computing most predictive features\")\n",
    "    computeMostPredictive(dataset, \"gramab\")\n",
    "    # Now the second ML run, using the most predictive features plus the rest\n",
    "    # of the features detailed in Appendix D\n",
    "    print(\"*** A->B full ML run\")\n",
    "    prepareML(dataset, \"fullab\")\n",
    "    runML(dataset, \"fullab\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "da006398-3e0b-40be-b111-db6d6ad03e9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** B->A n-gram ML run\n",
      "# A obs: 129751\n",
      "# B obs: 129751\n",
      "# A_train obs: 103800\n",
      "# A_val obs: 25951\n",
      "# B_train obs: 103800\n",
      "# B_val obs: 25951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\1619589998.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  feature_df[\"description\"] = feature_df[\"description\"].astype(str)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\1619589998.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  feature_df[\"kw_parsed\"] = feature_df[\"kw_parsed\"].astype(str)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\1619589998.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  feature_df[\"qualifications\"] = feature_df[\"qualifications\"].astype(str)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\1619589998.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  feature_df[\"title\"] = feature_df[\"title\"].astype(str)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descriptions vectorized for train data\n",
      "Keywords vectorized for train data\n",
      "Titles vectorized for train data\n",
      "(103800, 421264)\n",
      "(103800, 9077)\n",
      "(103800, 283234)\n",
      "Feature names saved to .\\ml_input\\feat_names_ipeirotis_gramba.pkl\n",
      "Validation set descriptions vectorized\n",
      "Validation set keywords vectorized\n",
      "Validation set titles vectorized\n",
      "(25951, 421264)\n",
      "(25951, 9077)\n",
      "(25951, 283234)\n",
      "Train rewards saved to .\\ml_input\\./train_rew_ipeirotis_gramba.pkl\n",
      "Train durations saved to .\\ml_input\\./train_dur_ipeirotis_gramba.pkl\n",
      "Train text features saved to .\\ml_input\\./train_txtfeats_ipeirotis_gramba.pkl\n",
      "Training data saved\n",
      "Test rewards saved to .\\ml_input\\./test_rew_ipeirotis_gramba.pkl\n",
      "Test durations saved to .\\ml_input\\./test_dur_ipeirotis_gramba.pkl\n",
      "Test text features saved to .\\ml_input\\./test_txtfeats_ipeirotis_gramba.pkl\n",
      "Validation data saved\n",
      "Textual features exported\n",
      "*** Train data: ***\n",
      "Features: (103800, 713575)\n",
      "Reward labels: (103800,)\n",
      "Duration labels: (103800,)\n",
      "*** Validation data: ***\n",
      "Features: (25951, 713575)\n",
      "Reward labels: (25951,)\n",
      "Duration labels: (25951,)\n",
      "Training data loaded\n",
      "Test data loaded\n",
      "----- [Running *reward* ML with text features] -----\n",
      "Running ipeirotis_gramba_rew\n",
      "building tree 1 of 40\n",
      "building tree 2 of 40\n",
      "building tree 3 of 40\n",
      "building tree 4 of 40\n",
      "building tree 5 of 40\n",
      "building tree 6 of 40\n",
      "building tree 7 of 40\n",
      "building tree 8 of 40\n",
      "building tree 9 of 40\n",
      "building tree 10 of 40\n",
      "building tree 11 of 40\n",
      "building tree 12 of 40\n",
      "building tree 13 of 40\n",
      "building tree 14 of 40\n",
      "building tree 15 of 40\n",
      "building tree 16 of 40\n",
      "building tree 17 of 40\n",
      "building tree 18 of 40\n",
      "building tree 19 of 40\n",
      "building tree 20 of 40\n",
      "building tree 21 of 40\n",
      "building tree 22 of 40\n",
      "building tree 23 of 40\n",
      "building tree 24 of 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 24 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 25 of 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed: 15.1min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 26 of 40\n",
      "building tree 27 of 40\n",
      "building tree 28 of 40\n",
      "building tree 29 of 40\n",
      "building tree 30 of 40\n",
      "building tree 31 of 40\n",
      "building tree 32 of 40\n",
      "building tree 33 of 40\n",
      "building tree 34 of 40\n",
      "building tree 35 of 40\n",
      "building tree 36 of 40\n",
      "building tree 37 of 40\n",
      "building tree 38 of 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  14 out of  40 | elapsed: 15.4min remaining: 28.7min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 39 of 40\n",
      "building tree 40 of 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  35 out of  40 | elapsed: 24.5min remaining:  3.5min\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed: 24.5min finished\n",
      "[Parallel(n_jobs=24)]: Using backend ThreadingBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=24)]: Done   1 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=24)]: Done  14 out of  40 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=24)]: Done  35 out of  40 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=24)]: Done  40 out of  40 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=24)]: Using backend ThreadingBackend with 24 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ipeirotis_gramba_rew fit complete\n",
      "Fitted model saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=24)]: Done   1 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=24)]: Done  14 out of  40 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=24)]: Done  35 out of  40 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=24)]: Done  40 out of  40 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 24 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitAndPredict: 1472.277501821518 seconds\n",
      "0.7655546683835237\n",
      "----- [Running *duration* ML with text features] -----\n",
      "Running ipeirotis_gramba_dur\n",
      "building tree 1 of 40\n",
      "building tree 2 of 40\n",
      "building tree 3 of 40\n",
      "building tree 4 of 40\n",
      "building tree 5 of 40\n",
      "building tree 6 of 40\n",
      "building tree 7 of 40\n",
      "building tree 8 of 40\n",
      "building tree 9 of 40\n",
      "building tree 10 of 40\n",
      "building tree 11 of 40\n",
      "building tree 12 of 40\n",
      "building tree 13 of 40\n",
      "building tree 14 of 40\n",
      "building tree 15 of 40\n",
      "building tree 16 of 40\n",
      "building tree 17 of 40\n",
      "building tree 18 of 40\n",
      "building tree 19 of 40\n",
      "building tree 20 of 40\n",
      "building tree 21 of 40\n",
      "building tree 22 of 40\n",
      "building tree 23 of 40\n",
      "building tree 24 of 40\n",
      "building tree 25 of 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed: 28.9min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 26 of 40\n",
      "building tree 27 of 40\n",
      "building tree 28 of 40\n",
      "building tree 29 of 40\n",
      "building tree 30 of 40\n",
      "building tree 31 of 40\n",
      "building tree 32 of 40\n",
      "building tree 33 of 40\n",
      "building tree 34 of 40\n",
      "building tree 35 of 40\n",
      "building tree 36 of 40\n",
      "building tree 37 of 40\n",
      "building tree 38 of 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  14 out of  40 | elapsed: 29.7min remaining: 55.2min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 39 of 40\n",
      "building tree 40 of 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  35 out of  40 | elapsed: 47.7min remaining:  6.8min\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed: 47.8min finished\n",
      "[Parallel(n_jobs=24)]: Using backend ThreadingBackend with 24 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ipeirotis_gramba_dur fit complete\n",
      "Fitted model saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=24)]: Done   1 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=24)]: Done  14 out of  40 | elapsed:    0.2s remaining:    0.4s\n",
      "[Parallel(n_jobs=24)]: Done  35 out of  40 | elapsed:    0.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=24)]: Done  40 out of  40 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=24)]: Using backend ThreadingBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=24)]: Done   1 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=24)]: Done  14 out of  40 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=24)]: Done  35 out of  40 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=24)]: Done  40 out of  40 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitAndPredict: 2870.4311413764954 seconds\n",
      "0.4071585242707978\n",
      "*** B->A computing most predictive features\n",
      "Generating most predictive features for dur\n",
      "Number of features: 713575\n",
      "Features outputted to: .\\predictive_feats\\predictive_ipeirotis_gramba_dur.csv\n",
      "Generating most predictive features for rew\n",
      "Number of features: 713575\n",
      "Features outputted to: .\\predictive_feats\\predictive_ipeirotis_gramba_rew.csv\n",
      "*** B->A full ML run\n",
      "# A obs: 129751\n",
      "# B obs: 129751\n",
      "# A_train obs: 103800\n",
      "# A_val obs: 25951\n",
      "# B_train obs: 103800\n",
      "# B_val obs: 25951\n",
      "Number of description features: 94\n",
      "Number of title features: 73\n",
      "Number of keyword features: 33\n",
      "Computing feature #0: easy\n",
      "Computing feature #1: transcribe\n",
      "Computing feature #2: writing\n",
      "Computing feature #3: audio\n",
      "Computing feature #4: image\n",
      "Computing feature #5: video\n",
      "Computing feature #6: bonus\n",
      "Computing feature #7: copy\n",
      "Computing feature #8: search\n",
      "Computing feature #9: identify\n",
      "Computing feature #10: text\n",
      "Computing feature #11: date\n",
      "Computing feature #12: fun\n",
      "Computing feature #13: simple\n",
      "Computing feature #14: summarize\n",
      "Computing feature #15: only\n",
      "Computing feature #16: improve\n",
      "Computing feature #17: five\n",
      "Computing feature #18: questionmark\n",
      "Computing feature #19: exclamation\n",
      "Computing feature #20: find\n",
      "Computing feature #21: check\n",
      "Computing feature #22: match\n",
      "Computing feature #23: choose\n",
      "Computing feature #24: categorize\n",
      "Computing feature #25: suggest\n",
      "Computing feature #26: translate\n",
      "Computing feature #27: survey\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[kw_var] = (hit_df[\"kw_lower\"].str.count(str_to_search).fillna(0)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing feature #28: click\n",
      "Computing feature #29: link\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[kw_var] = (hit_df[\"kw_lower\"].str.count(str_to_search).fillna(0)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[kw_var] = (hit_df[\"kw_lower\"].str.count(str_to_search).fillna(0)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[kw_var] = (hit_df[\"kw_lower\"].str.count(str_to_search).fillna(0)).astype(int)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing feature #30: read\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[kw_var] = (hit_df[\"kw_lower\"].str.count(str_to_search).fillna(0)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[kw_var] = (hit_df[\"kw_lower\"].str.count(str_to_search).fillna(0)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[kw_var] = (hit_df[\"kw_lower\"].str.count(str_to_search).fillna(0)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[kw_var] = (hit_df[\"kw_lower\"].str.count(str_to_search).fillna(0)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[kw_var] = (hit_df[\"kw_lower\"].str.count(str_to_search).fillna(0)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[kw_var] = (hit_df[\"kw_lower\"].str.count(str_to_search).fillna(0)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[kw_var] = (hit_df[\"kw_lower\"].str.count(str_to_search).fillna(0)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[kw_var] = (hit_df[\"kw_lower\"].str.count(str_to_search).fillna(0)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[kw_var] = (hit_df[\"kw_lower\"].str.count(str_to_search).fillna(0)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[kw_var] = (hit_df[\"kw_lower\"].str.count(str_to_search).fillna(0)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[kw_var] = (hit_df[\"kw_lower\"].str.count(str_to_search).fillna(0)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[kw_var] = (hit_df[\"kw_lower\"].str.count(str_to_search).fillna(0)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[kw_var] = (hit_df[\"kw_lower\"].str.count(str_to_search).fillna(0)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[kw_var] = (hit_df[\"kw_lower\"].str.count(str_to_search).fillna(0)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[kw_var] = (hit_df[\"kw_lower\"].str.count(str_to_search).fillna(0)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[kw_var] = (hit_df[\"kw_lower\"].str.count(str_to_search).fillna(0)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[kw_var] = (hit_df[\"kw_lower\"].str.count(str_to_search).fillna(0)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[kw_var] = (hit_df[\"kw_lower\"].str.count(str_to_search).fillna(0)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[kw_var] = (hit_df[\"kw_lower\"].str.count(str_to_search).fillna(0)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[kw_var] = (hit_df[\"kw_lower\"].str.count(str_to_search).fillna(0)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[kw_var] = (hit_df[\"kw_lower\"].str.count(str_to_search).fillna(0)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[kw_var] = (hit_df[\"kw_lower\"].str.count(str_to_search).fillna(0)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[kw_var] = (hit_df[\"kw_lower\"].str.count(str_to_search).fillna(0)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[kw_var] = (hit_df[\"kw_lower\"].str.count(str_to_search).fillna(0)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[kw_var] = (hit_df[\"kw_lower\"].str.count(str_to_search).fillna(0)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[kw_var] = (hit_df[\"kw_lower\"].str.count(str_to_search).fillna(0)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[kw_var] = (hit_df[\"kw_lower\"].str.count(str_to_search).fillna(0)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[kw_var] = (hit_df[\"kw_lower\"].str.count(str_to_search).fillna(0)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[kw_var] = (hit_df[\"kw_lower\"].str.count(str_to_search).fillna(0)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[kw_var] = (hit_df[\"kw_lower\"].str.count(str_to_search).fillna(0)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[kw_var] = (hit_df[\"kw_lower\"].str.count(str_to_search).fillna(0)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[kw_var] = (hit_df[\"kw_lower\"].str.count(str_to_search).fillna(0)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[kw_var] = (hit_df[\"kw_lower\"].str.count(str_to_search).fillna(0)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[\"minutes_title\"] = hit_df[\"title_lower\"].str.extract(minutes_reg,expand=False).fillna(0).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:72: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[\"minutes_desc\"] = hit_df[\"desc_lower\"].str.extract(minutes_reg,expand=False).fillna(0).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:73: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[\"minutes_kw\"] = hit_df[\"kw_lower\"].str.extract(minutes_reg,expand=False).fillna(0).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\1226819826.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[\"qual_len\"] = hit_df[\"qualifications\"].apply(lambda x: len(x) if pd.notnull(x) else 0)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\1226819826.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[\"num_quals\"] = (hit_df[\"qualifications\"].str.count(list_sep) + 1).fillna(0).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\1226819826.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[\"custom_not_granted\"] = hit_df[\"qualifications\"].str.count(qual_not_granted).fillna(0).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\1226819826.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[\"custom_granted\"] = hit_df[\"qualifications\"].str.count(qual_granted).fillna(0).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\1226819826.py:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[\"any_loc\"] = ((hit_df[\"locs\"] + hit_df[\"locs_mult\"]) != \"\").astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\1226819826.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[\"us_only\"] = ((hit_df[\"locs\"] + \"|\" + hit_df[\"locs_mult\"]).str.contains(\"US\")).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\1226819826.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[\"appr_rate_gt\"] = hit_df[\"qualifications\"].str.extract(qual_appr_rate_gt,expand=False).fillna(-1).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\1226819826.py:34: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[\"appr_num_gt\"] = hit_df[\"qualifications\"].str.extract(qual_appr_num_gt,expand=False).fillna(-1).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3226286950.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df.reset_index(inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDA features merged in\n",
      "Doc2Vec features merged in\n",
      "                              group_id      duration  log_duration  reward  \\\n",
      "259497  3ZY19HV01BIMKUJC8R23XWPE2U4GSE   1512.933333      7.321806       5   \n",
      "259498  3ZY19HV01BIUAL70JGMVTT0E150GSD     35.766667      3.577016      40   \n",
      "259499  3ZY19HV01BMN1HMYRKAG7N9SYLVGSY    396.566667      5.982844      15   \n",
      "259500            4YFZK2ZCCXSZ64ZJNTR0     34.916667      3.552964       5   \n",
      "259501            J1ZZNQGNTW1YZVD8FWTZ  20171.916667      9.912047       5   \n",
      "\n",
      "        log_reward  meandiff_lreward  meandiff_ldur  time_allotted  \\\n",
      "259497    1.609438         -0.405465      -0.990035           1500   \n",
      "259498    3.688879          0.000000      -4.468027           3600   \n",
      "259499    2.708050         -0.815037      -2.454863           3600   \n",
      "259500    1.609438          0.000000       0.000000           1200   \n",
      "259501    1.609438          0.000000       1.182741           3600   \n",
      "\n",
      "        first_hits  last_hits  ...  doc2vec_kw_40  doc2vec_kw_41  \\\n",
      "259497           1          0  ...       0.001703      -0.022494   \n",
      "259498           1          0  ...       0.035416      -0.013044   \n",
      "259499           1          0  ...       0.022562       0.000857   \n",
      "259500         176          0  ...       0.063211      -0.022357   \n",
      "259501          64          0  ...      -0.270207       0.080985   \n",
      "\n",
      "        doc2vec_kw_42  doc2vec_kw_43  doc2vec_kw_44  doc2vec_kw_45  \\\n",
      "259497      -0.020022       0.004839      -0.071768      -0.070872   \n",
      "259498      -0.014742       0.012896       0.005869      -0.008734   \n",
      "259499       0.000976       0.029591      -0.004299      -0.003275   \n",
      "259500       0.006728       0.023312      -0.023521      -0.012213   \n",
      "259501       0.120046      -0.101056       0.053459       0.055652   \n",
      "\n",
      "        doc2vec_kw_46  doc2vec_kw_47  doc2vec_kw_48  doc2vec_kw_49  \n",
      "259497      -0.044790      -0.019276       0.009722      -0.045072  \n",
      "259498      -0.024511       0.014906       0.013756      -0.021019  \n",
      "259499      -0.022727      -0.010653       0.012825      -0.016798  \n",
      "259500      -0.056970      -0.005674      -0.018408      -0.048212  \n",
      "259501       0.396261       0.026271       0.192404       0.170060  \n",
      "\n",
      "[5 rows x 479 columns]\n",
      "avg_hitrate: 10 nans, 0 infs\n",
      "Mean hitrate: 62.771909907471965\n",
      "Max hitrate: 78241.55253860554\n",
      "Train rewards saved to .\\ml_input\\./train_rew_ipeirotis_fullba.pkl\n",
      "Train durations saved to .\\ml_input\\./train_dur_ipeirotis_fullba.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\2253851036.py:109: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_df.drop([col_name],axis=1,inplace=True)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\2253851036.py:109: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_df.drop([col_name],axis=1,inplace=True)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\2253851036.py:109: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_df.drop([col_name],axis=1,inplace=True)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\2253851036.py:109: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_df.drop([col_name],axis=1,inplace=True)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\2253851036.py:109: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_df.drop([col_name],axis=1,inplace=True)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\2253851036.py:109: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_df.drop([col_name],axis=1,inplace=True)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\2253851036.py:109: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_df.drop([col_name],axis=1,inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train features saved to .\\ml_input\\./train_feats_ipeirotis_fullba.pkl\n",
      "Training data saved\n",
      "Test rewards saved to .\\ml_input\\./test_rew_ipeirotis_fullba.pkl\n",
      "Test durations saved to .\\ml_input\\./test_dur_ipeirotis_fullba.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\2253851036.py:136: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df.drop([col_name],axis=1,inplace=True)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\2253851036.py:136: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df.drop([col_name],axis=1,inplace=True)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\2253851036.py:136: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df.drop([col_name],axis=1,inplace=True)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\2253851036.py:136: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df.drop([col_name],axis=1,inplace=True)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\2253851036.py:136: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df.drop([col_name],axis=1,inplace=True)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\2253851036.py:136: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df.drop([col_name],axis=1,inplace=True)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\2253851036.py:136: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df.drop([col_name],axis=1,inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test features saved to .\\ml_input\\./test_feats_ipeirotis_fullba.pkl\n",
      "Test data saved\n",
      "Training data dimensions: (129751, 322)\n",
      "Test data dimensions: (129751, 322)\n",
      "Training data loaded\n",
      "Test data loaded\n",
      "----- [Running *reward* ML with numeric features] -----\n",
      "Running ipeirotis_fullba_rew\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 24 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 600building tree 2 of 600\n",
      "\n",
      "building tree 3 of 600\n",
      "building tree 4 of 600\n",
      "building tree 5 of 600\n",
      "building tree 6 of 600\n",
      "building tree 7 of 600\n",
      "building tree 8 of 600\n",
      "building tree 9 of 600\n",
      "building tree 10 of 600\n",
      "building tree 11 of 600\n",
      "building tree 12 of 600\n",
      "building tree 13 of 600\n",
      "building tree 14 of 600\n",
      "building tree 15 of 600\n",
      "building tree 16 of 600\n",
      "building tree 17 of 600\n",
      "building tree 18 of 600\n",
      "building tree 19 of 600\n",
      "building tree 20 of 600\n",
      "building tree 21 of 600\n",
      "building tree 22 of 600\n",
      "building tree 23 of 600\n",
      "building tree 24 of 600\n",
      "building tree 25 of 600\n",
      "building tree 26 of 600\n",
      "building tree 27 of 600\n",
      "building tree 28 of 600\n",
      "building tree 29 of 600\n",
      "building tree 30 of 600\n",
      "building tree 31 of 600\n",
      "building tree 32 of 600\n",
      "building tree 33 of 600\n",
      "building tree 34 of 600\n",
      "building tree 35 of 600\n",
      "building tree 36 of 600\n",
      "building tree 37 of 600\n",
      "building tree 38 of 600\n",
      "building tree 39 of 600\n",
      "building tree 40 of 600\n",
      "building tree 41 of 600\n",
      "building tree 42 of 600\n",
      "building tree 43 of 600\n",
      "building tree 44 of 600\n",
      "building tree 45 of 600\n",
      "building tree 46 of 600\n",
      "building tree 47 of 600\n",
      "building tree 48 of 600\n",
      "building tree 49 of 600\n",
      "building tree 50 of 600\n",
      "building tree 51 of 600\n",
      "building tree 52 of 600\n",
      "building tree 53 of 600\n",
      "building tree 54 of 600\n",
      "building tree 55 of 600\n",
      "building tree 56 of 600\n",
      "building tree 57 of 600\n",
      "building tree 58 of 600\n",
      "building tree 59 of 600\n",
      "building tree 60 of 600\n",
      "building tree 61 of 600\n",
      "building tree 62 of 600\n",
      "building tree 63 of 600\n",
      "building tree 64 of 600\n",
      "building tree 65 of 600\n",
      "building tree 66 of 600\n",
      "building tree 67 of 600\n",
      "building tree 68 of 600\n",
      "building tree 69 of 600\n",
      "building tree 70 of 600\n",
      "building tree 71 of 600\n",
      "building tree 72 of 600\n",
      "building tree 73 of 600\n",
      "building tree 74 of 600\n",
      "building tree 75 of 600\n",
      "building tree 76 of 600\n",
      "building tree 77 of 600\n",
      "building tree 78 of 600\n",
      "building tree 79 of 600\n",
      "building tree 80 of 600\n",
      "building tree 81 of 600\n",
      "building tree 82 of 600\n",
      "building tree 83 of 600\n",
      "building tree 84 of 600\n",
      "building tree 85 of 600\n",
      "building tree 86 of 600\n",
      "building tree 87 of 600\n",
      "building tree 88 of 600\n",
      "building tree 89 of 600\n",
      "building tree 90 of 600\n",
      "building tree 91 of 600\n",
      "building tree 92 of 600\n",
      "building tree 93 of 600\n",
      "building tree 94 of 600\n",
      "building tree 95 of 600\n",
      "building tree 96 of 600\n",
      "building tree 97 of 600\n",
      "building tree 98 of 600\n",
      "building tree 99 of 600\n",
      "building tree 100 of 600\n",
      "building tree 101 of 600\n",
      "building tree 102 of 600\n",
      "building tree 103 of 600\n",
      "building tree 104 of 600\n",
      "building tree 105 of 600\n",
      "building tree 106 of 600\n",
      "building tree 107 of 600\n",
      "building tree 108 of 600\n",
      "building tree 109 of 600\n",
      "building tree 110 of 600\n",
      "building tree 111 of 600\n",
      "building tree 112 of 600\n",
      "building tree 113 of 600\n",
      "building tree 114 of 600\n",
      "building tree 115 of 600\n",
      "building tree 116 of 600\n",
      "building tree 117 of 600\n",
      "building tree 118 of 600\n",
      "building tree 119 of 600\n",
      "building tree 120 of 600\n",
      "building tree 121 of 600\n",
      "building tree 122 of 600\n",
      "building tree 123 of 600\n",
      "building tree 124 of 600\n",
      "building tree 125 of 600\n",
      "building tree 126 of 600\n",
      "building tree 127 of 600\n",
      "building tree 128 of 600\n",
      "building tree 129 of 600\n",
      "building tree 130 of 600building tree 131 of 600\n",
      "\n",
      "building tree 132 of 600\n",
      "building tree 133 of 600\n",
      "building tree 134 of 600\n",
      "building tree 135 of 600\n",
      "building tree 136 of 600\n",
      "building tree 137 of 600\n",
      "building tree 138 of 600\n",
      "building tree 139 of 600\n",
      "building tree 140 of 600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 114 tasks      | elapsed:   17.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 141 of 600\n",
      "building tree 142 of 600\n",
      "building tree 143 of 600\n",
      "building tree 144 of 600\n",
      "building tree 145 of 600\n",
      "building tree 146 of 600\n",
      "building tree 147 of 600\n",
      "building tree 148 of 600\n",
      "building tree 149 of 600building tree 150 of 600\n",
      "\n",
      "building tree 151 of 600\n",
      "building tree 152 of 600\n",
      "building tree 153 of 600\n",
      "building tree 154 of 600\n",
      "building tree 155 of 600\n",
      "building tree 156 of 600\n",
      "building tree 157 of 600\n",
      "building tree 158 of 600\n",
      "building tree 159 of 600\n",
      "building tree 160 of 600\n",
      "building tree 161 of 600\n",
      "building tree 162 of 600\n",
      "building tree 163 of 600\n",
      "building tree 164 of 600\n",
      "building tree 165 of 600\n",
      "building tree 166 of 600\n",
      "building tree 167 of 600\n",
      "building tree 168 of 600\n",
      "building tree 169 of 600\n",
      "building tree 170 of 600\n",
      "building tree 171 of 600\n",
      "building tree 172 of 600\n",
      "building tree 173 of 600\n",
      "building tree 174 of 600\n",
      "building tree 175 of 600\n",
      "building tree 176 of 600\n",
      "building tree 177 of 600\n",
      "building tree 178 of 600\n",
      "building tree 179 of 600\n",
      "building tree 180 of 600\n",
      "building tree 181 of 600\n",
      "building tree 182 of 600\n",
      "building tree 183 of 600building tree 184 of 600\n",
      "\n",
      "building tree 185 of 600\n",
      "building tree 186 of 600\n",
      "building tree 187 of 600\n",
      "building tree 188 of 600\n",
      "building tree 189 of 600\n",
      "building tree 190 of 600\n",
      "building tree 191 of 600\n",
      "building tree 192 of 600\n",
      "building tree 193 of 600\n",
      "building tree 194 of 600\n",
      "building tree 195 of 600\n",
      "building tree 196 of 600\n",
      "building tree 197 of 600\n",
      "building tree 198 of 600\n",
      "building tree 199 of 600\n",
      "building tree 200 of 600\n",
      "building tree 201 of 600\n",
      "building tree 202 of 600\n",
      "building tree 203 of 600\n",
      "building tree 204 of 600\n",
      "building tree 205 of 600\n",
      "building tree 206 of 600\n",
      "building tree 207 of 600\n",
      "building tree 208 of 600\n",
      "building tree 209 of 600\n",
      "building tree 210 of 600\n",
      "building tree 211 of 600\n",
      "building tree 212 of 600\n",
      "building tree 213 of 600\n",
      "building tree 214 of 600\n",
      "building tree 215 of 600\n",
      "building tree 216 of 600\n",
      "building tree 217 of 600\n",
      "building tree 218 of 600\n",
      "building tree 219 of 600\n",
      "building tree 220 of 600\n",
      "building tree 221 of 600\n",
      "building tree 222 of 600\n",
      "building tree 223 of 600\n",
      "building tree 224 of 600\n",
      "building tree 225 of 600\n",
      "building tree 226 of 600\n",
      "building tree 227 of 600\n",
      "building tree 228 of 600\n",
      "building tree 229 of 600\n",
      "building tree 230 of 600\n",
      "building tree 231 of 600\n",
      "building tree 232 of 600\n",
      "building tree 233 of 600\n",
      "building tree 234 of 600\n",
      "building tree 235 of 600\n",
      "building tree 236 of 600\n",
      "building tree 237 of 600\n",
      "building tree 238 of 600\n",
      "building tree 239 of 600\n",
      "building tree 240 of 600\n",
      "building tree 241 of 600\n",
      "building tree 242 of 600\n",
      "building tree 243 of 600\n",
      "building tree 244 of 600\n",
      "building tree 245 of 600\n",
      "building tree 246 of 600\n",
      "building tree 247 of 600\n",
      "building tree 248 of 600\n",
      "building tree 249 of 600\n",
      "building tree 250 of 600\n",
      "building tree 251 of 600\n",
      "building tree 252 of 600\n",
      "building tree 253 of 600\n",
      "building tree 254 of 600\n",
      "building tree 255 of 600\n",
      "building tree 256 of 600\n",
      "building tree 257 of 600\n",
      "building tree 258 of 600\n",
      "building tree 259 of 600\n",
      "building tree 260 of 600\n",
      "building tree 261 of 600\n",
      "building tree 262 of 600\n",
      "building tree 263 of 600\n",
      "building tree 264 of 600\n",
      "building tree 265 of 600\n",
      "building tree 266 of 600\n",
      "building tree 267 of 600\n",
      "building tree 268 of 600\n",
      "building tree 269 of 600\n",
      "building tree 270 of 600\n",
      "building tree 271 of 600\n",
      "building tree 272 of 600\n",
      "building tree 273 of 600\n",
      "building tree 274 of 600\n",
      "building tree 275 of 600\n",
      "building tree 276 of 600\n",
      "building tree 277 of 600\n",
      "building tree 278 of 600\n",
      "building tree 279 of 600\n",
      "building tree 280 of 600\n",
      "building tree 281 of 600\n",
      "building tree 282 of 600\n",
      "building tree 283 of 600\n",
      "building tree 284 of 600\n",
      "building tree 285 of 600\n",
      "building tree 286 of 600\n",
      "building tree 287 of 600\n",
      "building tree 288 of 600\n",
      "building tree 289 of 600\n",
      "building tree 290 of 600\n",
      "building tree 291 of 600\n",
      "building tree 292 of 600\n",
      "building tree 293 of 600\n",
      "building tree 294 of 600\n",
      "building tree 295 of 600\n",
      "building tree 296 of 600\n",
      "building tree 297 of 600\n",
      "building tree 298 of 600\n",
      "building tree 299 of 600\n",
      "building tree 300 of 600\n",
      "building tree 301 of 600\n",
      "building tree 302 of 600\n",
      "building tree 303 of 600\n",
      "building tree 304 of 600\n",
      "building tree 305 of 600\n",
      "building tree 306 of 600\n",
      "building tree 307 of 600\n",
      "building tree 308 of 600\n",
      "building tree 309 of 600\n",
      "building tree 310 of 600\n",
      "building tree 311 of 600\n",
      "building tree 312 of 600\n",
      "building tree 313 of 600\n",
      "building tree 314 of 600\n",
      "building tree 315 of 600\n",
      "building tree 316 of 600\n",
      "building tree 317 of 600\n",
      "building tree 318 of 600\n",
      "building tree 319 of 600\n",
      "building tree 320 of 600\n",
      "building tree 321 of 600\n",
      "building tree 322 of 600\n",
      "building tree 323 of 600\n",
      "building tree 324 of 600\n",
      "building tree 325 of 600\n",
      "building tree 326 of 600\n",
      "building tree 327 of 600\n",
      "building tree 328 of 600\n",
      "building tree 329 of 600\n",
      "building tree 330 of 600\n",
      "building tree 331 of 600\n",
      "building tree 332 of 600\n",
      "building tree 333 of 600\n",
      "building tree 334 of 600\n",
      "building tree 335 of 600\n",
      "building tree 336 of 600\n",
      "building tree 337 of 600\n",
      "building tree 338 of 600\n",
      "building tree 339 of 600\n",
      "building tree 340 of 600\n",
      "building tree 341 of 600\n",
      "building tree 342 of 600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 317 tasks      | elapsed:   45.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 343 of 600\n",
      "building tree 344 of 600\n",
      "building tree 345 of 600\n",
      "building tree 346 of 600\n",
      "building tree 347 of 600\n",
      "building tree 348 of 600\n",
      "building tree 349 of 600\n",
      "building tree 350 of 600\n",
      "building tree 351 of 600\n",
      "building tree 352 of 600\n",
      "building tree 353 of 600\n",
      "building tree 354 of 600\n",
      "building tree 355 of 600\n",
      "building tree 356 of 600\n",
      "building tree 357 of 600\n",
      "building tree 358 of 600\n",
      "building tree 359 of 600\n",
      "building tree 360 of 600\n",
      "building tree 361 of 600\n",
      "building tree 362 of 600\n",
      "building tree 363 of 600\n",
      "building tree 364 of 600\n",
      "building tree 365 of 600\n",
      "building tree 366 of 600\n",
      "building tree 367 of 600\n",
      "building tree 368 of 600\n",
      "building tree 369 of 600\n",
      "building tree 370 of 600\n",
      "building tree 371 of 600\n",
      "building tree 372 of 600\n",
      "building tree 373 of 600\n",
      "building tree 374 of 600\n",
      "building tree 375 of 600\n",
      "building tree 376 of 600\n",
      "building tree 377 of 600\n",
      "building tree 378 of 600\n",
      "building tree 379 of 600\n",
      "building tree 380 of 600\n",
      "building tree 381 of 600\n",
      "building tree 382 of 600\n",
      "building tree 383 of 600\n",
      "building tree 384 of 600\n",
      "building tree 385 of 600\n",
      "building tree 386 of 600\n",
      "building tree 387 of 600\n",
      "building tree 388 of 600\n",
      "building tree 389 of 600\n",
      "building tree 390 of 600\n",
      "building tree 391 of 600\n",
      "building tree 392 of 600\n",
      "building tree 393 of 600\n",
      "building tree 394 of 600\n",
      "building tree 395 of 600\n",
      "building tree 396 of 600\n",
      "building tree 397 of 600\n",
      "building tree 398 of 600\n",
      "building tree 399 of 600\n",
      "building tree 400 of 600\n",
      "building tree 401 of 600\n",
      "building tree 402 of 600\n",
      "building tree 403 of 600\n",
      "building tree 404 of 600\n",
      "building tree 405 of 600\n",
      "building tree 406 of 600\n",
      "building tree 407 of 600\n",
      "building tree 408 of 600\n",
      "building tree 409 of 600\n",
      "building tree 410 of 600\n",
      "building tree 411 of 600\n",
      "building tree 412 of 600\n",
      "building tree 413 of 600\n",
      "building tree 414 of 600\n",
      "building tree 415 of 600\n",
      "building tree 416 of 600\n",
      "building tree 417 of 600\n",
      "building tree 418 of 600\n",
      "building tree 419 of 600\n",
      "building tree 420 of 600\n",
      "building tree 421 of 600\n",
      "building tree 422 of 600\n",
      "building tree 423 of 600\n",
      "building tree 424 of 600\n",
      "building tree 425 of 600\n",
      "building tree 426 of 600\n",
      "building tree 427 of 600\n",
      "building tree 428 of 600\n",
      "building tree 429 of 600\n",
      "building tree 430 of 600\n",
      "building tree 431 of 600\n",
      "building tree 432 of 600\n",
      "building tree 433 of 600\n",
      "building tree 434 of 600\n",
      "building tree 435 of 600\n",
      "building tree 436 of 600\n",
      "building tree 437 of 600\n",
      "building tree 438 of 600\n",
      "building tree 439 of 600\n",
      "building tree 440 of 600\n",
      "building tree 441 of 600\n",
      "building tree 442 of 600\n",
      "building tree 443 of 600\n",
      "building tree 444 of 600\n",
      "building tree 445 of 600\n",
      "building tree 446 of 600\n",
      "building tree 447 of 600\n",
      "building tree 448 of 600\n",
      "building tree 449 of 600\n",
      "building tree 450 of 600\n",
      "building tree 451 of 600\n",
      "building tree 452 of 600\n",
      "building tree 453 of 600\n",
      "building tree 454 of 600\n",
      "building tree 455 of 600\n",
      "building tree 456 of 600\n",
      "building tree 457 of 600\n",
      "building tree 458 of 600\n",
      "building tree 459 of 600\n",
      "building tree 460 of 600\n",
      "building tree 461 of 600\n",
      "building tree 462 of 600\n",
      "building tree 463 of 600\n",
      "building tree 464 of 600\n",
      "building tree 465 of 600\n",
      "building tree 466 of 600\n",
      "building tree 467 of 600\n",
      "building tree 468 of 600\n",
      "building tree 469 of 600\n",
      "building tree 470 of 600\n",
      "building tree 471 of 600\n",
      "building tree 472 of 600\n",
      "building tree 473 of 600\n",
      "building tree 474 of 600\n",
      "building tree 475 of 600\n",
      "building tree 476 of 600\n",
      "building tree 477 of 600\n",
      "building tree 478 of 600\n",
      "building tree 479 of 600\n",
      "building tree 480 of 600\n",
      "building tree 481 of 600\n",
      "building tree 482 of 600\n",
      "building tree 483 of 600\n",
      "building tree 484 of 600\n",
      "building tree 485 of 600\n",
      "building tree 486 of 600\n",
      "building tree 487 of 600\n",
      "building tree 488 of 600\n",
      "building tree 489 of 600\n",
      "building tree 490 of 600\n",
      "building tree 491 of 600\n",
      "building tree 492 of 600\n",
      "building tree 493 of 600\n",
      "building tree 494 of 600\n",
      "building tree 495 of 600\n",
      "building tree 496 of 600\n",
      "building tree 497 of 600\n",
      "building tree 498 of 600\n",
      "building tree 499 of 600\n",
      "building tree 500 of 600\n",
      "building tree 501 of 600\n",
      "building tree 502 of 600\n",
      "building tree 503 of 600\n",
      "building tree 504 of 600\n",
      "building tree 505 of 600\n",
      "building tree 506 of 600\n",
      "building tree 507 of 600\n",
      "building tree 508 of 600\n",
      "building tree 509 of 600\n",
      "building tree 510 of 600\n",
      "building tree 511 of 600\n",
      "building tree 512 of 600\n",
      "building tree 513 of 600\n",
      "building tree 514 of 600\n",
      "building tree 515 of 600\n",
      "building tree 516 of 600\n",
      "building tree 517 of 600\n",
      "building tree 518 of 600\n",
      "building tree 519 of 600\n",
      "building tree 520 of 600\n",
      "building tree 521 of 600\n",
      "building tree 522 of 600\n",
      "building tree 523 of 600\n",
      "building tree 524 of 600\n",
      "building tree 525 of 600\n",
      "building tree 526 of 600\n",
      "building tree 527 of 600\n",
      "building tree 528 of 600\n",
      "building tree 529 of 600\n",
      "building tree 530 of 600\n",
      "building tree 531 of 600\n",
      "building tree 532 of 600\n",
      "building tree 533 of 600\n",
      "building tree 534 of 600\n",
      "building tree 535 of 600\n",
      "building tree 536 of 600\n",
      "building tree 537 of 600\n",
      "building tree 538 of 600\n",
      "building tree 539 of 600\n",
      "building tree 540 of 600\n",
      "building tree 541 of 600\n",
      "building tree 542 of 600\n",
      "building tree 543 of 600\n",
      "building tree 544 of 600\n",
      "building tree 545 of 600\n",
      "building tree 546 of 600\n",
      "building tree 547 of 600\n",
      "building tree 548 of 600\n",
      "building tree 549 of 600\n",
      "building tree 550 of 600\n",
      "building tree 551 of 600\n",
      "building tree 552 of 600\n",
      "building tree 553 of 600\n",
      "building tree 554 of 600\n",
      "building tree 555 of 600\n",
      "building tree 556 of 600\n",
      "building tree 557 of 600\n",
      "building tree 558 of 600\n",
      "building tree 559 of 600\n",
      "building tree 560 of 600\n",
      "building tree 561 of 600\n",
      "building tree 562 of 600\n",
      "building tree 563 of 600\n",
      "building tree 564 of 600\n",
      "building tree 565 of 600\n",
      "building tree 566 of 600\n",
      "building tree 567 of 600\n",
      "building tree 568 of 600\n",
      "building tree 569 of 600\n",
      "building tree 570 of 600\n",
      "building tree 571 of 600\n",
      "building tree 572 of 600\n",
      "building tree 573 of 600\n",
      "building tree 574 of 600\n",
      "building tree 575 of 600\n",
      "building tree 576 of 600\n",
      "building tree 577 of 600\n",
      "building tree 578 of 600\n",
      "building tree 579 of 600\n",
      "building tree 580 of 600\n",
      "building tree 581 of 600\n",
      "building tree 582 of 600\n",
      "building tree 583 of 600\n",
      "building tree 584 of 600\n",
      "building tree 585 of 600\n",
      "building tree 586 of 600\n",
      "building tree 587 of 600\n",
      "building tree 588 of 600\n",
      "building tree 589 of 600\n",
      "building tree 590 of 600\n",
      "building tree 591 of 600\n",
      "building tree 592 of 600\n",
      "building tree 593 of 600\n",
      "building tree 594 of 600\n",
      "building tree 595 of 600\n",
      "building tree 596 of 600\n",
      "building tree 597 of 600\n",
      "building tree 598 of 600\n",
      "building tree 599 of 600\n",
      "building tree 600 of 600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 600 out of 600 | elapsed:  1.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ipeirotis_fullba_rew fit complete\n",
      "Fitted model saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=24)]: Using backend ThreadingBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=24)]: Done 114 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=24)]: Done 317 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=24)]: Done 600 out of 600 | elapsed:    1.9s finished\n",
      "[Parallel(n_jobs=24)]: Using backend ThreadingBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=24)]: Done 114 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=24)]: Done 317 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=24)]: Done 600 out of 600 | elapsed:    1.9s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 24 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitAndPredict: 121.50878810882568 seconds\n",
      "0.7746620772327191\n",
      "----- [Running *duration* ML with numeric features] -----\n",
      "Running ipeirotis_fullba_dur\n",
      "building tree 1 of 600\n",
      "building tree 2 of 600\n",
      "building tree 3 of 600\n",
      "building tree 4 of 600\n",
      "building tree 5 of 600\n",
      "building tree 6 of 600\n",
      "building tree 7 of 600\n",
      "building tree 8 of 600\n",
      "building tree 9 of 600\n",
      "building tree 10 of 600\n",
      "building tree 11 of 600\n",
      "building tree 12 of 600\n",
      "building tree 13 of 600\n",
      "building tree 14 of 600\n",
      "building tree 15 of 600\n",
      "building tree 16 of 600\n",
      "building tree 17 of 600\n",
      "building tree 18 of 600\n",
      "building tree 19 of 600\n",
      "building tree 20 of 600\n",
      "building tree 21 of 600\n",
      "building tree 22 of 600\n",
      "building tree 23 of 600\n",
      "building tree 24 of 600\n",
      "building tree 25 of 600\n",
      "building tree 26 of 600\n",
      "building tree 27 of 600\n",
      "building tree 28 of 600\n",
      "building tree 29 of 600\n",
      "building tree 30 of 600\n",
      "building tree 31 of 600\n",
      "building tree 32 of 600\n",
      "building tree 33 of 600\n",
      "building tree 34 of 600\n",
      "building tree 35 of 600\n",
      "building tree 36 of 600\n",
      "building tree 37 of 600\n",
      "building tree 38 of 600\n",
      "building tree 39 of 600\n",
      "building tree 40 of 600\n",
      "building tree 41 of 600\n",
      "building tree 42 of 600\n",
      "building tree 43 of 600\n",
      "building tree 44 of 600\n",
      "building tree 45 of 600\n",
      "building tree 46 of 600\n",
      "building tree 47 of 600\n",
      "building tree 48 of 600\n",
      "building tree 49 of 600\n",
      "building tree 50 of 600\n",
      "building tree 51 of 600\n",
      "building tree 52 of 600\n",
      "building tree 53 of 600\n",
      "building tree 54 of 600\n",
      "building tree 55 of 600\n",
      "building tree 56 of 600\n",
      "building tree 57 of 600\n",
      "building tree 58 of 600\n",
      "building tree 59 of 600\n",
      "building tree 60 of 600\n",
      "building tree 61 of 600\n",
      "building tree 62 of 600\n",
      "building tree 63 of 600\n",
      "building tree 64 of 600\n",
      "building tree 65 of 600\n",
      "building tree 66 of 600\n",
      "building tree 67 of 600\n",
      "building tree 68 of 600\n",
      "building tree 69 of 600\n",
      "building tree 70 of 600\n",
      "building tree 71 of 600\n",
      "building tree 72 of 600\n",
      "building tree 73 of 600\n",
      "building tree 74 of 600\n",
      "building tree 75 of 600\n",
      "building tree 76 of 600\n",
      "building tree 77 of 600\n",
      "building tree 78 of 600\n",
      "building tree 79 of 600\n",
      "building tree 80 of 600\n",
      "building tree 81 of 600\n",
      "building tree 82 of 600\n",
      "building tree 83 of 600\n",
      "building tree 84 of 600\n",
      "building tree 85 of 600\n",
      "building tree 86 of 600\n",
      "building tree 87 of 600\n",
      "building tree 88 of 600\n",
      "building tree 89 of 600\n",
      "building tree 90 of 600\n",
      "building tree 91 of 600\n",
      "building tree 92 of 600\n",
      "building tree 93 of 600\n",
      "building tree 94 of 600\n",
      "building tree 95 of 600\n",
      "building tree 96 of 600\n",
      "building tree 97 of 600\n",
      "building tree 98 of 600\n",
      "building tree 99 of 600\n",
      "building tree 100 of 600\n",
      "building tree 101 of 600\n",
      "building tree 102 of 600\n",
      "building tree 103 of 600\n",
      "building tree 104 of 600\n",
      "building tree 105 of 600\n",
      "building tree 106 of 600\n",
      "building tree 107 of 600\n",
      "building tree 108 of 600\n",
      "building tree 109 of 600\n",
      "building tree 110 of 600\n",
      "building tree 111 of 600\n",
      "building tree 112 of 600\n",
      "building tree 113 of 600\n",
      "building tree 114 of 600\n",
      "building tree 115 of 600\n",
      "building tree 116 of 600\n",
      "building tree 117 of 600\n",
      "building tree 118 of 600\n",
      "building tree 119 of 600\n",
      "building tree 120 of 600\n",
      "building tree 121 of 600\n",
      "building tree 122 of 600\n",
      "building tree 123 of 600\n",
      "building tree 124 of 600\n",
      "building tree 125 of 600\n",
      "building tree 126 of 600\n",
      "building tree 127 of 600\n",
      "building tree 128 of 600\n",
      "building tree 129 of 600\n",
      "building tree 130 of 600\n",
      "building tree 131 of 600\n",
      "building tree 132 of 600\n",
      "building tree 133 of 600\n",
      "building tree 134 of 600\n",
      "building tree 135 of 600\n",
      "building tree 136 of 600\n",
      "building tree 137 of 600\n",
      "building tree 138 of 600\n",
      "building tree 139 of 600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 114 tasks      | elapsed:   17.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 140 of 600\n",
      "building tree 141 of 600\n",
      "building tree 142 of 600\n",
      "building tree 143 of 600\n",
      "building tree 144 of 600\n",
      "building tree 145 of 600\n",
      "building tree 146 of 600\n",
      "building tree 147 of 600\n",
      "building tree 148 of 600\n",
      "building tree 149 of 600\n",
      "building tree 150 of 600\n",
      "building tree 151 of 600\n",
      "building tree 152 of 600\n",
      "building tree 153 of 600\n",
      "building tree 154 of 600\n",
      "building tree 155 of 600\n",
      "building tree 156 of 600\n",
      "building tree 157 of 600\n",
      "building tree 158 of 600\n",
      "building tree 159 of 600\n",
      "building tree 160 of 600\n",
      "building tree 161 of 600\n",
      "building tree 162 of 600\n",
      "building tree 163 of 600\n",
      "building tree 164 of 600\n",
      "building tree 165 of 600\n",
      "building tree 166 of 600\n",
      "building tree 167 of 600\n",
      "building tree 168 of 600\n",
      "building tree 169 of 600\n",
      "building tree 170 of 600\n",
      "building tree 171 of 600\n",
      "building tree 172 of 600\n",
      "building tree 173 of 600\n",
      "building tree 174 of 600\n",
      "building tree 175 of 600\n",
      "building tree 176 of 600\n",
      "building tree 177 of 600\n",
      "building tree 178 of 600\n",
      "building tree 179 of 600\n",
      "building tree 180 of 600\n",
      "building tree 181 of 600\n",
      "building tree 182 of 600\n",
      "building tree 183 of 600\n",
      "building tree 184 of 600\n",
      "building tree 185 of 600\n",
      "building tree 186 of 600\n",
      "building tree 187 of 600\n",
      "building tree 188 of 600\n",
      "building tree 189 of 600\n",
      "building tree 190 of 600\n",
      "building tree 191 of 600\n",
      "building tree 192 of 600\n",
      "building tree 193 of 600\n",
      "building tree 194 of 600\n",
      "building tree 195 of 600\n",
      "building tree 196 of 600\n",
      "building tree 197 of 600\n",
      "building tree 198 of 600\n",
      "building tree 199 of 600\n",
      "building tree 200 of 600\n",
      "building tree 201 of 600\n",
      "building tree 202 of 600\n",
      "building tree 203 of 600\n",
      "building tree 204 of 600\n",
      "building tree 205 of 600\n",
      "building tree 206 of 600\n",
      "building tree 207 of 600\n",
      "building tree 208 of 600\n",
      "building tree 209 of 600\n",
      "building tree 210 of 600\n",
      "building tree 211 of 600\n",
      "building tree 212 of 600\n",
      "building tree 213 of 600\n",
      "building tree 214 of 600\n",
      "building tree 215 of 600\n",
      "building tree 216 of 600\n",
      "building tree 217 of 600\n",
      "building tree 218 of 600\n",
      "building tree 219 of 600\n",
      "building tree 220 of 600\n",
      "building tree 221 of 600\n",
      "building tree 222 of 600\n",
      "building tree 223 of 600\n",
      "building tree 224 of 600\n",
      "building tree 225 of 600\n",
      "building tree 226 of 600\n",
      "building tree 227 of 600\n",
      "building tree 228 of 600\n",
      "building tree 229 of 600\n",
      "building tree 230 of 600\n",
      "building tree 231 of 600\n",
      "building tree 232 of 600\n",
      "building tree 233 of 600\n",
      "building tree 234 of 600\n",
      "building tree 235 of 600\n",
      "building tree 236 of 600\n",
      "building tree 237 of 600\n",
      "building tree 238 of 600\n",
      "building tree 239 of 600\n",
      "building tree 240 of 600\n",
      "building tree 241 of 600\n",
      "building tree 242 of 600\n",
      "building tree 243 of 600\n",
      "building tree 244 of 600\n",
      "building tree 245 of 600\n",
      "building tree 246 of 600\n",
      "building tree 247 of 600\n",
      "building tree 248 of 600\n",
      "building tree 249 of 600\n",
      "building tree 250 of 600\n",
      "building tree 251 of 600\n",
      "building tree 252 of 600\n",
      "building tree 253 of 600\n",
      "building tree 254 of 600\n",
      "building tree 255 of 600\n",
      "building tree 256 of 600\n",
      "building tree 257 of 600\n",
      "building tree 258 of 600\n",
      "building tree 259 of 600\n",
      "building tree 260 of 600\n",
      "building tree 261 of 600\n",
      "building tree 262 of 600\n",
      "building tree 263 of 600\n",
      "building tree 264 of 600\n",
      "building tree 265 of 600\n",
      "building tree 266 of 600\n",
      "building tree 267 of 600\n",
      "building tree 268 of 600\n",
      "building tree 269 of 600\n",
      "building tree 270 of 600\n",
      "building tree 271 of 600\n",
      "building tree 272 of 600\n",
      "building tree 273 of 600\n",
      "building tree 274 of 600\n",
      "building tree 275 of 600\n",
      "building tree 276 of 600\n",
      "building tree 277 of 600\n",
      "building tree 278 of 600\n",
      "building tree 279 of 600\n",
      "building tree 280 of 600\n",
      "building tree 281 of 600\n",
      "building tree 282 of 600\n",
      "building tree 283 of 600\n",
      "building tree 284 of 600\n",
      "building tree 285 of 600\n",
      "building tree 286 of 600\n",
      "building tree 287 of 600\n",
      "building tree 288 of 600\n",
      "building tree 289 of 600\n",
      "building tree 290 of 600\n",
      "building tree 291 of 600\n",
      "building tree 292 of 600\n",
      "building tree 293 of 600\n",
      "building tree 294 of 600\n",
      "building tree 295 of 600\n",
      "building tree 296 of 600\n",
      "building tree 297 of 600\n",
      "building tree 298 of 600\n",
      "building tree 299 of 600\n",
      "building tree 300 of 600\n",
      "building tree 301 of 600\n",
      "building tree 302 of 600\n",
      "building tree 303 of 600\n",
      "building tree 304 of 600\n",
      "building tree 305 of 600\n",
      "building tree 306 of 600\n",
      "building tree 307 of 600\n",
      "building tree 308 of 600\n",
      "building tree 309 of 600\n",
      "building tree 310 of 600\n",
      "building tree 311 of 600\n",
      "building tree 312 of 600\n",
      "building tree 313 of 600\n",
      "building tree 314 of 600\n",
      "building tree 315 of 600\n",
      "building tree 316 of 600\n",
      "building tree 317 of 600\n",
      "building tree 318 of 600\n",
      "building tree 319 of 600\n",
      "building tree 320 of 600\n",
      "building tree 321 of 600\n",
      "building tree 322 of 600\n",
      "building tree 323 of 600\n",
      "building tree 324 of 600\n",
      "building tree 325 of 600\n",
      "building tree 326 of 600\n",
      "building tree 327 of 600\n",
      "building tree 328 of 600\n",
      "building tree 329 of 600\n",
      "building tree 330 of 600\n",
      "building tree 331 of 600\n",
      "building tree 332 of 600\n",
      "building tree 333 of 600\n",
      "building tree 334 of 600\n",
      "building tree 335 of 600\n",
      "building tree 336 of 600\n",
      "building tree 337 of 600\n",
      "building tree 338 of 600\n",
      "building tree 339 of 600\n",
      "building tree 340 of 600\n",
      "building tree 341 of 600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 317 tasks      | elapsed:   45.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 342 of 600\n",
      "building tree 343 of 600\n",
      "building tree 344 of 600\n",
      "building tree 345 of 600\n",
      "building tree 346 of 600\n",
      "building tree 347 of 600\n",
      "building tree 348 of 600\n",
      "building tree 349 of 600\n",
      "building tree 350 of 600\n",
      "building tree 351 of 600\n",
      "building tree 352 of 600\n",
      "building tree 353 of 600\n",
      "building tree 354 of 600\n",
      "building tree 355 of 600\n",
      "building tree 356 of 600\n",
      "building tree 357 of 600\n",
      "building tree 358 of 600\n",
      "building tree 359 of 600\n",
      "building tree 360 of 600\n",
      "building tree 361 of 600\n",
      "building tree 362 of 600\n",
      "building tree 363 of 600\n",
      "building tree 364 of 600\n",
      "building tree 365 of 600\n",
      "building tree 366 of 600\n",
      "building tree 367 of 600\n",
      "building tree 368 of 600\n",
      "building tree 369 of 600\n",
      "building tree 370 of 600\n",
      "building tree 371 of 600\n",
      "building tree 372 of 600\n",
      "building tree 373 of 600\n",
      "building tree 374 of 600\n",
      "building tree 375 of 600\n",
      "building tree 376 of 600\n",
      "building tree 377 of 600\n",
      "building tree 378 of 600\n",
      "building tree 379 of 600\n",
      "building tree 380 of 600\n",
      "building tree 381 of 600\n",
      "building tree 382 of 600\n",
      "building tree 383 of 600\n",
      "building tree 384 of 600\n",
      "building tree 385 of 600\n",
      "building tree 386 of 600\n",
      "building tree 387 of 600\n",
      "building tree 388 of 600\n",
      "building tree 389 of 600\n",
      "building tree 390 of 600\n",
      "building tree 391 of 600\n",
      "building tree 392 of 600\n",
      "building tree 393 of 600\n",
      "building tree 394 of 600\n",
      "building tree 395 of 600\n",
      "building tree 396 of 600\n",
      "building tree 397 of 600\n",
      "building tree 398 of 600\n",
      "building tree 399 of 600\n",
      "building tree 400 of 600\n",
      "building tree 401 of 600\n",
      "building tree 402 of 600\n",
      "building tree 403 of 600\n",
      "building tree 404 of 600\n",
      "building tree 405 of 600\n",
      "building tree 406 of 600\n",
      "building tree 407 of 600\n",
      "building tree 408 of 600\n",
      "building tree 409 of 600\n",
      "building tree 410 of 600\n",
      "building tree 411 of 600\n",
      "building tree 412 of 600\n",
      "building tree 413 of 600\n",
      "building tree 414 of 600\n",
      "building tree 415 of 600\n",
      "building tree 416 of 600\n",
      "building tree 417 of 600\n",
      "building tree 418 of 600\n",
      "building tree 419 of 600\n",
      "building tree 420 of 600\n",
      "building tree 421 of 600\n",
      "building tree 422 of 600\n",
      "building tree 423 of 600\n",
      "building tree 424 of 600\n",
      "building tree 425 of 600\n",
      "building tree 426 of 600\n",
      "building tree 427 of 600\n",
      "building tree 428 of 600\n",
      "building tree 429 of 600\n",
      "building tree 430 of 600\n",
      "building tree 431 of 600\n",
      "building tree 432 of 600\n",
      "building tree 433 of 600\n",
      "building tree 434 of 600\n",
      "building tree 435 of 600\n",
      "building tree 436 of 600\n",
      "building tree 437 of 600\n",
      "building tree 438 of 600\n",
      "building tree 439 of 600\n",
      "building tree 440 of 600\n",
      "building tree 441 of 600\n",
      "building tree 442 of 600\n",
      "building tree 443 of 600\n",
      "building tree 444 of 600\n",
      "building tree 445 of 600\n",
      "building tree 446 of 600\n",
      "building tree 447 of 600\n",
      "building tree 448 of 600\n",
      "building tree 449 of 600\n",
      "building tree 450 of 600\n",
      "building tree 451 of 600\n",
      "building tree 452 of 600\n",
      "building tree 453 of 600\n",
      "building tree 454 of 600\n",
      "building tree 455 of 600\n",
      "building tree 456 of 600\n",
      "building tree 457 of 600\n",
      "building tree 458 of 600\n",
      "building tree 459 of 600\n",
      "building tree 460 of 600\n",
      "building tree 461 of 600\n",
      "building tree 462 of 600\n",
      "building tree 463 of 600\n",
      "building tree 464 of 600\n",
      "building tree 465 of 600\n",
      "building tree 466 of 600\n",
      "building tree 467 of 600\n",
      "building tree 468 of 600\n",
      "building tree 469 of 600\n",
      "building tree 470 of 600\n",
      "building tree 471 of 600\n",
      "building tree 472 of 600\n",
      "building tree 473 of 600\n",
      "building tree 474 of 600\n",
      "building tree 475 of 600\n",
      "building tree 476 of 600\n",
      "building tree 477 of 600\n",
      "building tree 478 of 600\n",
      "building tree 479 of 600\n",
      "building tree 480 of 600\n",
      "building tree 481 of 600\n",
      "building tree 482 of 600\n",
      "building tree 483 of 600\n",
      "building tree 484 of 600\n",
      "building tree 485 of 600\n",
      "building tree 486 of 600\n",
      "building tree 487 of 600\n",
      "building tree 488 of 600\n",
      "building tree 489 of 600\n",
      "building tree 490 of 600\n",
      "building tree 491 of 600\n",
      "building tree 492 of 600\n",
      "building tree 493 of 600\n",
      "building tree 494 of 600\n",
      "building tree 495 of 600\n",
      "building tree 496 of 600\n",
      "building tree 497 of 600\n",
      "building tree 498 of 600\n",
      "building tree 499 of 600\n",
      "building tree 500 of 600\n",
      "building tree 501 of 600\n",
      "building tree 502 of 600\n",
      "building tree 503 of 600\n",
      "building tree 504 of 600\n",
      "building tree 505 of 600\n",
      "building tree 506 of 600\n",
      "building tree 507 of 600\n",
      "building tree 508 of 600\n",
      "building tree 509 of 600\n",
      "building tree 510 of 600\n",
      "building tree 511 of 600\n",
      "building tree 512 of 600\n",
      "building tree 513 of 600\n",
      "building tree 514 of 600\n",
      "building tree 515 of 600\n",
      "building tree 516 of 600\n",
      "building tree 517 of 600\n",
      "building tree 518 of 600\n",
      "building tree 519 of 600\n",
      "building tree 520 of 600\n",
      "building tree 521 of 600\n",
      "building tree 522 of 600\n",
      "building tree 523 of 600\n",
      "building tree 524 of 600\n",
      "building tree 525 of 600\n",
      "building tree 526 of 600\n",
      "building tree 527 of 600\n",
      "building tree 528 of 600\n",
      "building tree 529 of 600\n",
      "building tree 530 of 600\n",
      "building tree 531 of 600\n",
      "building tree 532 of 600\n",
      "building tree 533 of 600\n",
      "building tree 534 of 600\n",
      "building tree 535 of 600\n",
      "building tree 536 of 600\n",
      "building tree 537 of 600\n",
      "building tree 538 of 600\n",
      "building tree 539 of 600\n",
      "building tree 540 of 600\n",
      "building tree 541 of 600\n",
      "building tree 542 of 600\n",
      "building tree 543 of 600\n",
      "building tree 544 of 600\n",
      "building tree 545 of 600\n",
      "building tree 546 of 600\n",
      "building tree 547 of 600\n",
      "building tree 548 of 600\n",
      "building tree 549 of 600\n",
      "building tree 550 of 600\n",
      "building tree 551 of 600\n",
      "building tree 552 of 600\n",
      "building tree 553 of 600\n",
      "building tree 554 of 600\n",
      "building tree 555 of 600\n",
      "building tree 556 of 600\n",
      "building tree 557 of 600\n",
      "building tree 558 of 600\n",
      "building tree 559 of 600\n",
      "building tree 560 of 600\n",
      "building tree 561 of 600\n",
      "building tree 562 of 600\n",
      "building tree 563 of 600\n",
      "building tree 564 of 600\n",
      "building tree 565 of 600\n",
      "building tree 566 of 600\n",
      "building tree 567 of 600\n",
      "building tree 568 of 600\n",
      "building tree 569 of 600\n",
      "building tree 570 of 600\n",
      "building tree 571 of 600\n",
      "building tree 572 of 600\n",
      "building tree 573 of 600\n",
      "building tree 574 of 600\n",
      "building tree 575 of 600\n",
      "building tree 576 of 600\n",
      "building tree 577 of 600\n",
      "building tree 578 of 600\n",
      "building tree 579 of 600\n",
      "building tree 580 of 600\n",
      "building tree 581 of 600\n",
      "building tree 582 of 600\n",
      "building tree 583 of 600\n",
      "building tree 584 of 600\n",
      "building tree 585 of 600\n",
      "building tree 586 of 600\n",
      "building tree 587 of 600\n",
      "building tree 588 of 600\n",
      "building tree 589 of 600\n",
      "building tree 590 of 600\n",
      "building tree 591 of 600\n",
      "building tree 592 of 600\n",
      "building tree 593 of 600\n",
      "building tree 594 of 600\n",
      "building tree 595 of 600\n",
      "building tree 596 of 600\n",
      "building tree 597 of 600\n",
      "building tree 598 of 600\n",
      "building tree 599 of 600\n",
      "building tree 600 of 600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 600 out of 600 | elapsed:  1.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ipeirotis_fullba_dur fit complete\n",
      "Fitted model saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=24)]: Using backend ThreadingBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=24)]: Done 114 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=24)]: Done 317 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=24)]: Done 600 out of 600 | elapsed:    1.8s finished\n",
      "[Parallel(n_jobs=24)]: Using backend ThreadingBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=24)]: Done 114 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=24)]: Done 317 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=24)]: Done 600 out of 600 | elapsed:    1.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitAndPredict: 125.45697808265686 seconds\n",
      "0.8971990578092152\n",
      "*** B->A n-gram ML run\n",
      "# A obs: 146373\n",
      "# B obs: 146373\n",
      "# A_train obs: 117098\n",
      "# A_val obs: 29275\n",
      "# B_train obs: 117098\n",
      "# B_val obs: 29275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\1619589998.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  feature_df[\"title\"] = feature_df[\"title\"].astype(str)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Titles vectorized for train data\n",
      "(117098, 418112)\n",
      "Feature names saved to .\\ml_input\\feat_names_textlab_30_gramba.pkl\n",
      "Validation set titles vectorized\n",
      "(29275, 418112)\n",
      "Train rewards saved to .\\ml_input\\./train_rew_textlab_30_gramba.pkl\n",
      "Train durations saved to .\\ml_input\\./train_dur_textlab_30_gramba.pkl\n",
      "Train text features saved to .\\ml_input\\./train_txtfeats_textlab_30_gramba.pkl\n",
      "Training data saved\n",
      "Test rewards saved to .\\ml_input\\./test_rew_textlab_30_gramba.pkl\n",
      "Test durations saved to .\\ml_input\\./test_dur_textlab_30_gramba.pkl\n",
      "Test text features saved to .\\ml_input\\./test_txtfeats_textlab_30_gramba.pkl\n",
      "Validation data saved\n",
      "Textual features exported\n",
      "*** Train data: ***\n",
      "Features: (117098, 418112)\n",
      "Reward labels: (117098,)\n",
      "Duration labels: (117098,)\n",
      "*** Validation data: ***\n",
      "Features: (29275, 418112)\n",
      "Reward labels: (29275,)\n",
      "Duration labels: (29275,)\n",
      "Training data loaded\n",
      "Test data loaded\n",
      "----- [Running *reward* ML with text features] -----\n",
      "Running textlab_30_gramba_rew\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 24 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 40building tree 2 of 40\n",
      "\n",
      "building tree 3 of 40\n",
      "building tree 4 of 40\n",
      "building tree 5 of 40\n",
      "building tree 6 of 40\n",
      "building tree 7 of 40\n",
      "building tree 8 of 40\n",
      "building tree 9 of 40\n",
      "building tree 10 of 40\n",
      "building tree 11 of 40\n",
      "building tree 12 of 40\n",
      "building tree 13 of 40\n",
      "building tree 14 of 40\n",
      "building tree 15 of 40\n",
      "building tree 16 of 40\n",
      "building tree 17 of 40\n",
      "building tree 18 of 40\n",
      "building tree 19 of 40\n",
      "building tree 20 of 40\n",
      "building tree 21 of 40\n",
      "building tree 22 of 40\n",
      "building tree 23 of 40\n",
      "building tree 24 of 40\n",
      "building tree 25 of 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:  6.5min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 26 of 40\n",
      "building tree 27 of 40\n",
      "building tree 28 of 40\n",
      "building tree 29 of 40\n",
      "building tree 30 of 40\n",
      "building tree 31 of 40\n",
      "building tree 32 of 40\n",
      "building tree 33 of 40\n",
      "building tree 34 of 40\n",
      "building tree 35 of 40\n",
      "building tree 36 of 40\n",
      "building tree 37 of 40\n",
      "building tree 38 of 40\n",
      "building tree 39 of 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  14 out of  40 | elapsed:  6.8min remaining: 12.6min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 40 of 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  35 out of  40 | elapsed: 10.8min remaining:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed: 10.8min finished\n",
      "[Parallel(n_jobs=24)]: Using backend ThreadingBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=24)]: Done   1 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=24)]: Done  14 out of  40 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=24)]: Done  35 out of  40 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=24)]: Done  40 out of  40 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=24)]: Using backend ThreadingBackend with 24 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "textlab_30_gramba_rew fit complete\n",
      "Fitted model saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=24)]: Done   1 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=24)]: Done  14 out of  40 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=24)]: Done  35 out of  40 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=24)]: Done  40 out of  40 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 24 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitAndPredict: 650.3174576759338 seconds\n",
      "0.8559067924358515\n",
      "----- [Running *duration* ML with text features] -----\n",
      "Running textlab_30_gramba_dur\n",
      "building tree 1 of 40\n",
      "building tree 2 of 40\n",
      "building tree 3 of 40\n",
      "building tree 4 of 40\n",
      "building tree 5 of 40\n",
      "building tree 6 of 40\n",
      "building tree 7 of 40\n",
      "building tree 8 of 40\n",
      "building tree 9 of 40\n",
      "building tree 10 of 40\n",
      "building tree 11 of 40\n",
      "building tree 12 of 40\n",
      "building tree 13 of 40\n",
      "building tree 14 of 40\n",
      "building tree 15 of 40\n",
      "building tree 16 of 40\n",
      "building tree 17 of 40\n",
      "building tree 18 of 40\n",
      "building tree 19 of 40\n",
      "building tree 20 of 40\n",
      "building tree 21 of 40\n",
      "building tree 22 of 40\n",
      "building tree 23 of 40\n",
      "building tree 24 of 40\n",
      "building tree 25 of 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed: 12.8min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 26 of 40\n",
      "building tree 27 of 40\n",
      "building tree 28 of 40\n",
      "building tree 29 of 40\n",
      "building tree 30 of 40\n",
      "building tree 31 of 40\n",
      "building tree 32 of 40\n",
      "building tree 33 of 40\n",
      "building tree 34 of 40\n",
      "building tree 35 of 40\n",
      "building tree 36 of 40\n",
      "building tree 37 of 40\n",
      "building tree 38 of 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  14 out of  40 | elapsed: 13.4min remaining: 24.8min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 39 of 40\n",
      "building tree 40 of 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  35 out of  40 | elapsed: 21.6min remaining:  3.1min\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed: 21.8min finished\n",
      "[Parallel(n_jobs=24)]: Using backend ThreadingBackend with 24 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "textlab_30_gramba_dur fit complete\n",
      "Fitted model saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=24)]: Done   1 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=24)]: Done  14 out of  40 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=24)]: Done  35 out of  40 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=24)]: Done  40 out of  40 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=24)]: Using backend ThreadingBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=24)]: Done   1 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=24)]: Done  14 out of  40 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=24)]: Done  35 out of  40 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=24)]: Done  40 out of  40 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitAndPredict: 1309.2180652618408 seconds\n",
      "0.2625678748028928\n",
      "*** B->A computing most predictive features\n",
      "Generating most predictive features for dur\n",
      "Number of features: 418112\n",
      "Features outputted to: .\\predictive_feats\\predictive_textlab_30_gramba_dur.csv\n",
      "Generating most predictive features for rew\n",
      "Number of features: 418112\n",
      "Features outputted to: .\\predictive_feats\\predictive_textlab_30_gramba_rew.csv\n",
      "*** B->A full ML run\n",
      "# A obs: 146373\n",
      "# B obs: 146373\n",
      "# A_train obs: 117098\n",
      "# A_val obs: 29275\n",
      "# B_train obs: 117098\n",
      "# B_val obs: 29275\n",
      "Number of description features: 0\n",
      "Number of title features: 200\n",
      "Number of keyword features: 0\n",
      "Computing feature #0: easy\n",
      "Computing feature #1: transcribe\n",
      "Computing feature #2: writing\n",
      "Computing feature #3: audio\n",
      "Computing feature #4: image\n",
      "Computing feature #5: video\n",
      "Computing feature #6: bonus\n",
      "Computing feature #7: copy\n",
      "Computing feature #8: search\n",
      "Computing feature #9: identify\n",
      "Computing feature #10: text\n",
      "Computing feature #11: date\n",
      "Computing feature #12: fun\n",
      "Computing feature #13: simple\n",
      "Computing feature #14: summarize\n",
      "Computing feature #15: only\n",
      "Computing feature #16: improve\n",
      "Computing feature #17: five\n",
      "Computing feature #18: questionmark\n",
      "Computing feature #19: exclamation\n",
      "Computing feature #20: find\n",
      "Computing feature #21: check\n",
      "Computing feature #22: match\n",
      "Computing feature #23: choose\n",
      "Computing feature #24: categorize\n",
      "Computing feature #25: suggest\n",
      "Computing feature #26: translate\n",
      "Computing feature #27: survey\n",
      "Computing feature #28: click\n",
      "Computing feature #29: link\n",
      "Computing feature #30: read\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[\"minutes_title\"] = hit_df[\"title_lower\"].str.extract(minutes_reg,expand=False).fillna(0).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3226286950.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df.reset_index(inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDA features merged in\n",
      "Doc2Vec features merged in\n",
      "                                group_id  duration  log_duration  reward  \\\n",
      "292741  fffdae03eb029f2d8e60eabaa971adc2     240.0      5.480639     2.0   \n",
      "292742  ffff1d8b216a25a0619474b6a465dde5     120.0      4.787492   369.0   \n",
      "292743  ffff9f464f1e1d0a8c9e8588ce435e5e    5220.0      8.560253    15.0   \n",
      "292744  ffffc1d9b78826955e9687d8c6ca714a    2910.0      7.975908    60.0   \n",
      "292745  ffffc57feb6f5ee5ef5d95a54548bcc5     120.0      4.787492     2.0   \n",
      "\n",
      "        log_reward  meandiff_lreward  meandiff_ldur  time_allotted  \\\n",
      "292741    0.693147         -4.308529      -1.490776             60   \n",
      "292742    5.910797          0.909121      -2.183924             60   \n",
      "292743    2.708050         -0.105361      -0.034272             10   \n",
      "292744    4.094345          0.017075      -0.527354             60   \n",
      "292745    0.693147          0.000000      -0.406011              8   \n",
      "\n",
      "        first_hits  last_hits  ...  doc2vec_title_40  doc2vec_title_41  \\\n",
      "292741           0          0  ...          0.008363         -0.006260   \n",
      "292742           0          0  ...          0.046744         -0.016521   \n",
      "292743           0          0  ...          0.067740          0.000037   \n",
      "292744           6          1  ...          0.025640         -0.020772   \n",
      "292745           0          0  ...          0.052734          0.001159   \n",
      "\n",
      "        doc2vec_title_42  doc2vec_title_43  doc2vec_title_44  \\\n",
      "292741          0.010535         -0.010594          0.009250   \n",
      "292742         -0.011025         -0.000218          0.015323   \n",
      "292743          0.011005         -0.037205          0.072878   \n",
      "292744         -0.032470         -0.069878          0.104790   \n",
      "292745          0.001235         -0.012121          0.068618   \n",
      "\n",
      "        doc2vec_title_45  doc2vec_title_46  doc2vec_title_47  \\\n",
      "292741         -0.006053          0.009979          0.002506   \n",
      "292742          0.004408          0.012567         -0.036121   \n",
      "292743          0.005271          0.011413          0.006818   \n",
      "292744          0.038554         -0.040410         -0.041124   \n",
      "292745          0.000113         -0.031259         -0.027557   \n",
      "\n",
      "        doc2vec_title_48  doc2vec_title_49  \n",
      "292741          0.000179          0.002364  \n",
      "292742          0.005923         -0.054891  \n",
      "292743         -0.020776         -0.017559  \n",
      "292744          0.127619         -0.027586  \n",
      "292745          0.045267         -0.019086  \n",
      "\n",
      "[5 rows x 302 columns]\n",
      "avg_hitrate: 8007 nans, 0 infs\n",
      "Mean hitrate: 12.96194478684621\n",
      "Max hitrate: 42614.0\n",
      "Train rewards saved to .\\ml_input\\./train_rew_textlab_30_fullba.pkl\n",
      "Train durations saved to .\\ml_input\\./train_dur_textlab_30_fullba.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\2253851036.py:109: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_df.drop([col_name],axis=1,inplace=True)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\2253851036.py:109: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_df.drop([col_name],axis=1,inplace=True)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\2253851036.py:109: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_df.drop([col_name],axis=1,inplace=True)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\2253851036.py:109: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_df.drop([col_name],axis=1,inplace=True)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\2253851036.py:109: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_df.drop([col_name],axis=1,inplace=True)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\2253851036.py:109: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_df.drop([col_name],axis=1,inplace=True)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\2253851036.py:109: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_df.drop([col_name],axis=1,inplace=True)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\2253851036.py:136: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df.drop([col_name],axis=1,inplace=True)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\2253851036.py:136: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df.drop([col_name],axis=1,inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train features saved to .\\ml_input\\./train_feats_textlab_30_fullba.pkl\n",
      "Training data saved\n",
      "Test rewards saved to .\\ml_input\\./test_rew_textlab_30_fullba.pkl\n",
      "Test durations saved to .\\ml_input\\./test_dur_textlab_30_fullba.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\2253851036.py:136: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df.drop([col_name],axis=1,inplace=True)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\2253851036.py:136: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df.drop([col_name],axis=1,inplace=True)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\2253851036.py:136: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df.drop([col_name],axis=1,inplace=True)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\2253851036.py:136: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df.drop([col_name],axis=1,inplace=True)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\2253851036.py:136: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df.drop([col_name],axis=1,inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test features saved to .\\ml_input\\./test_feats_textlab_30_fullba.pkl\n",
      "Test data saved\n",
      "Training data dimensions: (146373, 245)\n",
      "Test data dimensions: (146373, 245)\n",
      "Training data loaded\n",
      "Test data loaded\n",
      "----- [Running *reward* ML with numeric features] -----\n",
      "Running textlab_30_fullba_rew\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 24 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 600\n",
      "building tree 2 of 600\n",
      "building tree 3 of 600\n",
      "building tree 4 of 600\n",
      "building tree 5 of 600\n",
      "building tree 6 of 600\n",
      "building tree 7 of 600\n",
      "building tree 8 of 600\n",
      "building tree 9 of 600\n",
      "building tree 10 of 600\n",
      "building tree 11 of 600\n",
      "building tree 12 of 600\n",
      "building tree 13 of 600\n",
      "building tree 14 of 600\n",
      "building tree 15 of 600\n",
      "building tree 16 of 600\n",
      "building tree 17 of 600\n",
      "building tree 18 of 600\n",
      "building tree 19 of 600\n",
      "building tree 20 of 600\n",
      "building tree 21 of 600\n",
      "building tree 22 of 600\n",
      "building tree 23 of 600\n",
      "building tree 24 of 600\n",
      "building tree 25 of 600\n",
      "building tree 26 of 600\n",
      "building tree 27 of 600\n",
      "building tree 28 of 600\n",
      "building tree 29 of 600\n",
      "building tree 30 of 600\n",
      "building tree 31 of 600\n",
      "building tree 32 of 600\n",
      "building tree 33 of 600\n",
      "building tree 34 of 600\n",
      "building tree 35 of 600\n",
      "building tree 36 of 600\n",
      "building tree 37 of 600\n",
      "building tree 38 of 600\n",
      "building tree 39 of 600\n",
      "building tree 40 of 600\n",
      "building tree 41 of 600\n",
      "building tree 42 of 600\n",
      "building tree 43 of 600\n",
      "building tree 44 of 600\n",
      "building tree 45 of 600\n",
      "building tree 46 of 600\n",
      "building tree 47 of 600\n",
      "building tree 48 of 600\n",
      "building tree 49 of 600\n",
      "building tree 50 of 600\n",
      "building tree 51 of 600\n",
      "building tree 52 of 600\n",
      "building tree 53 of 600\n",
      "building tree 54 of 600\n",
      "building tree 55 of 600\n",
      "building tree 56 of 600\n",
      "building tree 57 of 600\n",
      "building tree 58 of 600\n",
      "building tree 59 of 600\n",
      "building tree 60 of 600\n",
      "building tree 61 of 600\n",
      "building tree 62 of 600\n",
      "building tree 63 of 600\n",
      "building tree 64 of 600\n",
      "building tree 65 of 600\n",
      "building tree 66 of 600\n",
      "building tree 67 of 600\n",
      "building tree 68 of 600\n",
      "building tree 69 of 600\n",
      "building tree 70 of 600\n",
      "building tree 71 of 600\n",
      "building tree 72 of 600\n",
      "building tree 73 of 600\n",
      "building tree 74 of 600\n",
      "building tree 75 of 600\n",
      "building tree 76 of 600\n",
      "building tree 77 of 600\n",
      "building tree 78 of 600\n",
      "building tree 79 of 600\n",
      "building tree 80 of 600\n",
      "building tree 81 of 600\n",
      "building tree 82 of 600\n",
      "building tree 83 of 600\n",
      "building tree 84 of 600\n",
      "building tree 85 of 600\n",
      "building tree 86 of 600\n",
      "building tree 87 of 600\n",
      "building tree 88 of 600\n",
      "building tree 89 of 600\n",
      "building tree 90 of 600\n",
      "building tree 91 of 600\n",
      "building tree 92 of 600\n",
      "building tree 93 of 600\n",
      "building tree 94 of 600\n",
      "building tree 95 of 600\n",
      "building tree 96 of 600\n",
      "building tree 97 of 600\n",
      "building tree 98 of 600\n",
      "building tree 99 of 600\n",
      "building tree 100 of 600\n",
      "building tree 101 of 600\n",
      "building tree 102 of 600\n",
      "building tree 103 of 600\n",
      "building tree 104 of 600\n",
      "building tree 105 of 600\n",
      "building tree 106 of 600\n",
      "building tree 107 of 600\n",
      "building tree 108 of 600\n",
      "building tree 109 of 600\n",
      "building tree 110 of 600\n",
      "building tree 111 of 600\n",
      "building tree 112 of 600\n",
      "building tree 113 of 600\n",
      "building tree 114 of 600\n",
      "building tree 115 of 600\n",
      "building tree 116 of 600\n",
      "building tree 117 of 600\n",
      "building tree 118 of 600\n",
      "building tree 119 of 600\n",
      "building tree 120 of 600\n",
      "building tree 121 of 600\n",
      "building tree 122 of 600\n",
      "building tree 123 of 600\n",
      "building tree 124 of 600\n",
      "building tree 125 of 600\n",
      "building tree 126 of 600\n",
      "building tree 127 of 600\n",
      "building tree 128 of 600\n",
      "building tree 129 of 600\n",
      "building tree 130 of 600\n",
      "building tree 131 of 600\n",
      "building tree 132 of 600\n",
      "building tree 133 of 600\n",
      "building tree 134 of 600\n",
      "building tree 135 of 600\n",
      "building tree 136 of 600\n",
      "building tree 137 of 600\n",
      "building tree 138 of 600\n",
      "building tree 139 of 600\n",
      "building tree 140 of 600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 114 tasks      | elapsed:   11.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 141 of 600\n",
      "building tree 142 of 600\n",
      "building tree 143 of 600\n",
      "building tree 144 of 600\n",
      "building tree 145 of 600\n",
      "building tree 146 of 600\n",
      "building tree 147 of 600\n",
      "building tree 148 of 600\n",
      "building tree 149 of 600\n",
      "building tree 150 of 600\n",
      "building tree 151 of 600\n",
      "building tree 152 of 600\n",
      "building tree 153 of 600\n",
      "building tree 154 of 600\n",
      "building tree 155 of 600\n",
      "building tree 156 of 600\n",
      "building tree 157 of 600\n",
      "building tree 158 of 600\n",
      "building tree 159 of 600\n",
      "building tree 160 of 600\n",
      "building tree 161 of 600\n",
      "building tree 162 of 600\n",
      "building tree 163 of 600\n",
      "building tree 164 of 600\n",
      "building tree 165 of 600\n",
      "building tree 166 of 600\n",
      "building tree 167 of 600\n",
      "building tree 168 of 600\n",
      "building tree 169 of 600\n",
      "building tree 170 of 600\n",
      "building tree 171 of 600\n",
      "building tree 172 of 600\n",
      "building tree 173 of 600\n",
      "building tree 174 of 600\n",
      "building tree 175 of 600\n",
      "building tree 176 of 600\n",
      "building tree 177 of 600\n",
      "building tree 178 of 600\n",
      "building tree 179 of 600\n",
      "building tree 180 of 600\n",
      "building tree 181 of 600\n",
      "building tree 182 of 600\n",
      "building tree 183 of 600\n",
      "building tree 184 of 600\n",
      "building tree 185 of 600\n",
      "building tree 186 of 600\n",
      "building tree 187 of 600\n",
      "building tree 188 of 600\n",
      "building tree 189 of 600\n",
      "building tree 190 of 600\n",
      "building tree 191 of 600\n",
      "building tree 192 of 600\n",
      "building tree 193 of 600\n",
      "building tree 194 of 600\n",
      "building tree 195 of 600\n",
      "building tree 196 of 600\n",
      "building tree 197 of 600\n",
      "building tree 198 of 600building tree 199 of 600\n",
      "\n",
      "building tree 200 of 600\n",
      "building tree 201 of 600\n",
      "building tree 202 of 600\n",
      "building tree 203 of 600\n",
      "building tree 204 of 600\n",
      "building tree 205 of 600\n",
      "building tree 206 of 600\n",
      "building tree 207 of 600\n",
      "building tree 208 of 600\n",
      "building tree 209 of 600\n",
      "building tree 210 of 600\n",
      "building tree 211 of 600\n",
      "building tree 212 of 600\n",
      "building tree 213 of 600\n",
      "building tree 214 of 600\n",
      "building tree 215 of 600\n",
      "building tree 216 of 600\n",
      "building tree 217 of 600\n",
      "building tree 218 of 600\n",
      "building tree 219 of 600\n",
      "building tree 220 of 600\n",
      "building tree 221 of 600\n",
      "building tree 222 of 600\n",
      "building tree 223 of 600\n",
      "building tree 224 of 600\n",
      "building tree 225 of 600\n",
      "building tree 226 of 600\n",
      "building tree 227 of 600\n",
      "building tree 228 of 600\n",
      "building tree 229 of 600\n",
      "building tree 230 of 600\n",
      "building tree 231 of 600\n",
      "building tree 232 of 600\n",
      "building tree 233 of 600\n",
      "building tree 234 of 600\n",
      "building tree 235 of 600\n",
      "building tree 236 of 600\n",
      "building tree 237 of 600\n",
      "building tree 238 of 600\n",
      "building tree 239 of 600\n",
      "building tree 240 of 600\n",
      "building tree 241 of 600\n",
      "building tree 242 of 600\n",
      "building tree 243 of 600\n",
      "building tree 244 of 600\n",
      "building tree 245 of 600\n",
      "building tree 246 of 600\n",
      "building tree 247 of 600\n",
      "building tree 248 of 600\n",
      "building tree 249 of 600\n",
      "building tree 250 of 600\n",
      "building tree 251 of 600\n",
      "building tree 252 of 600\n",
      "building tree 253 of 600\n",
      "building tree 254 of 600\n",
      "building tree 255 of 600\n",
      "building tree 256 of 600\n",
      "building tree 257 of 600\n",
      "building tree 258 of 600\n",
      "building tree 259 of 600\n",
      "building tree 260 of 600\n",
      "building tree 261 of 600\n",
      "building tree 262 of 600\n",
      "building tree 263 of 600\n",
      "building tree 264 of 600\n",
      "building tree 265 of 600\n",
      "building tree 266 of 600\n",
      "building tree 267 of 600\n",
      "building tree 268 of 600\n",
      "building tree 269 of 600\n",
      "building tree 270 of 600\n",
      "building tree 271 of 600\n",
      "building tree 272 of 600\n",
      "building tree 273 of 600\n",
      "building tree 274 of 600\n",
      "building tree 275 of 600\n",
      "building tree 276 of 600\n",
      "building tree 277 of 600\n",
      "building tree 278 of 600\n",
      "building tree 279 of 600\n",
      "building tree 280 of 600\n",
      "building tree 281 of 600\n",
      "building tree 282 of 600\n",
      "building tree 283 of 600\n",
      "building tree 284 of 600\n",
      "building tree 285 of 600\n",
      "building tree 286 of 600\n",
      "building tree 287 of 600\n",
      "building tree 288 of 600\n",
      "building tree 289 of 600\n",
      "building tree 290 of 600\n",
      "building tree 291 of 600\n",
      "building tree 292 of 600\n",
      "building tree 293 of 600\n",
      "building tree 294 of 600\n",
      "building tree 295 of 600\n",
      "building tree 296 of 600\n",
      "building tree 297 of 600\n",
      "building tree 298 of 600\n",
      "building tree 299 of 600\n",
      "building tree 300 of 600\n",
      "building tree 301 of 600\n",
      "building tree 302 of 600\n",
      "building tree 303 of 600\n",
      "building tree 304 of 600\n",
      "building tree 305 of 600\n",
      "building tree 306 of 600\n",
      "building tree 307 of 600\n",
      "building tree 308 of 600\n",
      "building tree 309 of 600\n",
      "building tree 310 of 600\n",
      "building tree 311 of 600\n",
      "building tree 312 of 600\n",
      "building tree 313 of 600\n",
      "building tree 314 of 600\n",
      "building tree 315 of 600\n",
      "building tree 316 of 600\n",
      "building tree 317 of 600\n",
      "building tree 318 of 600\n",
      "building tree 319 of 600\n",
      "building tree 320 of 600\n",
      "building tree 321 of 600\n",
      "building tree 322 of 600\n",
      "building tree 323 of 600\n",
      "building tree 324 of 600\n",
      "building tree 325 of 600\n",
      "building tree 326 of 600\n",
      "building tree 327 of 600\n",
      "building tree 328 of 600\n",
      "building tree 329 of 600\n",
      "building tree 330 of 600\n",
      "building tree 331 of 600\n",
      "building tree 332 of 600\n",
      "building tree 333 of 600\n",
      "building tree 334 of 600\n",
      "building tree 335 of 600\n",
      "building tree 336 of 600\n",
      "building tree 337 of 600\n",
      "building tree 338 of 600\n",
      "building tree 339 of 600\n",
      "building tree 340 of 600\n",
      "building tree 341 of 600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 317 tasks      | elapsed:   31.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 342 of 600building tree 343 of 600\n",
      "\n",
      "building tree 344 of 600\n",
      "building tree 345 of 600\n",
      "building tree 346 of 600\n",
      "building tree 347 of 600\n",
      "building tree 348 of 600\n",
      "building tree 349 of 600\n",
      "building tree 350 of 600\n",
      "building tree 351 of 600\n",
      "building tree 352 of 600\n",
      "building tree 353 of 600\n",
      "building tree 354 of 600\n",
      "building tree 355 of 600\n",
      "building tree 356 of 600\n",
      "building tree 357 of 600\n",
      "building tree 358 of 600\n",
      "building tree 359 of 600\n",
      "building tree 360 of 600\n",
      "building tree 361 of 600\n",
      "building tree 362 of 600\n",
      "building tree 363 of 600\n",
      "building tree 364 of 600\n",
      "building tree 365 of 600\n",
      "building tree 366 of 600\n",
      "building tree 367 of 600\n",
      "building tree 368 of 600\n",
      "building tree 369 of 600\n",
      "building tree 370 of 600\n",
      "building tree 371 of 600\n",
      "building tree 372 of 600\n",
      "building tree 373 of 600\n",
      "building tree 374 of 600\n",
      "building tree 375 of 600\n",
      "building tree 376 of 600\n",
      "building tree 377 of 600\n",
      "building tree 378 of 600\n",
      "building tree 379 of 600\n",
      "building tree 380 of 600\n",
      "building tree 381 of 600\n",
      "building tree 382 of 600\n",
      "building tree 383 of 600\n",
      "building tree 384 of 600\n",
      "building tree 385 of 600\n",
      "building tree 386 of 600\n",
      "building tree 387 of 600\n",
      "building tree 388 of 600\n",
      "building tree 389 of 600\n",
      "building tree 390 of 600\n",
      "building tree 391 of 600\n",
      "building tree 392 of 600\n",
      "building tree 393 of 600\n",
      "building tree 394 of 600\n",
      "building tree 395 of 600\n",
      "building tree 396 of 600\n",
      "building tree 397 of 600\n",
      "building tree 398 of 600\n",
      "building tree 399 of 600\n",
      "building tree 400 of 600\n",
      "building tree 401 of 600\n",
      "building tree 402 of 600\n",
      "building tree 403 of 600\n",
      "building tree 404 of 600\n",
      "building tree 405 of 600\n",
      "building tree 406 of 600\n",
      "building tree 407 of 600\n",
      "building tree 408 of 600\n",
      "building tree 409 of 600\n",
      "building tree 410 of 600\n",
      "building tree 411 of 600\n",
      "building tree 412 of 600\n",
      "building tree 413 of 600\n",
      "building tree 414 of 600\n",
      "building tree 415 of 600\n",
      "building tree 416 of 600\n",
      "building tree 417 of 600\n",
      "building tree 418 of 600\n",
      "building tree 419 of 600\n",
      "building tree 420 of 600\n",
      "building tree 421 of 600\n",
      "building tree 422 of 600\n",
      "building tree 423 of 600\n",
      "building tree 424 of 600\n",
      "building tree 425 of 600\n",
      "building tree 426 of 600\n",
      "building tree 427 of 600\n",
      "building tree 428 of 600\n",
      "building tree 429 of 600\n",
      "building tree 430 of 600\n",
      "building tree 431 of 600\n",
      "building tree 432 of 600\n",
      "building tree 433 of 600\n",
      "building tree 434 of 600\n",
      "building tree 435 of 600\n",
      "building tree 436 of 600\n",
      "building tree 437 of 600\n",
      "building tree 438 of 600\n",
      "building tree 439 of 600\n",
      "building tree 440 of 600\n",
      "building tree 441 of 600\n",
      "building tree 442 of 600\n",
      "building tree 443 of 600\n",
      "building tree 444 of 600\n",
      "building tree 445 of 600\n",
      "building tree 446 of 600\n",
      "building tree 447 of 600\n",
      "building tree 448 of 600\n",
      "building tree 449 of 600\n",
      "building tree 450 of 600\n",
      "building tree 451 of 600\n",
      "building tree 452 of 600\n",
      "building tree 453 of 600\n",
      "building tree 454 of 600\n",
      "building tree 455 of 600\n",
      "building tree 456 of 600\n",
      "building tree 457 of 600\n",
      "building tree 458 of 600\n",
      "building tree 459 of 600\n",
      "building tree 460 of 600\n",
      "building tree 461 of 600\n",
      "building tree 462 of 600\n",
      "building tree 463 of 600\n",
      "building tree 464 of 600\n",
      "building tree 465 of 600\n",
      "building tree 466 of 600\n",
      "building tree 467 of 600\n",
      "building tree 468 of 600\n",
      "building tree 469 of 600\n",
      "building tree 470 of 600\n",
      "building tree 471 of 600\n",
      "building tree 472 of 600\n",
      "building tree 473 of 600\n",
      "building tree 474 of 600\n",
      "building tree 475 of 600\n",
      "building tree 476 of 600\n",
      "building tree 477 of 600\n",
      "building tree 478 of 600\n",
      "building tree 479 of 600\n",
      "building tree 480 of 600\n",
      "building tree 481 of 600\n",
      "building tree 482 of 600\n",
      "building tree 483 of 600\n",
      "building tree 484 of 600\n",
      "building tree 485 of 600\n",
      "building tree 486 of 600\n",
      "building tree 487 of 600\n",
      "building tree 488 of 600\n",
      "building tree 489 of 600\n",
      "building tree 490 of 600\n",
      "building tree 491 of 600\n",
      "building tree 492 of 600\n",
      "building tree 493 of 600\n",
      "building tree 494 of 600\n",
      "building tree 495 of 600\n",
      "building tree 496 of 600\n",
      "building tree 497 of 600\n",
      "building tree 498 of 600\n",
      "building tree 499 of 600\n",
      "building tree 500 of 600\n",
      "building tree 501 of 600\n",
      "building tree 502 of 600\n",
      "building tree 503 of 600\n",
      "building tree 504 of 600\n",
      "building tree 505 of 600\n",
      "building tree 506 of 600\n",
      "building tree 507 of 600\n",
      "building tree 508 of 600\n",
      "building tree 509 of 600\n",
      "building tree 510 of 600\n",
      "building tree 511 of 600\n",
      "building tree 512 of 600building tree 513 of 600\n",
      "\n",
      "building tree 514 of 600\n",
      "building tree 515 of 600\n",
      "building tree 516 of 600\n",
      "building tree 517 of 600\n",
      "building tree 518 of 600\n",
      "building tree 519 of 600\n",
      "building tree 520 of 600\n",
      "building tree 521 of 600\n",
      "building tree 522 of 600\n",
      "building tree 523 of 600\n",
      "building tree 524 of 600\n",
      "building tree 525 of 600\n",
      "building tree 526 of 600\n",
      "building tree 527 of 600\n",
      "building tree 528 of 600\n",
      "building tree 529 of 600\n",
      "building tree 530 of 600\n",
      "building tree 531 of 600\n",
      "building tree 532 of 600\n",
      "building tree 533 of 600\n",
      "building tree 534 of 600\n",
      "building tree 535 of 600\n",
      "building tree 536 of 600\n",
      "building tree 537 of 600\n",
      "building tree 538 of 600\n",
      "building tree 539 of 600\n",
      "building tree 540 of 600\n",
      "building tree 541 of 600\n",
      "building tree 542 of 600\n",
      "building tree 543 of 600\n",
      "building tree 544 of 600\n",
      "building tree 545 of 600\n",
      "building tree 546 of 600\n",
      "building tree 547 of 600\n",
      "building tree 548 of 600\n",
      "building tree 549 of 600\n",
      "building tree 550 of 600\n",
      "building tree 551 of 600\n",
      "building tree 552 of 600\n",
      "building tree 553 of 600\n",
      "building tree 554 of 600\n",
      "building tree 555 of 600\n",
      "building tree 556 of 600\n",
      "building tree 557 of 600\n",
      "building tree 558 of 600\n",
      "building tree 559 of 600\n",
      "building tree 560 of 600\n",
      "building tree 561 of 600\n",
      "building tree 562 of 600\n",
      "building tree 563 of 600\n",
      "building tree 564 of 600\n",
      "building tree 565 of 600\n",
      "building tree 566 of 600\n",
      "building tree 567 of 600\n",
      "building tree 568 of 600\n",
      "building tree 569 of 600\n",
      "building tree 570 of 600\n",
      "building tree 571 of 600\n",
      "building tree 572 of 600\n",
      "building tree 573 of 600\n",
      "building tree 574 of 600\n",
      "building tree 575 of 600\n",
      "building tree 576 of 600\n",
      "building tree 577 of 600\n",
      "building tree 578 of 600\n",
      "building tree 579 of 600\n",
      "building tree 580 of 600\n",
      "building tree 581 of 600\n",
      "building tree 582 of 600\n",
      "building tree 583 of 600\n",
      "building tree 584 of 600\n",
      "building tree 585 of 600\n",
      "building tree 586 of 600\n",
      "building tree 587 of 600\n",
      "building tree 588 of 600\n",
      "building tree 589 of 600\n",
      "building tree 590 of 600\n",
      "building tree 591 of 600\n",
      "building tree 592 of 600\n",
      "building tree 593 of 600\n",
      "building tree 594 of 600\n",
      "building tree 595 of 600\n",
      "building tree 596 of 600\n",
      "building tree 597 of 600\n",
      "building tree 598 of 600\n",
      "building tree 599 of 600\n",
      "building tree 600 of 600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 600 out of 600 | elapsed:   59.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "textlab_30_fullba_rew fit complete\n",
      "Fitted model saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=24)]: Using backend ThreadingBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=24)]: Done 114 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=24)]: Done 317 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=24)]: Done 600 out of 600 | elapsed:    1.6s finished\n",
      "[Parallel(n_jobs=24)]: Using backend ThreadingBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=24)]: Done 114 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=24)]: Done 317 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=24)]: Done 600 out of 600 | elapsed:    1.7s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 24 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitAndPredict: 87.16325283050537 seconds\n",
      "0.8944850863659228\n",
      "----- [Running *duration* ML with numeric features] -----\n",
      "Running textlab_30_fullba_dur\n",
      "building tree 1 of 600\n",
      "building tree 2 of 600\n",
      "building tree 3 of 600\n",
      "building tree 4 of 600\n",
      "building tree 5 of 600\n",
      "building tree 6 of 600\n",
      "building tree 7 of 600\n",
      "building tree 8 of 600\n",
      "building tree 9 of 600\n",
      "building tree 10 of 600\n",
      "building tree 11 of 600\n",
      "building tree 12 of 600\n",
      "building tree 13 of 600\n",
      "building tree 14 of 600\n",
      "building tree 15 of 600\n",
      "building tree 16 of 600\n",
      "building tree 17 of 600\n",
      "building tree 18 of 600\n",
      "building tree 19 of 600\n",
      "building tree 20 of 600\n",
      "building tree 21 of 600\n",
      "building tree 22 of 600\n",
      "building tree 23 of 600\n",
      "building tree 24 of 600\n",
      "building tree 25 of 600\n",
      "building tree 26 of 600\n",
      "building tree 27 of 600\n",
      "building tree 28 of 600\n",
      "building tree 29 of 600\n",
      "building tree 30 of 600\n",
      "building tree 31 of 600\n",
      "building tree 32 of 600\n",
      "building tree 33 of 600\n",
      "building tree 34 of 600\n",
      "building tree 35 of 600\n",
      "building tree 36 of 600\n",
      "building tree 37 of 600\n",
      "building tree 38 of 600\n",
      "building tree 39 of 600\n",
      "building tree 40 of 600\n",
      "building tree 41 of 600\n",
      "building tree 42 of 600\n",
      "building tree 43 of 600\n",
      "building tree 44 of 600\n",
      "building tree 45 of 600\n",
      "building tree 46 of 600\n",
      "building tree 47 of 600\n",
      "building tree 48 of 600\n",
      "building tree 49 of 600building tree 50 of 600\n",
      "\n",
      "building tree 51 of 600\n",
      "building tree 52 of 600\n",
      "building tree 53 of 600\n",
      "building tree 54 of 600\n",
      "building tree 55 of 600\n",
      "building tree 56 of 600\n",
      "building tree 57 of 600\n",
      "building tree 58 of 600\n",
      "building tree 59 of 600\n",
      "building tree 60 of 600\n",
      "building tree 61 of 600\n",
      "building tree 62 of 600\n",
      "building tree 63 of 600\n",
      "building tree 64 of 600\n",
      "building tree 65 of 600\n",
      "building tree 66 of 600\n",
      "building tree 67 of 600\n",
      "building tree 68 of 600\n",
      "building tree 69 of 600\n",
      "building tree 70 of 600\n",
      "building tree 71 of 600\n",
      "building tree 72 of 600\n",
      "building tree 73 of 600\n",
      "building tree 74 of 600\n",
      "building tree 75 of 600\n",
      "building tree 76 of 600\n",
      "building tree 77 of 600\n",
      "building tree 78 of 600\n",
      "building tree 79 of 600\n",
      "building tree 80 of 600\n",
      "building tree 81 of 600\n",
      "building tree 82 of 600\n",
      "building tree 83 of 600\n",
      "building tree 84 of 600\n",
      "building tree 85 of 600\n",
      "building tree 86 of 600\n",
      "building tree 87 of 600\n",
      "building tree 88 of 600\n",
      "building tree 89 of 600\n",
      "building tree 90 of 600\n",
      "building tree 91 of 600\n",
      "building tree 92 of 600\n",
      "building tree 93 of 600\n",
      "building tree 94 of 600\n",
      "building tree 95 of 600\n",
      "building tree 96 of 600\n",
      "building tree 97 of 600\n",
      "building tree 98 of 600\n",
      "building tree 99 of 600\n",
      "building tree 100 of 600\n",
      "building tree 101 of 600\n",
      "building tree 102 of 600\n",
      "building tree 103 of 600\n",
      "building tree 104 of 600\n",
      "building tree 105 of 600\n",
      "building tree 106 of 600\n",
      "building tree 107 of 600\n",
      "building tree 108 of 600\n",
      "building tree 109 of 600\n",
      "building tree 110 of 600\n",
      "building tree 111 of 600\n",
      "building tree 112 of 600\n",
      "building tree 113 of 600\n",
      "building tree 114 of 600\n",
      "building tree 115 of 600\n",
      "building tree 116 of 600\n",
      "building tree 117 of 600\n",
      "building tree 118 of 600\n",
      "building tree 119 of 600\n",
      "building tree 120 of 600\n",
      "building tree 121 of 600\n",
      "building tree 122 of 600\n",
      "building tree 123 of 600\n",
      "building tree 124 of 600\n",
      "building tree 125 of 600\n",
      "building tree 126 of 600\n",
      "building tree 127 of 600\n",
      "building tree 128 of 600\n",
      "building tree 129 of 600\n",
      "building tree 130 of 600\n",
      "building tree 131 of 600\n",
      "building tree 132 of 600\n",
      "building tree 133 of 600\n",
      "building tree 134 of 600\n",
      "building tree 135 of 600\n",
      "building tree 136 of 600\n",
      "building tree 137 of 600\n",
      "building tree 138 of 600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 114 tasks      | elapsed:   15.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 139 of 600\n",
      "building tree 140 of 600\n",
      "building tree 141 of 600\n",
      "building tree 142 of 600\n",
      "building tree 143 of 600\n",
      "building tree 144 of 600\n",
      "building tree 145 of 600\n",
      "building tree 146 of 600\n",
      "building tree 147 of 600\n",
      "building tree 148 of 600\n",
      "building tree 149 of 600\n",
      "building tree 150 of 600\n",
      "building tree 151 of 600\n",
      "building tree 152 of 600\n",
      "building tree 153 of 600\n",
      "building tree 154 of 600\n",
      "building tree 155 of 600\n",
      "building tree 156 of 600\n",
      "building tree 157 of 600\n",
      "building tree 158 of 600\n",
      "building tree 159 of 600\n",
      "building tree 160 of 600\n",
      "building tree 161 of 600\n",
      "building tree 162 of 600\n",
      "building tree 163 of 600\n",
      "building tree 164 of 600\n",
      "building tree 165 of 600\n",
      "building tree 166 of 600\n",
      "building tree 167 of 600\n",
      "building tree 168 of 600\n",
      "building tree 169 of 600\n",
      "building tree 170 of 600\n",
      "building tree 171 of 600\n",
      "building tree 172 of 600\n",
      "building tree 173 of 600\n",
      "building tree 174 of 600\n",
      "building tree 175 of 600\n",
      "building tree 176 of 600\n",
      "building tree 177 of 600\n",
      "building tree 178 of 600\n",
      "building tree 179 of 600\n",
      "building tree 180 of 600\n",
      "building tree 181 of 600\n",
      "building tree 182 of 600building tree 183 of 600\n",
      "\n",
      "building tree 184 of 600\n",
      "building tree 185 of 600\n",
      "building tree 186 of 600\n",
      "building tree 187 of 600\n",
      "building tree 188 of 600\n",
      "building tree 189 of 600\n",
      "building tree 190 of 600\n",
      "building tree 191 of 600\n",
      "building tree 192 of 600\n",
      "building tree 193 of 600\n",
      "building tree 194 of 600\n",
      "building tree 195 of 600\n",
      "building tree 196 of 600\n",
      "building tree 197 of 600\n",
      "building tree 198 of 600\n",
      "building tree 199 of 600\n",
      "building tree 200 of 600\n",
      "building tree 201 of 600\n",
      "building tree 202 of 600\n",
      "building tree 203 of 600\n",
      "building tree 204 of 600\n",
      "building tree 205 of 600\n",
      "building tree 206 of 600\n",
      "building tree 207 of 600\n",
      "building tree 208 of 600\n",
      "building tree 209 of 600\n",
      "building tree 210 of 600\n",
      "building tree 211 of 600\n",
      "building tree 212 of 600\n",
      "building tree 213 of 600\n",
      "building tree 214 of 600\n",
      "building tree 215 of 600\n",
      "building tree 216 of 600\n",
      "building tree 217 of 600\n",
      "building tree 218 of 600\n",
      "building tree 219 of 600\n",
      "building tree 220 of 600\n",
      "building tree 221 of 600\n",
      "building tree 222 of 600\n",
      "building tree 223 of 600\n",
      "building tree 224 of 600\n",
      "building tree 225 of 600\n",
      "building tree 226 of 600\n",
      "building tree 227 of 600\n",
      "building tree 228 of 600\n",
      "building tree 229 of 600\n",
      "building tree 230 of 600\n",
      "building tree 231 of 600\n",
      "building tree 232 of 600\n",
      "building tree 233 of 600\n",
      "building tree 234 of 600\n",
      "building tree 235 of 600\n",
      "building tree 236 of 600\n",
      "building tree 237 of 600\n",
      "building tree 238 of 600\n",
      "building tree 239 of 600\n",
      "building tree 240 of 600\n",
      "building tree 241 of 600\n",
      "building tree 242 of 600\n",
      "building tree 243 of 600\n",
      "building tree 244 of 600\n",
      "building tree 245 of 600\n",
      "building tree 246 of 600\n",
      "building tree 247 of 600\n",
      "building tree 248 of 600\n",
      "building tree 249 of 600\n",
      "building tree 250 of 600\n",
      "building tree 251 of 600\n",
      "building tree 252 of 600\n",
      "building tree 253 of 600\n",
      "building tree 254 of 600\n",
      "building tree 255 of 600\n",
      "building tree 256 of 600\n",
      "building tree 257 of 600\n",
      "building tree 258 of 600\n",
      "building tree 259 of 600\n",
      "building tree 260 of 600\n",
      "building tree 261 of 600\n",
      "building tree 262 of 600\n",
      "building tree 263 of 600\n",
      "building tree 264 of 600\n",
      "building tree 265 of 600\n",
      "building tree 266 of 600\n",
      "building tree 267 of 600\n",
      "building tree 268 of 600\n",
      "building tree 269 of 600\n",
      "building tree 270 of 600\n",
      "building tree 271 of 600\n",
      "building tree 272 of 600\n",
      "building tree 273 of 600\n",
      "building tree 274 of 600\n",
      "building tree 275 of 600\n",
      "building tree 276 of 600\n",
      "building tree 277 of 600\n",
      "building tree 278 of 600\n",
      "building tree 279 of 600\n",
      "building tree 280 of 600\n",
      "building tree 281 of 600\n",
      "building tree 282 of 600\n",
      "building tree 283 of 600\n",
      "building tree 284 of 600\n",
      "building tree 285 of 600\n",
      "building tree 286 of 600\n",
      "building tree 287 of 600\n",
      "building tree 288 of 600\n",
      "building tree 289 of 600\n",
      "building tree 290 of 600\n",
      "building tree 291 of 600\n",
      "building tree 292 of 600\n",
      "building tree 293 of 600\n",
      "building tree 294 of 600\n",
      "building tree 295 of 600\n",
      "building tree 296 of 600\n",
      "building tree 297 of 600\n",
      "building tree 298 of 600\n",
      "building tree 299 of 600\n",
      "building tree 300 of 600\n",
      "building tree 301 of 600\n",
      "building tree 302 of 600\n",
      "building tree 303 of 600\n",
      "building tree 304 of 600\n",
      "building tree 305 of 600\n",
      "building tree 306 of 600\n",
      "building tree 307 of 600\n",
      "building tree 308 of 600\n",
      "building tree 309 of 600\n",
      "building tree 310 of 600\n",
      "building tree 311 of 600\n",
      "building tree 312 of 600\n",
      "building tree 313 of 600\n",
      "building tree 314 of 600\n",
      "building tree 315 of 600\n",
      "building tree 316 of 600\n",
      "building tree 317 of 600\n",
      "building tree 318 of 600\n",
      "building tree 319 of 600\n",
      "building tree 320 of 600\n",
      "building tree 321 of 600\n",
      "building tree 322 of 600\n",
      "building tree 323 of 600\n",
      "building tree 324 of 600\n",
      "building tree 325 of 600\n",
      "building tree 326 of 600\n",
      "building tree 327 of 600\n",
      "building tree 328 of 600\n",
      "building tree 329 of 600\n",
      "building tree 330 of 600\n",
      "building tree 331 of 600\n",
      "building tree 332 of 600\n",
      "building tree 333 of 600\n",
      "building tree 334 of 600\n",
      "building tree 335 of 600\n",
      "building tree 336 of 600\n",
      "building tree 337 of 600\n",
      "building tree 338 of 600\n",
      "building tree 339 of 600\n",
      "building tree 340 of 600\n",
      "building tree 341 of 600\n",
      "building tree 342 of 600\n",
      "building tree 343 of 600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 317 tasks      | elapsed:   42.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 344 of 600\n",
      "building tree 345 of 600\n",
      "building tree 346 of 600\n",
      "building tree 347 of 600\n",
      "building tree 348 of 600\n",
      "building tree 349 of 600\n",
      "building tree 350 of 600\n",
      "building tree 351 of 600\n",
      "building tree 352 of 600\n",
      "building tree 353 of 600\n",
      "building tree 354 of 600\n",
      "building tree 355 of 600\n",
      "building tree 356 of 600\n",
      "building tree 357 of 600\n",
      "building tree 358 of 600\n",
      "building tree 359 of 600\n",
      "building tree 360 of 600\n",
      "building tree 361 of 600\n",
      "building tree 362 of 600\n",
      "building tree 363 of 600\n",
      "building tree 364 of 600\n",
      "building tree 365 of 600\n",
      "building tree 366 of 600\n",
      "building tree 367 of 600\n",
      "building tree 368 of 600\n",
      "building tree 369 of 600\n",
      "building tree 370 of 600\n",
      "building tree 371 of 600\n",
      "building tree 372 of 600\n",
      "building tree 373 of 600\n",
      "building tree 374 of 600\n",
      "building tree 375 of 600\n",
      "building tree 376 of 600\n",
      "building tree 377 of 600\n",
      "building tree 378 of 600\n",
      "building tree 379 of 600\n",
      "building tree 380 of 600\n",
      "building tree 381 of 600\n",
      "building tree 382 of 600\n",
      "building tree 383 of 600\n",
      "building tree 384 of 600\n",
      "building tree 385 of 600\n",
      "building tree 386 of 600\n",
      "building tree 387 of 600\n",
      "building tree 388 of 600\n",
      "building tree 389 of 600\n",
      "building tree 390 of 600\n",
      "building tree 391 of 600\n",
      "building tree 392 of 600\n",
      "building tree 393 of 600\n",
      "building tree 394 of 600\n",
      "building tree 395 of 600\n",
      "building tree 396 of 600\n",
      "building tree 397 of 600\n",
      "building tree 398 of 600\n",
      "building tree 399 of 600\n",
      "building tree 400 of 600\n",
      "building tree 401 of 600\n",
      "building tree 402 of 600\n",
      "building tree 403 of 600\n",
      "building tree 404 of 600\n",
      "building tree 405 of 600\n",
      "building tree 406 of 600\n",
      "building tree 407 of 600\n",
      "building tree 408 of 600\n",
      "building tree 409 of 600\n",
      "building tree 410 of 600\n",
      "building tree 411 of 600\n",
      "building tree 412 of 600\n",
      "building tree 413 of 600\n",
      "building tree 414 of 600\n",
      "building tree 415 of 600\n",
      "building tree 416 of 600\n",
      "building tree 417 of 600\n",
      "building tree 418 of 600\n",
      "building tree 419 of 600\n",
      "building tree 420 of 600\n",
      "building tree 421 of 600\n",
      "building tree 422 of 600\n",
      "building tree 423 of 600\n",
      "building tree 424 of 600\n",
      "building tree 425 of 600\n",
      "building tree 426 of 600\n",
      "building tree 427 of 600\n",
      "building tree 428 of 600\n",
      "building tree 429 of 600\n",
      "building tree 430 of 600\n",
      "building tree 431 of 600\n",
      "building tree 432 of 600\n",
      "building tree 433 of 600\n",
      "building tree 434 of 600\n",
      "building tree 435 of 600\n",
      "building tree 436 of 600\n",
      "building tree 437 of 600\n",
      "building tree 438 of 600\n",
      "building tree 439 of 600\n",
      "building tree 440 of 600\n",
      "building tree 441 of 600\n",
      "building tree 442 of 600\n",
      "building tree 443 of 600\n",
      "building tree 444 of 600\n",
      "building tree 445 of 600\n",
      "building tree 446 of 600\n",
      "building tree 447 of 600\n",
      "building tree 448 of 600\n",
      "building tree 449 of 600\n",
      "building tree 450 of 600\n",
      "building tree 451 of 600\n",
      "building tree 452 of 600\n",
      "building tree 453 of 600\n",
      "building tree 454 of 600\n",
      "building tree 455 of 600\n",
      "building tree 456 of 600\n",
      "building tree 457 of 600\n",
      "building tree 458 of 600\n",
      "building tree 459 of 600\n",
      "building tree 460 of 600\n",
      "building tree 461 of 600\n",
      "building tree 462 of 600\n",
      "building tree 463 of 600\n",
      "building tree 464 of 600\n",
      "building tree 465 of 600\n",
      "building tree 466 of 600\n",
      "building tree 467 of 600\n",
      "building tree 468 of 600\n",
      "building tree 469 of 600\n",
      "building tree 470 of 600\n",
      "building tree 471 of 600\n",
      "building tree 472 of 600\n",
      "building tree 473 of 600\n",
      "building tree 474 of 600\n",
      "building tree 475 of 600\n",
      "building tree 476 of 600\n",
      "building tree 477 of 600\n",
      "building tree 478 of 600\n",
      "building tree 479 of 600\n",
      "building tree 480 of 600\n",
      "building tree 481 of 600\n",
      "building tree 482 of 600\n",
      "building tree 483 of 600\n",
      "building tree 484 of 600\n",
      "building tree 485 of 600\n",
      "building tree 486 of 600\n",
      "building tree 487 of 600\n",
      "building tree 488 of 600\n",
      "building tree 489 of 600\n",
      "building tree 490 of 600\n",
      "building tree 491 of 600\n",
      "building tree 492 of 600\n",
      "building tree 493 of 600\n",
      "building tree 494 of 600\n",
      "building tree 495 of 600\n",
      "building tree 496 of 600\n",
      "building tree 497 of 600\n",
      "building tree 498 of 600\n",
      "building tree 499 of 600\n",
      "building tree 500 of 600\n",
      "building tree 501 of 600\n",
      "building tree 502 of 600\n",
      "building tree 503 of 600\n",
      "building tree 504 of 600\n",
      "building tree 505 of 600\n",
      "building tree 506 of 600\n",
      "building tree 507 of 600\n",
      "building tree 508 of 600\n",
      "building tree 509 of 600\n",
      "building tree 510 of 600\n",
      "building tree 511 of 600\n",
      "building tree 512 of 600\n",
      "building tree 513 of 600\n",
      "building tree 514 of 600\n",
      "building tree 515 of 600\n",
      "building tree 516 of 600\n",
      "building tree 517 of 600\n",
      "building tree 518 of 600\n",
      "building tree 519 of 600\n",
      "building tree 520 of 600\n",
      "building tree 521 of 600\n",
      "building tree 522 of 600\n",
      "building tree 523 of 600\n",
      "building tree 524 of 600\n",
      "building tree 525 of 600\n",
      "building tree 526 of 600\n",
      "building tree 527 of 600\n",
      "building tree 528 of 600\n",
      "building tree 529 of 600\n",
      "building tree 530 of 600\n",
      "building tree 531 of 600\n",
      "building tree 532 of 600\n",
      "building tree 533 of 600\n",
      "building tree 534 of 600\n",
      "building tree 535 of 600\n",
      "building tree 536 of 600\n",
      "building tree 537 of 600\n",
      "building tree 538 of 600\n",
      "building tree 539 of 600\n",
      "building tree 540 of 600\n",
      "building tree 541 of 600\n",
      "building tree 542 of 600\n",
      "building tree 543 of 600\n",
      "building tree 544 of 600\n",
      "building tree 545 of 600\n",
      "building tree 546 of 600\n",
      "building tree 547 of 600\n",
      "building tree 548 of 600\n",
      "building tree 549 of 600\n",
      "building tree 550 of 600\n",
      "building tree 551 of 600\n",
      "building tree 552 of 600\n",
      "building tree 553 of 600\n",
      "building tree 554 of 600\n",
      "building tree 555 of 600\n",
      "building tree 556 of 600\n",
      "building tree 557 of 600\n",
      "building tree 558 of 600building tree 559 of 600\n",
      "\n",
      "building tree 560 of 600\n",
      "building tree 561 of 600\n",
      "building tree 562 of 600\n",
      "building tree 563 of 600\n",
      "building tree 564 of 600\n",
      "building tree 565 of 600\n",
      "building tree 566 of 600\n",
      "building tree 567 of 600\n",
      "building tree 568 of 600\n",
      "building tree 569 of 600\n",
      "building tree 570 of 600\n",
      "building tree 571 of 600\n",
      "building tree 572 of 600\n",
      "building tree 573 of 600\n",
      "building tree 574 of 600\n",
      "building tree 575 of 600\n",
      "building tree 576 of 600\n",
      "building tree 577 of 600\n",
      "building tree 578 of 600\n",
      "building tree 579 of 600\n",
      "building tree 580 of 600\n",
      "building tree 581 of 600\n",
      "building tree 582 of 600\n",
      "building tree 583 of 600\n",
      "building tree 584 of 600\n",
      "building tree 585 of 600\n",
      "building tree 586 of 600\n",
      "building tree 587 of 600\n",
      "building tree 588 of 600\n",
      "building tree 589 of 600\n",
      "building tree 590 of 600\n",
      "building tree 591 of 600\n",
      "building tree 592 of 600\n",
      "building tree 593 of 600\n",
      "building tree 594 of 600\n",
      "building tree 595 of 600\n",
      "building tree 596 of 600\n",
      "building tree 597 of 600\n",
      "building tree 598 of 600\n",
      "building tree 599 of 600\n",
      "building tree 600 of 600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 600 out of 600 | elapsed:  1.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "textlab_30_fullba_dur fit complete\n",
      "Fitted model saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=24)]: Using backend ThreadingBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=24)]: Done 114 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=24)]: Done 317 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=24)]: Done 600 out of 600 | elapsed:    3.1s finished\n",
      "[Parallel(n_jobs=24)]: Using backend ThreadingBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=24)]: Done 114 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=24)]: Done 317 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=24)]: Done 600 out of 600 | elapsed:    3.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitAndPredict: 117.23593020439148 seconds\n",
      "0.44233408783918216\n",
      "*** B->A n-gram ML run\n",
      "# A obs: 46887\n",
      "# B obs: 46888\n",
      "# A_train obs: 37509\n",
      "# A_val obs: 9378\n",
      "# B_train obs: 37510\n",
      "# B_val obs: 9378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\1619589998.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  feature_df[\"description\"] = feature_df[\"description\"].astype(str)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\1619589998.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  feature_df[\"kw_parsed\"] = feature_df[\"kw_parsed\"].astype(str)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\1619589998.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  feature_df[\"title\"] = feature_df[\"title\"].astype(str)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descriptions vectorized for train data\n",
      "Keywords vectorized for train data\n",
      "Titles vectorized for train data\n",
      "(37510, 84971)\n",
      "(37510, 3531)\n",
      "(37510, 134509)\n",
      "Feature names saved to .\\ml_input\\feat_names_textlab_10_gramba.pkl\n",
      "Validation set descriptions vectorized\n",
      "Validation set keywords vectorized\n",
      "Validation set titles vectorized\n",
      "(9378, 84971)\n",
      "(9378, 3531)\n",
      "(9378, 134509)\n",
      "Train rewards saved to .\\ml_input\\./train_rew_textlab_10_gramba.pkl\n",
      "Train durations saved to .\\ml_input\\./train_dur_textlab_10_gramba.pkl\n",
      "Train text features saved to .\\ml_input\\./train_txtfeats_textlab_10_gramba.pkl\n",
      "Training data saved\n",
      "Test rewards saved to .\\ml_input\\./test_rew_textlab_10_gramba.pkl\n",
      "Test durations saved to .\\ml_input\\./test_dur_textlab_10_gramba.pkl\n",
      "Test text features saved to .\\ml_input\\./test_txtfeats_textlab_10_gramba.pkl\n",
      "Validation data saved\n",
      "Textual features exported\n",
      "*** Train data: ***\n",
      "Features: (37510, 223011)\n",
      "Reward labels: (37510,)\n",
      "Duration labels: (37510,)\n",
      "*** Validation data: ***\n",
      "Features: (9378, 223011)\n",
      "Reward labels: (9378,)\n",
      "Duration labels: (9378,)\n",
      "Training data loaded\n",
      "Test data loaded\n",
      "----- [Running *reward* ML with text features] -----\n",
      "Running textlab_10_gramba_rew\n",
      "building tree 1 of 40\n",
      "building tree 2 of 40\n",
      "building tree 3 of 40\n",
      "building tree 4 of 40\n",
      "building tree 5 of 40\n",
      "building tree 6 of 40\n",
      "building tree 7 of 40\n",
      "building tree 8 of 40\n",
      "building tree 9 of 40\n",
      "building tree 10 of 40\n",
      "building tree 11 of 40\n",
      "building tree 12 of 40\n",
      "building tree 13 of 40\n",
      "building tree 14 of 40\n",
      "building tree 15 of 40\n",
      "building tree 16 of 40\n",
      "building tree 17 of 40\n",
      "building tree 18 of 40\n",
      "building tree 19 of 40\n",
      "building tree 20 of 40\n",
      "building tree 21 of 40\n",
      "building tree 22 of 40\n",
      "building tree 23 of 40\n",
      "building tree 24 of 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 24 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 25 of 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:   35.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 26 of 40\n",
      "building tree 27 of 40\n",
      "building tree 28 of 40\n",
      "building tree 29 of 40\n",
      "building tree 30 of 40\n",
      "building tree 31 of 40\n",
      "building tree 32 of 40\n",
      "building tree 33 of 40\n",
      "building tree 34 of 40\n",
      "building tree 35 of 40\n",
      "building tree 36 of 40\n",
      "building tree 37 of 40\n",
      "building tree 38 of 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  14 out of  40 | elapsed:   40.6s remaining:  1.3min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 39 of 40\n",
      "building tree 40 of 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  35 out of  40 | elapsed:  1.2min remaining:    9.9s\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:  1.2min finished\n",
      "[Parallel(n_jobs=24)]: Using backend ThreadingBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=24)]: Done   1 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=24)]: Done  14 out of  40 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=24)]: Done  35 out of  40 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=24)]: Done  40 out of  40 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=24)]: Using backend ThreadingBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=24)]: Done   1 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=24)]: Done  14 out of  40 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=24)]: Done  35 out of  40 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=24)]: Done  40 out of  40 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 24 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "textlab_10_gramba_rew fit complete\n",
      "Fitted model saved\n",
      "fitAndPredict: 71.32107877731323 seconds\n",
      "0.8783569450346098\n",
      "----- [Running *duration* ML with text features] -----\n",
      "Running textlab_10_gramba_dur\n",
      "building tree 1 of 40\n",
      "building tree 2 of 40\n",
      "building tree 3 of 40\n",
      "building tree 4 of 40\n",
      "building tree 5 of 40\n",
      "building tree 6 of 40\n",
      "building tree 7 of 40\n",
      "building tree 8 of 40\n",
      "building tree 9 of 40\n",
      "building tree 10 of 40\n",
      "building tree 11 of 40\n",
      "building tree 12 of 40\n",
      "building tree 13 of 40\n",
      "building tree 14 of 40\n",
      "building tree 15 of 40\n",
      "building tree 16 of 40\n",
      "building tree 17 of 40\n",
      "building tree 18 of 40\n",
      "building tree 19 of 40\n",
      "building tree 20 of 40\n",
      "building tree 21 of 40\n",
      "building tree 22 of 40\n",
      "building tree 23 of 40\n",
      "building tree 24 of 40\n",
      "building tree 25 of 40\n",
      "building tree 26 of 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:  1.3min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 27 of 40\n",
      "building tree 28 of 40\n",
      "building tree 29 of 40\n",
      "building tree 30 of 40\n",
      "building tree 31 of 40\n",
      "building tree 32 of 40\n",
      "building tree 33 of 40\n",
      "building tree 34 of 40\n",
      "building tree 35 of 40\n",
      "building tree 36 of 40\n",
      "building tree 37 of 40\n",
      "building tree 38 of 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  14 out of  40 | elapsed:  1.4min remaining:  2.6min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 39 of 40\n",
      "building tree 40 of 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  35 out of  40 | elapsed:  2.5min remaining:   21.2s\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:  2.5min finished\n",
      "[Parallel(n_jobs=24)]: Using backend ThreadingBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=24)]: Done   1 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=24)]: Done  14 out of  40 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=24)]: Done  35 out of  40 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=24)]: Done  40 out of  40 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=24)]: Using backend ThreadingBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=24)]: Done   1 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=24)]: Done  14 out of  40 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=24)]: Done  35 out of  40 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=24)]: Done  40 out of  40 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "textlab_10_gramba_dur fit complete\n",
      "Fitted model saved\n",
      "fitAndPredict: 151.81178164482117 seconds\n",
      "0.37133279297204114\n",
      "*** B->A computing most predictive features\n",
      "Generating most predictive features for dur\n",
      "Number of features: 223011\n",
      "Features outputted to: .\\predictive_feats\\predictive_textlab_10_gramba_dur.csv\n",
      "Generating most predictive features for rew\n",
      "Number of features: 223011\n",
      "Features outputted to: .\\predictive_feats\\predictive_textlab_10_gramba_rew.csv\n",
      "*** B->A full ML run\n",
      "# A obs: 46887\n",
      "# B obs: 46888\n",
      "# A_train obs: 37509\n",
      "# A_val obs: 9378\n",
      "# B_train obs: 37510\n",
      "# B_val obs: 9378\n",
      "Number of description features: 54\n",
      "Number of title features: 101\n",
      "Number of keyword features: 45\n",
      "Computing feature #0: easy\n",
      "Computing feature #1: transcribe\n",
      "Computing feature #2: writing\n",
      "Computing feature #3: audio\n",
      "Computing feature #4: image\n",
      "Computing feature #5: video\n",
      "Computing feature #6: bonus\n",
      "Computing feature #7: copy\n",
      "Computing feature #8: search\n",
      "Computing feature #9: identify\n",
      "Computing feature #10: text\n",
      "Computing feature #11: date\n",
      "Computing feature #12: fun\n",
      "Computing feature #13: simple\n",
      "Computing feature #14: summarize\n",
      "Computing feature #15: only\n",
      "Computing feature #16: improve\n",
      "Computing feature #17: five\n",
      "Computing feature #18: questionmark\n",
      "Computing feature #19: exclamation\n",
      "Computing feature #20: find\n",
      "Computing feature #21: check\n",
      "Computing feature #22: match\n",
      "Computing feature #23: choose\n",
      "Computing feature #24: categorize\n",
      "Computing feature #25: suggest\n",
      "Computing feature #26: translate\n",
      "Computing feature #27: survey\n",
      "Computing feature #28: click\n",
      "Computing feature #29: link\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[kw_var] = (hit_df[\"kw_lower\"].str.count(str_to_search).fillna(0)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[kw_var] = (hit_df[\"kw_lower\"].str.count(str_to_search).fillna(0)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[kw_var] = (hit_df[\"kw_lower\"].str.count(str_to_search).fillna(0)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing feature #30: read\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[kw_var] = (hit_df[\"kw_lower\"].str.count(str_to_search).fillna(0)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[title_var] = (hit_df[\"title_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[desc_var] = (hit_df[\"desc_lower\"].str.count(str_to_search)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[kw_var] = (hit_df[\"kw_lower\"].str.count(str_to_search).fillna(0)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[kw_var] = (hit_df[\"kw_lower\"].str.count(str_to_search).fillna(0)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[kw_var] = (hit_df[\"kw_lower\"].str.count(str_to_search).fillna(0)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[kw_var] = (hit_df[\"kw_lower\"].str.count(str_to_search).fillna(0)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[kw_var] = (hit_df[\"kw_lower\"].str.count(str_to_search).fillna(0)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[kw_var] = (hit_df[\"kw_lower\"].str.count(str_to_search).fillna(0)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[kw_var] = (hit_df[\"kw_lower\"].str.count(str_to_search).fillna(0)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[kw_var] = (hit_df[\"kw_lower\"].str.count(str_to_search).fillna(0)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[kw_var] = (hit_df[\"kw_lower\"].str.count(str_to_search).fillna(0)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[kw_var] = (hit_df[\"kw_lower\"].str.count(str_to_search).fillna(0)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[kw_var] = (hit_df[\"kw_lower\"].str.count(str_to_search).fillna(0)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[kw_var] = (hit_df[\"kw_lower\"].str.count(str_to_search).fillna(0)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[kw_var] = (hit_df[\"kw_lower\"].str.count(str_to_search).fillna(0)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[kw_var] = (hit_df[\"kw_lower\"].str.count(str_to_search).fillna(0)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[kw_var] = (hit_df[\"kw_lower\"].str.count(str_to_search).fillna(0)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[kw_var] = (hit_df[\"kw_lower\"].str.count(str_to_search).fillna(0)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[kw_var] = (hit_df[\"kw_lower\"].str.count(str_to_search).fillna(0)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[kw_var] = (hit_df[\"kw_lower\"].str.count(str_to_search).fillna(0)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[kw_var] = (hit_df[\"kw_lower\"].str.count(str_to_search).fillna(0)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[kw_var] = (hit_df[\"kw_lower\"].str.count(str_to_search).fillna(0)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[kw_var] = (hit_df[\"kw_lower\"].str.count(str_to_search).fillna(0)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[kw_var] = (hit_df[\"kw_lower\"].str.count(str_to_search).fillna(0)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[kw_var] = (hit_df[\"kw_lower\"].str.count(str_to_search).fillna(0)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[kw_var] = (hit_df[\"kw_lower\"].str.count(str_to_search).fillna(0)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[kw_var] = (hit_df[\"kw_lower\"].str.count(str_to_search).fillna(0)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[kw_var] = (hit_df[\"kw_lower\"].str.count(str_to_search).fillna(0)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[kw_var] = (hit_df[\"kw_lower\"].str.count(str_to_search).fillna(0)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[kw_var] = (hit_df[\"kw_lower\"].str.count(str_to_search).fillna(0)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[kw_var] = (hit_df[\"kw_lower\"].str.count(str_to_search).fillna(0)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[kw_var] = (hit_df[\"kw_lower\"].str.count(str_to_search).fillna(0)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[kw_var] = (hit_df[\"kw_lower\"].str.count(str_to_search).fillna(0)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[kw_var] = (hit_df[\"kw_lower\"].str.count(str_to_search).fillna(0)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[kw_var] = (hit_df[\"kw_lower\"].str.count(str_to_search).fillna(0)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[kw_var] = (hit_df[\"kw_lower\"].str.count(str_to_search).fillna(0)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[kw_var] = (hit_df[\"kw_lower\"].str.count(str_to_search).fillna(0)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[kw_var] = (hit_df[\"kw_lower\"].str.count(str_to_search).fillna(0)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[kw_var] = (hit_df[\"kw_lower\"].str.count(str_to_search).fillna(0)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[kw_var] = (hit_df[\"kw_lower\"].str.count(str_to_search).fillna(0)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[kw_var] = (hit_df[\"kw_lower\"].str.count(str_to_search).fillna(0)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[kw_var] = (hit_df[\"kw_lower\"].str.count(str_to_search).fillna(0)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[kw_var] = (hit_df[\"kw_lower\"].str.count(str_to_search).fillna(0)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[kw_var] = (hit_df[\"kw_lower\"].str.count(str_to_search).fillna(0)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[kw_var] = (hit_df[\"kw_lower\"].str.count(str_to_search).fillna(0)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[kw_var] = (hit_df[\"kw_lower\"].str.count(str_to_search).fillna(0)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[kw_var] = (hit_df[\"kw_lower\"].str.count(str_to_search).fillna(0)).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[\"minutes_title\"] = hit_df[\"title_lower\"].str.extract(minutes_reg,expand=False).fillna(0).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:72: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[\"minutes_desc\"] = hit_df[\"desc_lower\"].str.extract(minutes_reg,expand=False).fillna(0).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3308281101.py:73: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df[\"minutes_kw\"] = hit_df[\"kw_lower\"].str.extract(minutes_reg,expand=False).fillna(0).astype(int)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\3226286950.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_df.reset_index(inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDA features merged in\n",
      "Doc2Vec features merged in\n",
      "                             group_id  duration  log_duration  reward  \\\n",
      "93770  3ZY19HV01BONLIR1KK5SXUJQHSGGS1   60950.0     11.017809    44.0   \n",
      "93771  3ZY19HV01BONLIR1KK5SXUJQHSIGS3   14720.0      9.596962    52.0   \n",
      "93772  3ZY19HV01BONLIR1KK5SXUJQIWEGS8   19640.0      9.885324    78.0   \n",
      "93773  3ZY19HV01BPM76GKCNBV9R7GD76SG1    5930.0      8.687779    10.0   \n",
      "93774  3ZY19HV01BSBSMWQ8SJ63FS1C9KSG5   32060.0     10.375364   350.0   \n",
      "\n",
      "       log_reward  meandiff_lreward  meandiff_ldur  time_allotted  first_hits  \\\n",
      "93770    3.784190          0.232745       0.775686             22           0   \n",
      "93771    3.951244          0.399799      -0.645160             26           0   \n",
      "93772    4.356709          0.805264      -0.356799             39           0   \n",
      "93773    2.302585         -0.370374       0.813040             60           0   \n",
      "93774    5.857933          0.292848      -0.045906            300           0   \n",
      "\n",
      "       last_hits  ...  doc2vec_kw_40  doc2vec_kw_41  doc2vec_kw_42  \\\n",
      "93770          0  ...       0.057277      -0.015378      -0.007566   \n",
      "93771          0  ...       0.017443      -0.010658      -0.000646   \n",
      "93772          0  ...       0.007987      -0.006276      -0.001892   \n",
      "93773          0  ...       0.046992      -0.037043      -0.037068   \n",
      "93774          0  ...       0.093032      -0.000971       0.027968   \n",
      "\n",
      "       doc2vec_kw_43  doc2vec_kw_44  doc2vec_kw_45  doc2vec_kw_46  \\\n",
      "93770      -0.017273       0.016873       0.014011      -0.060737   \n",
      "93771      -0.006335       0.012017       0.010868      -0.015269   \n",
      "93772      -0.001618       0.004430       0.010374       0.002604   \n",
      "93773      -0.033143       0.034212       0.039987      -0.030635   \n",
      "93774      -0.013535       0.063752       0.025086      -0.066204   \n",
      "\n",
      "       doc2vec_kw_47  doc2vec_kw_48  doc2vec_kw_49  \n",
      "93770      -0.027929       0.024993       0.004436  \n",
      "93771      -0.000832       0.005807      -0.006922  \n",
      "93772      -0.007765      -0.002077      -0.006186  \n",
      "93773      -0.028525       0.029824       0.042585  \n",
      "93774      -0.053561      -0.000151      -0.000190  \n",
      "\n",
      "[5 rows x 471 columns]\n",
      "avg_hitrate: 1822 nans, 0 infs\n",
      "Mean hitrate: 29.57481617676986\n",
      "Max hitrate: 81435.0\n",
      "Train rewards saved to .\\ml_input\\./train_rew_textlab_10_fullba.pkl\n",
      "Train durations saved to .\\ml_input\\./train_dur_textlab_10_fullba.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\2253851036.py:109: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_df.drop([col_name],axis=1,inplace=True)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\2253851036.py:109: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_df.drop([col_name],axis=1,inplace=True)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\2253851036.py:109: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_df.drop([col_name],axis=1,inplace=True)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\2253851036.py:109: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_df.drop([col_name],axis=1,inplace=True)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\2253851036.py:109: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_df.drop([col_name],axis=1,inplace=True)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\2253851036.py:109: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_df.drop([col_name],axis=1,inplace=True)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\2253851036.py:109: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_df.drop([col_name],axis=1,inplace=True)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\2253851036.py:136: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df.drop([col_name],axis=1,inplace=True)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\2253851036.py:136: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df.drop([col_name],axis=1,inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train features saved to .\\ml_input\\./train_feats_textlab_10_fullba.pkl\n",
      "Training data saved\n",
      "Test rewards saved to .\\ml_input\\./test_rew_textlab_10_fullba.pkl\n",
      "Test durations saved to .\\ml_input\\./test_dur_textlab_10_fullba.pkl\n",
      "Test features saved to .\\ml_input\\./test_feats_textlab_10_fullba.pkl\n",
      "Test data saved\n",
      "Training data dimensions: (46888, 314)\n",
      "Test data dimensions: (46887, 314)\n",
      "Training data loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\2253851036.py:136: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df.drop([col_name],axis=1,inplace=True)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\2253851036.py:136: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df.drop([col_name],axis=1,inplace=True)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\2253851036.py:136: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df.drop([col_name],axis=1,inplace=True)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\2253851036.py:136: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df.drop([col_name],axis=1,inplace=True)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\2253851036.py:136: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df.drop([col_name],axis=1,inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data loaded\n",
      "----- [Running *reward* ML with numeric features] -----\n",
      "Running textlab_10_fullba_rew\n",
      "building tree 1 of 600\n",
      "building tree 2 of 600\n",
      "building tree 3 of 600\n",
      "building tree 4 of 600\n",
      "building tree 5 of 600\n",
      "building tree 6 of 600\n",
      "building tree 7 of 600\n",
      "building tree 8 of 600\n",
      "building tree 9 of 600\n",
      "building tree 10 of 600\n",
      "building tree 11 of 600\n",
      "building tree 12 of 600\n",
      "building tree 13 of 600\n",
      "building tree 14 of 600\n",
      "building tree 15 of 600\n",
      "building tree 16 of 600\n",
      "building tree 17 of 600\n",
      "building tree 18 of 600\n",
      "building tree 19 of 600\n",
      "building tree 20 of 600\n",
      "building tree 21 of 600\n",
      "building tree 22 of 600\n",
      "building tree 23 of 600\n",
      "building tree 24 of 600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 24 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 25 of 600building tree 26 of 600\n",
      "\n",
      "building tree 27 of 600\n",
      "building tree 28 of 600\n",
      "building tree 29 of 600\n",
      "building tree 30 of 600\n",
      "building tree 31 of 600\n",
      "building tree 32 of 600\n",
      "building tree 33 of 600\n",
      "building tree 34 of 600\n",
      "building tree 35 of 600\n",
      "building tree 36 of 600\n",
      "building tree 37 of 600\n",
      "building tree 38 of 600\n",
      "building tree 39 of 600\n",
      "building tree 40 of 600\n",
      "building tree 41 of 600\n",
      "building tree 42 of 600\n",
      "building tree 43 of 600\n",
      "building tree 44 of 600\n",
      "building tree 45 of 600\n",
      "building tree 46 of 600\n",
      "building tree 47 of 600\n",
      "building tree 48 of 600\n",
      "building tree 49 of 600\n",
      "building tree 50 of 600\n",
      "building tree 51 of 600\n",
      "building tree 52 of 600\n",
      "building tree 53 of 600\n",
      "building tree 54 of 600\n",
      "building tree 55 of 600\n",
      "building tree 56 of 600\n",
      "building tree 57 of 600\n",
      "building tree 58 of 600\n",
      "building tree 59 of 600\n",
      "building tree 60 of 600\n",
      "building tree 61 of 600\n",
      "building tree 62 of 600\n",
      "building tree 63 of 600\n",
      "building tree 64 of 600\n",
      "building tree 65 of 600\n",
      "building tree 66 of 600\n",
      "building tree 67 of 600\n",
      "building tree 68 of 600\n",
      "building tree 69 of 600\n",
      "building tree 70 of 600\n",
      "building tree 71 of 600\n",
      "building tree 72 of 600\n",
      "building tree 73 of 600\n",
      "building tree 74 of 600\n",
      "building tree 75 of 600\n",
      "building tree 76 of 600\n",
      "building tree 77 of 600\n",
      "building tree 78 of 600\n",
      "building tree 79 of 600\n",
      "building tree 80 of 600\n",
      "building tree 81 of 600\n",
      "building tree 82 of 600\n",
      "building tree 83 of 600\n",
      "building tree 84 of 600\n",
      "building tree 85 of 600\n",
      "building tree 86 of 600\n",
      "building tree 87 of 600\n",
      "building tree 88 of 600\n",
      "building tree 89 of 600\n",
      "building tree 90 of 600\n",
      "building tree 91 of 600\n",
      "building tree 92 of 600\n",
      "building tree 93 of 600\n",
      "building tree 94 of 600\n",
      "building tree 95 of 600\n",
      "building tree 96 of 600\n",
      "building tree 97 of 600\n",
      "building tree 98 of 600\n",
      "building tree 99 of 600\n",
      "building tree 100 of 600\n",
      "building tree 101 of 600\n",
      "building tree 102 of 600\n",
      "building tree 103 of 600\n",
      "building tree 104 of 600\n",
      "building tree 105 of 600\n",
      "building tree 106 of 600\n",
      "building tree 107 of 600\n",
      "building tree 108 of 600\n",
      "building tree 109 of 600\n",
      "building tree 110 of 600\n",
      "building tree 111 of 600\n",
      "building tree 112 of 600\n",
      "building tree 113 of 600\n",
      "building tree 114 of 600\n",
      "building tree 115 of 600\n",
      "building tree 116 of 600\n",
      "building tree 117 of 600\n",
      "building tree 118 of 600\n",
      "building tree 119 of 600\n",
      "building tree 120 of 600\n",
      "building tree 121 of 600\n",
      "building tree 122 of 600\n",
      "building tree 123 of 600\n",
      "building tree 124 of 600\n",
      "building tree 125 of 600\n",
      "building tree 126 of 600\n",
      "building tree 127 of 600\n",
      "building tree 128 of 600\n",
      "building tree 129 of 600\n",
      "building tree 130 of 600\n",
      "building tree 131 of 600\n",
      "building tree 132 of 600\n",
      "building tree 133 of 600\n",
      "building tree 134 of 600\n",
      "building tree 135 of 600\n",
      "building tree 136 of 600\n",
      "building tree 137 of 600\n",
      "building tree 138 of 600\n",
      "building tree 139 of 600\n",
      "building tree 140 of 600\n",
      "building tree 141 of 600\n",
      "building tree 142 of 600\n",
      "building tree 143 of 600\n",
      "building tree 144 of 600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 114 tasks      | elapsed:    2.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 145 of 600\n",
      "building tree 146 of 600\n",
      "building tree 147 of 600\n",
      "building tree 148 of 600\n",
      "building tree 149 of 600\n",
      "building tree 150 of 600\n",
      "building tree 151 of 600\n",
      "building tree 152 of 600\n",
      "building tree 153 of 600\n",
      "building tree 154 of 600\n",
      "building tree 155 of 600\n",
      "building tree 156 of 600\n",
      "building tree 157 of 600\n",
      "building tree 158 of 600\n",
      "building tree 159 of 600\n",
      "building tree 160 of 600\n",
      "building tree 161 of 600\n",
      "building tree 162 of 600\n",
      "building tree 163 of 600\n",
      "building tree 164 of 600\n",
      "building tree 165 of 600\n",
      "building tree 166 of 600\n",
      "building tree 167 of 600\n",
      "building tree 168 of 600\n",
      "building tree 169 of 600\n",
      "building tree 170 of 600\n",
      "building tree 171 of 600\n",
      "building tree 172 of 600\n",
      "building tree 173 of 600\n",
      "building tree 174 of 600\n",
      "building tree 175 of 600\n",
      "building tree 176 of 600\n",
      "building tree 177 of 600\n",
      "building tree 178 of 600\n",
      "building tree 179 of 600\n",
      "building tree 180 of 600\n",
      "building tree 181 of 600\n",
      "building tree 182 of 600\n",
      "building tree 183 of 600\n",
      "building tree 184 of 600\n",
      "building tree 185 of 600\n",
      "building tree 186 of 600\n",
      "building tree 187 of 600\n",
      "building tree 188 of 600\n",
      "building tree 189 of 600\n",
      "building tree 190 of 600\n",
      "building tree 191 of 600\n",
      "building tree 192 of 600\n",
      "building tree 193 of 600\n",
      "building tree 194 of 600\n",
      "building tree 195 of 600\n",
      "building tree 196 of 600\n",
      "building tree 197 of 600\n",
      "building tree 198 of 600\n",
      "building tree 199 of 600\n",
      "building tree 200 of 600\n",
      "building tree 201 of 600\n",
      "building tree 202 of 600\n",
      "building tree 203 of 600\n",
      "building tree 204 of 600\n",
      "building tree 205 of 600\n",
      "building tree 206 of 600\n",
      "building tree 207 of 600\n",
      "building tree 208 of 600\n",
      "building tree 209 of 600\n",
      "building tree 210 of 600\n",
      "building tree 211 of 600\n",
      "building tree 212 of 600\n",
      "building tree 213 of 600\n",
      "building tree 214 of 600\n",
      "building tree 215 of 600\n",
      "building tree 216 of 600\n",
      "building tree 217 of 600\n",
      "building tree 218 of 600\n",
      "building tree 219 of 600\n",
      "building tree 220 of 600\n",
      "building tree 221 of 600\n",
      "building tree 222 of 600\n",
      "building tree 223 of 600\n",
      "building tree 224 of 600\n",
      "building tree 225 of 600\n",
      "building tree 226 of 600\n",
      "building tree 227 of 600\n",
      "building tree 228 of 600\n",
      "building tree 229 of 600\n",
      "building tree 230 of 600\n",
      "building tree 231 of 600\n",
      "building tree 232 of 600\n",
      "building tree 233 of 600\n",
      "building tree 234 of 600\n",
      "building tree 235 of 600\n",
      "building tree 236 of 600\n",
      "building tree 237 of 600\n",
      "building tree 238 of 600\n",
      "building tree 239 of 600\n",
      "building tree 240 of 600\n",
      "building tree 241 of 600\n",
      "building tree 242 of 600\n",
      "building tree 243 of 600\n",
      "building tree 244 of 600\n",
      "building tree 245 of 600\n",
      "building tree 246 of 600\n",
      "building tree 247 of 600\n",
      "building tree 248 of 600\n",
      "building tree 249 of 600\n",
      "building tree 250 of 600\n",
      "building tree 251 of 600\n",
      "building tree 252 of 600\n",
      "building tree 253 of 600\n",
      "building tree 254 of 600\n",
      "building tree 255 of 600\n",
      "building tree 256 of 600\n",
      "building tree 257 of 600\n",
      "building tree 258 of 600\n",
      "building tree 259 of 600\n",
      "building tree 260 of 600\n",
      "building tree 261 of 600\n",
      "building tree 262 of 600\n",
      "building tree 263 of 600\n",
      "building tree 264 of 600\n",
      "building tree 265 of 600\n",
      "building tree 266 of 600\n",
      "building tree 267 of 600\n",
      "building tree 268 of 600\n",
      "building tree 269 of 600\n",
      "building tree 270 of 600\n",
      "building tree 271 of 600\n",
      "building tree 272 of 600\n",
      "building tree 273 of 600\n",
      "building tree 274 of 600\n",
      "building tree 275 of 600\n",
      "building tree 276 of 600\n",
      "building tree 277 of 600\n",
      "building tree 278 of 600\n",
      "building tree 279 of 600\n",
      "building tree 280 of 600\n",
      "building tree 281 of 600\n",
      "building tree 282 of 600\n",
      "building tree 283 of 600\n",
      "building tree 284 of 600\n",
      "building tree 285 of 600\n",
      "building tree 286 of 600\n",
      "building tree 287 of 600\n",
      "building tree 288 of 600\n",
      "building tree 289 of 600\n",
      "building tree 290 of 600\n",
      "building tree 291 of 600\n",
      "building tree 292 of 600\n",
      "building tree 293 of 600\n",
      "building tree 294 of 600\n",
      "building tree 295 of 600\n",
      "building tree 296 of 600\n",
      "building tree 297 of 600\n",
      "building tree 298 of 600\n",
      "building tree 299 of 600\n",
      "building tree 300 of 600\n",
      "building tree 301 of 600\n",
      "building tree 302 of 600\n",
      "building tree 303 of 600\n",
      "building tree 304 of 600\n",
      "building tree 305 of 600\n",
      "building tree 306 of 600\n",
      "building tree 307 of 600\n",
      "building tree 308 of 600\n",
      "building tree 309 of 600\n",
      "building tree 310 of 600\n",
      "building tree 311 of 600\n",
      "building tree 312 of 600\n",
      "building tree 313 of 600\n",
      "building tree 314 of 600\n",
      "building tree 315 of 600\n",
      "building tree 316 of 600\n",
      "building tree 317 of 600\n",
      "building tree 318 of 600\n",
      "building tree 319 of 600\n",
      "building tree 320 of 600\n",
      "building tree 321 of 600\n",
      "building tree 322 of 600\n",
      "building tree 323 of 600\n",
      "building tree 324 of 600\n",
      "building tree 325 of 600\n",
      "building tree 326 of 600\n",
      "building tree 327 of 600\n",
      "building tree 328 of 600\n",
      "building tree 329 of 600\n",
      "building tree 330 of 600\n",
      "building tree 331 of 600\n",
      "building tree 332 of 600\n",
      "building tree 333 of 600\n",
      "building tree 334 of 600\n",
      "building tree 335 of 600\n",
      "building tree 336 of 600\n",
      "building tree 337 of 600\n",
      "building tree 338 of 600\n",
      "building tree 339 of 600\n",
      "building tree 340 of 600\n",
      "building tree 341 of 600\n",
      "building tree 342 of 600\n",
      "building tree 343 of 600\n",
      "building tree 344 of 600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 317 tasks      | elapsed:    7.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 345 of 600\n",
      "building tree 346 of 600\n",
      "building tree 347 of 600\n",
      "building tree 348 of 600\n",
      "building tree 349 of 600\n",
      "building tree 350 of 600\n",
      "building tree 351 of 600\n",
      "building tree 352 of 600\n",
      "building tree 353 of 600\n",
      "building tree 354 of 600\n",
      "building tree 355 of 600\n",
      "building tree 356 of 600\n",
      "building tree 357 of 600\n",
      "building tree 358 of 600\n",
      "building tree 359 of 600\n",
      "building tree 360 of 600\n",
      "building tree 361 of 600\n",
      "building tree 362 of 600\n",
      "building tree 363 of 600\n",
      "building tree 364 of 600\n",
      "building tree 365 of 600\n",
      "building tree 366 of 600\n",
      "building tree 367 of 600\n",
      "building tree 368 of 600\n",
      "building tree 369 of 600\n",
      "building tree 370 of 600\n",
      "building tree 371 of 600\n",
      "building tree 372 of 600\n",
      "building tree 373 of 600\n",
      "building tree 374 of 600\n",
      "building tree 375 of 600\n",
      "building tree 376 of 600\n",
      "building tree 377 of 600\n",
      "building tree 378 of 600\n",
      "building tree 379 of 600\n",
      "building tree 380 of 600\n",
      "building tree 381 of 600\n",
      "building tree 382 of 600\n",
      "building tree 383 of 600\n",
      "building tree 384 of 600\n",
      "building tree 385 of 600\n",
      "building tree 386 of 600\n",
      "building tree 387 of 600\n",
      "building tree 388 of 600\n",
      "building tree 389 of 600\n",
      "building tree 390 of 600\n",
      "building tree 391 of 600\n",
      "building tree 392 of 600\n",
      "building tree 393 of 600\n",
      "building tree 394 of 600\n",
      "building tree 395 of 600\n",
      "building tree 396 of 600\n",
      "building tree 397 of 600\n",
      "building tree 398 of 600\n",
      "building tree 399 of 600\n",
      "building tree 400 of 600\n",
      "building tree 401 of 600\n",
      "building tree 402 of 600\n",
      "building tree 403 of 600\n",
      "building tree 404 of 600\n",
      "building tree 405 of 600\n",
      "building tree 406 of 600\n",
      "building tree 407 of 600\n",
      "building tree 408 of 600\n",
      "building tree 409 of 600\n",
      "building tree 410 of 600\n",
      "building tree 411 of 600\n",
      "building tree 412 of 600\n",
      "building tree 413 of 600\n",
      "building tree 414 of 600\n",
      "building tree 415 of 600\n",
      "building tree 416 of 600\n",
      "building tree 417 of 600\n",
      "building tree 418 of 600\n",
      "building tree 419 of 600\n",
      "building tree 420 of 600\n",
      "building tree 421 of 600\n",
      "building tree 422 of 600\n",
      "building tree 423 of 600\n",
      "building tree 424 of 600\n",
      "building tree 425 of 600\n",
      "building tree 426 of 600\n",
      "building tree 427 of 600\n",
      "building tree 428 of 600\n",
      "building tree 429 of 600\n",
      "building tree 430 of 600\n",
      "building tree 431 of 600\n",
      "building tree 432 of 600\n",
      "building tree 433 of 600\n",
      "building tree 434 of 600\n",
      "building tree 435 of 600\n",
      "building tree 436 of 600\n",
      "building tree 437 of 600\n",
      "building tree 438 of 600\n",
      "building tree 439 of 600\n",
      "building tree 440 of 600\n",
      "building tree 441 of 600\n",
      "building tree 442 of 600\n",
      "building tree 443 of 600\n",
      "building tree 444 of 600\n",
      "building tree 445 of 600\n",
      "building tree 446 of 600\n",
      "building tree 447 of 600\n",
      "building tree 448 of 600\n",
      "building tree 449 of 600\n",
      "building tree 450 of 600\n",
      "building tree 451 of 600\n",
      "building tree 452 of 600\n",
      "building tree 453 of 600\n",
      "building tree 454 of 600\n",
      "building tree 455 of 600\n",
      "building tree 456 of 600\n",
      "building tree 457 of 600\n",
      "building tree 458 of 600\n",
      "building tree 459 of 600\n",
      "building tree 460 of 600\n",
      "building tree 461 of 600\n",
      "building tree 462 of 600\n",
      "building tree 463 of 600\n",
      "building tree 464 of 600\n",
      "building tree 465 of 600\n",
      "building tree 466 of 600\n",
      "building tree 467 of 600\n",
      "building tree 468 of 600\n",
      "building tree 469 of 600\n",
      "building tree 470 of 600\n",
      "building tree 471 of 600\n",
      "building tree 472 of 600\n",
      "building tree 473 of 600\n",
      "building tree 474 of 600\n",
      "building tree 475 of 600\n",
      "building tree 476 of 600\n",
      "building tree 477 of 600\n",
      "building tree 478 of 600\n",
      "building tree 479 of 600\n",
      "building tree 480 of 600\n",
      "building tree 481 of 600\n",
      "building tree 482 of 600\n",
      "building tree 483 of 600\n",
      "building tree 484 of 600\n",
      "building tree 485 of 600\n",
      "building tree 486 of 600\n",
      "building tree 487 of 600\n",
      "building tree 488 of 600\n",
      "building tree 489 of 600\n",
      "building tree 490 of 600\n",
      "building tree 491 of 600\n",
      "building tree 492 of 600\n",
      "building tree 493 of 600\n",
      "building tree 494 of 600\n",
      "building tree 495 of 600\n",
      "building tree 496 of 600\n",
      "building tree 497 of 600\n",
      "building tree 498 of 600\n",
      "building tree 499 of 600\n",
      "building tree 500 of 600\n",
      "building tree 501 of 600\n",
      "building tree 502 of 600\n",
      "building tree 503 of 600\n",
      "building tree 504 of 600\n",
      "building tree 505 of 600\n",
      "building tree 506 of 600\n",
      "building tree 507 of 600\n",
      "building tree 508 of 600\n",
      "building tree 509 of 600\n",
      "building tree 510 of 600\n",
      "building tree 511 of 600\n",
      "building tree 512 of 600\n",
      "building tree 513 of 600\n",
      "building tree 514 of 600\n",
      "building tree 515 of 600\n",
      "building tree 516 of 600\n",
      "building tree 517 of 600\n",
      "building tree 518 of 600\n",
      "building tree 519 of 600\n",
      "building tree 520 of 600\n",
      "building tree 521 of 600\n",
      "building tree 522 of 600\n",
      "building tree 523 of 600\n",
      "building tree 524 of 600\n",
      "building tree 525 of 600\n",
      "building tree 526 of 600\n",
      "building tree 527 of 600\n",
      "building tree 528 of 600\n",
      "building tree 529 of 600\n",
      "building tree 530 of 600\n",
      "building tree 531 of 600\n",
      "building tree 532 of 600\n",
      "building tree 533 of 600\n",
      "building tree 534 of 600\n",
      "building tree 535 of 600\n",
      "building tree 536 of 600\n",
      "building tree 537 of 600\n",
      "building tree 538 of 600\n",
      "building tree 539 of 600\n",
      "building tree 540 of 600\n",
      "building tree 541 of 600\n",
      "building tree 542 of 600\n",
      "building tree 543 of 600\n",
      "building tree 544 of 600\n",
      "building tree 545 of 600\n",
      "building tree 546 of 600\n",
      "building tree 547 of 600\n",
      "building tree 548 of 600\n",
      "building tree 549 of 600\n",
      "building tree 550 of 600\n",
      "building tree 551 of 600\n",
      "building tree 552 of 600\n",
      "building tree 553 of 600\n",
      "building tree 554 of 600\n",
      "building tree 555 of 600\n",
      "building tree 556 of 600\n",
      "building tree 557 of 600\n",
      "building tree 558 of 600\n",
      "building tree 559 of 600\n",
      "building tree 560 of 600\n",
      "building tree 561 of 600\n",
      "building tree 562 of 600\n",
      "building tree 563 of 600\n",
      "building tree 564 of 600\n",
      "building tree 565 of 600\n",
      "building tree 566 of 600\n",
      "building tree 567 of 600\n",
      "building tree 568 of 600\n",
      "building tree 569 of 600\n",
      "building tree 570 of 600\n",
      "building tree 571 of 600\n",
      "building tree 572 of 600\n",
      "building tree 573 of 600\n",
      "building tree 574 of 600\n",
      "building tree 575 of 600\n",
      "building tree 576 of 600\n",
      "building tree 577 of 600\n",
      "building tree 578 of 600\n",
      "building tree 579 of 600\n",
      "building tree 580 of 600\n",
      "building tree 581 of 600\n",
      "building tree 582 of 600\n",
      "building tree 583 of 600\n",
      "building tree 584 of 600\n",
      "building tree 585 of 600\n",
      "building tree 586 of 600\n",
      "building tree 587 of 600\n",
      "building tree 588 of 600\n",
      "building tree 589 of 600\n",
      "building tree 590 of 600\n",
      "building tree 591 of 600\n",
      "building tree 592 of 600\n",
      "building tree 593 of 600\n",
      "building tree 594 of 600\n",
      "building tree 595 of 600\n",
      "building tree 596 of 600\n",
      "building tree 597 of 600\n",
      "building tree 598 of 600\n",
      "building tree 599 of 600\n",
      "building tree 600 of 600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 600 out of 600 | elapsed:   14.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "textlab_10_fullba_rew fit complete\n",
      "Fitted model saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=24)]: Using backend ThreadingBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=24)]: Done 114 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=24)]: Done 317 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=24)]: Done 600 out of 600 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=24)]: Using backend ThreadingBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=24)]: Done 114 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=24)]: Done 317 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=24)]: Done 600 out of 600 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 24 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitAndPredict: 23.72581672668457 seconds\n",
      "0.8984563861901683\n",
      "----- [Running *duration* ML with numeric features] -----\n",
      "Running textlab_10_fullba_dur\n",
      "building tree 1 of 600\n",
      "building tree 2 of 600\n",
      "building tree 3 of 600\n",
      "building tree 4 of 600\n",
      "building tree 5 of 600\n",
      "building tree 6 of 600\n",
      "building tree 7 of 600\n",
      "building tree 8 of 600\n",
      "building tree 9 of 600\n",
      "building tree 10 of 600\n",
      "building tree 11 of 600\n",
      "building tree 12 of 600\n",
      "building tree 13 of 600\n",
      "building tree 14 of 600\n",
      "building tree 15 of 600\n",
      "building tree 16 of 600\n",
      "building tree 17 of 600\n",
      "building tree 18 of 600\n",
      "building tree 19 of 600\n",
      "building tree 20 of 600\n",
      "building tree 21 of 600\n",
      "building tree 22 of 600\n",
      "building tree 23 of 600\n",
      "building tree 24 of 600\n",
      "building tree 25 of 600\n",
      "building tree 26 of 600\n",
      "building tree 27 of 600\n",
      "building tree 28 of 600\n",
      "building tree 29 of 600\n",
      "building tree 30 of 600\n",
      "building tree 31 of 600\n",
      "building tree 32 of 600\n",
      "building tree 33 of 600\n",
      "building tree 34 of 600\n",
      "building tree 35 of 600\n",
      "building tree 36 of 600\n",
      "building tree 37 of 600\n",
      "building tree 38 of 600\n",
      "building tree 39 of 600\n",
      "building tree 40 of 600\n",
      "building tree 41 of 600\n",
      "building tree 42 of 600\n",
      "building tree 43 of 600\n",
      "building tree 44 of 600\n",
      "building tree 45 of 600\n",
      "building tree 46 of 600\n",
      "building tree 47 of 600\n",
      "building tree 48 of 600\n",
      "building tree 49 of 600\n",
      "building tree 50 of 600\n",
      "building tree 51 of 600\n",
      "building tree 52 of 600\n",
      "building tree 53 of 600\n",
      "building tree 54 of 600\n",
      "building tree 55 of 600\n",
      "building tree 56 of 600\n",
      "building tree 57 of 600\n",
      "building tree 58 of 600\n",
      "building tree 59 of 600\n",
      "building tree 60 of 600\n",
      "building tree 61 of 600\n",
      "building tree 62 of 600\n",
      "building tree 63 of 600\n",
      "building tree 64 of 600\n",
      "building tree 65 of 600\n",
      "building tree 66 of 600\n",
      "building tree 67 of 600\n",
      "building tree 68 of 600\n",
      "building tree 69 of 600\n",
      "building tree 70 of 600\n",
      "building tree 71 of 600\n",
      "building tree 72 of 600\n",
      "building tree 73 of 600\n",
      "building tree 74 of 600\n",
      "building tree 75 of 600\n",
      "building tree 76 of 600\n",
      "building tree 77 of 600\n",
      "building tree 78 of 600\n",
      "building tree 79 of 600\n",
      "building tree 80 of 600\n",
      "building tree 81 of 600\n",
      "building tree 82 of 600\n",
      "building tree 83 of 600\n",
      "building tree 84 of 600\n",
      "building tree 85 of 600\n",
      "building tree 86 of 600\n",
      "building tree 87 of 600\n",
      "building tree 88 of 600\n",
      "building tree 89 of 600\n",
      "building tree 90 of 600\n",
      "building tree 91 of 600\n",
      "building tree 92 of 600\n",
      "building tree 93 of 600\n",
      "building tree 94 of 600\n",
      "building tree 95 of 600\n",
      "building tree 96 of 600\n",
      "building tree 97 of 600\n",
      "building tree 98 of 600\n",
      "building tree 99 of 600\n",
      "building tree 100 of 600\n",
      "building tree 101 of 600\n",
      "building tree 102 of 600\n",
      "building tree 103 of 600\n",
      "building tree 104 of 600\n",
      "building tree 105 of 600\n",
      "building tree 106 of 600\n",
      "building tree 107 of 600\n",
      "building tree 108 of 600\n",
      "building tree 109 of 600\n",
      "building tree 110 of 600\n",
      "building tree 111 of 600\n",
      "building tree 112 of 600\n",
      "building tree 113 of 600\n",
      "building tree 114 of 600\n",
      "building tree 115 of 600\n",
      "building tree 116 of 600\n",
      "building tree 117 of 600\n",
      "building tree 118 of 600\n",
      "building tree 119 of 600\n",
      "building tree 120 of 600\n",
      "building tree 121 of 600\n",
      "building tree 122 of 600\n",
      "building tree 123 of 600\n",
      "building tree 124 of 600\n",
      "building tree 125 of 600\n",
      "building tree 126 of 600\n",
      "building tree 127 of 600\n",
      "building tree 128 of 600\n",
      "building tree 129 of 600\n",
      "building tree 130 of 600\n",
      "building tree 131 of 600\n",
      "building tree 132 of 600\n",
      "building tree 133 of 600\n",
      "building tree 134 of 600\n",
      "building tree 135 of 600\n",
      "building tree 136 of 600\n",
      "building tree 137 of 600\n",
      "building tree 138 of 600\n",
      "building tree 139 of 600\n",
      "building tree 140 of 600\n",
      "building tree 141 of 600\n",
      "building tree 142 of 600\n",
      "building tree 143 of 600\n",
      "building tree 144 of 600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 114 tasks      | elapsed:    2.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 145 of 600\n",
      "building tree 146 of 600\n",
      "building tree 147 of 600\n",
      "building tree 148 of 600\n",
      "building tree 149 of 600\n",
      "building tree 150 of 600\n",
      "building tree 151 of 600\n",
      "building tree 152 of 600\n",
      "building tree 153 of 600\n",
      "building tree 154 of 600\n",
      "building tree 155 of 600\n",
      "building tree 156 of 600\n",
      "building tree 157 of 600\n",
      "building tree 158 of 600\n",
      "building tree 159 of 600\n",
      "building tree 160 of 600\n",
      "building tree 161 of 600\n",
      "building tree 162 of 600\n",
      "building tree 163 of 600\n",
      "building tree 164 of 600\n",
      "building tree 165 of 600\n",
      "building tree 166 of 600\n",
      "building tree 167 of 600\n",
      "building tree 168 of 600\n",
      "building tree 169 of 600\n",
      "building tree 170 of 600\n",
      "building tree 171 of 600\n",
      "building tree 172 of 600\n",
      "building tree 173 of 600\n",
      "building tree 174 of 600\n",
      "building tree 175 of 600\n",
      "building tree 176 of 600\n",
      "building tree 177 of 600\n",
      "building tree 178 of 600\n",
      "building tree 179 of 600\n",
      "building tree 180 of 600\n",
      "building tree 181 of 600\n",
      "building tree 182 of 600\n",
      "building tree 183 of 600\n",
      "building tree 184 of 600\n",
      "building tree 185 of 600building tree 186 of 600\n",
      "building tree 187 of 600\n",
      "\n",
      "building tree 188 of 600\n",
      "building tree 189 of 600\n",
      "building tree 190 of 600\n",
      "building tree 191 of 600\n",
      "building tree 192 of 600\n",
      "building tree 193 of 600\n",
      "building tree 194 of 600\n",
      "building tree 195 of 600\n",
      "building tree 196 of 600\n",
      "building tree 197 of 600\n",
      "building tree 198 of 600\n",
      "building tree 199 of 600\n",
      "building tree 200 of 600\n",
      "building tree 201 of 600\n",
      "building tree 202 of 600\n",
      "building tree 203 of 600\n",
      "building tree 204 of 600\n",
      "building tree 205 of 600\n",
      "building tree 206 of 600\n",
      "building tree 207 of 600\n",
      "building tree 208 of 600\n",
      "building tree 209 of 600\n",
      "building tree 210 of 600\n",
      "building tree 211 of 600\n",
      "building tree 212 of 600\n",
      "building tree 213 of 600\n",
      "building tree 214 of 600\n",
      "building tree 215 of 600\n",
      "building tree 216 of 600\n",
      "building tree 217 of 600\n",
      "building tree 218 of 600\n",
      "building tree 219 of 600\n",
      "building tree 220 of 600\n",
      "building tree 221 of 600\n",
      "building tree 222 of 600\n",
      "building tree 223 of 600\n",
      "building tree 224 of 600\n",
      "building tree 225 of 600\n",
      "building tree 226 of 600\n",
      "building tree 227 of 600\n",
      "building tree 228 of 600\n",
      "building tree 229 of 600\n",
      "building tree 230 of 600\n",
      "building tree 231 of 600\n",
      "building tree 232 of 600\n",
      "building tree 233 of 600\n",
      "building tree 234 of 600\n",
      "building tree 235 of 600\n",
      "building tree 236 of 600\n",
      "building tree 237 of 600\n",
      "building tree 238 of 600\n",
      "building tree 239 of 600\n",
      "building tree 240 of 600\n",
      "building tree 241 of 600\n",
      "building tree 242 of 600\n",
      "building tree 243 of 600\n",
      "building tree 244 of 600\n",
      "building tree 245 of 600\n",
      "building tree 246 of 600\n",
      "building tree 247 of 600\n",
      "building tree 248 of 600\n",
      "building tree 249 of 600\n",
      "building tree 250 of 600\n",
      "building tree 251 of 600\n",
      "building tree 252 of 600\n",
      "building tree 253 of 600\n",
      "building tree 254 of 600\n",
      "building tree 255 of 600\n",
      "building tree 256 of 600\n",
      "building tree 257 of 600\n",
      "building tree 258 of 600\n",
      "building tree 259 of 600\n",
      "building tree 260 of 600\n",
      "building tree 261 of 600\n",
      "building tree 262 of 600\n",
      "building tree 263 of 600\n",
      "building tree 264 of 600\n",
      "building tree 265 of 600\n",
      "building tree 266 of 600\n",
      "building tree 267 of 600building tree 268 of 600\n",
      "\n",
      "building tree 269 of 600\n",
      "building tree 270 of 600\n",
      "building tree 271 of 600\n",
      "building tree 272 of 600\n",
      "building tree 273 of 600\n",
      "building tree 274 of 600\n",
      "building tree 275 of 600\n",
      "building tree 276 of 600\n",
      "building tree 277 of 600\n",
      "building tree 278 of 600\n",
      "building tree 279 of 600\n",
      "building tree 280 of 600\n",
      "building tree 281 of 600\n",
      "building tree 282 of 600\n",
      "building tree 283 of 600\n",
      "building tree 284 of 600\n",
      "building tree 285 of 600\n",
      "building tree 286 of 600\n",
      "building tree 287 of 600\n",
      "building tree 288 of 600\n",
      "building tree 289 of 600\n",
      "building tree 290 of 600\n",
      "building tree 291 of 600\n",
      "building tree 292 of 600\n",
      "building tree 293 of 600\n",
      "building tree 294 of 600\n",
      "building tree 295 of 600\n",
      "building tree 296 of 600\n",
      "building tree 297 of 600\n",
      "building tree 298 of 600\n",
      "building tree 299 of 600building tree 300 of 600\n",
      "\n",
      "building tree 301 of 600\n",
      "building tree 302 of 600\n",
      "building tree 303 of 600\n",
      "building tree 304 of 600\n",
      "building tree 305 of 600\n",
      "building tree 306 of 600\n",
      "building tree 307 of 600\n",
      "building tree 308 of 600\n",
      "building tree 309 of 600\n",
      "building tree 310 of 600\n",
      "building tree 311 of 600\n",
      "building tree 312 of 600\n",
      "building tree 313 of 600\n",
      "building tree 314 of 600\n",
      "building tree 315 of 600\n",
      "building tree 316 of 600\n",
      "building tree 317 of 600\n",
      "building tree 318 of 600\n",
      "building tree 319 of 600\n",
      "building tree 320 of 600\n",
      "building tree 321 of 600building tree 322 of 600\n",
      "\n",
      "building tree 323 of 600\n",
      "building tree 324 of 600\n",
      "building tree 325 of 600\n",
      "building tree 326 of 600\n",
      "building tree 327 of 600\n",
      "building tree 328 of 600\n",
      "building tree 329 of 600\n",
      "building tree 330 of 600\n",
      "building tree 331 of 600\n",
      "building tree 332 of 600\n",
      "building tree 333 of 600\n",
      "building tree 334 of 600\n",
      "building tree 335 of 600\n",
      "building tree 336 of 600\n",
      "building tree 337 of 600\n",
      "building tree 338 of 600\n",
      "building tree 339 of 600\n",
      "building tree 340 of 600\n",
      "building tree 341 of 600\n",
      "building tree 342 of 600\n",
      "building tree 343 of 600\n",
      "building tree 344 of 600\n",
      "building tree 345 of 600\n",
      "building tree 346 of 600\n",
      "building tree 347 of 600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 317 tasks      | elapsed:    7.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 348 of 600\n",
      "building tree 349 of 600\n",
      "building tree 350 of 600\n",
      "building tree 351 of 600\n",
      "building tree 352 of 600\n",
      "building tree 353 of 600\n",
      "building tree 354 of 600\n",
      "building tree 355 of 600\n",
      "building tree 356 of 600\n",
      "building tree 357 of 600\n",
      "building tree 358 of 600\n",
      "building tree 359 of 600\n",
      "building tree 360 of 600\n",
      "building tree 361 of 600\n",
      "building tree 362 of 600\n",
      "building tree 363 of 600\n",
      "building tree 364 of 600\n",
      "building tree 365 of 600\n",
      "building tree 366 of 600\n",
      "building tree 367 of 600\n",
      "building tree 368 of 600\n",
      "building tree 369 of 600\n",
      "building tree 370 of 600\n",
      "building tree 371 of 600\n",
      "building tree 372 of 600\n",
      "building tree 373 of 600\n",
      "building tree 374 of 600\n",
      "building tree 375 of 600\n",
      "building tree 376 of 600\n",
      "building tree 377 of 600\n",
      "building tree 378 of 600\n",
      "building tree 379 of 600\n",
      "building tree 380 of 600\n",
      "building tree 381 of 600\n",
      "building tree 382 of 600\n",
      "building tree 383 of 600\n",
      "building tree 384 of 600\n",
      "building tree 385 of 600\n",
      "building tree 386 of 600\n",
      "building tree 387 of 600\n",
      "building tree 388 of 600\n",
      "building tree 389 of 600\n",
      "building tree 390 of 600\n",
      "building tree 391 of 600\n",
      "building tree 392 of 600\n",
      "building tree 393 of 600\n",
      "building tree 394 of 600\n",
      "building tree 395 of 600\n",
      "building tree 396 of 600\n",
      "building tree 397 of 600\n",
      "building tree 398 of 600\n",
      "building tree 399 of 600\n",
      "building tree 400 of 600\n",
      "building tree 401 of 600\n",
      "building tree 402 of 600\n",
      "building tree 403 of 600\n",
      "building tree 404 of 600\n",
      "building tree 405 of 600\n",
      "building tree 406 of 600\n",
      "building tree 407 of 600\n",
      "building tree 408 of 600\n",
      "building tree 409 of 600\n",
      "building tree 410 of 600\n",
      "building tree 411 of 600\n",
      "building tree 412 of 600\n",
      "building tree 413 of 600\n",
      "building tree 414 of 600\n",
      "building tree 415 of 600\n",
      "building tree 416 of 600\n",
      "building tree 417 of 600\n",
      "building tree 418 of 600\n",
      "building tree 419 of 600\n",
      "building tree 420 of 600\n",
      "building tree 421 of 600\n",
      "building tree 422 of 600\n",
      "building tree 423 of 600\n",
      "building tree 424 of 600\n",
      "building tree 425 of 600\n",
      "building tree 426 of 600\n",
      "building tree 427 of 600\n",
      "building tree 428 of 600\n",
      "building tree 429 of 600\n",
      "building tree 430 of 600\n",
      "building tree 431 of 600\n",
      "building tree 432 of 600\n",
      "building tree 433 of 600\n",
      "building tree 434 of 600\n",
      "building tree 435 of 600\n",
      "building tree 436 of 600\n",
      "building tree 437 of 600\n",
      "building tree 438 of 600\n",
      "building tree 439 of 600\n",
      "building tree 440 of 600\n",
      "building tree 441 of 600\n",
      "building tree 442 of 600\n",
      "building tree 443 of 600\n",
      "building tree 444 of 600\n",
      "building tree 445 of 600\n",
      "building tree 446 of 600\n",
      "building tree 447 of 600\n",
      "building tree 448 of 600\n",
      "building tree 449 of 600\n",
      "building tree 450 of 600\n",
      "building tree 451 of 600\n",
      "building tree 452 of 600\n",
      "building tree 453 of 600\n",
      "building tree 454 of 600\n",
      "building tree 455 of 600\n",
      "building tree 456 of 600\n",
      "building tree 457 of 600\n",
      "building tree 458 of 600\n",
      "building tree 459 of 600\n",
      "building tree 460 of 600\n",
      "building tree 461 of 600\n",
      "building tree 462 of 600\n",
      "building tree 463 of 600\n",
      "building tree 464 of 600\n",
      "building tree 465 of 600\n",
      "building tree 466 of 600\n",
      "building tree 467 of 600\n",
      "building tree 468 of 600\n",
      "building tree 469 of 600\n",
      "building tree 470 of 600\n",
      "building tree 471 of 600\n",
      "building tree 472 of 600\n",
      "building tree 473 of 600\n",
      "building tree 474 of 600\n",
      "building tree 475 of 600\n",
      "building tree 476 of 600\n",
      "building tree 477 of 600\n",
      "building tree 478 of 600\n",
      "building tree 479 of 600\n",
      "building tree 480 of 600\n",
      "building tree 481 of 600\n",
      "building tree 482 of 600\n",
      "building tree 483 of 600\n",
      "building tree 484 of 600\n",
      "building tree 485 of 600\n",
      "building tree 486 of 600\n",
      "building tree 487 of 600\n",
      "building tree 488 of 600\n",
      "building tree 489 of 600\n",
      "building tree 490 of 600\n",
      "building tree 491 of 600\n",
      "building tree 492 of 600\n",
      "building tree 493 of 600\n",
      "building tree 494 of 600\n",
      "building tree 495 of 600\n",
      "building tree 496 of 600\n",
      "building tree 497 of 600\n",
      "building tree 498 of 600\n",
      "building tree 499 of 600\n",
      "building tree 500 of 600\n",
      "building tree 501 of 600\n",
      "building tree 502 of 600\n",
      "building tree 503 of 600\n",
      "building tree 504 of 600\n",
      "building tree 505 of 600\n",
      "building tree 506 of 600\n",
      "building tree 507 of 600\n",
      "building tree 508 of 600\n",
      "building tree 509 of 600\n",
      "building tree 510 of 600\n",
      "building tree 511 of 600\n",
      "building tree 512 of 600\n",
      "building tree 513 of 600\n",
      "building tree 514 of 600\n",
      "building tree 515 of 600\n",
      "building tree 516 of 600\n",
      "building tree 517 of 600\n",
      "building tree 518 of 600\n",
      "building tree 519 of 600\n",
      "building tree 520 of 600\n",
      "building tree 521 of 600\n",
      "building tree 522 of 600\n",
      "building tree 523 of 600\n",
      "building tree 524 of 600\n",
      "building tree 525 of 600\n",
      "building tree 526 of 600\n",
      "building tree 527 of 600\n",
      "building tree 528 of 600\n",
      "building tree 529 of 600\n",
      "building tree 530 of 600\n",
      "building tree 531 of 600\n",
      "building tree 532 of 600\n",
      "building tree 533 of 600\n",
      "building tree 534 of 600\n",
      "building tree 535 of 600\n",
      "building tree 536 of 600\n",
      "building tree 537 of 600\n",
      "building tree 538 of 600\n",
      "building tree 539 of 600\n",
      "building tree 540 of 600\n",
      "building tree 541 of 600\n",
      "building tree 542 of 600\n",
      "building tree 543 of 600\n",
      "building tree 544 of 600\n",
      "building tree 545 of 600\n",
      "building tree 546 of 600\n",
      "building tree 547 of 600\n",
      "building tree 548 of 600\n",
      "building tree 549 of 600\n",
      "building tree 550 of 600\n",
      "building tree 551 of 600\n",
      "building tree 552 of 600\n",
      "building tree 553 of 600\n",
      "building tree 554 of 600\n",
      "building tree 555 of 600\n",
      "building tree 556 of 600\n",
      "building tree 557 of 600\n",
      "building tree 558 of 600\n",
      "building tree 559 of 600\n",
      "building tree 560 of 600\n",
      "building tree 561 of 600\n",
      "building tree 562 of 600\n",
      "building tree 563 of 600\n",
      "building tree 564 of 600\n",
      "building tree 565 of 600\n",
      "building tree 566 of 600\n",
      "building tree 567 of 600\n",
      "building tree 568 of 600\n",
      "building tree 569 of 600\n",
      "building tree 570 of 600\n",
      "building tree 571 of 600\n",
      "building tree 572 of 600\n",
      "building tree 573 of 600\n",
      "building tree 574 of 600\n",
      "building tree 575 of 600\n",
      "building tree 576 of 600\n",
      "building tree 577 of 600\n",
      "building tree 578 of 600\n",
      "building tree 579 of 600\n",
      "building tree 580 of 600\n",
      "building tree 581 of 600\n",
      "building tree 582 of 600\n",
      "building tree 583 of 600\n",
      "building tree 584 of 600\n",
      "building tree 585 of 600\n",
      "building tree 586 of 600\n",
      "building tree 587 of 600\n",
      "building tree 588 of 600\n",
      "building tree 589 of 600\n",
      "building tree 590 of 600\n",
      "building tree 591 of 600\n",
      "building tree 592 of 600\n",
      "building tree 593 of 600\n",
      "building tree 594 of 600\n",
      "building tree 595 of 600\n",
      "building tree 596 of 600\n",
      "building tree 597 of 600\n",
      "building tree 598 of 600\n",
      "building tree 599 of 600\n",
      "building tree 600 of 600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 600 out of 600 | elapsed:   14.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "textlab_10_fullba_dur fit complete\n",
      "Fitted model saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=24)]: Using backend ThreadingBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=24)]: Done 114 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=24)]: Done 317 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=24)]: Done 600 out of 600 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=24)]: Using backend ThreadingBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=24)]: Done 114 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=24)]: Done 317 tasks      | elapsed:    0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitAndPredict: 24.23042368888855 seconds\n",
      "0.503218291590726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=24)]: Done 600 out of 600 | elapsed:    0.3s finished\n"
     ]
    }
   ],
   "source": [
    "for dataset in all_datasets:\n",
    "# Repeat the above, but for the B->A run\n",
    "    print(\"*** B->A n-gram ML run\")\n",
    "    prepareML(dataset, \"gramba\")\n",
    "    runML(dataset, \"gramba\")\n",
    "    print(\"*** B->A computing most predictive features\")\n",
    "    computeMostPredictive(dataset, \"gramba\")\n",
    "    print(\"*** B->A full ML run\")\n",
    "    prepareML(dataset, \"fullba\")\n",
    "    runML(dataset, \"fullba\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "56185fc2-beaa-434c-a002-6c840a7b48cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Computing final point estimate, exporting Stata residual file\n",
      "doubleMLEstimate()\n",
      "Loaded predicted_lrew_ab: (129751,)\n",
      "Loaded predicted_lrew_ba: (129751,)\n",
      "Loaded lrew_ab: (129751,)\n",
      "Loaded lrew_ba: (129751,)\n",
      "Standard theta_check: -0.0307111856201729\n",
      "Standard theta_check (flipped data): -0.030649770471615295\n",
      "Averaged theta_check: -0.030680478045894098\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\2386103530.py:143: FutureWarning: The behavior of Series.replace (and DataFrame.replace) with CategoricalDtype is deprecated. In a future version, replace will only be used for cases that preserve the categories. To change the categories, use ser.cat.rename_categories instead.\n",
      "  full_df_merged[\"_merge\"] = full_df_merged[\"_merge\"].replace('both',1)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\2386103530.py:144: FutureWarning: The behavior of Series.replace (and DataFrame.replace) with CategoricalDtype is deprecated. In a future version, replace will only be used for cases that preserve the categories. To change the categories, use ser.cat.rename_categories instead.\n",
      "  full_df_merged[\"_merge\"] = full_df_merged[\"_merge\"].replace('left_only',0)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\2386103530.py:145: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  full_df_merged[\"_merge\"] = full_df_merged[\"_merge\"].replace('right_only',0)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\2386103530.py:145: FutureWarning: The behavior of Series.replace (and DataFrame.replace) with CategoricalDtype is deprecated. In a future version, replace will only be used for cases that preserve the categories. To change the categories, use ser.cat.rename_categories instead.\n",
      "  full_df_merged[\"_merge\"] = full_df_merged[\"_merge\"].replace('right_only',0)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\2386103530.py:159: FutureWarning: The behavior of Series.replace (and DataFrame.replace) with CategoricalDtype is deprecated. In a future version, replace will only be used for cases that preserve the categories. To change the categories, use ser.cat.rename_categories instead.\n",
      "  full_df_merged[\"_merge\"] = full_df_merged[\"_merge\"].replace('both',2)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\2386103530.py:160: FutureWarning: The behavior of Series.replace (and DataFrame.replace) with CategoricalDtype is deprecated. In a future version, replace will only be used for cases that preserve the categories. To change the categories, use ser.cat.rename_categories instead.\n",
      "  full_df_merged[\"_merge\"] = full_df_merged[\"_merge\"].replace('left_only',0)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\2386103530.py:161: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  full_df_merged[\"_merge\"] = full_df_merged[\"_merge\"].replace('right_only',0)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\2386103530.py:161: FutureWarning: The behavior of Series.replace (and DataFrame.replace) with CategoricalDtype is deprecated. In a future version, replace will only be used for cases that preserve the categories. To change the categories, use ser.cat.rename_categories instead.\n",
      "  full_df_merged[\"_merge\"] = full_df_merged[\"_merge\"].replace('right_only',0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported Stata file .\\estimates\\residuals_full_ipeirotis.dta\n",
      "*** Computing final point estimate, exporting Stata residual file\n",
      "doubleMLEstimate()\n",
      "Loaded predicted_lrew_ab: (146373,)\n",
      "Loaded predicted_lrew_ba: (146373,)\n",
      "Loaded lrew_ab: (146373,)\n",
      "Loaded lrew_ba: (146373,)\n",
      "Standard theta_check: -0.18114334854128308\n",
      "Standard theta_check (flipped data): -0.1802563565861239\n",
      "Averaged theta_check: -0.1806998525637035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\2386103530.py:143: FutureWarning: The behavior of Series.replace (and DataFrame.replace) with CategoricalDtype is deprecated. In a future version, replace will only be used for cases that preserve the categories. To change the categories, use ser.cat.rename_categories instead.\n",
      "  full_df_merged[\"_merge\"] = full_df_merged[\"_merge\"].replace('both',1)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\2386103530.py:144: FutureWarning: The behavior of Series.replace (and DataFrame.replace) with CategoricalDtype is deprecated. In a future version, replace will only be used for cases that preserve the categories. To change the categories, use ser.cat.rename_categories instead.\n",
      "  full_df_merged[\"_merge\"] = full_df_merged[\"_merge\"].replace('left_only',0)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\2386103530.py:145: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  full_df_merged[\"_merge\"] = full_df_merged[\"_merge\"].replace('right_only',0)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\2386103530.py:145: FutureWarning: The behavior of Series.replace (and DataFrame.replace) with CategoricalDtype is deprecated. In a future version, replace will only be used for cases that preserve the categories. To change the categories, use ser.cat.rename_categories instead.\n",
      "  full_df_merged[\"_merge\"] = full_df_merged[\"_merge\"].replace('right_only',0)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\2386103530.py:159: FutureWarning: The behavior of Series.replace (and DataFrame.replace) with CategoricalDtype is deprecated. In a future version, replace will only be used for cases that preserve the categories. To change the categories, use ser.cat.rename_categories instead.\n",
      "  full_df_merged[\"_merge\"] = full_df_merged[\"_merge\"].replace('both',2)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\2386103530.py:160: FutureWarning: The behavior of Series.replace (and DataFrame.replace) with CategoricalDtype is deprecated. In a future version, replace will only be used for cases that preserve the categories. To change the categories, use ser.cat.rename_categories instead.\n",
      "  full_df_merged[\"_merge\"] = full_df_merged[\"_merge\"].replace('left_only',0)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\2386103530.py:161: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  full_df_merged[\"_merge\"] = full_df_merged[\"_merge\"].replace('right_only',0)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\2386103530.py:161: FutureWarning: The behavior of Series.replace (and DataFrame.replace) with CategoricalDtype is deprecated. In a future version, replace will only be used for cases that preserve the categories. To change the categories, use ser.cat.rename_categories instead.\n",
      "  full_df_merged[\"_merge\"] = full_df_merged[\"_merge\"].replace('right_only',0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported Stata file .\\estimates\\residuals_full_textlab_30.dta\n",
      "*** Computing final point estimate, exporting Stata residual file\n",
      "doubleMLEstimate()\n",
      "Loaded predicted_lrew_ab: (46888,)\n",
      "Loaded predicted_lrew_ba: (46887,)\n",
      "Loaded lrew_ab: (46887,)\n",
      "Loaded lrew_ba: (46888,)\n",
      "Standard theta_check: -0.17677600126012047\n",
      "Standard theta_check (flipped data): -0.21566935879689308\n",
      "Averaged theta_check: -0.1962226800285068\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\2386103530.py:143: FutureWarning: The behavior of Series.replace (and DataFrame.replace) with CategoricalDtype is deprecated. In a future version, replace will only be used for cases that preserve the categories. To change the categories, use ser.cat.rename_categories instead.\n",
      "  full_df_merged[\"_merge\"] = full_df_merged[\"_merge\"].replace('both',1)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\2386103530.py:144: FutureWarning: The behavior of Series.replace (and DataFrame.replace) with CategoricalDtype is deprecated. In a future version, replace will only be used for cases that preserve the categories. To change the categories, use ser.cat.rename_categories instead.\n",
      "  full_df_merged[\"_merge\"] = full_df_merged[\"_merge\"].replace('left_only',0)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\2386103530.py:145: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  full_df_merged[\"_merge\"] = full_df_merged[\"_merge\"].replace('right_only',0)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\2386103530.py:145: FutureWarning: The behavior of Series.replace (and DataFrame.replace) with CategoricalDtype is deprecated. In a future version, replace will only be used for cases that preserve the categories. To change the categories, use ser.cat.rename_categories instead.\n",
      "  full_df_merged[\"_merge\"] = full_df_merged[\"_merge\"].replace('right_only',0)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\2386103530.py:159: FutureWarning: The behavior of Series.replace (and DataFrame.replace) with CategoricalDtype is deprecated. In a future version, replace will only be used for cases that preserve the categories. To change the categories, use ser.cat.rename_categories instead.\n",
      "  full_df_merged[\"_merge\"] = full_df_merged[\"_merge\"].replace('both',2)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\2386103530.py:160: FutureWarning: The behavior of Series.replace (and DataFrame.replace) with CategoricalDtype is deprecated. In a future version, replace will only be used for cases that preserve the categories. To change the categories, use ser.cat.rename_categories instead.\n",
      "  full_df_merged[\"_merge\"] = full_df_merged[\"_merge\"].replace('left_only',0)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\2386103530.py:161: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  full_df_merged[\"_merge\"] = full_df_merged[\"_merge\"].replace('right_only',0)\n",
      "C:\\Users\\caiyuyang\\AppData\\Local\\Temp\\ipykernel_36472\\2386103530.py:161: FutureWarning: The behavior of Series.replace (and DataFrame.replace) with CategoricalDtype is deprecated. In a future version, replace will only be used for cases that preserve the categories. To change the categories, use ser.cat.rename_categories instead.\n",
      "  full_df_merged[\"_merge\"] = full_df_merged[\"_merge\"].replace('right_only',0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported Stata file .\\estimates\\residuals_full_textlab_10.dta\n"
     ]
    }
   ],
   "source": [
    "for dataset in all_datasets:\n",
    "# Finally, compute the double ML estimate using the ML residuals\n",
    "    print(\"*** Computing final point estimate, exporting Stata residual file\")\n",
    "    computeEta(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a15b2459-9f2b-4020-b116-5a787513f909",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### （十）结果展示"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d3aaf70-8c6c-4808-bb48-2cd2dc0f5cff",
   "metadata": {},
   "source": [
    "#### 1、双重机器学习与ols估计对比"
   ]
  },
  {
   "attachments": {
    "d82089f3-97c9-48df-a5d0-bc97d7f779d4.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "84a1b3d3-3df9-4549-aeb9-2ce80b9e6e59",
   "metadata": {},
   "source": [
    "![屏幕截图 2025-06-27 103005.png](attachment:d82089f3-97c9-48df-a5d0-bc97d7f779d4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7cd1973-bdb7-49a4-b009-7cc0721e6d90",
   "metadata": {},
   "source": [
    "#### 2、对数duration和对数reward的机器学习残差的分箱散点图"
   ]
  },
  {
   "attachments": {
    "7dd28c89-02f9-465e-88f7-1712bb078a4b.png": {
     "image/png": "iVBORw0KGgoAAAANSUhEUgAAApIAAAHdCAYAAACubplCAAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAAAJcEhZcwAADsMAAA7DAcdvqGQAAF/MSURBVHhe7d11fFX1H8fx17pgdHd3t3THDxEEqTFKQEIQQWmlGwklJKS2wUBEJKQ7paW7u9nGxuLu/v5QkR1qXO/6/Xw8zh9+v59zdnevXt/7nu/3e2zMZrMZEREREZH3ZGtsEBERERGJDAVJEREREbGIgqSIiIiIWERBUkREREQsoiApIiIiIhZRkBQRERERiyhIioiIiIhFFCRFRERExCIKkiIiIiJiEQVJEREREbGIgqSIiIiIWERBUkREREQsoiApIiIiIhZRkBQRERERiyToIHn16lV27txpbBYRERGRSEjQQXLv3r1MmzbN2CwiIiIikZCgg6SIiIiIWE5BUkREREQsoiApIiIiIhaJvUHS9JCzu9bw64p17Lvkh8nYj4kb+37Dd+k2LoQa+0REREQkqsXKIGm6s5lRH5WmeOX6fNyoLuULl6B+/585HfByVTBnfhlAm44/ceD5y+0iIiIiEh1iYZB8zMaxXzB8bzKajvbm12VzGd40JUcntKZhxx857GesFxEREZGYEPuCZOAhNm+8Rome05nex4OGjdsxYO7vrPy+ITYretO6pzdng40niYiIiEh0i31B0vSUJw/tyZYjNy4vGpNRqstMvMbWItDnCzqO2My9VydNioiIiEg0sjGbzWZjY4wK2s23lerya3lftkyuR6qX+0x32TSkKc0n3KTahIW0utyRT2YXZ/4NL1okfrkworNnz3Lu3DljMzt27OD8hQv4+Poau0RERETiPUd7exzs7IzNkRb7giRBHBhdl5rDLlO8TSeaf9yUdrVy4fBPd/BZvDo3pov3HZKnC+Pm0w/xfkeQXLRoEYsXLzY2c/PmTdKkS4fXkiXGLhEREZF4z83RCRfHFynrvcXCIAkEnMR3SC++mbUD9x4b2TWiwku3uYHAMywd0p0+P2zhqmNLFr0jSL6Jr68vK1aswFcjkiIiIiLvLXYGyb8F3TvP9ZAM5M7oauwCTNw/toF1e4Mp3LYhRZyM/e+mICkiIiJiudi32OYlLqlzvSFEAtjhnDIXpSoXJ7O9sU9EREREolqsDpJvF8i+7+qTr0R/1gYa+0REREQkqsXhIOlA9lq9mTS6CQUdjX0iIiIiEtXidJDMUbsjPXs0orAF8yNFRERE5L+Jw0FSRERERGKSgqSIiIiIWERBUkREREQsoiApIiIiIhZRkBQRERERiyhIioiIiIhFFCRFRERExCIKkiIiIiJiEQVJEREREbGIgqSIiIiIWERBUkREREQsoiApIiIiIhZRkBQRERERiyhIioiIiIhFFCRFRERExCIKkiIiIiJiEQVJEREREbGIgqSIiIiIWERBUkREREQsoiApIiIiIhZRkBQRERERiyhIioiIiIhFFCRFRERExCIKkiIiIiJiEQVJEREREbGIgqSIiIiIWERBUkREREQsoiApIiIiIhZRkBQRERERiyhIioiIiIhFFCSFa3cecunm/Tce1+88NJ4iIiIigo3ZbDYbGxMKX19fVqxYga+vr7ErQSncbBAPnwYYm19InzIpB7yHGJtFREQkgdOIpGAyhZM3azrmD+34ypEjY2pM4eHGU0REREQUJAXs7GypVio/NcsUeOWoWjIfdrb610RERERepYQgIiIiIhZRkBQRERERiyhIioiIiIhFFCRFRERExCLa/kfb/1CgyQCeBARSKGdGYxfHL9wgTXJ3Di8aZuwSERGRBE4jkkKDysVoWKU4OTKmfuVoWKU4/6tY1HiKiIiIiEYkNSIpIiIiYhmNSIqIiIiIRRQkRURERMQiCpIiIiIiYhEFSRERERGxiIKkvOLxtes8vnrN2CwiIiISgYKkvGL31B/x8WjLgflehJtMxm4RERERUJCU16n57QDy/a8ue6bPZEm7Ttw/f8FYIiIiIqIgKa9ySuRG9f5f8/G0KQT7+7O49afsmT6TsJAQY6mIiIgkYAqS8kaZSpXAY/FCijX/hIMLffBp2YabR/80lomIiEgCpSApb+Xg7EzFLz6n2dxZ2Ds6sqxTN7aOm0hIYKCxVERERBIYBUmJlDT589J84U+U+6wDJ1asxLu5J1f3/mEsExERkQREQVIizc7entKftqWl11zcUqZkxRe92TBsJMH+/sZSERERSQAUJOW9pciRnaZzZlCxZ3fOb9zCwqYeXNi6zVgmIiIi8ZyCpFjExtaW4i2b4bF4IcmzZmFN30Gs7jOQZw8eGEtFREQknlKQlP8kacYMNJ7xA9UH9uX6wUMsbNqKE7+tMpaJiIhIPKQgKVZR8KMPab3Um0wli7N55FiWd/uCpzdvGctEREQkHlGQFKtxS5mS+uNGUW/0cB5evIR3i9Yc8V2KOTzcWCoiIiLxgIKkWF2u6lXxXOJDzqqV2THxe5Z27MKjK1eNZSIiIhLHKUhKlHBO4k7tod/w0eQJBNy9zyKPtvwxZx6m0FBjqYiIiMRRCpISpbJ+UBbPJd4UaFCffbPnstizPXdOnTaWiYiISBykIClRztHNlap9e9N09gzCTSaWtv+MnVOmEfY82FgqIiIicYiCpESbdIUL0tJnPiVbe3DEdyk+Hm24efiosUxERETiCAVJiVb2jo580PUzms+fjb2LM8s6f86WMeMJeRZoLBUREZFYTkFSYkTqPLlpMX8O5bp04tSq3/Fu7smVPfuMZSIiIhKLKUhKjLG1t6d0u9a09JmPW+qU/NbzK9Z/O4ygJ0+MpSIiIhILKUhKjEueNQtNZ8+gcq8vuLh9Jws/8eD02vXGMhEREYllFCQlVrCxtaVo809otcSLtAXysWHwcFb26oP/3XvGUhEREYklFCQlVnFPm5aPJk+g1pBB3D5+Au/mrTi+fAVms9lYKiIiIjFMQVJipXz16uC5xIcsZcuwZcwElnftwZMbN41lIiIiEoMUJCXWck2ejHqjh/O/sSN4dOUqPi1ac3jREszh4cZSERERiQEKkhLr5axaBc8l3uSqWY2dk39gSbtO3D9/wVgmIiIi0UxBUuIEZ3d3an07kIY/TCToqR++rT9l78w5mEJDjaUiIiISTRQkJU7JUqY0rXwXUqRpY/bPXcCiVu24c+KksUxERESigYKkxDkOzs5U+rIHTefMAGDJp53ZMfkHQp8/N5aKiIhIFFKQlDgrXaGCtPSeR6l2rTm6ZBk+LVpz/eBhY5mIiIhEEQVJidPsHBz4oHNHWiz8CafEiVnetQebR40j2N/fWCoiIiJWpiAp8UKqXDlpNm8W5bt15vTadSxs6sGFrduMZSIiImJFCpISb9ja2VGyTStaLfYiebasrOk7iDV9B/Ls4SNjqYiIiFiBgqTEO0kzZqDx9O+p3r8P1/YfwKuZB6dW/24sExERkf9IQVLirYKNGtDK15v0hQuxcdgoVnzRG/+7d41lIiIiYiEFSYnXEqdJTYOJ46g97FvunjqNV7NW/LlsOWaz2VgqIiIi7yl6gqTpLgeWTGbYkNHMXH0CzViT6Ja3Ti08l/qQrfwHbBs3kZ87duXRlavGMhEREXkPNuYoGJoJOOHD4D5j2VFgPNvHV+H8942p3XsNd8MA+zRUG/IzvwysSFLjiQCm6xzecor74caON7BJSb6qJcjsYOx4N19fX1asWIGvr6+xS+KxSzt3s3XsBIIeP6F0h3aU9GyJrb29sUxERETewfpBMvQ0Uz+uSO/9WWnYZwIzO5kYWb4eMxL14hevdpgXdKX1j8kYvd+XT7PaGc+GgFV0K/wxP14OI1JZ0r0Vi2540SKxsePdFCQTrpBngeyaOp3jv6wgVe5c1PxmAKny5DKWiYiIyFtYPUiabs2lecEhJJq+nznN0xK4/kvKNJhL9u8O8OvnubG9OI2GJaaSa8khJtZ2NZ4OgP+pRfRt05Wf7lWm/zAP8rsYK15il44SDSqSQyOSYoEbh4+wacQY/G7foaRnS0p3aIe9o6OxTERERF7D+kHy4jQ+KjGV3EsOMbF2GGu/KE3D+TmZcOBXuud2IPjwaGpVXUzZX/cxttrrgyRA8KmfaPvhl5xvspwNY2uQ3FjwHkJCQggJCTE2s2zZMtasWYPP4sXGLklAwoKD2T97Lsd8fyZJpoxU7d+HtIULGstERETiHTtbW+xsLV8yY/UgSeA2+n3wP3zTf86X1fxZNm42ZytOZ5+vB87H1/HT0K8YcagC8w7Mo2W619zafiGUi/NaU/Wrh/TYsoqvijgZCyJt5MiRjB492thMWFgYFStVZtEvvxi7JAF6cPosf0yYyNOr18jVoD5FO7TDwfXNf+yIiIjEdW5Ojrj+hztx1g+SmLjyWz9ad57M7jvhOOdowEifBfQsfospH5ak165MNJvoy5xORXjn/6JD73L22A3M6QuSN53lQfJNfH19Wf7rryxatMjYJQmUKSyMwwu8ObjAG5ekSanSrzdZPyhnLBMREYkXbG1tsbWxMTZHWhQEyb+E3j/PnxcDSJG3MNmS2gHBHF/zM9cz16Z2oVS8bSwyumiOpLzJ46vX2DhsFLePnyBPnZpU7tUTl6RJjGUiIiIJmnWCZNAupvaez5HgSF7KoQhtJ/Wg4tsW0USC/60L3PRzJE2uzCSzIJkqSMrbmMPD+XPpL+yePhMHF2eqft2LXDWqGctEREQSLOsESf+ltMvRgvmR3fzR3ROfGwtpacGWPf8KZGPv4tT6sQQ+d3wsupaCpESG363bbBo5lusHDpK9ckWq9e2NW8qUxjIREZEEx/JlOi9L3JR590yYzebIHU//a4gEcCB7rd5MGt2EgpbPERV5J/f06fh42mRqfNOfG4eO4NXMk1OrfjeWiYiIJDjWGZGMozQiKe/r2YMHbB49nss7d5O5dCmq9f+aJBnSG8tEREQSBOuMSL5WEE/u3ebWjRtcv379r+PqZc6f3Mtvc5ZxMMhYLxL7uaVMSYPvxlJ35FDunz+Pd4vWHF60BHN4JKd1iIiIxCNRECRNXFvzLf/Lm4FU6dKTIVMmMmfO/NeRNTu5C35Aw96/cT7MeJ5I3JG7ZnVaL11ErupV2Tn5B5Z82pmHly4by0REROI16wfJoH3MGTqeLWGl+LTvIFqXTkzi0p4MHPQVneoXJJlzblpN/Jq6/3mOpEjMck7iTq3BA2n4/UQCHz5kUat2/DFnHqYw/ZUkIiIJg9WDpOneCY6fTc4nQxcwbdQgejUuiU1wBmr0H8/MFRtZ3D0pW5dt4Vqw8UyRuClL2dK0WuxFwY8+ZN+sn1js2Z67p84Yy0REROIdqwfJ8NBQQu1SkzFTEuxwInue3CS5fJyTt01gl5ZqbZqS/49fWXNSSVLiD0c3V6r27U2TWdMwhYaypH0ndn4/jbBg/XsuIiLxl9WDpEPqjGR0v8afRy8RBDjnyEke8wmOH/P7q8DGBkx3uXffZDxVJM7LULQIHosWUMKzJUcWL8W7RWuuHzhkLBMREYkXrB4kcS9P/QZp2NK/HnUHrycgRzk+yHefn8f0YtT07xk84Ed22mQnWxYH45ki8YK9oyPlu3Wm+fzZOCVKxPJuX7Bp1FiCA54ZS0VEROI06wdJUlF38Fy+/7Qo7raOOLmUpcuIfpS+78s33b5g7EYT1fv2oUVeBUmJ31LnyU2zebMo/3kXzvy+Hq9mHlzauctYJiIiEmdF24bkJr+rnDh5C3O6fBTKmhQLHo1tddqQXKLL46vX2DRyDLeOHiNP7ZpU7v0FLkmTGstERETiFOsHSdNtDvy+gwsBb9mg2S4dpRpVIWcMD0oqSEp0MpvNHFu2nN1Tf8TeyYnKX/UkT60axjIREZE4w/pBMmgXgyrWZOSh58aef7m3YtENL1rE8F6SCpISE/zu3GHL6PFc3fsH2SqWp2qf3iROk9pYJiIiEutZP0iaHnJm31FuBEW8bHiIH7dPbmTerH1k6/EDw7pWIFMM399WkJSYdGr17+yY/APhYWGU/7wLhRs3wsbGxlgmIiISa1k/SL6VieuLO1BtbAqmbp1A7WTG/uilICkxLfDxY7ZPmMy5jZvJUKwo1Qf2JVnmTMYyERGRWCkKVm2/jR3py5WmwLUNbDkSaOwUSXBckyWj7sih1B83isfXruPj0YZD3osIN2mfVRERif2iOUiauLX/MKdD7LCz1y08kX/kqFKJ1ku9yVOrJru+n87S9p/x4MJFY5mIiEisYv1b26FnWDJiKtvuGUdUzIQ8ucie9Vu4kqkXq3aOp4a7oSSa6da2xEbX9h9g86hxBNy9R8m2npRu3wY7hxje4kBEROQ1rB8kg3YztFZjvj8VGrHdxgZ7l+RkKVaHT/t/Q4dyqWJ8L0kFSYmtQoOC2DNjNkeX/EyyLJmpMagf6QsXMpaJiIjEKOsHyThEQVJiuzsnTrJpxBgeXr5CkU8+pny3zji4uBjLREREYoSVgmQA92884XlkL2XjTLKMqUhkbI9mCpISF5jCwjgwbyEH5i0kUepUVB/Qh8ylSxnLREREop11gqT/Utpla8H8h295ms3LtCG5yHt7cPESm4aN4u7pM+SvX49KX3bHKXEM/0ckIiIJmnWCZPBRlk75nfOhf10q/MF+vGf9zsNs1alXrShZU7hgE3if8/vXs3pfCKU/HcG47zwp7mS8UPRSkJS4Jtxk4qjvz+z5cRbOiRNTrd/XZK9UwVgmIiISLawTJF8WepJpTWozxW0Iy2Z2oPDLAyamu2wZ2oyWq0uxcNN4aiV/qS8GKEhKXPXk+g02jRjDzSNHyVWjGpV798QtRQz/ByUiIgmO1feRNN3YwYbt7jRo1zJiiASwS0NFz8aUuLSWjYe1IbmIpZJmykjjH3+gWv+vubr3D7yaenBy1RpjmYiISJSyepDE2Rlnu4dcuXIb406SYOLhiZNcDHPDzVUbkov8FzY2NhRq9BGeS31IX7Qwm4aP5tfuX+J3546xVEREJEpYPUjapa5Gg/purBrUmi7fLWXr4TNcvnqF83/u5NcfvqRlj3k8qtCUj0poCxMRa0iUKiUNvhtL3ZFDuX/2PN7NPDm6dBnWnrUiIiJiZP05koDpxgbG9ujJ2N9O4/fyQm7bxOSq+wUTpgyiQY4YXmmjOZISDwU9ecL276Zwdv1G0hUuRM1v+pMsS2ZjmYiIiFVESZD8SwA3juxm58Fz3HoSjH3iNOQoXonKpbNgnDoZUxQkJb66vHsvW0aPJ+jJE8p0aEeJVi2wtbc3lr3VwycBPHwaYGyOIGOaZLg6x/wfhSIiEjOiMEjGfgqSEp+FPAtk5/fTOPHrb6TMmYMag/qTJn9eY9kbjZ63mqlLNhmbI1g8qguViucxNouISAJhnSAZtIupvRdwpWQXRnq6sGzwJLbcfXWpzQsORWg7qQcVY3iapIKkJAQ3j/zJppFjeHrjJsU9mlO206fYO717FPGfIOkz4jNjF6ev3GbEnJUKkiIiCZx1gqT/Utrl8GSvx0oOj3JjVMWajDz03Fj1L3dPfG4spGUM3+NWkJSEIiw4mH2z53LYx5ck6dNRY1B/MhQrYiyLYPS81fis3cuJpSONXZy+fIsaXcYpSIqIJHDWWbWduCnz7gVzZlJtXF0qMOJgEGaz+c3H05gPkSIJib2TExU+70LzebOwd3Fm2Wfd2DpuIiHPtJ+riIhYzjpB8l1MdzmwZDLDhoxm5uoTPDL2i0i0SJ03D83nz6HcZx04sWIl3s09ubr3D2OZiIhIpERJkAw44UPveoUp9fV6Agnmz2mf8mGrLxk8dACdG9Xgk5E7eWI8SUSihZ29PaU/bYuHz3zcUqVkxRe92TB0JM+f+hlLRURE3sr6QTL0NPP7f8HUQ45kT+tEiP8uvOdsJKBUP9ZdOMva/gU5PuV7frnylsU4IhLlkmfLStM5M6jYszvnN23Bq5kH5zZuNpbFWpv+OEn7oT+99dh3/ILxNBERsSKrB0nT/b1s3+1KyymrWdS7CnZ7VrPmrDNVWrajWo7c1GzTiDIhJzh5Nth4qohEMxtbW4q3bEYrXy9S5szJ2oGDWdm7LwH3HwDw2O8ZNbuMe+X4sOdk46Wi3ZVbD1i/9ziP/AJ47P8swnHxxj3W7z3Orfu69yEiEpWsHiQJCiIo3I1kydyxw49dv6/lonNFatfKhgMQ9tQPP7MDDg7GE0UkpiTJkJ5GUydR85sB3Dp6DK+mHmR5cJUm1UuRP3uGV47/VShCk+qlSJsiifFS0W75+O78OqFHhOOX8Z8by0REJApYPUjapStAwazXWD5lKFMm9GPU4oskqfER/8sWyq3Dyxk3dDb7EhelSL5372MnItEr/4f18FziTebSJbn/82IqX9nPsJZVmfK1x2uP3FnSGi8hIiIJiNWDJK4V6Ty0K5mPTKTX1zM57F6fAX2akZ1r/DygNUM2O9H42940TGdnPFNEYgG3lCn439iR1BszgocXL+Hd3JPDi5ZgDg83loqISAJn/SCJHVk/Gs/mY6f4Y+9BThxcRs8y7uCQjWrdf2TV3h14dSqCq/E0EYlVclWrgucSH3LVqMbOyT+wtGMXHl68ZCwTEZEELAqC5F8c3BNje+8Qv0wewNejV3Ax1IkMKVwJCAxD4xoicYNzEndqDR7IR5Mn8OzeAxa1ase+WT9hCgszloqISAIUJUHSdGMdgxuUoVyjz+g7fALTVx/nYXgQp1aPok3NOnTzvUCo8SQRibWyflAWz6XeFP6kMX/8NJ/Fnu25c/KUsSxGrNxxlJXbj0Q4Vu04aiwTEZEoYP0gabrBL4M/57ur5Ri99jg7RlTirwXaLpToMIpBlR7jNXgK6x8bTxSR2MzBxYXKvXrQdPYMwk0mln7amZ1TphL2PGa38uo2ZiFdRi+IcAya/ouxTEREooCN2Ww2Gxv/k/uLaF2oFyFjDuDTNjXHx9ahyspqbNjyDaWdIGjfEKrWXkX11bsYWdHFeHa08vX1ZcWKFfj6+hq7ROQtwkJC2P/TfA4u9ME9XVpqDOxLxhLFjWVRKvB5ME8DgozNESRN7IqLk6OxWURErMTqI5KhTx/x8HlasmVNwevWZTumSk0qm0CCAq2bX0Uk+tg7OvJBl060mD8HR1dXfunSg82jxxPyLNBYGmVcnZ1IlzLpWw+FSBGRqGX1IOmQMiOZkl7jyNErr5kHGcz5jZs4GJ6FzJm1I7lIXJcqTy6az5/NB107cXr17yxs2pKL23cay0REJJ6yepAkaRWae+Ri75gu9J6zjat+oRAWwO3D61k4vB0tBqzBvl5T6udUkBSJD2zt7SnVtjUeixaQNGNGVn/dn9/7f0PgI02EFhGJ76w/RxIg4Dhe/brSb/YeboW8tNmPrRu5/teHH6YNpHam1934jl6aIyliXWazmRMrVrLr+2nY2ttTqdcX5Ktb21gmIiLxRNQESQBCuXdyB9v2nuTao+fYuKYkW5FKVKuYk6TG0hiiICkSNfzv3mPL6HFc2bOPLOXKUn3A1yROk8ZYJiIicVwUBsk3CeX2H4d4WrQseWP4cdsKkiJR68zaDWyfOJnwsDDKf96VQh9/hI2NjbFMRETiKCvOkTRx7/AyJvXrQrs27ekxbB47rxv2l3v0J779G1Lpw2kcCYnYJSLxT966tfBc4kOWsmXYOnYCv3TuzuOr14xlIiISR1kpSJq4teor6lX9hF7jvVizfgUzB7enzv++ZPk1ExDK9U0TaFm1Ki3GHSB5g+oU0K4cIgmCa/Jk1Bs9nPrjR/Pk+nV8PNpyYP5CwvWYRRGROM86QTL0Mr/O/InTOT7D+88b3LtzjVMr+1DixjzGzd3Dkfmd+F/Dr1kZUpnBy7azcU5bCsfwbW0RiV45KlfEc6kP+erVYc/0Wfi268T98xeMZSIiEodYJ0gGn+PsGajUrjdNCyYFEpHjw6/oUt+dI0t60OaLVTg1m86GrcsY0igf7sbzRSRBcEqUiOoD+tB4xveEBATg2/pT9vw4m7AQzXUREYmLrBMkzc/w93MkTZq0fz9XGyARGTKmh3O3SNP7Z1bN6sIHaWN+yx8RiXkZSxTHY/FCijRrwsH5Xixq1Y7bx08Yy0REJJazTpDEjNkExrWYdvb2OORvTb9eVVGGFJGXOTg7U6lnd5rOmYGNjQ1LO3Rh+3dTCA16+/OzRUQk9rBSkHwzu5SpSKmH2IjIG6QtWICW3vMo3b4Nx5Ytx6u5J1f37TeWiYhILBTlQVJE5F3sHBwo91kHWnjPwzVZMlb06MWGoSN5/tTPWCoiIrGIdTYk919K26werE6Sh3Ru/97gDnlwiQvPkpErS7KX5k4CTjUYsW0SHyV6uTH6aUNykdjHHB7OEd+f2TtjFo5urlT5uhe5qlc1lomISCxgnSAZuJXxHaex73kkL+VYiq4/9aO6q7EjeilIisReT2/eYvOosVw/cIicVStT5eteuKVMYSwTEZEYZJ0gGUcpSIrEfidWrGLnlKnY2NpS6cvu5K9fz1giIiIxRHMkRSRWK9jwQzyX+pC+aGE2DhvFii9643fnjrFMRERigIKkiMR6iVKlpMF3Y6kzfDB3T53Bu5knR5cswxwebiwVEZFopCApInFGnto1af2zDzkqV2T7d5NZ2rELjy5fMZaJiEg0UZAUkTjFJWlSag/7lo8mT+DZvQcsatWO/XMXEB4WZiwVEZEopiApInFS1g/K0srXi/wN/sfeH2ezuE0H7p05aywTEZEoFO1BMmBtP8qX/JIVAcYeEZH34+jmSrW+X9H4xx8Ie/4c33ad2D1tJmEhIcZSERGJAtEeJM2BD7h47j6BCXbTIRGxtozFi+Hhs4BizZtyyMsHn5ZtuHn4qLFMRESsLNqDpIhIVLB3dqLiF91oOncm9o6OLOv8OZtHjSM44JmxVERErERBUkTilbT589Fi4U+U79aZ07+vw7t5Ky7v2mMsExERK4j2J9v4/9KBXO2eM/GmNy0TG3ujl55sIxK/Pb56jU0jxnDrz2PkqVOTyr164pI0ibEsgub9p/PYP9DY/EKa5O4sHNbJ2CwikiBpRFJE4q1kWTLTZNY0Kn/Vk4vbduLVzINzGzcbyyI4dv46Jy7cIHfmNK8cJy7c4OTFm8ZTREQSLOuMSAas4qvqA1j37N2XMgfe5tSDuvhoRFJEopHfrdtsHj2Oa38cIHvlilTr2xu3lCmNZRRqNpAWtcsyoP2Hxi6+/XE5a3cf44DXEGOXiEiCZJ0RSdtEpM6Zhzx53n3kLVaFj/9XgDR2xouIiEQd9/TpaPTDJGp+M4Abh46w8BMPji9fgTX+lhYRSaisMyIZR2lEUiRhevbgAdu/m8L5zVvJULwYNQb1I2nGDKARSRGR92KdEUkRkTjELWVK6o0eTv1xo3h89SreLTw55L0Yc3i4sVRERN7COiOSwUfw/W4VZ0MjeSn7XNTv1ZISLsaO6KURSRF57ufHzslTObX6d9IUyM+0J67U/bC6RiRFRCLBOkHSfyntsrVg/sNI/jXv3opFN7xoocU2IhJLXN23n82jxvLkzj0OJc5I+U7tsbGLOJl73II1JHdPxCGfoRHaRUQSKisFyWV8mrMZ859npUz1WtSqWYMaVcuQM6m9sfIvNk64p0mGq7E9milIisjLQgID6d6gHfn8bvLAzoX1blm57ZDoRb/ZbCZTmuTsW/BthPNERBIq6wRJwP/qfrZs2MCmjetZt2kfl8LSU7JaXWrXqE7N2jX4IFcyYttCbQVJEXmdW8eOs2nEGB5fvUbRpk34oGsnHFz++1yc5yGhbDt42tgcQerk7hTPm9XYLCISK1ktSL4s9NFZ9mxcz4aNG1i3fhtH7ziS44Oa1KlZg+q1alGtdBZi+K42KEiKyFuYQkPZP3cBB+d7kShNaqoP6Evm0iWNZe/lzsOnlPAYbGyOoFa5gswb3MHYLCISK0XJqm2H5Hmo3KwHI+es5tC58xxaNZFPS9pzavEgmpbLS87ifVgbYDxLRCT2sHNwoNxnHWjhNRfnJO78+nlPNo0cQ3CA5V9eV28/AMDVyYGkiV1eOWxtbDhw8pLxNBGRWCtKgmQELunImb8A+fMVIH+hXGRwCeHB1fv4W30cVETE+lLmzEGzubOo0L0rZ9ZtwKupB5d27jKWRcqte48BCAwO5Yl/0CtHuNnME/8g42kiIrFWFAXJUO6f3syiSf1oV7cIufKUpUk/L47blqTjlJXsP/oDTWPDvW0RkUiwtbOjhGdLPHwWkCRTRlb17sfagYMJfPxXMHxfGVIl5dcJPV45RETiGivOkfTnyh9bWL9+IxvXr2PTvsuEZypF9Tp1qFmzBrWrlyNH0vdbbhN44zDbt+3l2IWbPHj6jBCzHU5uSUmVITsFSlWiUqnM/Lue8v1pjqSIvC+z2cyxX35l99QZ2Dk4UKlnd/L9r66x7LUWrNrJgGm/YGtjQ5LEr+5b8djvGQA31002domIxErWCZKB6xlQuQ2TDvuTvFAlatWpSY0atalZsQCpnYzFkfDkMPMH92fU/E2c9wsHW1vsHV1wsjMRHBRCWHg42CYmZ83OjJw0hKb5Xv1CjgwFSRGxlP/du2wZM4Eru/eSuWxpqg/og3vatMayCOb9toNBM5bjYG/HZ42rGruZumQTKEiKSBxinSD594bkC0PSkztrMhyM/UZONRi+dSIfvXY40Y9tA6pRf2oQtb/8ig71ylEodxbSJXPBDjAFPeLWlbP8ufs3fhwzhV0ZvmH9ugGUsWBnDgVJEfmvzq7fyLYJk3keFAQVqkPhkmBjYywjSSJXzOHhDJqxnAypk7F/4aurtzPU6QkKkiISh1gnSAZuZXyn6fzxPJKXcixJlzn9qP66gcTATXxd+mN2NPqdTcMrvHWboPure1Cl5X4+Wb+VIeXeP0kqSIqINQQ+fkyfhu3IFfSAmw6J2ZQkB0/t//1Oeh4SSobUyejSuCqDZiwHwNnx1T+5n4eEgoKkiMQh1gmS1uT/Cx1zf8qzcRdZ5JnC2BtB6IWpNCw5jTxLDjGx9utS6V/mzJnD3Llzjc08ePCAbDlz4r1kqbFLROS9VG43kpZ5UpD68A5C/AMo1NaTvE0+xtbOjjE/rWLH4XM0r1OGiQvXAWD7mlHL8L+/jo/+PMLYJSISJRI5OeLi6GhsjrTYFySDjzCmdmWmpxjLmgVdKPTa298AD9k1vCkfTXBmyIEVdM/96l/3/7h+/TrXr183NrNp0yaO/vkn3osXG7tERN5LKY8htKhTls8bVWDf1BmcXb2WFLlzUalvb6ZtO8W2g6dp/1Elhs36zXjqK86vHGdsEhGJEo52dtjbvd9i6JfFviCJiStLu1K/3Xwe5K5N/RolyZs1HSkSO2NvYybseQCP7lzh9L51rNhwiYxdFrF2UgPSWfAe6Na2iFhLwU8G4Pm/8vRt+z8Arh84xObR4/C7dZuA/MVZHZqUYZ83oc3gOSRP4ka6lEmMl+D0pds4ONhxaeUEY5eISKwUC4MkQBCXN85myoxFrNxyiKtPwwh/qdfWMQU5y9SgQfMOdGlXg+zvPz0SFCRFxIqMQRIgLDiYfbN+4qD3YvwdXCj2+ed8Nn9LhPOMHB3subxKQVJE4oZYGiRfEnify5evcfdxICHhNjgmTkH6LNnJnNySfYUiUpAUEWt5XZD8x+Ch07DZtIpkIc845JiK/UmzkSjJq0sJ7zx4gpOjAxdXjjd2iYjESlH0ZBsrck1FtgIlKFuhIpUqVaBssXxWCZEiItYUZgrn6p2HXL394JXjUpg9a7OWIeNHDSkafJ82j4/xcfakNKhUNMJhb2+Hg70F83RERGJIlI1I+l85wN4/r/LkeRjh4WYi/BC7dJRqVIWcb14fEy00Iiki1lLwkwE89g80Nr+QKU1yxnT/hB79JlP32RXSm55x3j0dB1PmItTury/DOw+f6ta2iMQpURAkQznj9RnNui/g2NOXZza+xL0Vi2540eLVOzvRSkFSRKxl68HThISEGZtfcHF2JDw8HI9BM7EFKts8odijS4TY2vNHqtxcS5Sau4/8sLGxoUXtsozv2cx4CRGRWMf6QdJ/PV+WbsBcl+YM+PJjiqZ1w864XZptCvJWLkbGGL6DoyApItFp5+GzNB8w48U/p7UPp9qTC2QM8eOic3LWOWfkma0jubOkZevMfhHOFRGJjaw+RzL0zjnO3UpH828m0dfzI2rXrEGNGoajWsyHSBGR6JbU/a8HJ9ja2vCVZ132LJ/IiC0rqdz3a/LZh9Dh6UmKhT3C+Le3iEhsZfUg6ZA0JSkTueDq6mzsEhFJsLYfOkO30QsBCA83M8FrLdkbfEX2Bl/xv9lbmWSfnav2ianpd4lyF/bhd/uO8RIiIrGO1YMkqWrj2SYZmxYt41yQsVNEJGF6EhDIxZv3X/xz2hRJKJI704vjma0j2zMUYUuqfCQJ8sOrWSuO+C7FHP6GueYiIrGA9edIhp5hydDBTJyzkqtpKlG5eBaSOdtFvFXjUAiPsV2pYOFG4taiOZIiEl1+236Yrn+PSNra2tD6f+VpVqvMi/663b/D2cmB5O5uJHe0pVcGOLNuA+kKFaTGN/1JnjXLS1cTEYkdrB8kg3YztFZjvj8Vauz5l2sjZpyaQ1Ot2haRBOLlIPk26VMlJbGrM1tm9uPKnr1sHjWOoMdPKNWuNSXbemJnb288RUQkxlj/1rZLeQbvvMPDhw/ffFyP+RApIhITZg9qB38Hxq6fVHtxAJQrnJOHTwNe7Lub9YNytPL1psBHH7Jv9lwWe7bn7qkzL11NRCRmWT9I/iP0LkdW/cSEIf3o/WUvvh40iqmLtnLuibFQRCThKJ4vK44Odty6/4TpP295cQDsPXaB4JCwCFOBnBK5UbVPLz6ZPR1TaChL2ndi5/fTCAsOfqlKRCRmWP/WNmC6vo7hHTszeuNVQrDF0dGesJAQwsNtSVakNePnf8+nRWN+SFK3tkUkuvxza/uQz1DcnJ0wPO+LfI3783WberRvUBE7W1vcXF59FGxYSAh/zJ7HIe9FJMmQnhoD+5GhWBFjmYhItLH+iKTpOku/7cbY49no/OMGjt98SmBQMAF3zrFz8bdUeb6Ur3tN55D+mBaRBOjHZVvwXrsHn7V7IxwAzo4OuLu5vDZEAtg7OlK+22c0nz8beycnln3WjS1jJxDy7M2PZhQRiUrWH5G8541Hwd4EjdjDkk45MD5O+9G6L6nc9A8+2biVb8u8/ssyumhEUkSiy6odR+k8aj4ANjavbjluNpsZ3KkhnT6uYux6rfCwMA56LWL/nHm4Jk9O1X5fka18OWOZiEiUsnqQDL0wlUYlZ5Lvlz8YX/2vpzi8zHRxGh+VmEruJYeYWPvV/uikICkicd2jy1fYOGI0d46fJHetGlT5qicuSZMay0REooTVb207pMlB9jSX2fjbFm6ZjL1+HF6+iv3kJEcO41iliIi8r+TZstJ0zo9U6dOLyzt349W0FWfXbzSWiYhECauPSEIQhyd9TL0+e0lZx4Mm1QuTNbkzYX63OLtnBd6/nCRNF1/WfVeftDH8vG2NSIpIfOJ3+w5bxozn6t4/yFbhA6r2/YrEaVIby0RErCYKgiRgus2O6UMZ9oMv2y8+JSwcwBbnDCX4qEN/hnzViLyJjCdFPwVJEYmPTq9Zy/ZJ32M2majY43MKNPzwtfMyRUT+q6gJkv8w+XH97HluPHqObeK0ZM+bg1Qxu74mAgVJEYmvnj18xLbxE7mwZRsZSxSj+sB+JM2YwVgmIvKfRG2QjOUUJEUkvruwdRtbx00kOCCAcp06UKxlM2ztYnhekYjEG9YJkkG7mNp7AVdKdmGkpwvLBk9iy91XVtr8y6EIbSf1oKKLsSN6KUiKSEIQ7O/PzinTOLlyNanz5qHGN/1JlSunsUxE5L1ZJ0j6L6VdDk/2eqzk8Cg3RlWsychDz41V/3L3xOfGQlrG8MNtFCRFJCG5fuAQm0aOJeDuXUq29aR0+zbYOWgHDRGxnHWCZBylICkiCU3o8+fsmT6Lo0t+JnnWLNT8pj9pCxYwlomIRIrV95EEP64cP8SpG294ZJf/RXb99ht7b7zl1reIiEQJB2dnKvfqQdM5MwBY2qELO6dMJfT5W+4iiYi8gfWDZNAxZretRnffS4Qa+4DQG6sY7tmHJSf1sG0RkZiSrlBBWnjNpWSbVhzx/Rnv5q25tv+AsUxE5K2sdGv7Hr/3a0H/NfcIJ5gHly4SmDw3mZPaG+rMhDy6wrknpRizex19i8bsXkC6tS0iAvfPnWfTyDHcO32W/PXrUbHn5zi7uxvLREReYaURydRUb9mSSvlykztXVlI52+KaJhu5c+eOcOTJk4+iVVvS7/tRtC8UsyFSRET+kip3LprNnUWFHt04u3ETXs1acWHrNmOZiMgrrDQi+ZLgP5ndYyinq4xnbIscxOb1gBqRFBGJ6MmNm2weOYYbh46Qs1oVqvbpjWvyZMYyERGIkiD5QhBP7j0hMMSE6Z8fER7G84A7nNp7kwweTSipfSRFRF7raUAgWw+eMTZHkC19Sorkzmxs/s/MZjMnVqxk1/fTsLGzo3KvL8hXr46xTEQkKoKkiWtrhtKl91Q2nH/893O2DdxbseiGFy20j6SIyGuduHiD2t0mGJsjaFmnHON7NjM2W43/3XtsHTuBy7v2kPWDslTr/zWJ06QxlolIAmalOZIvCdrHnKHj2RJWik/7DqJ16cQkLu3JwEFf0al+QZI556bVxK+pG8MhUkQkLpja15PDPkNfOZIncTOWWl3iNKlpMHEctYd+y52Tp/Bq1opjy37F6uMPIhJnWT1Imu6d4PjZ5HwydAHTRg2iV+OS2ARnoEb/8cxcsZHF3ZOyddkWrmn3HxGRd0qd3J00KZK8ciR3T2QsjTJ569bCc6kP2cp/wNZx3/Fzx648unLVWCYiCZDVg2R4aCihdqnJmCkJdjiRPU9uklw+zsnbJrBLS7U2Tcn/x6+s0T6SIiJxhmuyZNQdOZQPvxuL/507LPJoy4H5CwkPCzOWikgCYvUg6ZA6Ixndr/Hn0UsEAc45cpLHfILjx/z+KrCxAdNd7t3Xk21EROKa7BXL47nEh/wf1mPP9Fn4tuvE/bPnjWUikkBYPUjiXp76DdKwpX896g5eT0COcnyQ7z4/j+nFqOnfM3jAj+y0yU62LLF5YyAREXkTRzdXqvX7msYzvickIIDFbTuwZ/pMTKGve56ZiMRn1g+SpKLu4Ll8/2lR3G0dcXIpS5cR/Sh935dvun3B2I0mqvftQ4u8CpIiInFZxhLFabXYi2LNP+HAAm98PNpy69hxY5mIxGPW3/4n9BReQ+fxuGIXutTO/mJDcpPfVU6cvIU5XT4KZU2KneG0mKDtf0QktooN2/+8jzsnTrJxxBgeXb5C4caNKP95ZxxdXY1lIhLPWD1Imi5Pp0H+MWRcfJSZDZMbu2MVBUkRia0ePglg2eYDxuYI8mVLT6XieYzNMcYUGsrBBd7sn7sAtxQpqNb/K7J+UM5YJiLxiNWDJI9X0bWEJ+c7b+KXPiVxN/bHIgqSIiLW9/DSZTaNHMOd4yfJW6cWlXv3xDlJbP6/gYhYyvpB0nSLjaM68Om3WzGXqEzpfBlI4WqPzcs19oXwnPA5FfSIRBGReMkcHs6fS39h9/SZOLq6UOXrXuSqXtVYJiJxnPWDZNAuBldrwHfHQ4w9/3L7hDkX5tE8hp9uoyApIhK1nt68xeZRY7l+4BA5qlSiap/euKVMYSwTkTjK+kEyDlGQFBGJHidXrmbH5KnY2NhQ8YtuFGhQ31giInFQFGz/IyIiElGBBvXxXOJNhmJF2DRiDL906c7TmzeNZSISx1h/RNJ0mwO/7+BCQLix51926SjVqAo5Y3grSY1IiohEvwtbt7F13ERCAp5RrksnijX/BBtbjWuIxEXWD5JBuxhUsSYjDz039vzLvRWLbnjRQnMkRUQSpOdP/dg+6XvO/L6OtAULUGNQP1Jkz2YsE5FYzvpB0vSQM/uOciMo4mXDQ/y4fXIj82btI1uPHxjWtQKZYnhXcgVJEZGYdXXvH2weNY7AR48o3b4NJdq0ws7e3lgmIrGU9YPkW5m4vrgD1camYOrWCdROZuyPXgqSIiIxL+RZILunzuDYL7+SMndOag7qT+q8sWejdRF5s2ielGJH+nKlKXBtA1uOBBo7RUQkAXJ0c6Vq3940mTWNsKDn+LbtyM4pUwl9/pYpUiISK0RzkDRxa/9hTofYYWcfYYtyERFJ4DIULYLHogWUbO3BUd+f8W7emusHDhnLRCQWsf6t7dAzLBkxlW33TIYOMyFPLrJn/RauZOrFqp3jqRHDT8zSrW0Rkdjp/vkLbBo+mntnzlKwYQMq9OiGUyI3Y5mIxDDrB8mg3Qyt1ZjvT4VGbLexwd4lOVmK1eHT/t/QoVwqYnitjYKkiEgsFm4ycdh7Mftmz8U5iTvV+n1N9orljWUiEoOsHyTjEAVJEZHY7/HVa2waMYZbfx4jT52aVO71BS5JkxrLRCQGRNEcyVAeXzvN4T/28cfh41y4q4U1IiJimWRZMtNk1jQqf9WTS9t3sfATD86s22AsE5EYYN0gGXCO37/rSv2iWcmYLT8lypajbInC5MmYnhzlmtBr2iYuBxlPEhEReTsbGxuKNm1CK18v0uTPy/pvh7Hii6/wv3vXWCoi0ch6t7b99vN9m+Z8vdqP3LUa8b/yBcmSJjGO4c95cus8R3f8zqptN0jzyXf4zulMsUTGC0Q/3doWEYmbzqzdwPaJUzCFhlChezcKffwRNjbaDUQkulkpSAZzeGxdqo18QvMZXoz3KMCrTz/044RPX9p0XUqqodv4rWchnIwl0UxBUkQk7gp8/Jht4ydxftMWMhQrSo1B/UiaKaOxTESikHVubQefYsPag6RqNZiRrw2RAO4U9BjBty2Ts2f1es4bFnWLiIi8D9dkyag3ahj1x43iyfXreLdszSHvxYSbjNvPiUhUsU6QDL3OtSu2FC5Rirevo0tBmVJFsT13gYvBxj4REZH3l6NKJTyX+pCnVk12fT+NpZ925sGFi8YyEYkC1gmS5mCeB9mTOHHid+4N6ebujnNAIIFWuKEuIiIC4JQoETW/6U/DHyYS9OQJizzbs3vaTMJCQoylImJF1gmSmDGbbInUNGdbW+zClSJFRMT6spQpTStfL4o1b8ohLx8WebTl1rHjxjIRsRIrBUkREZHYwcHZmYpfdKPp3JnY2tnxc8eubPtuMqFB2n9OxNqss2rbfyntsnmyJklu0rq9fVzSHHiHMw9qs/C6Fy1evyon2mjVtohI/Db/t+34bdmA+Y+dkMgdm5ofYpMl+4t+FydHOjSqHOEcEYk86wTJwK2M7zSdP55H8lKOJekypx/VXY0d0UtBUkQkfivlOYRb95+Q3iaEGk8vkjbsGSecU7EzcRb8TZDY1Zkzy8cYTxORSLJOkIyjFCRFROK3Mm2GUbNMAUZ0bUy4ycSRxUvYO3MOzokT86hkZRaeeciJpSONp4lIJGmOpIiIJAi2dnaUaNUSD58FJM2UCad1y6l+7yTPHj4ylopIJClIiohIgpIscyYa//gDIZVqkzHoMV7NPDi16ndjmYhEgoKkiIgkODY2NoQVKMbPGUqRoWgRNg4fxa89euF3546xVETeQkFSREQSrEB7Jz6cMIY6I4Zw7/RZvJt58ufPv5CAlw+IvBctttFiGxGJx/yeBRH+lodA2NnaktjN2dgcaRv2ncBrzW5jcwSdm1SjfJFcxuZoUcpzCAWyZ2B4l4+NXYyev4atB05z+pfRAAQ9ecL276Zwdv1G0hcrQo2B/UiWOZPxNBF5SRQEyWAe37lPQOjrL2tjY4e9kytJkifF5V3PU4xiCpIiEt8VbDqQx37PjM0vZEidjP0LBxubI23ubzv4ZsZyyhXOiZ1txH2EnwQEceLCDaZ85UGTGqUi9EWXMm2GcePumxfTJHN3e2XV9qWdu9gyejzP/fwp06EtJVq1xNbePkKNiPzF+kEyaBeDKtZk5KHnxp6X2GKfJCOFK35Ex74D6VghzTuf0R0VFCRFJL7L17g/iVyc+Kp1XWMXI35aibODAwe8hxi7Iu2fIHl1zXfY20X8Jn/k94xCTQfGaJDcfugMgc/f/LxtRwd7qpfOb2wmOCCAXd9P58SKlaTMmYMa3/QnTb68xjKRBM/6cyTt01P+4w8pkNiRNEU/pH2vAQweOpj+X7ShdoEU2NpnoXa3gfTrWJPUl7z5olVPFp4PNV5FRESswM7Olo+rl6RZrTKvHA2rlMDGMIoY31QukZe65Qu/8XhdiARwSpSI6gP60GTmNMJCQljSrhO7fphOWHCwsVQkQbN+kMTEraN/ENZwJlt2ruSn70Yy5NshjJo8n3W71vNdPROnHuWkw5g5rP59Bq0c17Bw+Sn0n6aIiMQ2GYoVwcNnPsU9mnPYxxcfj7bcPPqnsUwkwbJ6kDTd3srqTYmo79mU/IkMnUlL0LpZFQK37+JwINhlqUmVkrZcuHwZjUmKiEhsZO/kRIXuXWk+fzb2Tk4s69SNreMmEhIYaCwVSXCsHiSxtcOO+1y6dOs14TCQ8xcvE5LI9a+FNqEPePzEjIuT5SsGRUREokPqvHlovmAOZTt9yokVK/Fu7snVffuNZSIJitWDpF2aKvyvtjNrvm1N14nL2P7nea5cvcSpAxvwHtGBThOOkL1BPcrYnWXlqL5M356I0iUL4mK8kIiIxBnLtxxi+ZaDEY5ftxw0lsV5dvb2lOnQjpbe83BNkYIVPXqx/tthBD15YiwVSRCsv2obMF1fz5gvvmT8b6d5Gv5vu61jesq2H84Po9tT6O73NCj1Ddc+HIfP7M8o6vryFaKHVm2LSHyXr3F//J4FUbnEqyuOtx86Q/qUSa2yavttYnLVdlQyh4dzdOky9s7465Z3la+/JHfN6sYykXgtSoLkXwK4fngXOw+e49aTYBySZqZA+WpULpAKB8D06AInbjuTo0BGjFMpo4uCpIjEd51HzedpQJCx+YXUydyZ8rWHsTnSnoeE8izw7cslE7k64+QYf/dh9Lt9h80jx3Jt/wGyV6pAtX5f4ZYypbFMJF6KuiAZepcj61az+dB5bj8NwdYtJVnyl6NWvarkTmosjhkKkiIiYi2nVv3Ojsk/YDabqdTzcwo0qG8sEYl3oiRImq6vY3jHzozeeJUQbHF0tCcsJITwcFuSFWnN+Pnf82nRxMbTop2CpIiIWNOzBw/ZMnYCl7bvJFOpklQf0IckGdIby0TiDasvtsF0naXfdmPs8Wx0/nEDx28+JTAomIA759i5+FuqPF/K172mc+jtd0JERETiHLeUKfhw/GjqjRrGw4sX8W7uyWEfX8JNJmOpSLxg/SD5cDur1wRQd/AcJnSsScG0ibADXFLlokLzwcyZ3IkMB39jzVElSRERiZ9y1aiG5xIfctWsxs4pU1na/jMeXLhoLBOJ86weJEP9nvA0JDU5cqTDwdgJJMmVkyy2j3nyRH+diYhI/OWcxJ1a3w6k4Q8TCXr6lMWe7dk36ydMYWHGUpE4y/pzJP3X0qPkJ+yo7cvvk+qT3u7lTj8OjG/K/0Y6MPjgcrrlfE3UNF3n8JZT3H9p26C3sklJvqolyPyaS72L5kiKiEh0CA0KYvf0mfy59BdSZM9GjUH9SFvg9c/5FolLrB8kCeLwpI+p12cvKet40KR6YbImdybM7xZn96zA+5eTpOniy7rv6pM2Qsj8W8AquhX+mB8vhxGpLOneikU3vGhhwdodBUkREYlOt44dZ9Pw0Ty5foNiLZpR7rMO2Ds7GctE4owoCJKA6TY7pg9l2A++bL/4lLBwAFucM5Tgow79GfJVI/K+ZfNI/1OL6NumKz/dq0z/YR7kf9tjb+zSUaJBRXJoRFJEROKAsJAQ9s+Zx0GvRbinS0uNgX3JWKK4sUwkToiaIPkPkx/Xz57nxqPn2CZOS/a8OUgVyT+8gk/9RNsPv+R8k+VsGFuD5MYCK1CQFBGRmHLv7Dk2DR/N/XPnKfBRfSp+8TlOid4yyiISC1l9sU0Edu5kyl+CchXKU6bIXyEyYG0/ypf8khUBxuKInPK3ZsSg/3Fvzjjm/qkV3iIiEr+kzpOb5vNnU75bZ86s24BXUw8u7dhlLBOJ1aI2SL6GOfABF8/dJ/Cd46AO5Gg1mY0bRlM/tbFPREQk7rO1t6dkm1a0WrSQpJkyseqrfqwdOJjAx4+NpSKxUtTe2n4N/186kKvdcybe9KalBQtkLLF161a2b99ubObEiRM8DwnB23eJsUtERCRamc1mzv62mkMzZ2Pn6ECpbl3IUauGsUzEqlwcHHBysDc2R1q0j0hak/+tC5w5c43H2pJSRETiOBsbG/I2/JCGC+aQMm9edo0ay6a+A3l2776xVCTWiMMjkoFs7F2cWj+WwOeOj0XX0mIbERGJrc6s3cD2iZMJDwujQveuFGz0ETY2NsYykRgVh0ckHcheqzeTRjehoKOxT0REJG7LW7cWnkt8yFK2DFvGTOCXzt15fPWasUwkRllnRDJgFV9VH8C6Z+++lDnwNqce1MXnP49I/ncakRQRkbjg4vadbB07ged+/pTt2J7iHs2xtbd8XpuItVgnSAZuZVzHafzxPJKXcixJ15/6U93V2BG9FCRFRCSuCA54xq7vp3FixUpS5clNzW/6kyp3LmOZSLSyTpCMLgG/0blge/yGnWFR61TG3vemICkiInHN9YOH2TRiDAF371KiTSvKfNoWOwcLHu8mYgVxbI5kGCF+j3geZmwXERFJGDKVLE4r34UUadqYA/MWsqhVO+6cOGksE4kWcSxIioiIiIOzM5W+7EHTOTMAWPJpZ7Z/N4XQoCBjqUiUUpAUERGJo9IVKkhL73mUbt+GY8uW49Xck6v79hvLRKJM3JojGXycn6es4nnlHniW+e8PttccSRERiS8eXLzEpuGjuXvqNPnq16Xylz1wShzD26O8w9Gz12j89Q8Eh4a99ukqwaFhdGpUmW87NTR2SSwRt4KklSlIiohIfGIOD+eI78/snTELx0SJqNqnFzmrVjaWxRqHTl+hwZeTqVE6PyXyZTN2M3bBGto1qMiIro2NXRJL6Na2iIhIPGFja0vxls3wWLyQ5Fkzs6bvQNb0HcizBw+NpbFK9+Y16dHi1SNjmuTGUollFCRFRETimaQZM/Dx9O+p3r8P1/YfxKtZK06vWWssE/nPFCRFRETiIRsbGwo2aoDnUh/SFynEhqEj+fXzL3l685axVMRiCpIiIiLxWKJUKWkwcRx1Rw7lwYULeLdozVHfnzGHhxtLRd6bgqSIiEgCkLtmdTyX+JCzamW2T5zCzx278ujyFWOZyHvRqm2t2hYRkQTmyp69bB41nqDHjyndoR0lPVtia//q9jtR7Z9V27mzpKV4nizGbnw3/KFV27GcRiRFREQSmKwflMNziTf5P6zH3hmzWNy2A/fOnjOWRTkXJ0dyZ0mL2Wzm8Nmrrxy5MqchbYokxtMkFtGIpEYkRUQkAbt5+CibRo7h6a3blGjVkjId2mLv5GQsE3ktjUiKiIgkYBmKF8XDZwHFWjTlkJcP3i1ac/PwUWOZyGspSIqIiCRw9s5OVOzRjeYL5uDg6sKyzp+zZcx4Qp4FGktFIlCQFBEREQBS58lNi/lzKNe5I6dW/Y5Xs1Zc3rXHWCbygoKkiIiIvGBrb0/p9m1o6TOfxGnTsLJXH9Z/O4znT/2MpSIKkiIiIvKq5Fmz8Mns6VTu3ZML23awsGlLzm3cbCyTBE5BUkRERF7LxsaGos2a4OnrRapcuVg7cDAre/cl4N59Y6kkUAqSIiIi8lbu6dPRaOokan47gFt/HsOrmQfHl68gAe8gKH9TkBQREZFIyV+/Hq2XLiJL2TJsGTOB5V178OTGTWOZJCAKkiIiIhJprsmTUW/0cP43dgSPrlzFu4Unh318MYeHG0slAVCQFBERkfeWs2oVPJd4k6dmDXZOmcrSDl14ePGSsUziOQVJERERsYizuzs1vx1Awynf8ezBAxZ5tuePOfMwhYUZSyWeUpAUERGR/yRLuTK08vWiUKOP2DfrJxZ7tufOiZPGMomHFCRFRETkP3N0daXK11/SZNY0wk0mlnzame3fTSH0+XNjqcQjCpIiIiJiNRmKFsHDZz6l27fh2LLleDdvzfUDh4xlEk8oSIqIiIhV2Tk4UO6zDrTwmotzksQs7/YFm0aOITggwFgqcZyCpIiIiESJlDlz0GzuLCp078qZdRvwataKSzt3G8skDlOQFBERkShja2dHCc+WePgsIEmG9Kzq3Ze1AwcT+PixsVTiIAVJERERiXLJMmeiycxpVOnTi8u79+DV1IPTa9YayySOUZAUERGRaGFjY0ORJh/jucSHdIUKsmHoSFZ80Rv/u3eNpRJHKEiKiIhItEqcJjUNJo6jzvDB3D11Bq9mrfhz2XLMZrOxVGI5BUkRERGJEXlq18RzqTdZPyjHtnETWdb5c57cuGksk1hMQVJERERijGuyZNQbNYwPJ4zB7+Ztnj99aiyRWExBUkRERGJc9koVaPvrEtIWyG/sklhMQVJERERiBTsHB2OTxHIKkiIiIiJiEQVJEREREbGIgqSIiIiIWERBUkREREQsoiApIiIiIhZRkBQRERERiyhIioiIiIhFFCRFRERExCIKkiIiIiJiEQVJEREREbGIgqSIiIiIWERBUkREREQsoiApIiIiIhZRkBQRERERiyhIioiIiIhFFCRFRERExCIKkiIiIiJiEQVJEREREbGIgqSIiIiIWERBUkREREQsoiApIiIiIhZRkBQRERERiyhIioiIiIhFFCRFRERExCIKkiIiIiJiEQVJEREREbGIgqSIiIiIWERBUkREREQsoiApIiIiIhZRkBQRERERiyhIioiIiIhFFCRFRERExCIKkiIiIiJiEQVJEREREbGIgqSIiIiIWERBUkREREQsoiApIiIiIhZRkBQRERERiyhIioiIiIhFFCRFRERExCIKkiIiIiJiEQVJEREREbFI7A2Spoec3bWGX1esY98lP0zGfkzc2Pcbvku3cSHU2CciIiIiUS1WBknTnc2M+qg0xSvX5+NGdSlfuAT1+//M6YCXq4I588sA2nT8iQPPX24XERERkegQC4PkYzaO/YLhe5PRdLQ3vy6by/CmKTk6oTUNO/7IYT9jvYiIiIjEhNgXJAMPsXnjNUr0nM70Ph40bNyOAXN/Z+X3DbFZ0ZvWPb05G2w8SURERESiW+wLkqanPHloT7YcuXF50ZiMUl1m4jW2FoE+X9BxxGbuvTppUkRERESiUewLkvZpSZcxjKP793A/Qoc7pbr9yKw+BTk14TM+//EogeYIBSIiIiISjWJfkHQpzocfF+f6zC406zySWRvO82JRtl0aagyaxaTmzvzeswGfL71JWMSzRURERCSaxL4giQuluk/jx255ub5oBDN33I0YFp3y4DltGXO/LIbtfX/CX+4TERERkWhjYzabY+0N4qB757kekoHcGV2NXYCJ+8c2sG5vMIXbNqSIk7H/X9evX+f69evGZjZt2sTRP//Ee/FiY5eIiIhIvOdoZ4e9nZ2xOdJidZB8F/9bF7jp50iaXJlJ9pb3YM6cOcydO9fYzIMHD8iWMyfeS5Yau0RERETivUROjrg4OhqbIy0OB8lANvYuTq0fS+Bzx4eWiY397+br68uKFSvw9fU1domIiIjIO8TCOZKR5UD2Wr2ZNLoJBS0P0iIiIiJioTgdJHPU7kjPHo0o/Jb5kSIiIiISNeJwkBQRERGRmBS3gmTAb3TOmoKWCyNuVS4iIiIi0S9uBUnCCPF7xHPtQi4iIiIS4+JYkBQRERGR2EJBUkREREQsEreCpENu6vYbSaMCLsYeEREREYlmcXhD8v9u7dq1DBo0iJw5cxq7XvHs2TOcnJywt7c3dolEEBwcDICTk/alkrczmUw8f/4cNzc3Y5fIK/z9/XFzc8PWNm6NAUn0CwoKwt7eHgcHB2PXK9q1a0edOnWMzZGWoIMkf4dJPz8/Y/MrBg0aROvWrcmdO7exSySCn3/+GRsbG5o0aWLsEong4sWL/PTTT4waNcrYJfKKTp06MW7cOJImTWrsEolg6tSpFC5cmEqVKhm7XlG8eHFy5cplbI60BB8kI6tcuXJMnDiRcuXKGbtEIhg8eDC2trYMHjzY2CUSwYEDB+jatSsHDhwwdom8Ik2aNBw7dow0adIYu0Qi8PT0pFatWnh6ehq7rE7j4yIiIiJiEQVJEREREbGIgqSIiIiIWERBUkREREQsYjdkyJAhxkZ5vRIlSuDu7m5sFnlFtmzZyJo1q7FZJAIbGxsSJ05MiRIljF0ir1W+fHkcHR2NzSKvyJ8/f7QszNKqbRERERGxiG5ti4iIiIhFFCRFRERExCIKkpEReJ414zpRt3gOUidPTro85Wjcew577pqMlSIRBJ+exSfZ89NzfaCxSxKsAE79MoSWlfKRIUVKMhaoQstBi/jzibFO5F/6LpF3iqGsoiD5TvdZP7gFLb7ZQFiFLoz+YQrftsjOlfndaNpxOn8GGetF/hJ4bhl92vdj2dVQws3hxm5JoB5uGIZnmwkcSdGIAZMm0v+jZByd/Cke367mnrFYRN8lEikxmFXM8lZh1+aam6VyNOfu/Kv5zovW5+aTk+uYkzgXNvfd+ixCvYg55JZ57/yvzLWzOJtTp01jtrfPae6+1t9YJQlR2GXz7MYpzM7F+po3P/2n8al556AyZtcUjcwzL4VFrJeETd8lEkkxmVU0Ivku5kxU6vQ5XT6uxL+L6J3InC0bScPv8fBR1A4ZS9wTdGgmPb9Ygc0nc1g5tg5JjAWScD3dz+5dz8hWrTplX+wk5k6JOrXI/2wXO3Y/jFgvCZq+SyTSYjCrKEi+g13mGnQd8R09ayb/t9F0m42/b+W2SzEK5Xd+uVwExywfMXH3PlaP9yC/s42xWxKw4OuXueJvR9YsWXF4qd0xWxayOPhz8eIlovIOlMQt+i6RyIrJrKIg+d78OTL7S/rMu06hjj1onuvl/x2IgF26YnxQIAV2xg5J8MKfPuVpuB2JEyeJECTtEicikUM4fv7+aGNf+Ye+S8Ry0ZdVFCTfyyP+mNqB5l/+hk2j8cz+tg6p9V+4iLwnW1vjF4cNNnYQFhZ1t59EJKGI3qyiIPlCMIdGVcTNxgabvw+HzJ35LeCf7susGdScxl+uxbn5VJbO6kKxxIZLSALxjn9XRN7A1i0RbrZmngc9I0JkDHnO82Bb3Fxd0Q1MEbFYDGQVBckX7MlQ/Ut+mDOHOX8fP45sQgEnIOA48zp/RIvxp8nf14dff/yUonrkdgL2ln9XRN7CKVMmMjmZuH37FiEvtQffuMPdMAcyZMiAnqIsIhaJoayiZ22/03029P0fTSY/ovaERczsXpqXprKKvJX/0nZk89hFy1VH+L5OImO3JDShx5lQtxzDHUbxx8oe5HUAMHF51ieU+vIm3TZuY+gHLsazRPRdIu8Qc1lFQfIdgo+MpW7lAexOVYM2DQvh/vJ9JxsH8jX5lk/L6ItfXk9f/hJRKGd/bErlLw5SpPcEhrUpht1JX4Z9NZrduUex9bcvKayRbXkNfZfI28RkVlGQfKtQzkz+kJJfrueZsQvANgmePtdZ2DyKJyBInKUvf3lF4Cl8+nWm78zd3AwJB1tH0pbtwPhZ42lVwNVYLQL6LpG3itmsoiApIhLtTDy5fJQ/LzwkPEkOipTIQfIoXFUpIhJVFCRFRERExCJatS0iIiIiFlGQFBERERGLKEiKiIiIiEUUJEVERETEIgqSIgnWXeY3T4F7mW/ZFWTsiy53md8sOQ4ODi8dTji5JCJ5htyUqtuJCesvE2w8LVYL5tDoKiRJ/hEzLr3p2dn//t6JSgxgx2ve/9CLM2iYwgkHh0SUH76fYIs/rxh6jwN+o3MmJ7J2Xcmbnx4amffKApH62SJiDQqSIgmWmfDwMEJN4caOaPTXayDbJ4z28sHHxwcfHy+8Fsziu75NyH5nGX1bdmDy/kDjibGb2URYWDhv3hPjr987zMkFTm1k42FjMjRxc8tGdgQ74RQWSrjZTLjFn1cMvccOGSnr0YWWZTLiYOx72TvfK0uEEx4WQli4VS8qIq+hICkikRPqz73r17nrH2rsiSDU/y637gXwPuNLtomzUfajpjRt+s/RknY9RrHQ+1tqhu1gwZLdvBJzgv24c/0G9wPe5ye9Q6g/965f4eodP974WwY95Pb9V38/U8A9bt/zf/N5r+GYvSrVc59l0+ZjEUcETbfYumkXTlWqU8ZKe5RH3XtsIuDeDW49NoRhpxK0HTOZUW2KY3xYjyXv1WtF5vOK4A2vVUQspiApIm9nusXWyR2okjcj6bJmJn2GnFRsN4mttyKGC9ONTUxoU45sqdOTKUNWijUdyZwRTSlesgMLr74tiLyZU5bc5E4Vzs279wn5pzHwDMu/bUrJ7OnIkDkLaTPkpsqnk9lywwSPVvJVhWJUG7QB/xdXCWDz4JqUaDiB/S/yg4lbvl0pU6wOw3cEYrq/l5nd61E4c1rSZc5G1gxpyFy8CUNWX/kroASuZ0ClUnw2agyNCmcmferMfDBoKwGA6dYWJrWvSPY06UifLgtFG41k1/1Ijho65KV6zWyc3LiZky8lSdO97WzabkvVmh+Q6OVHnUWB936PXwjl0m/f0KhIBlKly0SmtJnIX68X3sf+fucD19O/YmEqD9jwIqC+870KXM+AysWoOmhjhFAbtHMkdYqVoffKv25Uv/PzesU7XquIWExBUkTeIphj0zvTqu8qTHVGs3z9OpaOqEf47/1o8ekUXtyRDT3L3J7tGLg6nLqjl7JmxWQ+MXvz1ehV/HnuLgFhhstGionb29ex/bo9+XJm/2tUy3SL3/o1p+3MGxTvNY/ft23it0ktSbZ7EC06TOKgQzHyp7/O3t828uJObdAhNq/cxeGNq9ly5p+09oDta3/jqF82Chd6zvoRHekx9zqFey9g/Y7trF3Qj7L+qxjddxrbA4HwIB5eOszc4fOwbb+QdcuG0rFyQRKFnmXuF23otzKMuqN/Zu1vU/jEZgnfTD/I839/kbewp2D1GmT8cxObz/6bJB/u2MS2sEpUL5+IqM2RFrzHf7+vplvLGNZ9HIczdWb++q38Prs96Y/8wBcDF3AmFAgP5OGF41x8FEQ4f/878q73KjyIR5dOcemfc/5mDnrEtVNnuR9oBh69+/MyeOdrFRHLmUUkgbpt/ukTd7NziYHmnYHGvr/5rzf3yu9oTl7/B/PpkH8aQ8wXZjU2p3HMYe6y4pHZbDabA/cONpdxdTfX+u6Y+fk/ZU+3mfuXcDaTuL552oWwf1oNbpt/apLYbJuxhvmzAYPMgwb9fQz42tzds6Y5j7ut2a3QZ+all/86//nRceZq7mnNjWefN794OWaz+dG6XuZCrtnNn/1633zpx4bmZM4lzYP+/qUC9w42l01V0ly2SDJz7Umn/jrv4TJzh8yO5swdl5kfhJw1/zKss7ntN7+Yr794mYHmHQOKm50TNzTPvBpmNvv/au6Uwdbs/MFw8/4Xv6DZHLh3iLmsq7u51nfH/309j9abvyrsGKnf27H4APPOB2vM3XO5m2tNPPn3NR6Yl32ayZys4Y/mC5d+NH/k5mguO3SfOTAyn9drWfs9/vsz3znIXNLZzfy/H/6p8zdvn9jR3LHPAvOhQLPZ7L/c3DEt5gyfrTD7R/a98v/V/FlGR3PmLr+Z/f/90eZn63uZ8zkmMXsu9jObI/V5GX72u16riFhMI5Ii8kbBF49y5IoDparXIMeLFRMOZK1Vk3JONzl0+DRBmLhz5AinKEzlyrn/nQ/nXoqqVbLh+OJqbxb+9CIHdmxj27YtrFsyg1GjxrPwsANVvvyJdWum8ElWO8DEvQP7OPg8GVz8me/GjGHM38fMA49w4RaHj5wjRbXqfOB4iq3bTxJMMGe3b+d8qZb0qJOFg1u3cc0Efru3su1OKqpVr0gKh9x8/M0M5g2rg8PFg2xb7cvsCcOZteUmYYQR9tJoqmvOXOR58QuauHv0CCcpSIUKuf5dUJLsA6pVzoL9i7PewaUc1aulYN/GzVwOBZ7sYtNWP8pVr0ZGK35DW+89Pk0Q4JK7BCUzh7J+2Cc0+2IMCzdeI9/ns5g1tjXFXYw/3UrvFcB7fF7/eL/XKiLvw4pfUyIS34Q/fcKTcDuSJU8RYeWtXfJkJHUM58lTf8yE8dTPD5NNYhK7v/yVYkeSJEkjFRIcc7Vgyoad7Ny5mwN/HuL3wTVxuX6NkBxlKJHpn+QWxqNHjwgLu8uf639l+fLl/x4rT2IuUITUjmHYZ61G9XI2HN22jfOBl9m+9RgFK1ahdqWKpNi3le03/di7dQs3kleleuUUf82X3DwBj1I5yJyvFFU/asfAn3ZyO+zvV/5i4a8tbq4uL31phvH4yRNMNklImuzl39uB5ClTRur3BsAmGRVqVCPJvk1svhaK357NbL5fmhrVskb+GpFgzffYDJD6Q4YtnEHP8rDnx4G0qVOEvEXr0m3qdgzTZ633XsF7fF4vea/XKiLvQ0FSRN7I1i0RbrYm/P2eRljEYHrqh1+ILYncXLHBnuTJk2FvesTDhy8PB5l4/OgRrxkgejuXLNT+ZiaTm4Ti0/MzRm25//cKaVvcXN2wccyFx/Tt7N+/33DsY/XASrg65KBatdKY9+9g++GtbDucnYoV8pK8bGUqOe9m+/YdbNt6GfcqNaiSyg4ermZE14Gsta3P+GU7OHb5FjdPb2BI7bTYvyGX/MUe98SJsDEH4O/38ow+E0GBzyLM8XuXFBWrU9VlFxu3XGbv5k3cKV6Dav8OAVvff32PAbAjVZn2jP/1IGdObWfplK+pl+Q4c75sRd/F1w2r2iP7Xv01I9Rs2LYnPPg5z/8psujzep/XKiLvQ0FSRN7IKUcBCqQJ5ciePdx+8X9bE/d27+ZQcBLy5cuFC3akKV2WEnYn2LLp+L8bQD/ew6ZtV/9dCfw+7LLRZOgY2qf9gwm9x7LpPoADGQoVJhcn2LzpeIRVvaEXf2PCkPF477mLCSfyVq9BcdN+Ns/cwL6UFalQ1AWSlKdShXB2+kxn8zlXKtaoQjo7CDp9kP3XnKjacTDdGlWkUOZkOITe5PiJS4SEmzC9cd9GO9IXKUqe8BPs2fvSauHgixw8dPn9AnTKytSobM+u9TP4deMNCtWsSl7jnjnW9p/eYxN31gylad1WTDkYRtIcFfjk81HM9xlIHZcHnD5j/Nwj+1454OgMAX5+L/3sUK6cO8e9vz+G9/+83ve1isj7UJAUSeDCA65yYPVLtzD/PlasP8rdxNXw8CxBwK8j6PXd7xy/dp1T63+g99Cl3M/fCs+6aQFwKtiS7q2zcGhMG1oPmM6CeVPo1bITU4/9vR7XgqXHdhk/ZODwtmQ5MYNvJm7hEeBStiUdaiVh36Tu9PpxM6eu3+DCvqUM796DgZN+4xJu2AFO+atSveBTVvn+jlPFipROBNilomLlcjzZuJZDThWpUTUjdoB9mnSkdwri0Bpftp27xfUzO/D65nNGr3kK5kACnxmDyb9cyrSgXU1HNo7tzuAl+zl37g98h/ZiyuseVfM2dmmoXL0SpjU/Mu9sHqpXLfjK3ov/eOvn9Z5Da5a/x3YkS+/Kw70/M2n4d6w+do0714+zduEqDoZmoETx3BinHkbqvXLKRb78bvhvmMP4pQe5fO0cuxcPod/M/S9GGt//83r/1yoi78G4+kZEEoq/VgH/fTfwlePF6mD/Y2av7pXMmZxt/+qzdTNnq/K5ed7hxxEv9/iI2evrhuYSmZOY3ZJkM5dt/q15XNdS/66kfa2XVi+/bvVs2FXzkk9zme0Tf2D+dudTs9lsNodcW28e9Ukhc3L7v18Ptma37DXNvRefND97ceLfq3htU5s9Ft5+0RpyerK5dmJbs/v/fjCffbF0+IF52+h65myu//5+Oev2N3vP7mzO65jK3GTOZXOY/6/mThnszZk6R1xNbDabzc8vrDD3r5PTnNj2r9eSrGhb8zedy5pdI7tq++/fO+ziDPNHSTA7Fuln3vZP25VXV20bP6dXPq9XvPqzIrD4PX5sPjCjjblYCnuz7d+vwTZxLnO9b1aZr4S9umrbHMn36uGuieYm+dz/vqatOUmhFuZJU7qY8/6zajtSn5fxZ7/jtYqIxWzMZus+mEpE4ie/q0c4ev4RtqlyUaRIZhK/1Gd6fJWLTxOTJWvyl0bSAtn0dWk+9CrDwnM/8Yn7Syf8Z6E8unCUY5cfYXLLSL6iBUj/n54AY+LxxUMcveiHQ9q8FC2ckUTGkrfy4+qRP7nol5icJYqS+f1OjqUi9x6HPrzA0eOXeByeiIz5i5E/7bvG9yLxXgXe4sTh09wlDflKFCT9K5e07PN6/9cqIu+iICki/1nw0THULj+C4N7rWD+sAu6A6dYqvqzXlIUZx/PHr5+TJwrXjoiISMxQkBSR/y70DHPbfEiXX/zJV7USBZKHcOWPLRwM+YAhixbRv2Jy4xkiIhIPKEiKiHUEXWXXsp/5/eAFHgQ7kiJ7CWo1bkzVHJG56SgiInGRgqSIiIiIWETb/4iIiIiIRRQkRURERMQiCpIiIiIiYhEFSRERERGxiIKkiIiIiFhEQVJERERELKIgKSIiIiIWUZAUEREREYsoSIqIiIiIRRQkRURERMQiCpIiIiIiYhEFSRERERGxiIKkiIiIiFhEQVJERERELKIgKSIiIiIWUZAUEREREYsoSIqIiIiIRRQkRURERMQi/wcu5NKhie1IQgAAAABJRU5ErkJggg=="
    }
   },
   "cell_type": "markdown",
   "id": "77a2485e-bce1-4325-aae2-a02a4029aed9",
   "metadata": {},
   "source": [
    "![image.png](attachment:7dd28c89-02f9-465e-88f7-1712bb078a4b.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e764f38f-e402-4789-afd7-545873cba7b3",
   "metadata": {},
   "source": [
    "#### 3、Horton、Rand和Zeckhauser实验"
   ]
  },
  {
   "attachments": {
    "36cf6773-6c0c-41cb-8ecd-783aaf376389.png": {
     "image/png": "iVBORw0KGgoAAAANSUhEUgAABTIAAAG/CAYAAABrMShBAAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAAAJcEhZcwAADsMAAA7DAcdvqGQAAP+lSURBVHhe7P1vUFTXvvD7ftfe9bRV59q8sHkj3iqh6kY49wI+VyEVhJTSlgorRiwjxrXA5Amu1AaTJejdgLUFcwKkHoHaAu5ErEogOxFOjCRucZmA5AqmIpIK4N02Vu2GPLXBqkX7YtGeWt2+WPSp8/R90f9mT2Z3z4YGUX+fKkvoMeme3T3mmHP85m+M8Ru32+1GCCGEEEIIIYQQQgghVrG/Uz8ghBBCCCGEEEIIIYQQq40EMoUQQgghhBBCCCGEEKueBDKFEEIIIYQQQgghhBCrngQyhRBCCCGEEEIIIYQQq54EMoUQQgghhBBCCCGEEKueBDKFEEIIIYQQQgghhBCrngQyhRBCCCGEEEIIIYQQq54EMoUQQgghhBBCCCGEEKueBDKFEEIIIYQQQgghhBCrngQyhRBCCCGEEEIIIYQQq54EMoUQQgghhBBCCCGEEKueBDKFEEIIIYRYMiej9YUcbJ1RFyzRDC2HCqkbdaoLhIiZ2Z5S9lTcZl5dsETzg5XsOfots+oCIWLFMU5dQREt0+qCJZq/zfH8Uq5I5RXLaLna3unWIl6vH8ehLnhOSCBTCCGEEEKIJXHSV1ZAue1dOisS1YVLlMiJz97FdqKA0n4JZorYs7YWsq9zE22tO1ijLlyiNeZm2pK/ZF/Bx1jVhUIslWOA0t9WYiu7yIkkdeESrdnB+ZZNdOwvpEUqr1gGy9n2JlVc5JitkryygecymCmBTCGEEEIIIZbA2lRM1cxeOtt3E6cuDGme6f6zFOUcp09dpBa3m4uf7WW6uphG6VCLGHL0H6eoez0NX58kRV0YxM79rrMUFZjZuvll0ja/TFpmHgcrPmZwNnwuUUpVFw0Jlyl6TjvU4mmZovHNGqb3XeRinlFdGGR+9jYtFUXsyPTW3c0vszWnkHeabofPFk45SU/9erqOHKdPKq+IIf1tbwiOAUozXyYt/1yIm0RG8tsvUjBTQ2HTlLrwmfcbt9vtVj8ohBBCCCGEiMzRf5zc6idU/9TJIV1RzHlmBz+h6sxlLE6AV2i6f5589WYaHD0lZDetpenWefJ1vZYQYVjPsefNATI/66chU12oYP2Coj984q2vWgwkl3fyTckmdYHCODXmMkbzurhZFW47IfRw0leWT5XzBMNdb4S5gTTP/dYSSj7/FZe6yMf4Ck3fh29TR2vzKBnbTU/fIoNOQijpbXtD8tb/uy5IOBy+Xjq+pejVFoyNfRED/s8SycgUQgghhBBiMRw3KK/9maTyBl1BzLnhj3nH/Cp5J3xBzOjEFTZQkfQzNSduSGabWKIpGk9cZm7PB+E70taPef1NTxDTkJhKbu52cjNewmRQbuRisq0kwtQHW2mo38Vcd6VkFYslc/RWUnN3IxWN4YKYYG09RPHnv2LMOEzTpT6GbvUxdK2d+oOp+EM6zp+pOvZt2DY1s/4D8uYuU/4cZraJlaaz7Q3DU/9DhuaDxb1BU/lGhmsruRaukj9jJJAphBBCCCHEItxpOMuY8TWqSxLURQvM9n5Mn+EAbYO/MPH1YSL/hZYEjla+hnHsLDWD6jIh9Jvt/JAuWyrVNVnqIgUbHWe+ZMb0CvXf/8J4byfnW5s539HN7dFfGLpwgMCMsC6Ga0+HH36bfYrqtEd0VX8cfjivEGGNUN9wD+O+kxzdoC5TmP2Cms+h4LNb3O44SX66ifh4E/FJW9lf28lQy3b88fiJq/TMBf95sCxqq1KxdZ+mRSqvWAJ9bW8Yjm8pO3MvdIaxhg0lJykw3qP+zG110TNLAplCCCGEEEJEy3qO+psuEve9i56kig0F73MkM8GTPZSSyqLXpch8l4JEF0PNoebFEiICxwD17b9iyH0rfCbxYAsXprdQf+08+zUCRvHZp/jTZ69h8j3g+pmum+GyMo0cKtmOYeYy9WGzN4UIzdp0ln7XRgpKt6qLggw2f0V8YxcNmdrDadeYz1Cd5vvtV0bHgsvV4grfItfwkK4GmetVLJLetjckGx1/aMS67S0KorobupWyfRtxDbU8NxnxEsgUQgghhBAiSoMXr2IjlSM6sjFjK4Gjxalgu8oFycoUizDb+SnDrnUUlOxQFwXp6/mRpLIz7A/X4c48yTF/MAimLRGG3prfosDkYrj9C8nKFItwmws9jyDtcPhsTEa4YzhJU9g5AY2kp6/3/ryWeH9EPpQdHN23DtfdT+mQyisWQW/bG8psZyWt07toa98dmBpBpw0lh0nnEVcuPh9ZmRLIFEIIIYQQIioDXBlyQdpr5IUL8iyTuD2vkY6LoZ4BdZEQEUzRdfMhGLPIT1eXKY0wOLGdYxED9UbM5pf8vznn7EGlC6WRn70WZn6g6znJDBIrqP8qQy5IL9gddm5MyOJMU6RtAOY9/xm2YtaRWr85LwsjD+nvjhCwF2IBvW1vCNaPKWmzU3DhI3LUZXrE7aYgDVxDV+lTlz2DJJAphBBCCCFENPpvMAwkm3fo6Cgvg7gdmJOBuzeeiw6JWEHWGwzawLBtd4QpEbKo/b4Bs/phDfEJgVQ2U1Jg1sxQMvOyMPCIwesSDBLR6ev9GXgJc260+WhabPQNPwYgveqMrrpO5m6yDWAbuiFTe4jo6G57tUzReOJLKDq/6AWCAjedfqa3X1327JFAphBCCCGEEFG4M3gPWEfmtohjEZeJifTktcA9BofVZUKENnd3HBuQnh15oYm4uDXqhyJKSd+kfmihtC2kALaxEcKuryJEkBEGxwDTVrLj1WXRc/SfpWsGEt/portQb2A0lcxkwDbOsFReEYVo2l41a1MlXRymrUpH+xpGfNomjMDo4Ii66JkjgUwhhBBCCCF0m2J4zAVsIj1FXbZyMjM2AS5GhyWrTeh3Z/hXYD0pyeqSxbP658V8hYI8VaGWuDTSTcDkCHfUZUKEYh1h1AUkp7LUptcx+iGF1fdIKb/CNxXRBIeMpKevA37ljtxEElFYdNtrPUd5NxS3nFxyvSdzK8mAa2zkmc8olkCmEEIIIYQQejkmsNiBhMTFrzweC8mbSADslglZQVfoNM7YJMDGGAbhp+gd8gzPNe17m3x1saZNpCcDTDE2qi4TQptj4gF2IEHH9AUhOaa4VpFH9h++w4YLS9shcovPMRpFI+rLOp4cG1cXCRHCYtveKRpPXIZ3mqmO6u9C2URKAmB/gCWKOr8aSSBTCCGEEEIIvWwPPastJy49K2hJEjYSj2d/bOoyITQ9YtYZ4yC85Sp9NsDwCtWVW9WlIcXHrwWeMCuVV+hkm/ZUliQ90xeozQ1QV1zA1leLqfUG3n2cE5cp+e1x+vQGdkwmjIDT9khdIkQIi2t7R2uP02V8j86osobDWU+SCcCG93B6ZkkgUwghhBBCCL1mZoi0LvOKiDNiBLDPMK0uE0KLdcob9DYQ/eyXWpz0td/AjoHs+o/Ij2Llq3iTZ05C26RMjSD0mZ4ODkBGJX43Z7p6Gb9/i6FbHbSXbyfBoCh3/kxN9YC+7PZ4TyAT29QzPzxXrJDFtL2jH1J53URFy9tsUJctmhGjEeAx0zPqsmeLBDKFEEIIIYTQac7mCWMuaXhjTCSSlABgxyaLTgg97HbP4jqJm6LKCgpp+Cw1d10Ytp2hKU/vYikeSSkbAZibWxW3BcSqZ8fT9K5naU2vkfj4NHJKmrk5eo3atEA003X3C3r0tKVJ3uNnzns8CRFJ1G3vCJXHvmNDzUWOxi6KCUBS0npQXMs8qySQKYQQQgghhE5zc0/UDz1lT5iT3rTQw+nEpX5s0capqf0Bkt+ju303USRjBnE5neqHhNBgZy7mVSWBQ11tFJh8v//K6FjwFmG5nMR8l8TzKaq210lfWSWD6WdoL4zuBlE0nM/4TSQJZAohhBBCCCGE0MlJX1k5vWsO033l7ac7V6wQS7KVqrJU/2/TFpnqQDxdjv7T1IxtoaFl76JvEL0IJJAphBBCCCGEEEIXa1MxVTO76Pz6pAQxxTMvLnc7yeoHhXhKhnt/xuX6mapXXyZtc6h/xXT5FuuxXaZQUVbar3rC55QEMoUQQgghhNDJs9ryarKW+Hj1Y0JoMBpRrm+yGNbOIop6NtL09QdkxiBdyOBZeUKICEzEL1dViV+PrwmNakV0g3fBNSEiiUHbG2vGeP+cCs8kCWQKIYQQQgihU3yC5+Lf9tSX/Jxh2gZgIkECmUIPk8kTsJl5sKjVlh39xylqN9Fw63xUK5RrsVoeAhD/jHemxUox4Wl6H8V+tWWHb67Ll8jMUBdqsD5gGs/q5dL0Cl2iaHvNjX0M3Yr0TzG3q+k12hVlTbmqJ1SZnn4EimuZZ5UEMoUQQgghhNArMRETgEv/1P3LypSocxVU8cJL2UQCwLy6IDJH/3Fya+0cuxQ5iOnoP03NoL4XSUiOIgNOvNCSktYBMK+vaul390csgGHb2xRGE5lM2CRTKwh9omh718SZiI+P/M+4xvcHxqDH43yPh7WOpET1Y88WCWQKIYQQQgihV8JGNgBMT0XMrFhWvqyghI2eDpIQEa1ngxGwR1d3HaMfUlj9kEOXujkaKXJj/ZiSNiOF5vC9aU9W0Fo2SOUVOiUkeSrL9KTeBXmczEVc6txGR+fPYHiFhsbd+hZXmZnBBhgT1qtLhAhhcW1v7E1hmQFIwHs4PbMkkCmEEEIIIYRecWmkmwD7jCeQuCguPYkZ4Xk706b0NH2dbyHYSkYywCMm9famreco/MN3zCWuZ/ZiJccrwvwrLmDrm1/izD3AZvXzBPF1pjeRkakuE0JbXFoqJsCua2z5CJWZO8nduZO0nBIah+3qDYB57jeV0Tr9EhU6Mo19fNMiJGdsVRcJEcIi2t5l4Z2SxpRKus76vlpJIFMIIYQQQgjdNpGdYQAeMDyqLtPH0XsDi/+3qUU9j9UyBRjIzJahuUK/nOyXgEdYJiJlqnmyK19/8zI2wDVzj6GhH8P/m3iEi43kFUWqk1NYbUByFjnqIiFCScki0wBMjBBVk+l8QNexfLYVnObS6AxzczOM9p7jeEE+5bZ3uX5HR6axgnXyEfASOdnqEiFCi6rtXS5WzxydhoysZ35aBAlkCiGEEEIIEYUc8xbgCaPDejKDvCxfcbyikncOmck+c4/ADJuP6f1DDq8Xe7LaLgUinGHYGR57DGzBLJ1pEYX4bVtJACyDI+qiYI4BSo98SRQ13CPtMEc3qB9UGR7BAiRkZMliKSIKWZgzAOc97kRMh8+i+VoTxRkbMRo960U7Z36g9UQJB4+dpc+exbFLg9xu3UtS+FkQVEYYtgAJW8mWyiuioLvtXUZzd8exA5nmLHXRM+c3brfbrX5QCCGEEEIIEcoApZtrGE6rZrjrjZUf2u34lqJXG7Fsa2Cifbe6VIgwpmjML6bL+Rqddz7gaYzsHq01U3LdSPHXvVQ/62lBYmX1Hyet+mfSa27RXWhUly6/0Q/Z9ofvMBZ1cbMqUuaxEEpPu+11cqV4J/UTr9B0/zz56uJnjGRkCiGEEEIIEZXdHMo1wMR39DvUZcvPcfM7LBjILZQgpojWJor3bATnj/RGNT43ViboG34CibsoliCmiFbeAXINYOkd4Ck0vdzvH8Gpa/oEIdSectvrGKB3Agy5B575ICYSyBRCCCGEECJ65tIDJPCAS502ddEys9HR9QASDnDMrC4TIrINJe+SbXhCX/dtddHyG/ySXruB7LK3iTQCXYiFdnCscD1MXKZjVl223G7Tcf0xhm3vRp4+QQgNT7Ptne28jIX1HCrdoS56JkkgUwghhBBCiGilnKQ618BM9yfcUZctp9FP6Z0xkFdz8pmfrF88JXG7qS3aiGvo0xUOBjm50vkjruR3qc17CsOCxXMhpeoEuYaHdLWt7FyDjp4vGXK9xLGa3Ss/nYh4Pjy1tnec9usPMew59dxM5yGBTCGEEEIIIRbBXHeKDH6gdcWyMm10NH+HM+MUtbLIj1iCDRUfUZzwKxdWMhg0fJbGifUU10k2pliKHTTUbIGbH69gMGiE+qYHJBR9INmYYkmeRts723mOXucWamue/UV+fCSQKYQQQgghxGLE7aWt/hWm22q4sgITtjl6amidfoWGlr2SESSWaBPVLYeJv/khNSsyX9s4NbU/EF/U/NxkBImnJ66gmYZtD2mt/nZF5socrf2Q/vjDtMkCP2LJVrjtdXxLVdtDsuub2f8cXThIIFMIIYQQQohFiss7T3eRnfo3z2FVF8aS9RyFDXaKL50n/znqjIinKOUkPY2b6Dt2nL5ljQY56Ssrpy+5gR4JBImYMJLf3kmxvZHCpil1YUw5+o9T2r+Jpq9lOg8RIyvW9k7R+GYjc0WdXHzOpvOQQKYQQgghhBBLkFLVRVPiDUrKlmklXccApX+4QVJjl2SziZjyBOIfUbOMgXhrUzE1tsN0t8vcgiKWNlH9dQNJ10sp7XeqC2PDeo7C2kdyA0nE3PK3vU76ykrpTXw+byD9xu12u9UPCiGEEEIIIaLhZLS+hEZjM99UJKoLl2CGlkOVOCs7OZP5fGVUiNVjtqeUkuHDXG/dwRp14RLMD1ayr/sVOjvekHkxxfJwjFN35BzG1m5OJKkLl2D+Nsf3Xybns4scksorlslytb3TrUUcd56ku3brc3kDSQKZQgghhBBCCCGEEEKIVU+GlgshhBBCCCGEEEIIIVY9CWQKIYQQQgghhBBCCCFWPQlkCiGEEEIIIYQQQgghVj0JZAohhBBCCCGEEEIIIVY9CWQKIYQQQgghhBBCCCFWPQlkCiGEEEIIIYQQQgghVj0JZAohhBBCCCGEEEIIIVY9CWQKIYQQQgghhBBCCCFWPQlkCiGEEEIIIYQQQgghVj0JZAohhBBCCCGEEEIIIVY9CWQKIYQQQgghhBBCCCFWvd+43W63+kEtJ/8/p/jh/zuoflgIIYQQQogl+b9vSODPszb1w+I59P/+r5v5//37ffXDz7SXXvp/8Ouv/0P9sHgO/d3f/R3/83/+T/XDz6z/+l/T+fd/t6gfFs+hLVv+K/fu/bv64Wfaf/kv/4X/8//8P9UPi+fM//q/JnPl8qWgxyQjUwghhBBCCCGEEEIIserpzsj8H//jP/k//o//Q/2wEEIIIYQQS/J3f/f3/M//+X+pHxbPob/7+7/nf/5fz9d3/bxl6YnQfvOb36Cz+/xM+Pu//3v+r+fseBTanse29zd/93e4pe197v0v/7f/hf/X//N/DXpMdyBTCCGEEEIIIYQQQgghnhYZWi6EEEIIIYQQQgghhFj1JJAphBBCCCGEEEIIIYRY9SSQKYQQQgghhBBCCCGEWPUkkCmEEEIIIYQQQgghhFj1JJAphBBCCCGEEEIIIYRY9SSQKYQQQgghhBBCCCGEWPUkkCmEEEIIIYQQQgghhFj1JJAphBBCCCGEEEIIIYRY9SSQKYQQQgghhBBCCCGEWPUkkCmEEEIIIYQQQgghhFj1JJAphBBCCCGEEEIIIYRY9SSQKYQQQgghhBBCCCGEWPUkkCmEEEIIIYQQQgghhFj1JJAphBBCCCGEEEIIIYRY9SSQKYQQQgghhBBCCCGEWPUkkCmEENFyjFNXUETLtLpAqM0PVrLn6LfMqguEEEIIIYQQQogo/cbtdrvVD4olcNiZc4Fzepz7NiNJ2ZtIijcRp95OCLEk8w47ThfMTo4w7VzP5oxNJMQbWaPeMNYcA5T+9izU9HIxz6guFRqsTQUUDe+iu/d9UtSFwl+X/QxriY9b9pqsaUX3Rc6XQgghhBBCiCgtKZB5v6uSpp4RLDPKXo8Gw1qMCYlkZx+guGQvm+PVGzwnLF9xvPMe9skRLDbfZ7Ke4q97qY5p732EysxyLIVd3KzapC5cZhNcqviEXssDJu3a37shMZWCsmbO5JkCD1q+4njTVYYnHqL1V4bEVCrqOzmSri4RYqG5/rPU9c9gG7vHpNP36Cs03T9PfvCmMTZFY34xg7l6j715pvs/oaVzgOHJx566b1hLYvoBqhvfJyfattAxxbWGD2kd+hXP4WcgMePw4p5r3sm0ZYTB/qv0DT1gOvkM4+271VtFNO+YwXL3R/p6Bhi0PCSl/g4X89RbOekry6eGMwy175ZAlZ+dvvqz9E1OMTzxyN82GnKbGG/dodp2ucV6X6ZoKSimc2Yt2Y0aQf8oz5eO/uPkVf+MM/Etel7IgLidO62nafxmCjswP+8iIfsUF1v3skG9qXjKItR94aWnTs8z3VtHZdsINpdnG2PyAZovnCRTTiRCCCHEC2tJgUwfR28puWfuBQJUCQfo+voUm+PAMTfD5PBlWpuvYvEGHBIPttNdu/U57swOULq5hmEA42t03vmATPUmS2BtKqCw+xFsa2BiEYGHWJluLWTf5w8DDxhSqb3WyaFwvSrHtxS92ojF/8B6Ci9d4Uz6MmX8iOeb9Rx73ryMDSCtmuGuN5axXfEE46qcJ/S9ztxtKg9V0W9XF/isI6+lh2azvk7ubE8phQ33IO0wDY3vYd6whvnZ29T/oYreuZeouNTN0UjRndnbNLZdZnRs4Y2I5PI+vilR3HwIY3bwHK3d44xafAFVn5eouNXNUc2g6jg15jJG8/QGgV8s1qY8CrsfA5BR9wufF6i3WDkx2Zfh02w99oM3eL+L9tGPyFFvAzrPl3Y6DuXTOun5LZq6+lxw3KZyfxX9a16j/dIH5MTbaCnYT+cMJL5zjT9VJKj/QjxNuuv+C0xXnZ6i41AJrdObqLrSzpGkNQxW5FA+5FrCDRYhhBBCPA9iMkdmXPImlP3W5MJ32ezt5cfFJ5JZcIru7xvINngem/mmjMKmKcVfPGesD/BPnZeWpdEpW4LZL6jpfuT5eeYBVnX5CkpKWR/0e3pVW/ggJkBcGunK/mfaW1RIEFMs1syMJ4gJJKSnRQ4uLoGjt5KauxupaNQRxHQMUJrvCWIaElPJzd1Obm4qCd420OMx/SdK6Yg4eaST0doC8hruMb+tgf6uk5g3eI6ZNRt20PB1NemuX2k98XHk9mDDDqqbLvLN4B3GLh0gEP5YT+Y2/YGhDeaTNHd0c3v0J7oOKtqBhK1kawYxAbbSUL+Lue5KGiPu6ItnetoTOISXyMkOLltpMdkXgyEwzYPRSMhwva7zpQGj4thZo/zluTdF45tV9NtfouKzD7yZ1w+xeRs+m01xM1GsDnrr/gtLT5120ldWQusk5LV2ciRpDWBn2pu97bI9Yi7oOYUQQgjxIolJIFMZTIB12h3iuN00lL3k/9XWfZYrjqAtnhuOiQf+zyPdnKUqXQonfQ2f4k1KAdtMoAP4FMzZlKlmWygs1HO5PoVV8WfJ5h2Rg0JP2fy8+hGxWj6U0eEH3p/Wkpm7nFl+I9Q33MO47yRHIwXrmaLlzRqGEw7QfusXxns7Od/azPnWTm6O/kTXOy8RCMP8yoXm20F/rWZtKqbk+iNIOEy31rDsuN0UpAG2y1wYVBeGtiY9NRDING7BHCmbU9MaNqcHApnGjO3hh/xmn6I67RFd1R/L4j9BRhgc8/4YNhi8EmK0L5knaXtnO+lp26m6cIrN6nIvfedLI4caz1CYlkp6URPtOs41q6SJWjJrUyVdNjDseV/R9mTRcKWN+sYObjaF+szEcgpbv3TW/ReVnjrt6D9NzV0XJL9Lhf9miomjFzpoqmvj+qXfBSVQCCGEEOLFEpNAptWiyK40bCU7RE82fttWAiHOBwzeDSp+bgwP+oIrL2HOjdzh0m30HI13leM4H2J5iplNo6O/Bn5JztI3dGp0PBCIjTIL7GmY6z3OntoR9cMvtrkblObXcUf9+IqbYnDsiedHQxZ52qlcMWFtOku/ayMFpVvVRQs4es7SyWF6ek9pzFu5hs0V3XQXBYJ/ruEfQn6Wjv7jFHU/AtZRUHcyRJDQSHr6OsDFcH8UdXV4xD/Fg2Hb7hCZcJHd8QeTDWTnRfp8jBwq2Y5h5jL1/f7JTYV1BIu3aY8YDF5uMdsXI5kVzXR3NXMkzJPoPl9u2MuZrk66qyLf/Hpu2m3Ht9T7jv/i4IDlmqQs9uelSTDnKYhcv/TV/ReSrjo9QWvTz7iA9MIDwXPAxqeRX5BFkgzkEUIIIV5oMQhk2hke8w1DAzK2hw1oKa89ppUB0OfGOMMT3h+Xks2ygI2O5u+wm9YpgsGPmJ4J2mgFKd4nYMrI0tWhmh6+hz98segssJUx13ucPWd+JiVkltALyBvEHE4Of5yvCMcEFl8qV4R2Z2luc6HnEaQd1pGNaae/Hyo+CxV09EgpfQv/ulauB4xqplaPUF/r6cyR9i5VYSONnpbVNTYSeXi512j/iH9e48xF1/Fx+v03V7Zg1jMM2fwWBSYXw+1fSFam19zdcW9Wop5g8PJa2X2J/fnyeWq377d96rnZYMwiXxbCWxWep/r1NOip046eFnrsAKkU7Alzc0MIIYQQL6ylBzIdtxkMpNiRnKm/42OMX93ZeIti/ZFRb6TOkJYVNpgRDUf/WS5MGsiu+oh8xbz+09anFMlUvE8wkJmtZ1ivk9Ex7/yehJsP7Wmb535rEXvO/IyLVMzb1OUvpnnLxxzMr2PYFW4I6Aq6+6M/ozCadidq/VcZckF6gcaw7gVMHOrojBzwjEsjXXEcuzSGKXqyQAEM5JbomJcTwK53uglFNutS6riyHUjbjp44JqSRn70WZn6gS2/U9bnmZHDQl92uMxi8bFZ4X2J6vnze2u1xem56bhIvJWNaxMrzVr+eBj112kl/rzdLO3k7Zl0nPiGEEEK8aJYeyFQEEyIOFQ6aS9NAUnKYbZ9Ryvm+Fp/lpDZOU9PPuJLfpTZvK+mJgRLb5NPJag1k7QCkkq2rwzvCoCKLc1UEw9TmRmgszqf481892WpyIQ3YudNUQu6RL5l0EXkI6AoJzI8Zod1Zor7en5f5PW8kXR3B8Q+/A0x7OWpWlas4nb5o4kOseiKZcyOM+g7gJdRxZTsQzXy3mXlZGHjE4PWn036tLop2UXcweLms7L7E7Hz5PLbbw1fp8x7WKZmp6lKxkp7H+vU06KnTc1e54m2DjMmpukb6CCGEEOLFs+RA5p3Be4FfIgwVDgQeAMN2CrR6SXMTXKoqYkdmDltzzOwwF/JO1wTzc1/xTk4OaZvztFe8nXcyPTpAR30Jrxec476yyPIV7xTkkLb5ZdIyi6gLpBJG5LAO0Hi0kB3mPLZlvkxaZh5FTeOEWqcoMN9X7O7Yz3aeo9e+nuK6t9kAJCUpVgmemdKZgRVLyqydaObHDMzJF1VgyDFFX1MlB81mtuWY/d/DwaobTGtksgWZd3J/+CsajxZQ2hP43ucGT7Mn82XSNps53u8EprhUbCZtZzldE75MNWDyE3I3v0za5pd5pzfw8AKL3UeH3bN/FUXsKLsRVK/mBs9y0Oypt1vNx7kSy3G48zZGu05zMD+PHb7XKKjkmuo1rF0lbNucT1n3g8CUAPxK607PZ5J29EbQ9tGan/YcX9syc9iWY2ZHfhF1g3YY/pAdmS+TtrmUa+o/guCMwgjtztJ4Fz4xxWbYq59iWLwh9wD5quLZzsv+Y8WYvSviYhFzc4E6q5XdqeYY+tE/V22CzmkhFlK2A1EGk9O2kALYxkaWsPKsk9nRAa51naOyotRz7GW+zMFO72picyO0HC1kq/f49bTdkV7P85wdVUW8Xj/uf3Te8jFFOS+TtjmH11u1g68O64DnOM7xtAFbN7/MVnMRlb0zhP1KFO1iIBg8z3Tvaf/xn7Y5hx3FZxnU2QYs+riK2b7M47CMeM7HFQPqQj/d50uHjdHecxw/VEJL0Pk/crv99mU706MDXGo6zTuHvOfx4m+1z+GjZ9mx+WXScirp09wgSvM2RrvOUlTgPS/k5JCWaeb1ox9zZ0FFnKEl31tXN79M2rEf/FM/WBp2Bh4P9d3pYud+l+e73JppZps5j9ePfsX9eTuXjnrq7I4m7fqtpK7r23LMbCsopUXPtdWCz8TMthzPuTJslfKbZ3b0KyoPFbDDnOc5vjMLOd4buLUKMO+Y4E7vDTrqKzleXOg5JjNPe+cjVtdp7/lvwck6cv1aeF2go+7H/HrVzn3vZ7o101PPtmaaeb347IJz+tJ5Pv8672fqaetyPN//sHIBSKKo04p/Oz/xn5uc18sUZSGu/UF3nQii+9pQCCGEEKuSe0km3WfzMt2p6d5/pTfVGwT89U/u/5YR2PaNjlnVBg73L43vuLPSM93bS//k/s+/BR7/vjTX/fui33v+NuOf3D/5/2bO/X35QXeW4nlT0zPdWTVj/i3+o+P37i3p2cHb5P5397/7twjhL0Puf8zLdqdm/N597r7D89jfhtz/4H2ef+hT/4Hb7Xbfdf+j73UK/9X9F3XxYvz1pvsfMjLdWyrvBh7r+6Pi/f7R/b1y+xVx0/0Pis97e+OkegNN/9G4T/Ed/LP7P9QbLDDn/slbJ7JK/ndFnVA8V8Yf3d//Vfk3brfbbXF/XfoP7r15uYrPaZ/7rPcF/6PlYFB9Sc37F/d/uv/m/utf5tx/+cuc+9/9+7nHffqO57G//GXOveBl3O5F7qPFfa5wz4J6+/sr3nrmdrhvVe5xp2bkBm9T9E2IfYjG39z/3uI9zipvuv/s3d//9H0mecHfy9/+6n3/9//Zvdv3fdfc9X8mf1n0Ds26/618jzs1Pdv9RuNdxbEy6T6bt8f9+6I9nv0JdRz95V/db3j3J+jYiLX/+Gf39vQIbdsi/NlfB3/v/uzP6tJZ97l9vu891336F3W5mrIdDtTzcL4vjeb5Q1G0A9n/mzu6p5l0n83NdKem/4P739RFus26f7n2J/e/dfzR8x0p3v9frv3RnZWR636j5B/dfyx/R1Ge6d5SelN1HM25bzX+0f37fXvcWxTb+dr4v/b90Z2leHxBm/uXu+6zRbnu1PRc93+7NO0ONAGB72XhawYE2kXvd/E3i/tcYbbn+M/ODdqn1PTfu79cUF+UlnZcLW1fLO4vy99x783OVmyjbNfUwp8v/9L3393/Td1OLqhnkdvtb8u19v2g+5zG56g8RymvI6L3N/d/XvtHT73b99/dPyne3F/7/ujdF/WxGngvf/nLXffpXO++ZvzR/W/+x+fcf/lLqM8zvL/+8s/u32dnulNz/+j+N8WJ6q99f3RnFb3jbU+z3f94J+jPgvnr+h73H68p67rF/WGu97MP2RAEPpOson8O+kz+du0fPO81wjnub/f/xfse/sn9vf/k9S/uvRqf51//Y8j9b9f+d/eHhYr6WHrT7f6bxX12X7Z7S9477j+W/6P7v+0Lvk44F+I7CVW/PPurp+4vz/Wq/zNJz3b/Xtn+/IfvnL3P/Y+X/uT+t2t/ct/6j8XVHZ+//eef3H/MzXSnph90f3hnLlDgvU5NTc907w66HtRXp6cnZ/w/f1nie+8H3WfvB9d7xeVV4BWiqBOLuzYUQgghxGq0tIxM5fDEcEOF5ydofLOOMe+tWMO2BjpLFBPEMUXHoXxKuh9gLOridvtexYqERvJLtjM94c38CVrUw0R+aw93b3VR7B9uHVigwNpaSMngXr755Q53R9sp8CUA2m2KYdELOQZPs2NnFf1zW2i61c2JdO8frkkgyfuj5kJFytVeYzQkZrT5HMOuVKprFJ9tYiKBT8+ObUFmxzILyqzUPz+mxRKYH9OQEWE+NMc4dQWeTEBjUQdDHb8LWqUypeqM5/t0/UzVMXV2TRqH2i/yp75B6jO8DxlSyU7xrAJdejeLtpYDgc/QtB4Ta4iLNxEfb2J60rufhq3kZXsei483LRw2u+h9TOPElX6Grp0hkJTqy1B10ldWQMuaDxgaHeTurerAojD2h2HrbWRTdBzaSfHn3uOsaTcbvPublOTNprMFz7G4Js77/qen/AuAZOZl+T+T+AUfig6O21Sa91M79ITsxj6+qVJmBG6irCQBy4RnHq2Q2YJj4/6sjZBD1GLAMfEAO5CQpJjPYakcA9R3PwQMZNRdXDif5twPDPumvtW1GvsM0/6KsZ7ksAcWgSxT9D5/CMM/Mur9MfR8Z6FsIj0ZYIox35NELYHMgr3sL/mIY2neh4xbyJw5zjvDB7g+Osg3Hc2cb+3k9k+B48h191M6grKUTJirztPd20930TrvYy+RmQFYz1HUBFWfVZNh8G2e4G87HKNneX1nOV0TRoov9fF5caJiQbtNVNe9hhFw3a2hTJH1E2Bn2DdvsCGLvMwpGg+VY9nXxdjoIHfvDDJ+v4/6bb4X/5XW5tvKJwhY8nG11H1J40hrJ38KOh+HybyPcL6MzzvF51f66a9/Bd8rLqxnkdvtA62+fb9GRbLv7x7S373wHJ5S+h7Z3t11zqmzy/SyceVoPvvO/Ihz2xmGek+Ro3hzcXkfUZ0G8IiuY2cV2XiB9xIfb2fW9/LJ2zH7HzcRHx/i8wzD2llE7h8uYzEepmfwPPsVJ6q4vLcxzzzwtqeh50X11/XJVOpv9XO+QFHXLd8xaAd4TF+P1mregc9kTVEHQ10nFZ+Jk94e78ieiav0hLiesXYWse3Il9738BH5/pNXorfuBC9+GJeyg/0Fv+NM5S58n1h6tonGoy0Y6m8x3tfJ+dZmPu8dpHOf77h/RNdFZZ2OXL88p0A9dX8ZrldHz7LnyJdYnJDwTifdyvYn5V2OeutZf3MdtWfqaLyumKM8SrM9peTur2PI+Qr1t3o4k63IwI/bTVOV5zxs6z5Onf8CUV+dTty00b+NzXcBYkzFnB5c79ULlUdbJxZ3bSiEEEKI1WhJgUzl8ERYR3Ky8qLNydz0ONeaStnx8lG6vFdiiQfbGWpXLpoxRUtBMa2TLgzbGuip0giKGY2BC1GtYGncen+AEUMW+dnei5LJd+nvCg4uAZCwKWQQzdF/nNwTP2BnPcWXzpOvDNTMDnDHDmAgXSN4F/PVXq3nqLn+mISiUxxS7kdKKkn+Xx5iVSy2tBKsQ4qVx3HRf0xjeNCCfzupV8yPGXY+tPkJGt8so2cGDBln6KlKW3ABC1vJ9gUvwnR+/NKzyJn9gpImE81XTmI2n6Kz5TB5B0/QdUG5kMoIw76L8HArYcdgH9dsWB943cQs8uLB2lTChaSL/KleI9CQmBqy3kY2RWN+6ONscMg3uf5WzYDUHf+0EKE7uro4Bij9bRX9dkgo6uRi3sJOeZxxrfentWTmLjzOCJrSQt1ZjC2bN0KYlK69H9Fz0lftWTDJsO0Mbf7eakBQu5quY9qGacX0EgbTwnqjNjrAsG98X7g6HsFSVz2Pj18LPGE2ZC9drweMej8wg2mKjt69dDftCP4c4nZT4DsWecjYXa2gooJpK9nxI1T+4QFHrp1nf+YbtHWcoHDPYdounWIzMG85R+EfrjKDgYy6LqrTF7YAZGb5A6iWnqsLh7UrFssz5GbhLDvOdFmvKiBqYn95oHPtGv7BOzxWIRbHVaz2ZQ0YfBUjzErkes+XcaCjnulptxM42vIWvhiSbXhg4VDmuN1cvNNFcQIkJGt8RhHZuVZ2iPqxJ5BwmO72vRrHo5H0dO/0MPYbdA2ry4HRwI0aU3rawptoUbC2FlLY9isuwys0fX1S4xxixOirLqHmRbX66rrnumi/+k05nf5rAqO/nvkL6fN+Jp5zj/pc6cLp+4JZg9EXtVawNhWEfg+DvnnavTcfVOYmprz7to75659ATScnVMdq5r4s/zWmayxwgyZAT/3SWfdjdr06QuWxq9gBTAdoqlDXV8X3mvAW1+//wk2t62sd5nqPs6/hHs5Q3z8Ql5bqbRce09ulEczWU6cdE1j8wU7taxGfpdSJILqvDYUQQgixmiwpkBmY3wrgMT1HggNXufvLqO2+h92wkfSDJ+i69Qt/qt2quDBw0ldWQucMYNhFW1CAU8G/SNB60tMWdtCUHVkydmF2fEtZeyIXlc839wCr90rbkLZVEQhUsJ6jsPpnXEDCO81UB10ZOelruMwMQMIBji642o/1aq9OrjRcxmbYRe2Ci89Ekvy3jF1MTy42c2QxFFk7AImvUV93JuK/2j0bFc8Rbj40J1eO+gLfqVS37NWuE0FCBXPHGfM+npy9iSvVX5HS+IH/4niD+STNtb9js/IFrCOMejsioVfCjtE+KupkQvZuNox+SOX0u3Qrv++Je/imhQq9P5F4jrMuG2B4hYZG1XFmPUfjkMsTUCg5oNHxnmLYl04doXMR3hQtb9Yw7ASS36NzQb32mLY+9P6USrbmi43Tf9e7P6E6izEyPe3JYIsVR/9pau56gsnBN3QCLKOBTLGEtMjZpo6xe4GMneQtgQzeEJQ3IjRvDOmy9FXP402etnzJC5YpjlmXLZEyzc9V0akH5qa1MpOcWCzeFXUztuCs/RBbeZv/JlJc+u8403QS8wbA8S0lRy57Pve0E5oB6QWmp/zHsp9isbwk5w06ks5rBiGDbl65AkEjjxgdVzHZF8Axzpi3QoZeiVz/+TIwt3aYoISudhvY8DZHfAHtmRH6F0SWATaRnLCWzOzos7BHa4uovesC1lFQpxU0VNM+fztmHvo/15Ql3ERx9B+n6HNP9ndeq+rGrF8goztBK8DkGKDUW9cTitTXRV7ZZ/jmwgmq6jr4ptZ/xwAAa1MxVXddYNhCrfrcA4CJoxc6qK88Qfu19uCbtr730P3Ic36q/0j1HqZobP4RF2DY9jaFGueCO8O+evYY8hq0919xsxynfeENB731S1fdj831qqPnU/q9+5S47y2NeZSd+NeAs2m0PXqNfsjBM57rYtO+M9qfn4prZmrBZ6irTk8+8N+UC3fuW2qdWNS1oRBCCCFWlSUEMhXDEwHDnjYm7t9i6Faf4t8txu7/wsRoD921v2Oz6oLC16kHSK86FfIut9Xi7YCFWtRDkWGUbjbRcuQy6Y2qTsTwiP9usHZWxwiVvo6p6TUaVHe3ra0l3ovxl6ho0eqgKC5OQ2U1RGP4LI0ToT6XTUErl09blxgIiIYiawcgueB99hfsjfgvAUXgICGV9BAXiLOdpf7MzQWZqEEUF+m4FD8r+DsD60ia+5gLCR/QoNWBV5i7O+7JcAizeEms9jGQebeWzIwZSqvtHFN19KzD495spND7E8lsZ6mn7gLpVaqLfscApX/w1HvTngaatAIXcyOMevva2kNS9bG2VtJpw9PJr/QsXKXF6hvCF+o4UnTyjBnbNY7FWLFjswOsJyYjy303ShLfolsz2AZgZ3LG25hhID0z8gsHBT61AhFBlDci1pORofF966GcViRhC5nhX1RTUorn5sbcoofwegSOWUgsek+jvfSY932sAAaNtC9FG54ef4+ayd/RVKj1+djo+EOjN+i3nuKaMFk7DkWgTyPop1wAb3JyPdUhgpBBz2MMzrqN1XEVi32B4ICo9rmWKM6XioB5mJsWetptDyNm80ven39lcEj9jeAJcsxtpyDCuWKB4dOUXvcGwredpCrM3zsVJwOtIeyBYzpM8DYSxwBVtZ4AFGknqA31IVt9wSOtTF0n1054MsghlaOl6nKfNSRl/44jBWnB9cF6jvJuT70z7XuP/aEOlPg09hf/jhx1OuLsF5R4by6TdkJ1fnLSV1bquUFn2kWzZpBUkUlp2M6xoCmNgqmX+VHSXb/01P2YXK8q68g6cvK03pfiGFu0ESqPfed574ZXqK4ME8RVZOVqBYP11OlA9myYc9+S68Tirg2FEEIIsbosPpCpmN8K/8WWUTGfjfacNgEj1Psusk0HqNLsMALY6Bv2dcCyNLPBpod9GUappE+fYzD3owV3jQNDY7Wzh0ZrP1Tc3X438DrzM1wry6Pw84dg2kVbXzdHtSIniovThAxl1uliTNHY8AMu02uU5bqYm7Mv+GeM983ppH33e9koLtQjXtT7KTLowgWfHAPUt/uyJ8J1mgCmsPjnPtIONPkDhQYT00N2jpRrdwiU/Nkb3nmTFojhPvozmo1ZGPvPgTrIiJ3hMW9GYKggfiSOb6lq872n7RxVHGdzw+c4uLOGYeda0t/p4GaTb5ViFX+nSntKBV1mv6Dmc99x/G6YTv5t+rw3SEIF5ZRDr9Ozw3SslszOnFacYzF8WU0Jh+npfV+7/oPqNTeRGZzcpEF5bK0jOy/C96O8EWHcQo5Wqo8Oyu/AmJGlmTGkl0sd4Y9SIOPqJfYXa3XoAaaYDIy/1+4k+9vw9TjHBkgv1w4KOvrPcsEfhHuLstBfZlCGEQmJqs9JmdVqILvqpOb5DYIzs4POgzE7rmKwL16BaR+0z7UQxflSETAPed7Q024rxO/bjW+qTMugxhDYwcuMZhxY8L7C856zwRNQLgsRQAHAyfR0YAXshdNWzDA64f1wjJtIDxG8jeROgy8AuY7CqtDB9tn+EW9Gt0amruUTWr3Z+Ibct8LctNPiHVUCwEYKSiI2ZipOrlT7VrA2kFuieA9zIzQeyqfq7hOMaW/R1fcRZq19U2RSGnIPYFaX+0xO+W+GaI060Fu/9NT9WFyvAjj94/E3ka61T8opRMLeLAjN2nTWf11s2vduiIxeD2XG5cJpcPTV6dFRX1se6twXgzqxyGtDIYQQQqwuiw5kBua3IuzFViiznR9HGBbjNXuVQW8wSHsYpJNRX4aR0Ubf0FaaF8wVpByKqpEN6PiWVm8mBaRypCQBx+w4l6oK2fbyIWonTOTVXWFs8CPMIS7AAhenixuSpuToOeu5o2z/jrKd+eRq/Cvz7+/CBVqWkzJrR3dwTZFBF24+tNnOTwMX3tsOh+80WX9k1PecIToX/kCh61dsae8vXFRlgcjzYMVuH8cZ9s0Zahhn0P7+wmxIZdBJI2Cgx/22T/2BZ9O+tzDPO7nff453zC+Te+wqzvS3aL81SHeFet6ygFjMj3mn7VPtzofa4Hfez1crO8gjMKVF9O3OUzE/QeObNQzHH6anTyubW0mxcI9xI0khPygvyw/c8dUx0w4KIo0rV9yIWLhwin6B7yD08bwyFMds8m4KQrTPQXOvhajHgSH3j5jkd1RobAM2Otq9N+CA7OIwdTnoOTWGmiqzWk17KVMf/wrK+UiV58GYHVcx2BcPxbk2eXvIQILe82UgYB6unkVut4PEZ5Hpi3eP/aia49PJlU4bedEG3QY/5Yo/Q3k3h8IehyMM+ueL1spOm2LS91waQTVdZr+g9abvAmsvR0Puj40rQ94RLxrBrsHOG94AnwFz4Q5VaQSzX3DJ9z6T93Ik4vlXxfIJF3x/b9rLUfM8DssAjUfzSNtZzhVnKiUX+rjb9T6bQ5y8ApmUBswF6roaMDqmyGpfMOpAb/3SU/djcL3qlZQUuJm9kJO+zh+8x9g6CsrDtA0h3eZCTyB7P78w/DGhnGpq4fB7PXVacePXFOJ9x6BOsKhrQyGEEEKsNosMZCrntwp30RbKFF09erJo4E6bd17KkMMgFZ0C5xMyazQCBRGGojpufqfIMpyi9bdm9p34FEv827R9f4uJO900K1foXEBxcbqUVYDBk6na9ABDbhMT938J/e/rw4HVFJ0PmQ5etnuZKLN29AdCgheFSiVb3VsCwE7/Xd8cbpBdsDuoVE0ZSDftO6zRuVBOfbCRQj133BVZxgsvxIntPiqDnHYTh+o05tlUZD4tDBjoMU7PzUDA2369nG07S2jqd5FT38HwL3e42fF+0Iq6C00x7MukCNkBiWSALl+n2rCdQyHTYmx0XPTMbaWZHQTBAeCo252nYYrG/UfpQk8QU0Vr2K7KaM+AP5MouTjMDSGvQMZQ6CGLkSmPLe2g4IpRZB0l52ktrOKhbOMNuQfIV5UHD7k3kFuqnY0ZtKI8r1CQF1wcTPmc6ygoDv68le1i2Jt53OZSv7fdDcqqjt1xtfR98Rq9waC3XVsYEPLRe7500t+r4yZKxHZbbRPZad6pBVzjDCsnD5z9gt74dzmh+eWHdkcR3E3I3Rv+OB9WLCaTdmDhHH7WB/52P9w8geFYu6/6v8/kgt9p12WA4U/o8tbnhZmxI/T579qFOm+HNndzxHvtBqaQdSE0ZduG/QZlOfkUNf3AfPYHdP30E+N9FzmhXDl7AcV1qmE7BSH3f4K+Yd91zUbyilSBRb31S1fdX/r1qk/Kvt3exXUeYlFNgBmYtslAcvn5xQ2bHv4hcNM2YTsFoXYEVOeEVA4dVH0vuur0FFZ/sFOd0emx9DrB4q4NhRBCCLHqLDKQqcwoCHfRFsL0AIP+7IXQ817h+JZ2X0ct1DBIZacg8bBmFk2krA7lneT0mj7u3hnk9pWLNFftJXODVvBUTfF5hL1jH5lnKM9GiisjZD+kbFIMU5zBEogULh9l1g6QkhnqgjRY0KJQyaFWYR5XzOeklaWiZONSbyAQfkQreyZoWNVhXXfcA4HHUEPmY7ePyiCnIfddzf0LZD4tcmXu6ZFAsNT4Gp2jg9y900N36ymOZqcRFzoyH6D4zqM+zn36b+BfmDfc8TH6KZf8GagLs4Mg+D0ten90MxG/iI89YIqOQyV0cZiuaxod1kgSlce4FmVQaRcVYeZ/81AOQ19CNmsMhiwqGZSr8EQpkNkX6phFFRBbz6FSjbZVmf1s2svRUEHBscDKuxED+7Nfcc0fTfrdgqy4wJxxnlEAoTh6vmTIF0gpOxEYHhvD42rJ++IVyEANNw2F3vOlYrswn3XkdnuhHPMW70+PgxZhG2weIV2rfoSluNkT9n17DPb4gsoG8soWZso5Jh74swg1p0CIaIa+oUAmXejPxMmVdt9weI3M2Lkppn1vyxRq5ezQrP7FpSAp6hXgZ7jjv2m6loLP7nD3ziB/6mrmTEkWm3WdvHTWs9Gr9HujY4ZtC8/FeuuXrrofg+tVv5STdNZswcgjrjR8gdUBMM9s/2n2Vf+Mi3XktfTyTUmIfYnAOvzAH5xfkE2uNniVQe/Ghj3vLhipoqtOK1Y11w4Yx6JOqM9f+q4NhRBCCLH6LC6QqbwYCzVULZzJqUAQJ+QFkpO+6k8CmZIhhtYGDXMr1s6iCQTStLI6lPMYrguxKnoEoyP+/dS+ANPJ8S313Y8w5L6nIyNkPYEY6xOmZ3wRq+UTnFmpN7gWvChUyOCTf8EBwJBIsuZGXpYv6fVlkRR9oHkhGrQyc0G4+coC/PMzhRoyH7N9VGY0r6OgRKvjrG+Ri7AUx1m4QEBY/sDNIo5zL/9iXWGPjylaGryLChBqHj/lCt1hOosxYyLBBPCIaX8boZdnpfhW5wG6rp0MO8wt2CaSQ8eRgiiDStqLgqkos4CXkM2qPLaSzSHmVdXBVy/i40MHB8JTDtMMccwSPBwx5Kq7iiH3ptzXQmYkKuuyIXGTdlvmdb/zhn80QXGd+tykZxgq/gx9ABLeokERZIzdcbX0ffFQZqBqnWu99J4vFdcZIc8betptLRlb/fNkTk96g7jWc1yYfzv8nKeaFNNBsJEU3xNrcXxLh/egNWSc0lyAZ9J/QRJqnsBIFMN4F0xpEuDoP02r/4a0RqbunD0w56Hu9isgMIcjrIn67xXvgU1kqPdND0U9Cz2iwcmVtu/8c1ZWaywOo69+6av7S79eDbah8CL9LdtZM/EV9WdKeD0nn6JOF/l17fT/0k+zebFtK0xP+94PJKWEO9c6udLpDc4btlBbs/Cz1lOnA3NsriUlTWu/Y1AnFnltKIQQQojVZ1GBTOWd2vBDw7QpO2ChOrGO/tN0Je31Z48oOzzz/uUlFcEerWFuEBxIU2SjOGZtGqtURn21DSGzgpz0tX7LbNCW4Tjpq27Bgo5sTFi4crll+VcuD8qs1BtcU979DhcMW6NYRTg+3JBaJ1earno65gmHadNcWVfZqUilYI9WvVBT1pNA0NzaPxAIXsZsHxWZIqHmLwuxyMXcrH9gVXQ0V2mOTLl4gb+jax2gL4pJWZUdonhPZHABa9NZJnNf8w6VUwYp5xXHe6hO3hSXOm9rHM9L55uHTLkPkTnpKyugamYXnV+HC2JO0VLxcWDhFAASyfQNe3U6CT1jhCKolFZNu2bbF0yZBRwuMBRe8Krn4TKU9EqIOlvLJ3AchZ7mIvhYvFivHTgL1PN1mAtC9LTVTUCIcxd4AlZN33imdUgoal4YPFUElcMNu/UvtmF4haavgxeJitlxFYN98VBkrCvPtapVufWeLwPXGcrzhp25oINCR7utJT6VFO8hY5+c8rx+2ziZ5UsNbJhICPUBAqPN3jmLDa/Q0KIxnQh2LJPea5pQ8wRGorzhFuo85RigqiuRAl9WtvJGl69ixJvwtyrKFal1MhoDB4tylfboGRZ1ZRYIWIW56Tp6znuTw0B2Y9uCTEL99UtP3Y/19SrM9pSQe2KKgq/76W7t5E93Brl9pZnqgq1sWMyHFkKo9gVUn2F9s8bK9PrqdCArXE+QcnF1YnHXhkIIIYRYjRYRyFReCEQYshOCsjOoeYFrPUdReyK1uU7vHfV1/g6PtbWEyiHv3yiCPYbs1xYMcwOC5zfyZQ9Zz1HScM97YagMCD7CMqGxP15zg6d5vfgrVeBBOyvI2lROb8puzTvumobPUnPXpTMbE8BIUtJa/29Om+I7UbJ+QZHZzI5DZxkMHRXRQTE3YYS5m5SUd781sz58kraSriPW5ug/TeOErzMdYrhu0CI5r5EX4sI5iGJ1U1/2hqP/OK1OxYrMsdpHRaZRYu4B7Triz4QMDC9z9B+ntDuKQGbyJm8AA5gYUWRRq8xP0FJcSOWwuu5PMexdsdbfqXIMUNrmJDv8mOeQtI53R/9xSqcPU7vhYWD13Gw8wYWKMi74e4yKOujv5DnpKzuLbduOQMcmZnUeEpI8n6A/ayuiee43FVM1mUXb1x+QGbLuzXO/qZJe08LjKKd4r2f+25kHigzoYKO1HwaCShcWDk9dSJkFHOaGQiSqVc9DZyhF5gnErWWDOrFPL0XGVahpLmY7S6mfAEy7aNM6FiE4IzHCgklJmalEbgJ8N6XAsK2BngU3MoKDyikLVq32cPQfp6j7ERheouLS+bArBi/luIrZvijaNf+5dvYLympHFAF5vedLxXWG4mbpnarjdPizsnS225q2ku2LV09PcX/0HBeM7y8MOOuylcxwWZg+1nPUXH/sydAN9RkqA2Ih5gmMKPgCSyMAOUXjkU9JqtmO05ep7AtgWz+mqPpHz/cVv4kk31M5p7DMBZ5BzdpUyMFO5RcDKSkbA+Wjipugao4BSvMruRMUqVNmpj9gOPTJi/utJbxepaxjAE4sFl89C7VK9giVx77DjoHk8k4uai1wpbd+6an7MbleVRg+zb6GB7hYS7zm+1uazMyX1A9pmKLxjCfjO6EoxGeoq04rVjVPSA2REb/UOrHIa0MhhBBCrErRBzLnbtCn6F0nJIWY7yYMZWfQ2f8p1/wXyPNM9x5nxzE7Jy6dJME/1CSR5BSwdpZQ7zrFee/FknKoc2aedhajY+KBt5PmDYY6Big9NsPRxkA2RH7hdv/+WJpOK/bHyzHFtbI89nVv4WLX71QXYg8UF2merAZfB3LBKtQhjVNT+wMu1pJfpP0+tBiVc8tNjmsEqiaoO/YJFvsT7JNXKT/27cILO72UqyMD6dnamU3BbPQNKwKsYYc3Z1GQ6/0WbA+waO2o9RyF1T/jMr5CfV+ojmDwMFG9Q4cCq5t6pxewnqOsdy9NQVkTsdnHwPCy9eTkaUdxAqvDe4MP3uB+g0ZQJKSkA+T5Dk/nd9Q0Tag6Q/PMDp7j4M46nOWdNGer6uvcCKPeuKkpPY04pmg8doOCRj2BswBlh8jS+Qn3/Tth505TEfs6t3KxfTc23/Az0yZScDJYVUJvXhsn/OmogUUQPPsD1qYSLiSfUgQgYljngbi0VEyAXefYcmvTIYq77SQkuLh2ppLjFRr/jhaxI/NVirsNFGjN75r+HsfSAOcPdPQvDEPM9R6n9PpjMISuYws4Buj1BYEXkUXvE7RoTsgsSD18U3royb7RFrhJoj0liGPwNEVtv0LiATqvfRR6yLQiI9GYvStEJ9orey9mXxNgmdCsW9amYqruujBuO8PNdu32586wL6i8Hq1T6Nygd5470y7a+ro5qtH7j9VxFYt9AZge9WVQKs61fxinWHGu1X++VAQ/0j3zKltbC2mM/yAo2Kiv3daWkrze84N9hPrmhxzRGBKrj4m8PN93ESLA4hig9MhlbGyk+NKV0AFTRTZl2GH34ShvuDl/4EJv4ObX/PQNSs3HmSvvpDphhmlvvU9K3uS5AdTgorbVV2ezKN7nWxn7Vy61jfufJ8DOYFUelc5TdKqmGog/eADfPQHXzU+5onGwzFs+5uD+y5g/ayYnKMUukUN7fIHQJ/SeOaeo3x7zs7dpPJRPjfM9upuyVMdZpPlVp+g4VEm/ay0ZNVdCziOpt37pqfuxul71uT/ou474ldadOew5eo4+i3NhwHOR4vfs9k+/YBnW+u4906d02SCxqIProa5NdNXpwLBxQ9rWEDchllonFndtKIQQQojVKcpA5jyjTV8FZQk55xZ2tCPKfhv/QuWue9TuzGFbjpltma+yrzOBZm+n0zbtuwC/R31mDqXWt2hXXCwFhpmGXj3W7h+K+5je6iJ2/PYLMi+oOv/mMzRs8175u36mdufLbDtUyvGKSt45lMfWnccZzLvIUMcbGtlzTvxTQVm+4J2jhRT2bKc7RAd2ISd9ZeV4+hoG9K97ocg4AHCO0LugA/WEoEQd15PAlABRsXOt7UZgtUhg1r+8ZCjz3G8qo1MZ/5mbCTvcL6epjUITwAMaq2+gjCfPDZ/l9TcvM597huu3zrM/TAZCIAgYZkiZin8eLB7TdcTM1mqo1fgOl76PyrkvQ68EOjfnm9T+Hq2HCtnmDe6H2DyEBE40HvZnZdq6j5KRWUBRRSXHK0p4PXMnhZ1Qca2HM5kan5NiYRN7dwnbMk9Djc7AmUL8wbfJ9nWsbVcpftlzvG/dnE/V5AG6r7xNivI92y9TlFnAhZSPgjM8FNlF9v4POV5cQKXzFN0Vyg5UrOq8V0oWmYYIGa1e1s4iT9YaLmwTPzI0FOLf2K/YXUDyXo4sbFAAI4cuNJBtdDFcW0rjoHdYoWOKvqpCcs/8zJq0w3SGrGNqTkYbvgzMN6xjNXRNjnHqOwOZVcZwQ6sj8q5QG3Lxr0iUIwNcBJ+G7NxpKiHvxAgbitoY6j0VJjNWGTyIsLgGAFk0XzjgyZidaKFKESQCO3fqCynsnie37gpD7aFWUXeyxujLpncG77tjimsVeeT69n3wI8zaTxKj4yo2+wJgjPM9j+Jc26JuL/SeL434RyaPfczBAjOltvfoVgVL9LbbWgI3VB9CXoPGsGL9NpQ0U5tm0AywzE9/xTu/rcGSfJj2Wz1Up4cZFOuf1zjUPIF6ZHG0yBukxcXYmXy25pjZlpNDxv4vSGjsodlsBNtD//lrrCGHrcemOHoh+ByzufwjCr0nEPv1MnZUfMEdi5256XH6Ok/zek4hHQnNfFOvXvEciHuDphrfZ/yA+t+WUNc7zvScnfvDX9F4NI9tFY84dqWTQxrt4IaKjwLXibbLFL+cw55iz82gooIctr35JZT38KdajddWzuOumqJjfvoGx83FtM5lUX+tj899b1CD3vqlp+7H7HrVa3PhAQL3HVzYxi5TdWQnGZkFHO+aCLo2WZQNb9Pm/f6c1+totCgr9QyXjhZQNbGJ4gt9/KkqLfRQbz11WrGqeajsepZaJxZ5bSiEEEKI1ek3brfbrX5Qy/2uEmraHjCjERUwmF4iPfdtmmt3h+i4aXCM03jsNFcmHuMCDMaNZJee4UxxWuA5Rs+y4w9XsRvWk1HewMVi5cXSCJWZ5Z7hlWnVDHeFyBKzfkXRH1qwOA2Y0g7Q0HqSHM2ddDLaWkndNw+Y8fa0DImpFBS+x9HC8PMNWVsLKfz8IRjWkV74AW1VoecZC2L5mIPHvmRS2Xk0rCM5PY2C8maOaA1xtHzF8c4fmB7W+i4MJKRlUVwV+FvH4Gn2nfgBuzGVis86Q2bTaLPTV3ucxn5v4EVF83ufG6Cu+gsGLdp/43t/6YWnOJOndVFr507raRq/ecCM0zPPlsFgJD7jMNXlB8gM90WAZ6hTfjFdNiDxLfp739cIPi/k6K8kr/pHnBhIyD1FZ+veMH+3hH2c+4KDOz9hEjDua+duiDn7HMMfUljxHTaXgcTcU5xv3EtSmKcNa/YGlSc+ZnDSc6xhWEdy9m6Olr5Lvm+iOC2OAY7/toYhJxgStlP7WTP7Q38o4c3e4Pixswx5K63BlEpB1Rmq8xL9x/RsTymFDfdwGl+isO48ZxYsVOCde/LuEzBsJLemmeaCwN/7LK3OL9RX9jJVd9dTcq2XE9qpIjD9MXv2fxlYXEmH9JpbdIfLHJuf4VrtaVqHfMeSAVPydo7WnORIuvqzUZvgUsWXjM7NMDb5MBA88jIkpJKdbALTLs6Ea7ctX3G88x726XGsM+qgsKe9SY6H+LxQx3MIw6fZeuwH4ou6uBkqkyesAUo313hW7U7YQobhEc74TSRgY9IGyblvc6x0NymaJ4Vgnu8XMGynbbRZe8in2twILdXn6LE8xMlajGsMGIwmMotOUhHhfOHjsA7QfvEL+sYeKeacXk928fscK8rSd7zH5LiK0b742wsDiRmHqW58X/Ncq/d8aW0tpOjzh2B6CXP5RzRoHetRtdsqvrY44TA9fdHeJNIyz3RvHZVtPzJp950XDBiTdnOsMkJb6zVaa6bk+hMw7KJ99KNFBvnxXM80lVPZ88DTdhjWkpj9Lg01v2Oz/8Mep85cRo/dQELGezRd+F2I+XyV5zsXYMBo2khy7u+oLt8b8Ribn75BTfXHDE8/xukCg3EtCYlZmEve45g5YcF3GszGtapKVRuYRX7Ju5TlbdK+5gOsTQUUdj8C1pGcYcI5t4akJAPO6Uc4jFkcKn+LQ5mRXjuK+hWx7i/D9WpTOTWWTRSbnfR2/hB8HYln6obary9qBomj4fv+Bicfg3EtawwGDMZE8stOhv0OfPTUaUdPCdkND4CXqLjVzVHN9+yzuDqx2GtDIYQQQqxOugOZQgjxQuo/Tlr1z5EDj0I3T+fWSPHXvaGH2YbjDYS69ASEhdB0g3c2f0rKYutgzDm5UrzTM6frtgYm2nerNxC62Ok4lE/rJGB8jc47H2gMLX+GOcapO1LOcHobPYpMWId1gPbmc3SNeRYZA8D0Gp2DT/P966vT/mBnzG4qCCGEEOJ5F+XQciGEeMHkHSDXAJbeAc05EUW0JugbfgKJuyheZI81sKK19vyYQkTi6B/AqbWi/FMTmD80u0A74CP0UC4uozU/5jPMMULl/jJ6408FBTEB4lJ2U93Rz8StNgp9Y87t39HRr9hoxemp04FVzRNy90oQUwghhBC6SCBTCCHC2sGxwvUwcZmOWXWZiNrgl/TaDWSXvb3IoX2K+YENW8mWnq+IlmOAqq4oF09bbr4Vqw3bORRiDkWhw+iIfz7g5OzFLuC0Ot1v+5B++1rySxcu/uMXn8WZ3iZ86xJOW6bUW6wcXXXaF3jeSF7RKjoehRBCCLGqSSBTCCEiSKk6Qa7hIV1tI+oiERUnVzp/xJX8LrVBq1RHQ7ki8Rb/yshC6OPkWvVlMhtX1xDWubvj2ADTvrf0zdMqNE0P3/MuChdmcZln0gyDdx97FsKK2HTuID/D81N8km/hp5Wnq077FmZKO8zRxd3ZEkIIIcQLSAKZQggR0Q4aarbAzY8lK3Mphs/SOLGe4rrFZmMGr3BrTEoMnZkkhAZrUzn9BW1PMWgyRUdxHjuKv/DXY7BxqfdXIJVj5WlBW4vo3J/wZmuTSHqyqvCZZmKDCcCJU72wzwJ2bHaAl8hbkdW59dRpJ4NVhWwrOM2gYo6WwZ4fcbGOgvIQCyAJIYQQQmiQQKYQQugQV9BMw7aHtFZ/K3NlLso4NbU/EL/EeQnn7o5j9/6cnLFVVSqEj5PBqgK2ZuZR2jXDPPPcby2h3nCKi4vOBo6B4S+4MPEY+8QntPrmLxz9lN4ZSC5v4JBEc5ZghGHfuHJTKunP1WdpJK8gFXhC38UbYc9Bjv4PuTAJCUUfcCTsCuAxoqdOz13lws2HOGd+oLFzxrON41s6hlwY9nxAw3M1makQQgghlpsEMoUQQhcj+e2dFNsbKWx6ivOOPZOc9JWV05fcQM+S5iX0Zfl4uFwRU5PEC2uEKzcf4XI9Zrj5EBmbd1Ifd4ruiqXUvxhIXE8CAKmYtwHzEzSe+Q72NNFZ4ikRizR4lUHPKmDgcnqHmD8/4grbaNq2FtdYHfvKbmBVRzPnbQw2lZBX/YCUdzq4vqS2Ngp66nT8RhIMAGvJzE4E7FyrbsGa/B7dTc/XXKZCCCGEWH6/cbvdbvWDQgghQnAMUPrbs1DT+3Qzu54h1qYCioZ30d37/qLnJbzfVUr9xXtMBkUn1pKYsZWk3Lc4XyxDcoWSkzu1xZRff4TLmEpxSxvVmavjeJ3traSk4Ufm1qxljWE92eUf0VCQyBr1hkKfuQHqKj6hd+IRvjgmeLIyc9M3kV9zivyVyExcIXOWr7jQdJX+yYc4WYtxDRgMBjAmkJl9mKOlu0lZ4WxUPXXaMXqOshOXscyvxbjGRPLBkzRXZPEcfTVCCCGEWCESyBRCiGg5xqk7cg5jazcnktSFQml+sJJ93a/Q2fHG4ufFFEIIIYQQQgghJJAphBBCCCGEEEIIIYR4FsgcmUIIIYQQQgghhBBCiFVPAplCCCGEEEIIIYQQQohVTwKZQgghhBBCCCGEEEKIVS+KOTInuFRcR/vkQ5xBy0JqMWA0GjAkbCIzYy+HinaRuUHW41wO844ZLENXudQ9wLDpJOPtu9WbCCGEEEIIBYf1Bq0NX9A78dC72rkBU3IWBaUnOGZOWJ5V5OcmuNRQyZWE8/ypapO6NLS5CS61t3Dl5hQz3otwg+klsve9S3XZDsJeYs9+zOu//ZIZ9eNhvULT/fPkqx8Wq8O8jcH2Fi5cH2HS7u2UGTaSvu9tasv3LtOq9fNM97dQ02Cj+E4s6sYUjfnFdNn01jUn1t5PqO+8gWXG957XkZy9l2OV72IOexCIlbJS7er87G0uNH9K7/Cv+A+BxFQKSk5RUbAJfYfAPNP9n9DSOcDw5GP//hoTN5FXeIJjxWnEq/8kCo7ZcQa7r9I7Ns7kHBjjs6i+8AFmHU86Pz1AY+1ZbMWDXMxTl4plsWLtaizaMjv3uz6lqWcA68wTT901rCUxfS/Hat4jPyncc9zmeGYVQxHjeUrrKbnWG2KB23lmBz+l8eIN1XGUSkH5GarNCeo/iJkoMjLTONLVw93Rn+g6uD64KGEX9Z9dYehWH0PX2mmqe5e8RCPOyXv0d9dR8ttX2VZ8jjtzwX8mFu9+axE7Ml8m49VDlJy5zJC/4gghhBBCCG1OBqvyyH6zjl5XFs3f/8TE/V+Y+KmTCtMEnSf2k1v8BVb1ny2FY4prFQVs3XmUpqHortesnSVs23mUpm8e+IOYAC77rwx9XkVeThEdYXZ2tufHKIOYQNp2stWPidXB+gVFO/dT/vkE8eWdDN//hYn7P9HfmMX89ToKX82jctCp/qslmGd28BxFOa+yr/oqlhg9tbWpki6b+tEQHLepNO+k8MwN5rMb6P/lFybu/8LwpfeJt3xJ+W/zKeqcUv+VWFEr165aO0vI/W0VnRYTFZdueV7nl2s0Z8/Te6aYbPNpBh3qv1KZu02l+VX2VQ9AUTND3jo19lM7VUk2epqPkptTypVZ9R9G4sTae5qDOS+T/dsymixGDtX1cHewn5tXIgcx52dv01hsJmN/DT0TT9TFYrmsVLsai7Zs9lveycmnuHmc5PIu7vr3dS9xk5ep2v8qr9ePE/IQGPyO4WguQgBMWZi1gpjzE7Qc2kneiS9VsSgXzpl7dJ3Yz7aygdD7skRRZGQqzH3BwZ2fMOn9NaGoi5tad5bnblN5qIp+u/d3Qyq11zo5tEG1nVikee7XH6L4m0eeX7c1MCEZmUIIIYQQmqxNBRR2P4KEw/T0nSQlqNTJtaP51I65MGxrYKh9t87MnhDmZ7hWW0nTzYcou0Ahr5tVrK2FFH7+EDCQmJZFUjw4bRNY1DevDa/QdOs8+Qt2doI681F67GBM3kJGglG9gYKTyeF72FyQXnOL7sJw24qnwjFA6c4ahl0GMur6+LxA9R1Zz7HnzcvYWE/x171UB1fuqM0Nf0xl7ZeM+fpxEJtsXf9+ouP5fJmbIY4bxw3e2VnHmMtAdmMfF/Ok3j4NK9WuOvqPk1v9My7DFupvXWS/6onC74eX/zhaR8Fn/TRkqjdQPI/pNToHP0BjkwXmLR9TcuxLT7Df9Ar1Hc3sD5sZpzA3Qkv1h3SOPQ56OLvxF8nIXG4r1q7GoC2LVHf95WDc1kD/gmPNyZXindRPgCEhlexkU1Cpmm3sRyadYNzXzt36rarSKVryi+m0rSOj6CQVJVvZADinR7jUdi4oEL9s1xTuRbnp/of0THeq99/uxkn1BgF//cb9e8W2qYX/6v6zehuxeH1/DHy2pTfVpUIIIYQQwu12u+/8k3tLeqY7NT3b/cdb6kKvP/+Le6/3uuqNjll1qX5/G3N/2XLT/e9//Zvb7Xa4/60kW991s8+f/9X9Rnqme3vpnzSum+fcP9UdDFz/pWe6t5TedP9Vvdmtf3RvyXjH/fXCJ1jIf73+jvvrBU8knr5Z92eF3u97379o1AmPW+XeepbxT+6f1IVR+PO1f3F/+cusp079xz+7d/vr2h/d36s3jsqY+3Suol8Y4fl+qvS9n390hzxkW3zHwu/dn4X6YMTyWal21dsmpqZnuve2hHqOIfcfM7xtYuVddaHb7Xa7/71uj6e+FP6r+y/qQr9ArOP3VxzqQpW/uf+95ffezyDTvaXom5DHp6Y//8l97tKY+89/dbvd7kn32bzA8fEPfeqNRWytXLu69LbM4f66yLuvRd8sPN97/fXKO97nyHb/Q5+q7v75X9x70/e5T/8SqU67PW11dqY7NT3XffoXdZnb/eeO37tT8/439y+aO/K3wGcW8VhbvCiGli9S3BuU7TEEfp/8ig6LcgMhhBBCCCGWk42Wph88mYzGXRwxq8u9NrzNkTTPj5PtLQyqy/Vas5UjFbvZHLcGMJISIfNBbbD5U6YzznC9fS8LBzKZyKntoXPfOv8jrruX6Q8av+XkSucE+Rf0jYRy3PwOC0Daa+QtNl1KLJ/BFi54h8KlF7+tUSc8zEW7MAK4fqCxVe/Y7YU2FLzPkcwETzZPSipaowoX405VOb1r3qJ4m7pEw+zHNN705B4b8w4T8pAtOUw6AL9yofm2ulgsq5VrVwebP/WOBk3lSEmoefd2cCRvLQCum+doWTA0fJyem96sR9P6MHNgJpLkfQnL4Ii6UMHJaO0hij//FRd4Mk673gh5fGrasJcTxVvZEAewifRE9QZi2axUuxqLtszyCRcmPD8mm3eEzGqOK3yLXAOAi+GmT7ivKLvfeYO4mi4aMnVkR47eYNAJGLdToM785DaNXSaavv6ATM0dWYO57oT3vQCT44wGbxATyx/IBNIzlamzj7EEj1EQQgghhBBi+Vi+pNc7WaRh2+4wQwWNmM0veX50/UhHTwzmxYraAFeGNnKsbm/IzgpAZuW7gY4CM1h8cz55JVd1Lhx6pslJf+8DiNBBEk+LkyudP3qnE3gJc26YTmjmbrK9+SMz178M6sQ+dcOnKb+5kYrP3lfU29Dud97wzu9qIDtPPaxRIW4H5mTPj66hL7myXBOyiYVWql11fEuHb3WS5O2YwzRSmXlZeA6Bh/R2eiM/fnbmfC9tm2JBnFODwRj6eLM2FVNy3TvFW8JhuhcM5RWr18q1q7Foy0Z7BvBE0Awkhb0xupUc73Ngv0HXcKAkvqCZdp1DvO/3j+AMdVwP/8yaqo80prNRiEsj3Xe/wWgKc9Ng8VYkkBln9NwZ8XHOSSBTCCGEEEKsjEAnAJJSws9PGZ+2yZN9AVh6l2+i+pCGf8SS+y5HQ6WH+Cg6PfCE4MtrI5v9vYgIHAP0TgC8RP6+cB0k8VT4vx/AkEhy2B5hKpn+TuwAPcuRBrMYjgFKK34gpeZi5HoNwZlzbCTFX8+1mEhP9vU1H9B7M8ogmVi0lWpX/RnjgCFxU/igSNoW/9yY9ptXVZlgiST5mriZG7SHOj4cE1i8iXcpmanqUo/RDynt9gYxWU9xS4g5OcXqtGLtaizashnujPnmnDQRH/Y0bSQ93Tdaw8Vw/7i/ZEN6ms5A+wS9Q48BA+aCLHUhZJ+iWWsOT7V5z3+GjO0Lg6ExsCKBTIczeNUtY/hPXwghhBBCiBhRdgLWkpIW4To0WTGUduJHFAkNKyP7FP2NO9SPajCR4H8r60ha5JBEf5AgMYu8sJ058VTc/dEfxCF5S4RsRiNJSb6O8BNGh6Nes34ZOOmrrmM0/YzubCCmRxj19eGNm0iPUC+TFeNxww8FFrGzcu3q8KAnY5xwgUWfuESSfNXMeY8708rCTWRn+Ka8e0zvseP0aURUrRe/9Bxzpteo0KyzUzSe+c4fxDXknljCIjDiqVipdjUmbdkUk1GMaI9XxNqckw+YCyrVwfIdg3bAkEV+trpQp9kB7tgBUqmu03M9E70VCWSODSuXkV9HekaEhg7PSo99TZUcNJvZuvll0jbnsM1cxPHW28x6o7s+97uK2LH5ZdKU/3KKeKfLG2a3fMU7Bebg8s0vk5ZZSFH9QNCXO9f/IQdzAttsO3pj4Zev2LdtOWa2Zb5MWqaZ14+eo29atXNKjinudJ7lnUN5bC0b8D42TsvRAs97zCykxar+I4B5pntPc9Cc49+vrQWltAzafIFuIYQQQgihSdkJMBJmpKBHnNGfOQQPsWhemy0nI3E6F7sN2ET6IjvSviBBQvbukHOEiafHankY+MVojJhRY1RUcNuksg/2dDj6T1MztoWGlvBTJQSZnPKuau55z5EPWcXov5kHrPgh+0JaqXZ1CosibqSs39qU+/KISdWUGzk1irn7XD9Ttf80g4pg5rzlHOXdj8DwEhUXtFcsd/R/zBX/e19LftHyBGrE8lmxdjXmbZkTZ4Sk8/jAHU6wzRAUy9fB2j/iCdJn7Ao5n2d4TvoaLjPDRkq+7uRQpA93kZY/kGk9R6NvTguA5N9xNHzIm9ne4+x4uYSu+S1UtPZw81YHTUWpGOy/MvR5FXk7S7mimNRic3E33eXeeTcASKX2+24+L/bOKpz+Oz7vHaRdueiQcRedoz101+4OSk+Pz/uAb+6cIQPPXBedHXuD09etX3Aw5xBVPfMUX+rj7p1B7o7+wlDjVuxjl6naX0DlcHDtmu33BiFfLaas7Spjk4898zE4BijdWUbn2CPP766HdDZ8G5xq77hNpflV9p0ZJ6G8neFffmHi/k9cr9nOZMN+chvuKbcWQgghhBBK1geKC/n1JEcM+CmGH/KI6SiSL1bWVGBezG17yVeV6jNA712A9Zj3hR8aKp6O6Wnf8FUw6Ui7TUleH/hFsyO8ghwDVNXeI7M+wnxqKkFBhoRNkYfsJibiP2QX0XEXi7Bi7eoM0/5IkJ7M800kK2bVmLaogk5xb9De+EogoGT/gfJXC6kbtmHtPc6eI5exJR6gva+bo5rvyUl/18/euRU9WWt5mU6sqqSjtEwzrxef5Vq4JCfx1KxUuxqbtsyI0R/GesJsFNmZOO0Lk/LCmqJ3yPPZZBfsVhfq4GS0tpiqsU1UXOviRMQ3vHjLGsicn/6KoiOXA1Fow0tU1IVeEQrA0X+cfWemSG/ppbv2d+Skm4iPTyO/6iK3L+zyTN7rvEf9kQ+D5rzYUPKud4UmgHmcitipT075YfzV1GCKGBFPL3k3uLI5Big98gmTLkgofJ/9GwK3y+PNzdRuA3hMf23wClEb8j7im8FbtO9RRNhdD2g8cg5qOrjeuMtfYQ0J3hUC8QU6q+i3r6f4637OF6R579CvYUPm77h4rYH0eY03KoQQQgghPOzKC3kDupIdFRvN2Vbp3O7WG57hX6yjoGQxHQ6g/4ZniGfCdgqWscMhFsuOsvrpq7uKxI25aDuxseTk2ok6RjPO0KRnPjWFOeWErwbF+wkj8NnYsT29N/3iWKl2de6R4nV0vUrwIaCxNkdc3nn6WwL9b3hIz7H9FJ55wIbKLsZ6T5ETagiwcm5FAOMMrTn5lHQ+IiE9i9zcVBINgOsJMxNXqd3/Kq/Xj0c1J6hYbivXrsamLVPM0QlYhpdx+gzrDQZtAK9QkKcuDM9hvcFx807PAliuB7Tuz6eoafnqfowDmfM45mYY7f+CykNmMva3YPHG2Yxph8Pc2fCa/YKS6p9xpb1Lg1njhJf9Nod8d1js39EatOLZDg75I5m/MjikkXO74W2OeJM0sY/QF2qpssEfsZBKwZ7gfXDcvMyw9/04NXJ6k5K8kXr7CIMLbgWuIcesmNNj7AbTZT1cLEgjKe8jbt/qoKmujW/qfROqeuaTGXaBad8Z7Xk34nZTUai4OyCEEEIIIYI5nYHsmUVYrYtU3u8ZwAYYtp2kSmv8ow59vT8DYNq2K3KmiHgKFKssL4bLyVL+fCkcPeXUWrbTtoiVnJ1aGSm6PWFOb5RBLN5Ktatz9iXVYZdGnx0gzvwRNy8pkpwAeIKl+Tg1njtE2ibuBWXjGeKzqL11h7u9nZxvbeZ8ayd/Gv2J65Wp3tXTYeabMgqbohiOLJbZyrWrsWnLjGRnbPQ/6hq6yqBys3CiXDHcev1HTxJi2nb0To8513+Wovwcst+sYyjo0HmCpbuMvLLoFvfSKyaBTFt3sTeN+lWydx6ipPoT+iefYEhIJa/oDJ3f/8TdrpOh72x4DTZ/yiSQXhDqhLeJ7LRAJFu94llO8V7/nRV1mYeRvAJfMPEhvZ3K2ykBg9dHIPetsOP5DWEj6gvn41gg7b3gu5PxaeQXZJHkC8FbPqHxrgtYT37R1sB2KinpgUothBBCCCFeAI4B2q8/BsMrNDSGum6O5DZ9YwBrycnz3ekXIgYc31LWMEVe60fkqMuEWCXmpmdwYlDN7/mY/hMFHOzUDjw6bN4p4cCzkMln77N5QUrfGpKKO+kuCiQc2bo/pCNUEpUQEWwoeZdsX/jJ9SN1tYHVyIM56etVTD0YVSDTRt+wZ1h56HjcQvF5p+juu8PET30MXWqjIne9P4gP4LxbR1W/3tCvfjEJZJr2tTF0q4/rda8E7TSJh6mt2kumYgh2aCP0edMdLQ07Fy7M4/1XdlMR1Z55QFC8MP0tCny3VSau0qNxNy7OZPLvo33ou6Ah4OA58XYMraWgZOGkvXGFbXS+s4vcg2forl3iBV+ESWUHO294Jlk1pJItt8iFEEIIIRbHaAy+Po2SUbEC6Gpxp6GOYZeB7CjnHgwy+J1npJFxOwWLzOgUy81EvMYgNd0MkReXiD0bHX9oZHZfG816U3pUjIEJ4RZhLfH6e+5isVaqXY2PPB1cOAbNxYGcDFblkXfmHimNfdy900f7QWVykIvJtmL2aGRR2qYVKWemVNLDtL8pVScUU9/9St/NMJmeYgWtXLsas7YsbjdN9YFYm/16GTvKbnDf4Z2Ddd7J/f5zvGPOp2bM9/dgzMgiKfBreLNXGZwBNEYm6xJnIj49i6OtvYx/X026/627GO68qns4vl4xCWSuMZqIjzeRVHA+6M6D626N/jRq64h3GPo6Ci70MXRLx79rJwOrjgGQwNFiX8blr1zrUs+EaqPj4o+Buyj2G3So8nJnOy9jSdwbYkEiI5kVH3G+dm/wPJ+OKfqaSinvCUwauzTjDI559zI+mii6EEIIIYQIYlratVTQCqCrweiH1NyE5PJOLkY596DSnf4RXIBh227NlXnFamBiSdXvKfQjrK1ltDoPc7E+9IiySOL1Brk0mUhY6Tf9IlqpdjV+/dJeZ0FdctJXlk/5zcckFPnaUBM5tT0Mf3aYZEXcydZdQmm4TLKIuVo7yM8I/DY5GiqLTqyslWtXF9a/aAS3ZXF557mpmNvVfreO4ldf9ST8vbyT4oYHpNRfoTYjkPiXnq2/HZ67OcIMQPJ2zGEC9LpseIPuC68F5qGdHA9a3yYWYhLIVEqp6kKZrBixAfCZmfEuCvSYOacnMBr5n3FB+xFX+Jb/zsfM9S+DMy4tX3Jp0kBuke9DdTHUM6DYYIKO6w9JLw6/IJHHPLOjX1F5KI8df/iCudwzNMVqvkrHDNM6PjIhhBBCCBFBSqoiI+EhlojLjSpXyV2vY5XcFeQYoPTYd6wp6uSbkqWsMj5C75ALMGAu8M3PLlYj/xz8gE3HUs9Bq+Qmpq7s3KfWjyn/HIpbTi7pdYOmztKzQrC/HwkkJOrPQBKLt2LtaiJJ/lXI9ax2PoVFsU1SenA7OdtZStVdFxi2U10VXBaXeZJvbjWR54++uBhuCl7EN2j1ah0Wu9q1WF4r1a7Gui2LN3/E7fu36LlwhoqD28nN3UVx5Rnav77FxJ1OqtNG6Lnr3diwnUO6F+yx09v/KwDJeXt1B2rDyjzJMX9cUE8bEZ2YBzLByKELDYEx/LgYri6mMYodn7ZGrkyh7eDovnWeH4MyLp1cabqKPfEw1VXvBoag373MFd9kmoNf0uvcztHC8He354bPUZTzKnnV98hu7OX2lY84kpmwIKi6aLaHMU+9FUIIIYR4MW0i2d8R9g7DCsehnMh/I+l6eyzLborGN2uYzmunR9UBj9rwDQZdno5OwSKH/4qVEdQRdkVeOEK5IGlC8hLrSZSs13/AxiO63lw4PZjyX5Wvo83PVCke9w/lTd5EdIfsk8AvUQQZxFKsVLu6iXRF0HM+4ks5CRwC60lWrPYME3R0eYI1ZOzCrCzyidtB8zVFLMN+g65hRXnC+sCw4oj7Akkpsp7FarRi7eqytGVGUrL3crS2mfOtH1FdvJecFE+tnO28jMW7lWnfW9p1XMvcDfomAV4if99SskiVjJjNL6kfjJllCGR6xvBfvHQ48KXxiK4jx+lbuPpOgCkw/4VtbGnLtG8u3O19bRdDnd96nsv6KR0TBnLL32dD0BD0B1zqtHkCnZ0/Ygz7hdu5VmYm99hlrGlnGBpsZr9/dZ4YWqPMaZ+KHLkXQgghhBAhJJKTsdb782MsExGGvdge4l+TIYqVO5fXFB2HSriS2EBP/daw86zrcafXM9WSIXuXLMay2m3bHphKS8fwvFmbryO8lsxs3Wlvq0tSFpm+jqH9AZYIHUNbINWPdLNkGK+MlWtXs82+fjtMjkUanv2IWd+uGLeQo0xpm7uHxTtNZUK4lNC43dQW+QJdLiyjiiSrZEUmqj3KfnrCphCBKbHiVqpdXdG2bITWbl/maCrHyvWv6TJ3fcCz9kxiFnkxScf0CEwhEc3NC32WJ5AJkHKStncUqdSun6l681zogz0pMRD4nLisb1Uv6zlKtebgTDlMnn/Rn+/od8DgxavYEg9T7Y1SBg1BH7rK7OwXXJrYSEFJ6C/8TlUBtXefABsprolRyq2WpE2KNOIpxiIdWUIIIYQQIqTMwt3+uZqmLRrXjgqOiQeeBRejXLlz+TjpKyvhgukMQ+2x2J9x+u96MlAy8xYubilWmbjdFPi6J86HTIftCI8z5lsJ1bSbwhWe/DSltHPhmgYa/6r88wZuoUrxeHepL9NpK4V7vCPsmMEStLqrmhOL5bH350UuUiEWZaXa1bg9r/mDTs7pmfAJT6Pj/sWATXsOBM//O2dXZIWGtyEvKzC/nzJjL24HZn+Wp45++nzgb6PK5BPLa8Xa1ZVry0ZrP6TfW92Syxs4pPsgczI46MlUTsjerWOKRf38GabJW2M+F/fyBTKBlIoumrYpswsvU64VeASIzyLTH8l8SNeZG+EbKccApX8YJ7NIq0FQZVw2nKZlCPKq3ld8MYoh6DM3KD9xg5m0wxwN+c0N0OVfMX09KSG3i4UszP546hP6um8HFwshhBBCCP3S3/JPK+Qc/iF4DvUgTvp7H3h+NESebmj5eRamqLG/S3fEIKaTvqoPGYw0fG30BoNOgFco0D1/lnh6jBwq2e5drfYBvTfDhGIsP3DHW5y47y02q8uXW5x6PYMQ//zdQ0Pw44oKvrlkL55D9gl3+icCBWqOAXq9xYbct6LovIslW6l2Ne4NjvoykLxJSqHc7x/xBis1EpRSAsN89cyL6Bt3GTzPponCQl+cIULdBKyTvtdZj3mfVtxCPB0r166uRFvm6D9O6XVPENSwrYHOksDY6Ij8rxv7Ojo8+AAwkF1yIOZJgMsayAQj+e2dFCs+x9CL/2yiuDAwht41Vse+qtuac0XOT9+gdH8N0/s+CBl4DMq4vPkDM8nvUqHKYQ9UqsdMTj4mu/iN0BeI1gdM+3/RnqzUZvPdZ1oqI3kFgRR611BNiM8MZq2xWildCCGEEOJ5lcCJql2eTov9Nj2hsmhmr3LF25FILjuhOd2QY/A0r+eYef3oV6FHGsWEk9HaYqpmDtB95e2IQxKtraW0Gg9gjjDr0ej1Hz0d/SiHd4qnyHyCY94sMEvvQMhkjztdNzxZb4ZdVFdodWSn6CjOY5u5iDpPNHv12vA+1Xs8nTn70NWQQz9nv7nqnRPuJY5VSobxylq5dtVc+S6eQyBc0GmELl8wZ89JTiyIE2wn3xfbVK6TocEx8cCz6IrhFQq2BZfFFZ7yxzfs1z8NM32ejb5hX3DpPcoiNeJiZa1Uu7rMbZlj9EMKq3/2TBeT/J6Om57BHDe/87yuKYs8vXXUYWcu1AfmM/sFHXfBsO0MTXlR3rzQYXGBzKDJeoMnP11oE9UtyvkyQy/+s6Hkg6Cgp/1mFbmZBRTVf8G13htc6zrH8UNmMvbXMZrcEGGic0XGJQbyyjVWIt/wNkd8jVmkVZ2CVmZ7RNeJDxmcnQeczFkGqCvOo24ssLl1eNyzsvnguGZjHGlS2bjCUwQC6S6Gqwsp7Z0KOsDmhj+k9HPFCloz97gf6S68EEIIIcSLKPsUDdsMwGN6z2hNd+Skr+FT7zxRb9GgldHg+JayEz8w43zCzFgLpfVhsiuCRH+BZm0qpuS6ncSER1yoqOR4mH9F+TkUfv4Ec2HoKZI8Jugb9gz1inZ4p3iaEjha95anPzXRQpVWgoP1HPU3XcBacutPac59er/+OK0Tj3Haf6XnRHnYQE6AaxG1NzZyas54Fl2xf0eN1qg+xwD17Z4hkYnvhE5wEctopdrVDW/T4J22ztJ0WjN4aG066xlaa9xOQ43W/IJGDtV4jyMe0FgdKng1RXunJ4M0uewU+QsaSkV8w/UzNSGex9F/lq4ZTzC0oVFfe6sYiS6W3cq1q8vVls32lJL3h++wAaY9TdzUcdMzWCBb2pT7mr5s0+HTbH01n9xXX2Zb8TnuaGYeTtD4h0+YXkRgVa9FBTID0WIPZ/8Xmo2JX8pJehpf8abu4l38p4gWi/q0uInqr9spVM6f6nqE5ZtPqD1TR23zZYYmn3i+JB0fiD/jUiMb0yOQUhx5VafdVBQp5vy0fUf5b18lbfNOco+cw1nSze1GX3oy2K+Xkbb5Vfb12P1B3NFhRaW13OBauM+MTZwI+iweM3ymmOzNOWzLMbMt82VyK+wcq3wl8Ce2qxS/nMOOQx+HSe0XQgghhHgRGclv76NtzzqwXabo0DnvTWnAMcW1skKq7rowJL9HT+/72p0B15OgoI5TucJoSFP0DvnmvQKbZUKz06tkbS2ksPsR4GJm7EeGhsL/s9hckLiLYs2dVrB8x6CdRc2/JZ6ylPe5+fV7JBvUCQ7zzA6e4+CRy9hYR15LL+dDZL8E19d5nDqCJo7eG4p+3xTDodKJlkPcbi7eaiLP5BnVd7DpNv5D1uoZoTfsMpBc3sWfKsIluIjls3LtakpFLz3lL2Fw/UzV/uNcs3oDT/M2BpuKKOp+BKZdtH3frBF89Ep5n+uX3iLZAK67NeQVn6XP9zzM47Dc4Li5mC7bWtLLu/hGK/CKJ75x8+v3SDd6nif3kOJ55p3c7z3OvuqfcRm3UHvtfOj9UXLcoFcRZPEkRolltVLtaozbsvnZ2zQWm8lruIfTmErxhT5uN+2Ifvi2f1j5WnLyIt0IXcg5cZmynWZer/qK0Wk7c9PjXGuq5PWdlcyWXuFu1IFV/X7jdrvd6ge1TXDp6Fk6LL9i1/pyMGBM3ERG4QnOF2t/CKO1eZR40719DKaXyK86T0Oecpl3J9beT6jvHMA68wQXgGEtiel7OVbzHvm6Vwr3TI4+XNJDQ8jZRSeoM7eQcq1TxzwE80z31lHZ9iOTdhcY1pGc+z7N9Xvx7JKTvooCqoaeAGtJL2qmvSqR4fpKLtycYmZBrV5LcsZWEnLfCvmZwTzT/Z9Q134Di/ezMBg3kr7vXc6U7yZp6DhptVMkZ++muOgw5syEiAFeIYQQQogX2ZzlKxobvmBw8rHnOhMDxsRUCspOUZGX6J8bTYu1s4SStgfMJ+yi+euPMGteeNnpqz9Ln93O5PADbKpLQIPpJdLTEzCadnGmdndQ58PRf5xc7zCxaKTX3KI7wtxz9+vzKP7mMaRVM9wVZkolsXrNz9DXdpYL1x8E+haGdSTnvk1t1e/YHK4n67hN5f4q+u1rSS+/SHdJiA6z5SuOd97DaRtnbFIdVDKQmJZFUjxkljRzxL/0r359ZS9TdRfgFZrunydfvcECdu53naO+09sHY7F9Q7Gclr9d9ZifHqC14VN6LQ/9QSOD6SXMJaeoLk7TF8yZtzHY/gkdQyOBeAMGjMb1JO05QFVZhGPJz1c3R5i2K54ncRN5JaeoKNgUoZ2d4FLFl4w6bYyN/bpgMSJDYirZSSbICBcvEEu2Eu0qLKktm3fMYBm6yqXuGwxNPsFgSqWg6hQVeZHqWGiOnhKyGx6A8TU673yge0Ge2cFz1LTdYNL2xHsMGjAa15KQvIP8kgMUZi9+n/SKIpAphBBCCCGEEEIIIYRYGeN0VFzmvikVs3kLOWlpQYujvYgkkCmEEEIIIYQQQgghhFj1FjVHphBCCCGEEEIIIYQQQqwkCWQKIYQQQgghhBBCCCFWPQlkCiGEEEIIIYQQQgghVj0JZAohhBBCCCGEEEIIIVY9CWQKIYQQQgghhBBCCCFWPQlkCiGEEEIIIYQQQgghVj0JZAohhBBCCCGEEEIIIVY9CWQKIYQQQgghhBBCCCFWPQlkCiGEEEIIIYQQQgghVj0JZAohhBBCCCGEEEIIIVY9CWQKIYQQQgghhBBCCCFWPQlkCiGEEEIIIYQQQgghVj0JZAohhBBCCCGEEEIIIVY9CWQKIYQQQgghhBBCCCFWPQlkCiGEEEKIZ8Pst7yTX8ngvLpAPC3zg5XsOfots+oCEcwxTl1BES3T6gLx1Mzf5nh+KVek8kY021PKnorbSNO7eky3FvF6/TgOdYEIJm3v6hODtlcCmUIIIYQQYvWzfszr+78kpaUZ8xp1oXha1pibaUv+kn0FH2NVFwoPxwClv63EVnaRE0nqQvHUrNnB+ZZNdOwvpEUqb0jW1kL2dW6irXUH0vSuHkkVFzlmqySvbECCmaFI27s6xaDt/Y3b7XarHxRCCCGEEGLVcAxQurMO6vu4mGdUlwaZn73NheZP6R3+FbvL85ghMZWCklNUFGwiTv0HizVvY7C9hQvXR5j0v9BG0ve9TW35XlJ0vZCd+12f0tQzgHXmCS4AwzqSs/dyrPJdzBsWEzaYZ7q/hZoGG8V3zpOvLg5Ja1/Wkpi+l2M175GfFG5fnPSV5VPDGYbad8fuM34uTNGYX8xgbhc3qzapC1WcWHs/ob7zBpYZX51aan3Q5rDeoLXhC3onHnq+awyYkrMoKD3BMXOCroDV/PQArW1f0Oc/1gwYEzeRF4tjzTFA6c4ahuMP09N3khR1eVh27nedpbxnPRd7I/+to/84ubXQcOs8+Uva6edPNJ9NLOqUHrFp47Xau+iPtTnLV1xoukr/5EOc/mMglYKyU1TkJep8z0vZl2jalxdNFJ9NTM7nesSijZ9ndvBTGi/eYHjysf9YMyamUlB+hmpzgvoPtDmmuNZ2lo6bU8x4Kq9nX3Lfprbmd2zW9Z6Xti/RtC9qEsgUQgghhBCrmKcz0pfRzu36rerCINbOEkraHuA0vUL9hY/Yn2L0dFDaKqns/hWXaRdt1z7CHOUF8wLWLyj6wydYnOvIrjtPU8Em4phndvATyqsvM+laR15LD83mMEFX/3OoC3wMJJd38k1JhA6Yn+f1q85c9j7nKzTd1xnInP2Wd95sZMy5kcKWNqrNCaxRPV/iwXa6a7eGCRKMU2MuYzRPR6fxheEJ8FY5TzDc9UaYzw5w3KZyfxX9dgPJRQ20le9gwxpPcKjqWB3D9rWkl1+kW3d9CMXJYFUh5TcfY0g+THPLe57Os2OKa9XHqb37GGPae3R2vR0mABh4jpCWdKx5P7e7LkiIJpDpxNpbR3nDj9hcRPW3o7V5lIzt1r39C8F6jj1vDpD5WT8NmepCpVjUKX1i0sbHpO21ceVoMfVjT0g82MTFKs/xOj97m9bqOromnkDiATovnSJzuffF8S1Fr7ZgbIx8o+/FEUXbG4vzuR6xaOPnJ2g5UkbnpDfwqMG4rYH+CDcU5wZPc/DED9jVBX4bKfm6hxPhDtgY7cti214JZAohhBBCiFXL2lRAYU8q7aMfkaMuVHD0Hye3+mdchi3U37rIftWVs7WpgMLuR1EFNzT5MsVcBjLq+vi8QNW5sZ5jz5uXsbGe4q97qdZ6IevHvP7ml8x4M4myk0zgtGGxBDKMPAxk6+iczg1/TGXtl4wF9Up0BjL972cdBVoBC3+5jk7J8Gm2HnvAoVDv+wXj6C0l94yTY993c3SDulTJE6zvskFCkUYg2HGDd3bWMebSVx/CCX8cOLl2NJ/aMReGbQ0hsmud9FUUUDX0xJO9k55GghHs0+OBbDIfzdeIzPO53fM8l67nmGe6t47jzT8wowwI6fpbnxEqM8uxFGp8/i8kT528ktbGeFOWujDI0uuUPjFp42PS9gYC7aZ9WjfYFIF44ys0fR8i2ywm++Ix21lEXrtR83N5Eelue2NxPtclFm38FC35xXTa1pFRdJKKkq1sAJzTI1xqO0fPxBP/luk1t+gu1HqOwHG0JnEXZTXvkp9kBGxYr39JTduPgeCm6QBdg6fYHPznXrHZF49Ftr1uIYQQQgghVqM//6v7jfRM9++vONQlwbzbpaZnuve2zKpLvYbcf8zwbLOl8q66UKdZ92eFnudI3fcv7j+ri71ulWd7tsn4J/dP6kLfc+T+0f1vGk/wlzv/3b3X+148z/FH9/d/VW8V8Odr/+L+8pdZ91/dbrf7P/7Zvdv/t390f6/eeAGH++si7/ZF33ieQ8Nfr7zjfc5s9z/0hfsuvM8X5rN5cdx1/2NGpnt7zZi6YIGfKn315R/dt9SFXn9uOej9Dn7v/myxH+6df3Jv8X6Pfwz5Qv/ir39vdGgcS3f+yb0lPdv9RuPYwvryt2n3lyW5gbqbnune3Tip3iq8v37j/r2y/uf9s/s/1NsE+Zv7l0v/4v7+vsP9N7fb/ddr/+B9j3r+Npinnh90n1vs5/sc+XPH792p6e+4v17wJavEok7pEZM2PjZtb6A9DPP5KOrxltKbC4+VGO1LwJj7dG6me0v5kLrgBaS37Y3F+VyfWLTxf+74vTs1739z/6JZD/4W2M/0THdq4b+6/6LexO32fjbZ7t9fCXEM/ee/+I+z1PRs9z/eUW/gEZt9CVhM2yuL/QghhBBCiFXISV/Dp0watnM07N18GGz+lEkAUjlSEmpOph0cyVsLgOvmOVoWs1rmYAsXPC9EevHbhEr0MBftwgjg+oHGVltw4WALF6a3UH/tPPs1niA++xR/+uw1TL4HXD/TdTPkuEM2FLzPkcwET5ZTSipRrWdg+YQLE54fk807QmZKxRW+Ra4BwMVw0yfcV2/gZ+RQyXYMM5ep7w+9zy8Ca9NZ+l0bKShVZ2upzH5M401P+pUx7zBmdbnXhpLDpAPwKxeab6uLdbDR0vSDJ8vRuIsjIV/obY6keX6cbG9hMKjQ8xzxRZ18U6UxzcCaRI509FLr/XsA2/WvGFVuE5aNjj80Yt32FgWhDuMF1pBZ/D756UbWAHHJm4hXb6KTp54/pKvhBV88xTFAffuvGHLf4tCCL1kpFnVKn5i08TFpeydobX/g+TF5e+gh7HFvcNTTaOK6e45Wi6o8JvuitJWyfRtxDbXQuMjFU54XutveWJzP9YhJG3+bxi4TTV9/EGKqgjWY6054/x6YHNdsd2dbP8ZS2El3YYhjKOl9ag+u8/7iwjI8pdqAmO2L0mLaXglkCiGEEEKI1Wf2Cy7cdWHa91bIC3/wzA/WMeQdhxeuYwlk5mXh6Vo+pLfTG8HTzcmVzh+9Q2dfwpwbJriauZtszwsxc/3LoMBfX8+PJJWdCT/8L/MkxxTBoGmLVmdi6UZ7BrzDyAwkJfu7zBq2kpPs/dF+g65hVbGS+S0KTC6G279AHUd4cdzmQs8jSDscflgjcL/zBjPgGT6aF6bjHbcDs/c7cA19yRW9vT0fy5f0el4Iw7bdqGcQCDBiNr/k+dH1Ix09iuCJ9TL9tl3Uhh3+Z+RQ+Wuejj+A8yHTOvd1trOS1uldtLXvDvz9itrB0X3rcN39lI4Xt/Iy2/mpZ6qJkh3qomCxqFN6xKiNj0nbO3qVfu/YW0Ni+KB5RrbvOHlMb9dIUFlM9kXFEwh7xJWL6iDYi0Rv2xub87keMWnjh39mTdVH2lMU+MSlke6LTxpNGnXTxqAti7aw7TdszgyUxyetDyqDWO2LWvRtrwQyhRBCCCHEqmPt/oEZ1pKTp+jJaXDc/A5fskukjiVpW/zzptlvXo2YJRDEMUCvr19sSCQ57AulkukP/A3Q43+hEQYntnMsZEaRj6LjDzjnQk/Jv3gz3BnzzWNlIj5cHBMj6emBLI3h/nFVuVIa+dlrYeYHul7UzKD+qwy5IL0g0nyA4/T4F8zZSIqvzmgykZ7syTaDB/SGzc5aKBC0hqSU8B3Z+LRN/kCipTeQITN3dxxD0Xth56qF4I4/2JnWk8Rk/ZiSNjsFF8LPhbvcNudlYeQh/d3hg0bPrym6bj4EYxb5/pQqbbGoU3rEpo2PTds7PXwP35EXH77RJC4t1Z9R6bo7EPN9WSBuNwVp4Bq6Sp+67EWht+2Nyflcjxi18dmnaNacN1Nl3vOfIWO7xo2FBI40va89d6zSvG+C1o1kbNN4zZjsy0LRtr0SyBRCCCGEEKvMFL1Dj8CQRV6EK+DhQe8wPyAlMzWobIG4RJJ819/Oe9yZVpWHc/dHf2ea5C2BYVOajCQl+TokTxgd9qYtkUXt9w3hM0y94hMCnWRTUmJQWWxMMaknwOSl7LQ7Jx8wF1QazJMV9YjB6/o6JM+bvt6fI2f5AEyPMOrrqxo3kR62Mw3J6YF6YBkMzvAKTxm0XktKWvgADMmKKQomfsSXgBtfdJHuikjBFzyBcf97WU9yxJ7zFI0nvoSi8wsXm1pp3iCsbegGL2Qc3nqDQVukDEtiVqf0iE0bH5u21zr5KOj3sOIVmWjOKSz+RjM2+7KQL/D5M7396rIXg+62Nybncx1WrI0HZge4YwdIpbouQjZ1GINDnuPNtO8UJ8JmtYaxmH2Jsu2VQKYQQgghhFhd5kYYtQHpWRGys6awKPoURmOEzgtGAps8YtI7P5YeVsvDwC9GY/hsD9W+2CYDAb24uDX+n/VKSQ+f7bR0TpwREvyUHWpsM4SNAXuzomxjI2EDns+nEQbHANNWsiN0Wpmcwh9LNhojDqeOM/o608DMA12dPQ9l0Fp5DIQQp9yXh1h8L7Qmcr1fIGFTxAwga1MlXRyOOORxZXizr2zjDL94lZe5u+PYgPTs8CuVx6xORRS7Nj7Wba8zYqO5XpE9+ohpRaMZ633x8WW+jkYbBHsu6G97Y3U+j2jF2ngnfQ2XmWEjJV93RpjbNgzrORqHXBi3NXC9Psww+LAWuy/Rtb0SyBRCCCGEEKvL8AiTQEJypI7bjGLY6joiJqywiWRFQlmkOceUpqcDmTiRM2MgJVkxt1RUHRIPq3/fXqEgT1UYE0aM/uG/T5iNIjsTpz18gDIujXQTMDnCHXXZ8846wqjLk4EWMYCn7EzrCPiRmBhY/CNSMFnJ+kCxrZ4MyUSS/C/0iOkoEpA8prB661NC7t7w78t6jvJuKG45GX67FeObRuFX7kSTNvicuDP8K7A+whDYlaxTK9fG+4Rre42BRhOnLYrsTJ4QaWS4lnD7oilzK8mAa2wk6nPOMy+Ktnelzucr08Y7Ga0tpmpsExXXujgR8UVCmP2WoiOXmd/TRn97hKH5IS1lX6JreyWQKYQQQgghVpXRMU/nLSlSBsrcI0VATV+Gy5pAP5Q53T1LOzbFprpeKeiFIgT+Fpiid8gzr5Zp39vkq4tjQjHvF2AZjmUGzybSkwGmGItqPrFnn2PiAXYgQUfnOKj+GRT1JYxA3bNj01up7Mr6Z9BZfwM/zikrvx79A4wBkMrR0nDH8BSNJy7DO81UR9XhXV6+zLfJsXBzwT6PxhmbBNhIeqTvY6Xq1Iq18T7h2950xUIoWJb7Rk34fdG2iZQEwP4ASzQTkT4H9Le9K3c+X+423mG9wXHzTkquPwLXA1r351PUNB7VHLTM2xhsKmHbbxuxuMB+s5xscyXXdC664xOLfYmm7ZVAphBCCCGEWFVmbU+A9ZGzb+bs/oUXFsMVaWign505vZtqcTmj20/LVfpsgOEVqisXO7wrEiPZGRv9v7mGrjIYVB6GjlVI4+PXRp/p+RywedPHIgbhAafTt6jCYjxhLkIn18/p9K7OuzgRFxkJ4uRK188AJBSdCjuscLT2OF3G9+isiPxZrSiTCWPUGXfPg0fMOoGExMB8lqGsVJ1asTbeK0LbG7dtC/7TkutHruhuNNdGWFBNQ4R90bbem/lq07fI1nNEf9u7cufz5Wrj5/rPUpSfQ/abdQwFHUpPsHSXkVemY0Gt+QkuVRSx7eX9lHc/CH5P9h+p/W0hLTpST2OyLz5RtL0SyBRCCCGEEKtIYO41g65UieeNk772G9gxkF3/EflhAkFLtaHk3cDq0q4fqasNlQXhpK/3XuBXPYFMk2c2sKjmE3sOTE/7Vqh9QVk/pWMCSIgw5+Xoh1ReN1HR8jaLXU9i2cR7OtPYpnQPIX0uWH3z+enMsHzu6Gh7N7zNsW3+RpOhhg8Vq5EHc/TfUJQZMUVqNIPo2BdNvjlCH0cxfP/58CK1vfF5p+juu8PET30MXWqjInc9ynxP5906qvojhFvXpHGktZu7939i+NYVOusOkB40iedDOk+ci9gGxmRffKJoeyWQKYQQQgghVhG7NwthIymR0oJ8F72LZIi4cISPiXi9m2oxRJ7k32/4LDV3XRi2naEpT/dfLU7cbprqX/F3OuzXy9hRdoP7jnnPA/NO7vef4x1zPjWescIAGDOyImZsJaV4sj2jH9r5LPMNWdSRTayaby96axUrg0dgNAZ1LKNl1J1KZqPjzGVsrKck7JyXI1Qe+44NNRc5uuqimEDSJk/9jmII6XPBN1w80fv+w1mpOrVibbzettdIfuOZwA0g+3eUmI9zzeLE02rO47AM0Hg0j9xa5c2fLeRE/FAVdO2LtqQkz3yOuofvPxeiaXtX7ny+7G18nIn49CyOtvYy/n016f6XczHceVVn+7WGuPhEMgtO0X3nFp37FPOB2q7SoWO+SojRvkTR9kogUwghhBBCrCJOdI/GCloVNnrxejvTmFAu2h21+MgZjB7j1NT+AMnv0b3oyfajE5d3npstu/wLDNjv1lH86qukbX6ZtJd3UtzwgJT6K9RmBL6U9Gy9wxwXMbTzmRbdkEX99U+LiQR9lQpMeuuftqAV68Nw9NTQOrmOvJZwizw46SurZDD9DO2FesMBT0kUQ0ifC9EMF1+hOrVybXwUbW/cbi72NZHnbzR/pvbITjI2v0za5lfJPnIWS/IHXK/ZEvg807LIDDxDBFHsSxi6h+8/F6Jpe1fqfB5N/dMSRRsPsOENui+8FlgsaHI8ZLZwaEYy67uoTfP97sIyvIhRFUvdFx1trwQyhRBCCCHEMyqRJP8KtXpWwp3Cotgm8lxaAb4sFwBb5BcKXq00MfIqqp4ATzm9aw7TfeVtHdvHTrz5I27fv0XPhTNUHNxObu4uiivP0P71LSbudFKdNkLPXe/Ghu0c0rN6rogoJT0wR6mulXBnZrxDf3XOY+iTkqrY9iGWyC+kmF9PT4aTZ/XxwoYpsht7aDaHDlA6+k9TM7aFhpa9iw7QiFVgJeoUrFAbv4i2N34HzYO/MPx1G/XlB8jN3U5e0QnqL3QxfH+Q7qpUhns8c8WCgdzC3aonCGUR+yKitvznc48Va+N9Mk9yzB+E1HNcajFyqOqAPwip5/PRFJN9CU0CmUIIIYQQ4hm1iXRFh3jeOyI6NCeBBMH1JCtW7Y4kqEPiipy35FRkIiYkR+5MW5uKqZrZRefX4YbkLicjKdl7OVrbzPnWj6gu3ktOiicgNdt5GYt3K9O+tzAH/Z1YtORN+GM0EesuOJxPAr9E0ZmGTSRH90KKbBgdK1g7Big9cpX4mitcjDAMdrj3Z1yun6l69WVP1q/mv2K6fL1522UKFWWl/aonFE/JMtcpv+Vv45fS9salZLG/5BTnW5tprvod+7M3eQL0s19wacK7kWkvR3U2mkvZF6Hfcp/P/VasjfcxYja/pH4weunbyVzKqHiI3b6EIIFMIYQQQgixihiJZlqpbHOq/+fJsVCL1fh4V+VlEXOWbdtOuu9nHcOkPCuvA6wlMzt8+pG1s4iino00ff0BmasuTW2E1m5fNkoqx8r9KRa6RDVH3TMvyrnXkrLI9G1vf4AlwtKuvlV5AdLNWUFl4SWSk7HW+/NjLBMRBu3ZHjLr+zltO9nBpcEct6ncX8N0YSfdhf4u+/MhirnwngtRzXu5jHVKZTnb+OVqe++0XcaXx5Ze9h6bVeVaYr0vuuchfS5E2fYu4/k8yIq18QGBaRuiuWGgZvLPz5mgP316gUXvi462VwKZQgghhBBiFfFdQOsbihS35zV/h8Q5PUPYfsLoOJPeH017DkQxZ5lnXrQCXwzP+ZDpsC80zpj/hXZTGOaFHP3HKWo30XDrfBQr066c0doP6fcmrCSXN3BI5z76huItbY6wZ41v7jU9Q2ABtlK4Z5335xksvjqjyYnF4luVN5WCPZG6ecEyC3f7hwpOW8LPeeaYeIBvdr30gnBz9E3R+GYVlrwuboZboVzB3NjH0K1I/9oo8O2s6TXaFWVNuaonXA7WB0wT3Vx4zwXfvJd6hsAuW51aaLna+GVre0c/pOamr9F8jyYdc8HGcl+mpx9BNPOQPheibHuX6Xy+0Mq18T7+rM7krWHrf3i+zGYD6dn62nYtUe9LFG2vBDKFEEIIIcQq4huyqGMcFkDcGxzN9eYRTXxHf5gOyf3+Ee/wxo0UlESXWQhGDpVs92YsPaD3ZpgMJMsP3PEWJ+57K2Q2jqP/OLm1do5ditx5dfSfpmZQ52cSI47+45Re93SsDNsa6CyJPuMuqmF4z4GkJE+nNfIQWI/NJXvx5Ls84U6/byyqBscAvd5iQ+5bugPKfulvUeBNrHEO/8B9dbmfk/7eB54fDds5GjIIM0VjfjF9aU30RAxiTtFY8QWzwJo4E/Hxkf8Z13j/dI0x6PE43+MrIWHTIoZ2PsNSvMNgddbd2NepEJahjV+2ttcxQOmx7zxBW8MrNH32NhvU26gsz76si2Ie0udDdG1v7M/noaxYG+81PPgAMJBdciBiMDAk64+MOoGEAxyNJn1aZdH7oqPtlUCmEEIIIYRYVTYkrAUeYw2bvRBgrnwXz1Ro4TokI3T5gnJ7TnJCq3dp/YIis5kdh84yqNVZNp/gmHfONUvvQMjMoDtdN7wd2V1UV2gH/xyjH1JY/ZBDl7o5GumK3foxJW1GCs0rF8Xx7N/PuADDIlbP9WQFrWWD9tt/biV4VyaZngyfoea34X2q93i60/ahqyGHOM5+c9U7T+lLHKvcoS4GnAxWFbItp5B3urReO4ETVbs8HXf7bXpCvtBVrng708llJ0LMh2rjSnEJVxIbuN60I0K9cDJYcRxL9oGIAZ1Vw7vghjEhsCDIi2E9G4yAfUpXRmYs65Rj8DSv55h5/ehXmq8dszZ+Odtexzg1b9Yw7AIML1GhJzAZ833xLXaUoFgk6cUQddsbs/P5FB3FeWwzF1E3qFE3Y9XGO+zMhdpJn9kv6LgLhm1naNKcr3gex5wz4r2KO51XsbGe4pYQc7XGZF80RNH2/sbtdrvVDwohhBBCCPHU9JaSduYeCUX6h6xaWwso/PyRJwtGY3ietamAwu5HYNxO0/fNC8phgjrzUXp84x/TqhnuemNhkMb6MXve/BLb/5+9/4tpMt0fvf/396SeWA4sJ+KBcKBwIJgoTEZgotSoMMslxiWM60cdnykz2aCzBSYbMD+BlQEmj0C2gM+MmMzA/FTIOOC4qYtZoMaiWSCTASabYrKBSTZ4QD34UpPdevDQE34H/Xf3pi0tFET9vJLG2vtue9Neve7r+tyf67rQkNHQv3xxk6mrHPvkDla2ktVg4pp6u2Kfhfh9ZCQE2K60MMPw5Etiw/os+vhsby1jAHxI48Q1ctS7hGG+p4i8+j9wALpjjdxtPBRZNoU7W6/Tuo+6iRucVG9+l01d5dAnd7Cl1zPZFuZKxfaHFB12BUAClnnF9vjPOvln6fJyYO8xklHvznpjG3m3B6jxTgLn4aC/OIeKZ06IO0NPv7qTqtge/yk9pi8DdGLd+4xtJSU1GV2omAoOrGN/MO2ItCx6yg9BjjMEz+fPKp7r5qkrUmt/58dc9dZ3W2/hB1SPbcfws4nKsD64KJQp+y8UfNTgW1DsdDtPqpdnU669jl/Hunf+Fz77pIExB6A7Qmv3N+hXqjTX5VgeUrS3imHdGXrM6u/iHbeaujcK5/OJumwMd31Dwqv/3bE8m3KtdfzwZfaff4QT0CafobHlKzLV5WtxkoaThXRrLwRZ8d7G7fwcGqcBzXayqlppyo1HXYUvmC5yrGYGfXMPTfrlf290jiWwSOpeycgUQgghhBCbS8YBEgGrZTJoloRaUqmJnpJdaJy/UXHyIr1T7syIRSvmxgIKul66OpjBOri8Vqx2CzhfE3At06QvefDzBRI1ToYr8ygyzbiPcZF581VOn72DlW1kNwfu9DD1LX/95A5WwDn3B4ODT0PfJl/iZCfZBaE6ry52U583GAAzDAdL/Qhicf4JDQY92fV/4NDuwXC9nycRBzEBZpiyAokHyFRvetclHXCt9jo5EjTzZpmYo9x43Ei2DqxdRk43PmHenTJjn+qj6GQVw04NiSUBOrhuTocyx0ZVlr205LT103psG1jvUJB/FbP3jWboLc6j4pkTTeKFwAEnHPQX57qCUs5XWJ4FKK9+tz+YdoAm61QEQcy1mbr/1DsXI9aVF9cIZGr6JbCLzDUMqXxbZWbsAl6uvHiP11rLlKuuVZZeh3LlZoU11/HrUfcuWjE3Gkn/uIExx1ZSCloZNIcTxFyHYwGYcs1vqkk9EPizfpetpu5d6/l8WXldxBGo4RCFOt7DMXmH4sN6/lrxE6OzNhZmx+ltLOevh8uZL+rmWYjAoffQnC8ZrMknVV9Ew8AkCws2JoZvUpufzYmeeFofDwQOYqqs5VgCiaTulYxMIYQQQgixyXgysiLN5ILF2Ye01H+PyfLC26HQ6HahN16i0pAcMihnN1/mRNkjbNo9lP7QEXqo3+Ic/a1XuH7/OXPeN9pGYtY5qiv+zt5Ab6TIuohIsOxQAMtPXOz4A4d1nLFpdQBAQ3zyARJiIc3YxNllGXqwaJ/DMniP2119DE6/RqPbQ27FJUqzdwd+v3C4MzZWzh56N/UXf0DFs+0Ye02UrbBqsj8bE51Xqet4yrTNU6a2Ep9ynPNVF8hJUOfOKM3QbiiiZdJJ3LF6elYY8r1g+YmG+puYp1+5O7catPF7yC2+RGn28iwdlBlxEQmWHRpKZBmZCwNXqB2wYZsewWJV/bg020hMSSZOqyOn6hI5gX6XfkYoTythIHbl930neTLQIslqc1tNmfKY6jBibH3OYtwRmn7+Bn2IwruqOj6ade+ig1nLU7q7fsI0+CcOzTZSTnxFdclRkkIct1c0j0VloaOArNY/yWj4nRvZ6q3vvlXXvas5n3vYn1B+soIB21ZSSm7QZQx1zlt9HT9vvkpVax/T1tfucq9Bq91KXOIhcoynyMsI45xtn+R2/RXan73A5v47NdqtbNHFk5FxivyCI6TtCH4MHlE5lmUiq3slkCmEEEIIITYd1xAjB7k/mKkPa7lLEblx2kvvMKHbg16/j8zkZGIj730sM1qtx3hfG8Hw1HfMwEWSK38jpeoxXZEubCLerNGvSf/8V7TvaRDeG0R2/IWOoX+Et9Lwe2a0o5zbFh17sw6SmrGHvbGb5TfuoNtwmLrJyC8AvjOk7n17RVj3ytByIYQQQgix6SQVHCGe15jvj6s3iajZT2FLE9eqz3EyIzpBTJikf/g1xB/B8D4GMQGyT5GlCb2AhNicXKtehzGE9521G8OxneB4iins8bnvlzRjE9daLlGYe2ATBTFdmZ6myY2dymHTkbr3rRVp3SuBTCGEEEIIsfnsOMf5dA2OgTuY1dvE5mW+hcmmIaP43NuzSnXUHeJ83naYvEP7vHqb2Lye0H7/FZr0Lyh8fwsvO4xfkKF5TX/XE/UmsYnNd9zBwnbyiwKseP3ekLr37RR53SuBTCGEEEIIsQlpyak6Q7zzKdc7rOqNYlNy0N3xFGfiF1QHWRjhfZFUUUaW5gWdrSPqTWKTsvfcYtC5i/NVR1cxv9s7JOYo1QU7cQ5+L8Ggt8Y4bfdfoDl26f2czkNB6t63z2rqXglkCiGEEEKIzWnHlzQVbGe67TuG1NvE5jN8hYbJ7Rhq3+dsTI9D1FftgwffSjDorTBCXeNz4gr+EXZG0LtsR+k3GOL+5LoEg94K8x1XMTn2UV11QL3pPSR179tldXWvBDKFEEIIIcSmlVTRhCH2EVXVMlfm5jZOVfUjYgua3vuMII+Y3Cbq01/QUvmLzNe2yY1Wf81A7Blaw1hk4v2wm8rmM8Q++JoqmStzc7P/QkXrCzLqmjgZbjrbO07q3rfHauteCWQKIYQQQohNbDeVP9eTNFBC0YBDvVFsCg76i0voT6ynJ8LOyLtNS05bBwZbA3mNM+qNYpOwD1ykaGA3jT9/hcTgFZK+oqdhN/3nL9Iv0aBNaoaGTxpYKOjgxns+nYc/qXvfBmupeyWQKYQQQgghNreYo9y4fYb5agMNU+qN4k2bajRQZT1DV1v481u9P1yB+IT7RRKI34ymrpJX/RLD7WvkSOFdJib7Gl0FL6n65CpS9W42DvqLizDFywWkwKTu3dTWWPf+x9LS0pL6QSGEEEIIITad+V/47PPfONvbhH6LeqN4ExbN5Zzo+pCO9r/JvJih2MepPXsVbUsXZQnqjeKNWHzCxZN3yPzhBvlSeEOa7ynCOHyG+y2HkKp3c5htKeCi4yu6qvfLBaRQpO7dfKJQ90ogUwghhBBCCCGEEEIIsenJ0HIhhBBCCCGEEEIIIcSmJ4FMIYQQQgghhBBCCCHEpieBTCGEEEIIIYQQQgghxKYngUwhhBBCCCGEEEIIIcSmJ4FMIYQQQgghhBBCCCHEpieBTCGEEEIIIYQQQgghxKYngUwhhBBCCCGEEEIIIcSmJ4FMIYQQQgghhBBCCCHEpieBTCGEEEIIIYQQQgghxKYngUwhhBBCCCGEEEIIIcSmJ4FMIYQQQgghhBBCCCHEpieBTCGEEEIIIYQQQgghxKYngUwhhBBCCCGEEEIIIcSmJ4FMIYQQQgghhBBCCCHEpieBTCGEEEIIIYQQQgghxKYngUwhhBBCCCGEEEKINVlkovFrbi+oHxdCRNN/LC0tLakfXBX7DEN379E+8IRp62scDicAGu1WtHG70WefI//0AZJi1E8MZBG75Q96TN/Te99B5u0eKpPU+4iN5WCoOo/i+6/QJl+go/Mc8pUIIYQQ4v2wyLz5expu9DE8/Qp3Kxdt/B5yS2qo1MepnxDYwiS325rpfjDDnKetrNtFxokvqCw+xI4t6icEtmD5ieuN9xiYfoH7ZVyvk32OspKjJIT5OuL9sDj/hOtN32Ma/hObp7xod5Jy4gL1FYfYoX5CEPapPlrqb2KafOH9DegSD5BbVMZ5fRzBi90TLqZVMOh+7/Bsx9hroixB/bh4ny3OPqSh+gpWg5kb2eqtwS3OPqSl9Sb93t+ABm38brKNlyjN3U1YIQqA4cvsP//IXf6DSK5kuPNv4b+meD8sTHK7vpzuuGv8s2K3emtIq65757/lrx/fYk79eEgf0jhxjRz1w5vM2gOZCyM0V35Nx9grALTxB8nNO0V29m52YGVq4BHdPX0Mzr0GQJf6KfUNX5IZq3odgIWHXCy8wvDca0XlsB3DzyYJZL5pCzc5ffg7pgHQkH19iKYM9U5CCCGEEO+YxUmazxbTMR2866pNr2eg7WjIjutUhxFj63Mc6g0eml2U3u6iMFSbd3GS5sISOiYhpaCGxqJD7IgB7FbMN6qo6nqOg53k/dBBTZpW/Wzx3llkosWI8cc/gwdetB/S+K9r5IQqvDgwV+RR8uAVmsQzNDVfQL9jC9hn6K28SPWzFRIdzOXsL3sa/BgC0Z2i03yJverHxXtpcf4JLZW1dE66YgoZDb+HGcj0ld2gdEdo7f0GfcjfAICDbsNh6ibVjytpyGoe4ppe/bh4b9ln6K0pp27wJU4grqCTB2EHMtdW98635JH94wv1w6G9JYH4NQUyF8yXOV32CBuuxpexvYOylMDx4EXLtxQU3sLVBtxGdnMXTXqdejeXhZ8oONyMBSSQuWkor6TKdyKEEEKI98EMzTkGOqzbSC34ilLjfnYAjtkRbrdepcfdqQZIqXpMV17g4OFUSx55P74ANMQnHyAhFhzWSSze7E43zYc0Pg4WVJqhIcdApzX4e9lNRWTV/IGTPVT/u4P8gK8j3hdTLbnk/fgSXeoZKkvOkRYHOOYY6vyOxruKoPoKHdepxlzyul5C3Bl6+r9SdZgd9BbmUD3mRJNez+CygL4v+KOJ20NGYpD+n5t17CnTDtCeaONZ3X71ZvG+USVNeYQXyHTQX5pLxeBr0GwjMSWZOC3YZseZ8kucIkjZVpm6yrFP7rCg3Ro8Ay7uFB3dX4Z+HfF+WJyjt7qcxgcv/C5gRhLIXFvdO0mtvpAeG2gT95Eat7zN4ONgevgPrM7g7YvNZtWBTPvARbIqf3NVACEbXQr2hxQdrmLYnc6d0dDPjexAH5KvoSZBs40zNTpOXNr+oI2Yxdk+Glqfk2D8grMpoRshQgghhBBvu/mOArJ7dtPx8z9IW9ZAWsRcepgSz3jZxAsMdp9j2aCj+Zuc/vg7FtJr6Go7rhrGa2Oorojiu76MicAdErD3GMmofw6aI7SNfkOmaruLrw0tgaD33PxNTn98j6QfOqkPkJ27aC4n3ZsluYvSx10ULiu8yqG0ITLNFMMXE0t6uWtUTLUw/y1//fgRe4Mch79xqjKLMTm2kvuDmfo09XbxXpnvo3lwO/kn9rMjRhkfCDOQOXyZ/eefklDQSkeFqo+7OMft80Yax3wXo1YKMJlLMymxHJdMYbGyxXFut9lIMR5kb4zTG3AkjHLmtda611zO/koblb0d5K80f4j9Fwo+asDyFl0EXd1iP1NXyfMEMdGQ3RJGEBMg5ig3Wo6gAcDJcKWBhin1TuKNmLpKSc1T3OeGgLYkHKem5ZIEMYUQQgjxHnhCQ6eOxoBBTIAt6GvLSPH8d3qcUf8dADA3fc9sag33lwUxAXRkVvfQcWKb9xHnszsM2P12AhwMmJ677sbqlgdLvXaTEu+65xgbYVa9Wbw3zE0/EdsQPHi4RV9DZbLnf38yOua/3cVKc6N7PkDtEc4G6kgD7DjHWfdrTbc1Y1ZsmujoI6Yq+HH4Ge3D7AC0B8mVIKbYcZwyw37X9BmKui08rrIbW9DBXXUQE2BLPGfbTVR7fwNgvf9TwDocXIGe9kEnKcUXJIgpVrZlP2dLj7I3ZgugJWmFTPTl1lr3OujumCTnehhBTMD+4FfXaOjkv5C97MeyOa0ikDlDQ9kdX8AruYzqSOZKzLikOGm+pLPsKhLLfNNU36kQQgghxPtu+De2VHwT+mJ9TDIpngQIbaAA40O6B3dyvvb48o60Qlr5F76AKHNYXJOSK7xk1ua+u/AyvDabVksYoSPxThphSPMVjQFHvnloSUnZ7r6/ldhA/WzLLUzuVSI06UcJHlvUotfvct11PqW9xzeQMja3ibYwhylODIzgWPG9hAjD1B0GrEeoDpn5piW/5C++etLxgtllF5FcJlq/x6I9SOGJ8MqyEGsShbo3saIjzKx234XSRP2hkG2VzSTiQKa954o3pRs0ZBmDz6cSmJZ8w4e+/1rvUKf4wMVGc9BfbFR8p0IIIYQQgoxLNIUMBLktuv7RpB5c3tkYfool6wsKV8qIiDmEPtHzn9cseIKWXrtJ9ARMVZ0Vf+MMuxei0CXvCxBYFe+HA9Q0Lp+eYDlP4d2PflnhhdGeh661EICEpFABIYhN3u0NCFlMD/HEg3akJIdxHACTmAZfARr0uQfUG4WIyMKzcTQFF4JMwaGQdpQM13BRwMZswD7xE9rvvwLHU0o++ID9mdmcLrxC+/CMt5wLEU1rr3u17PVeZV2B/SGmSYBd5JwIdEVrc4owkGmjp8c9rAWAfeQES3MNJfs4yiROS889FhT/FxvFRm9xLhXPIlpDUAghhBBCAMw/ZMgGsIfK2kPqrZBxiYGGAI8voyPO23/YRkKAIZSZGe6sC8BSH3h6JvvATfodAHs4X6IYMynEMlb6h10LqKRU1LC8SzfHkHf+wK0kJa/QwU3cQ4Ln/uRThv23rszyK2YboDlATiSj/YQIILbgBl2l4QRydMR6r/hsJzHAuhzzLd+5F7x1cTpeMT12j5bzBjL26iloHJFYhoiija17vcPK4w+Q/RZd/YwskGl/glk51CVu9ypX5FJcVQaYfop5xcsZi8wOXOWzXD37935A8t4P2K8voLxzcoWKY5FZ02VO6/WkZ7pv+gIuNv5Eb+NFakN904tz9DeWc1rvec9M13NbnjDvvoC53CLzo300VBj5a1qet5E5b7rM6UzXcaeXPsRu+YnPcvUku/8Wz21/jpHaAdVl+IWH1BpyvX938t5sCjrdl9u9XJ/Pxfxs99+Z6Tre3CIaBuY811t97OPU5uZQ/cw3wTHWO+QpjqVoQPmEReyWEdrrjBxLU28LxMZE5xUKFN+X9/NrfMjssgNScrg+w9ICDik+QxZGaC7M833/uUU0jwbLSHBbnKO3ooBDnu8+U8+h/HIaOvtoKL7CkHp/IYQQQoiwOOivv8McOzH+HGxyfC0xQZe3DWY3KQEa2LHGr8j19mde0nm2gHZlMHOhj4rq33Cyjezm1iDHI4SLfeAKnXMQ/1lnkBVqZ5j2Zqdp0QbaRSlGOZXBCywBAu2hTA2MuDKQUo8ECKoKEaEt2jAzgRUCxjasmJ/5FmNb7jWWrhKy9JfDiGcIEY6NrXuHza5ExbiMowHm8d68IgtkTv7hP59l/G5f9Dci8ST5XWmeYVQdl/MzQ3v+YU5U3mFs7rV7kSFw2v5koKkwRMXhfl69A8Ptfp4NmV237i+JGWymuus3rEHiYPOmixz6wEjn4j5KW3p48LidxoI9aGx/MvhjBdmHi+ieVzzBPk57YR77935E9ue1dD54zpzTdaRTjblk1zxi2v1ejsErNC7+nR9N/XQc803uDh9S399BTbYq6h57lJpOE10F24Bt5P4wQJdBeZXd8/ncw1nQweCQmWdDQ0w+rifV9gedlfkcqxjxT32P2UNpez+D1/+C9910f6HtcT+D7ltjFjD/xB1Q/IiMsyW03H2OdYUEzkXLtxRk5mBonSSx+AaDE78zOfFvhm9fIpU/Geyq4sQH2RSZ1Ln7NvorCjiWedj1GQ7+ic39GS6YLpJ+uISOsRe+73/uDzo+z6FoIMiXOHWT05n51Dn+Ttdj93c/ZOZuyVbMTbV0PrMS5JlCCCGEECE4GK02UDG2m9LeTsqW934jNOObFzP9ODmqrS77qb/+Kd4mtPNPWj7R81nnDPPDVzmdU8vwln1U9Jpo0q/U8xHvM/vo1+RV/kFSSTd3S4MMW5x6rlgsKnCmmr94EhSB9ln3/G7hmcE0+BKAjNyj6o1CrKMZptxd0ris4wECmXGc7f6dyYnfGft3P/d/qMGQtWv5/MO2R5ScvMxQwJiEEBHY0Lr3IaZnANvRnwhyLtikIgpk2q0vvUEkgLhA417ClJDgmVwawIk1WESRRUZrjLQsHKC0oY37j90VSKoiAGh7RMkn3y5bNGi+42tapp2kVHzDyR2Ky+GxB6j/uVIxqbo/+8BFTtTMkNJsoqv672Sm6IiNTSan4gZPrrtXXXf8Qd3Zr30rm8Xsp7C9h/HHF/BOcQQs3L9I0dhBWnvbMCZ6JuDYTkICwBbSqpSTu79kShkcVZmdfQXJX1DhN4eNa47LlmknxJ2iNDcO718ae4hrVa75SG0PvqbFonzeFmJidcTqtL79t2iJjdV5bzFbXJ9VaUsXT4ZaCWeaKKaucuLsLSyOXRi7u6jJ3u2+GraFmJTjXDP3U5EM8IrhmpMca5xRPFlHTmMXD4Y6MXgzdheZ6ijgRCtU/PyYyYnfmZzop+2Ep/w4GW78jgnfi7hZaa/5jmnnHiobjuP39Wf8g56qPcqdhRBCCCHCYp/q46L+MMb7L8H5nJaTORQ0jq9trrSpPtewWraRawwRyEn6kn/+fAFvk5LXjDUZyD5/B0d2K4NDNzibEHEKqHhf2GfoLc0m4/NfseLE0ppPluEqo4EKr82mGPWm8fUXQlHstGBdNtFrcFN9mK0AH5Kbrd4oxDoaeMgYAHsoLAodyNkSoyMh7TiVLV08m3hMT+1BX0IQ7phEpW9+WCFWZSPr3oE+11D0uIPkrhgw3VwiCmRavcslRt/CrOsq3HKvmNXVMGxuojB7Pwmx7gqkfYCeAkUw1HpLtWiQjYGBPwHQaAJE4GL+RmGWtxXoM38TY+VvOJO/oD7Q1eyMc+R7gmy2X2lRT7Yee4A0bxDuJQPD8dzo/gp9wn7Kuh9z/3oNjbevUeiZfyDmbxQf8xzHC0wdwVJTn9A/FmBxJftDOj1zXDocyzMM4+NxHc4rhs0Rheddtmxx/S62HEC/4lRLI5Sfda1+rjt9ibKA6bo6zl73BZGtXeUB5njaTYo3Rv4Ky9xROszXOJnk+T50ZNbVkOv5r20Es++yhcvCI/qnATRoAowriMn7lEBfvxBCCCFEIAsDVyjIySTjk1oG/ZrEr7F0FZNdvPoO7ETPQ6yAJv0r1QXrAJLOcbe/hgxVM9V6/zIlLZPLpxMSwjNN1UcGqgdd82J6OCbvYPz4Iv3qwutw+CWwRMqxfMWqoKbuP8UKkHzQbx0FIdaXg+7O3wCIK7gU4XQcWpJym3jy7zZyFVPmOZ9dVSUPCRGhDax7+02u8q9LPxIgG3lziyiQ+WZsI78k8Kp7SRVtGBVJoZbOm/gSGm0suKN6YzeuLsvWBNDnHVyWFm5u+p5pICU38HvCbjKSfREw5ap8y20lt+orRaHYQkLGcXJS/IeOZ5ac8Q4Tst2/hdlvq4u95xaDW45wNtSkMZotrmzRIKzTyuzH6JtvucqAE2AbOXkhop4xf6P02Fb3f17SWf9LiM8Q0oznAvyw9pPhfYuXTCvnbgVYsLmDun/Q5pf16XGI/Cz1ty+EEEIIEVhs9iW6+oeY/Hc/g7dbKc3a7tfucjyrpSLYdDeh2B/Sdv8VaD6kviFY+9OffXaGhUXQaj3tKVwB1R8LOVbxJGS7SryH3NNUjU88ZvBxO20lB4nzK7y/UfXGMsms9A+7ElqC97+EWAdT39M+CcSdobUidDZmUDH7qf+5XrHy+SsGesb99xFiU3pC/xjAVjKzQ8RuNqmIApmxscrGUnTF+g01VwqVTBtHWbFr6DQAc38w7D0DKwKO1jvk6cvpVa8wk/ENTX7DF0boH3bFvy31h5ctxOO5FT9QxMjnnqOOofmEMTkrwI5znPWUHedT2tVZnjgYMD1Hd+wUyy7Sx/yNth8+JTvrFHW3L7FXvX3DzND5wDMRcuBJ6pXScg/4Gv+rWF1rRUkHSPF8/V0GDpX2LVtgKLPxmyBzUAkhhBBCBBGjIzblAIUtJsb/Veltb4CT4Y57KyxCudxQfS3DTg0Zdd+QE0YUZ6qjgKzP7+DI6+TZUD/3y/f5XZi3Paggaw3ZoeJdpiU2NplMYxMPRnupViRnOJ/dpEdZeLXakAkSK9HGrrDSrsf8PVyDxvaQeyycjpMQ0WClveYOVrZjbFYmHq1CzFEa6z70/l4c1mAjTYUIw0bVveZfGXYC2oPkLgsybX6RBTLj/D8Ua2QzifqZVQ0l14YV8Qsg/aBijkkrs4r1YzJLvvDNV2l7SvXJjwIGtLymRrC4Mwpzr/sWvQl56/0q6Fyb4dOSX+JbdMc/s9Q13P325E5yjYEj5TFpX9LUcomTfstMOZgauMpnZfdcQzXWnW+i5LAk71OcMGYiXl1rZQcoLd7l/Z9tsJYTH2Rz0RRgBXchhBBCiNXY8Te6lAsnTo/75k8Px+jXVD2AxJIOboQxGflUYy55rX9Cej09Fbtdo30MN3j2rxoyFM1057Mq8loCjUgRwiOO/M5Wcr3l5k9GXZMFuuh0eGbCWg11vzGYhQcjzAEkHkQfRiBfiGiw91TRMr2N7OZoLNYGMdnnyPFU4daZgKNBhQjLBtW9QwMjOAFN+tHlyXJvgYgCmf5BQ2BuRrGiUiTmmPKLge5Bn678fwRi4knwtvte+a/StOMcHT+c8q3uuFJAa27OHfR7xYLDt+hN6JtisZy1SPuCXM+BzvXRrphbY6Kjj7nkMxT6BSoDW5wf53ZFAYf0RbQvHKS+4ZR7jsx1NjWjCJg6l3+2ajHJ+EbYq763KNlhvEHH6Z2KR14xWJNPaqDsXCGEEEKI1Uj7ivPea80vwr84a39I0flf2VLQwV1jGMMahy9T0PUS2ImhSjUEd8dxbpg7KfWtAoT1xyt0S1qmCGk/FcW+BTBnLYrgd9IefNPdh1Ou5xQJJdsJb01YGyb3mgaJ2cfX1HkXImxTV8mrnyGjoYemQGtirMp+UpUr/gqxWhtS945gGnQCGvS5B9Qb3wqRBTJjDqFX/kBXfbVhhmll9t6arsAph29vRZ1JG5N2iX8+bsWQrBwW7w5o5V4JvEofMOsfad0AcRQaPA2JV5hNnkV/ntB+//XyRX7UFkZoMOhJ/fgyoxnf8MDcRZNhPzvWkpe8ai+ZDqdgRCUCHIqWtOoeBq+fIcVvzJUrO/evdWtcYVQIIYQQAi16vW8USHhmaPikitnsNndm5UocdLc9ci0AEHeAnIAXt3dT2N2BwXsF+zndd8Of9F+8n2KyDvpGsPnZTaK3LIWRAGBXLjq6c8VppgBY6HMvzrmLnBPhZREJsSb2hxSdvUdsVXdYWfCR2OLpd2vXllEn3ncbUPcO92F2ApqD5L6lK6xFFshER16e76od/EF/oJVpVmJ+5DfsJiXvVJR+7PGkBDoTxx6gstPM4O0yspTnyLl7GD9RLASk03nnGLKObXyQS7mStmfRH3vPLQa1xykMscjPguki6YdL6JzeQ93jAa7lxq9/jFDN78rBS6aCTxwawHYSA31vURKb8RVdQ/10lh/0Df0C5u4WkxdwISAhhBBCiPD5hnKF04mYoT3fSHd8PT11+0NfqPZ6zqinbRW/J8R8brupLD/onV9relQWnRAriN3u7YclpCiD6vFkpnoSQV5hmVTP4a9ifeGbGivM1ccX7j90rTUQf4Ds6HQGhQjO/oTyk1XM5nXQlRf9MYuL7mU0tIl7ohTbEO+n9a97h0xPXcPKM46Qqd74logwkAkxeRcUc6k4GewIveL0cg66O1wfHAC6v1Cat5arITYWPBNT+2V22ujvfOg34Xpsyt+5Zv4392s/9AW0rHdoGXDfT4j3DcOevEO730SVQUxdpShqwbBDFJ7Y5rrrfEp7zww9Pc+JP/Fp8EV8hi9zrOY3HEB8wSVOvrFacz9pimDk9NhKDWfF96Y7gN4XBY2OhYfcHlBmIejYa2jiye/d1KW7P2PA2vUt/Yq9hBBCCCEiZXe8dt1J3L/CXFMO+ouNXNfVMNgWyQrNDhyKtSZD0qumghIiFG82zy7SUv03peUd9faZ/IadB2CffI6n5R3e6uMOzGbXsPK4jKMETDIWImpmaPikAkt2Jw/CyoKP1Dhj0wAaMrL3qzcKEZH1rXvHGXjmalCkZR9Sb3xrRBzIhP3UXz+jCPh9T2Mks5qPXuW6Z9Q02zFc/8cKDb4VeBfo0ZBhVGZ22rB09QWYcH0LCbnXuF+7z3u12ls4Yg+Q5v3DXtBZ0xc6SGt/SNHn46QVRK8y3Gs87p3T09JaRPv0Lk76xggt09/pHmYE7EgKvt/605Gd7RtW5RgM9NkrLMww6z7wkIHa1Vp4TqcpQDB1Szwn23qoS/V8++HMOyGEEEIIEdyw+XmAtqiag/7iHKpsX9C1YhDTQX/F15i9o8riSfD0auaerzC1k8Y7MicuvMmyxPvs2VMsgCb9HHnqwpvyqXcOf8fwIyZUm30cDJieu+5qDlIYTpKK/SGumbS2oz8Rvb6UEMvN0JBjoD+5MYypPGZoKFUtvBsOyyOGHEDiF5SGkxInRCjrWfeO9mF2AHxIbrZ649tjFYFMIOkrumo/dAcCX2E6f5H+kBE/N/ek5q6IsYaM2g4qg4+NCctEz0PXIjPJZTQum+fiNzp7AqfixuSe8gZQ4xI9FdpuDHm+YJxzrJYTFU/8sjo9Fmf7KDpZxeyJf4S1CE/YdpzjrGfCeMdrHMmnljcqvGawKKbyDBitt74MePxesb7h9DiU8ytEbofxK1+2ruMR7QPBX22+s881lERzhMrSdQrAPrsTZJJ7LSfz9rnvbydxjWVQCCGEEO8ou42FgG0JhfmbtD8DTXpNgLaoh4PRagMVc6fo6j4XYmi4y1RLES3aU+i9cwXtJjvLPaLE+pBuxaKQy4yO4NosAaL3m4OFheBtcRcr7R2/geZD6hsCBdfjKKs44urz2Z7QEyxLYf4e3e5ElcTiMkLMiOVlf/Crq5zqDpC90g9CiFWz0m1wTeVxv/FQgDKu5MBcehFLxilvhvDi7Ai9pj6GpkL9lhz0tvZhYzuG2nOSXSyiYP3q3tH7T10xnzCHoW9WqwtkArG513jQfMSV8ur8jYqPi7gdYiXoxdmf+OzjKoadANvIbjZxwzdGPQQHQc/BU1epuPsKdEdovR54MRxLx/eBr1p7hlFoPiQ/y/fwDuM/FJOkg+1BBVlpuRTU3aTX1Edv51Uu5utJPVnLaGL9Cld1gn8ewWnJN3rmNtKssMjPblIUF9qtXeVUma0sAvaFSfrrjByqV2QlTo8wCizOP2HU86HE7ibBk5zoGOG2KzwPi5M0G8rpVkRBPfN+BKfM1nUyXH05cIDb3kdV1wtXRu7tb1Y9L8PKx/Oc9hsBgruKIWCa9FNh/eCFEEII8Z4Zvsz+j3LI+ugD0g1XGQp0ZXhxkobPv2M28ULILMupRgPG+zbi415yvbSciyFuBTmZ5P34Gn2edyl0APaWfEWGBuAVPZWKOd79OOi98QgHoDl2ac0JA+JtNUJ52mGyDh8mOdNIw3CgRZ8WmWgspmV2F6W3r5ETrPBmXKI+XeNKXqkJVO4c9Nd/757r8lPqjeEkKPiyiHRZf4n+yCzxTlq576fmoL84n7rprSTxiKoA9a3vVsTpzMOUDO7G4M1qG6Eqv4TqmlqKPzlMuuFqgIWCXRepqse2Y7jdLXWuCGIVcaF1qXsn6R92xUHCG4a+ea06kAkQq/+GJ54VwR1/0HjyI9LzL9NuGmFiwcbCwiRDppuU5+tJPdnMmAO0yWdoezxAkz5UEHM3BuM+d6bgawY+z+azxp8YsthYcL9uf52R9E/u4Ej+lM7+b4Kvem69Q0G+qvG5OMft881Y2E7u9W9UJ+7dVP7cRp5yJI7zJZa731FdU0t10x0Gp1+jO9bIg0ANVvskFu+K7K8w3w8cSAtJ/6krs1EXepEfgJwSxTB/XmIqO0nq3g/IOFxIg+NT7pq/Qe8JVNp+xbj3A1JP3mPB+6QD5HpWGOIVg2WH2Z+pZ39mCdOGGvK92aBPMCuu/lvMAYZt48rWffCvSlK1ngC3kQaz1T1E38G8+SqnD9cytmUPpT+bglT24wwrFguan1Iuce/hfzxTw4GPx9pl5HTjiF9W6uLsTxQ3Poe4v3Aj4NVnIYQQQggfx+Qdig/r+WvFT4zO2liYHae3sZy/Hi5nvqibZyGyLKda8sjregk4mRt7yuBg6JvF6oT4IxjULxhzlBv9jWTrXO3bPH05t0ddF7AB7PNPaDDkUj3mRHeskcHGA6oXEO8lx3M6z+eQnnuZ26NzLCzMMWq6ysXcHEqsX3B/qItCdVnzoyWnrZ/WY9u8/SrzvLvU2WfoLc6j4pkTTeIFekxfBv0d+PEOK99KZrZ/wF6IgOx9mMLo+/k46C/OpeKZE5yvsDxbXtf63/5g2gGarFPkeF9jK1pFkr1j8g7Gj7K52DHCxMIkQ51X+UyfQ8nsQdoe91CZsuHL7Yq3wgymwVfe/1ktk6GnL/Rah7rX8itmG8Aeco8FG0HydviPpaWlJfWDq2KfYejuPdoHnjBtfY3DPSO5RrsVbdxu9NnnyD99gKRIokaLVkZ7bnH9/hOmZ195JznXaLeRkHqUwqIvyEkK9gXM0JB/BQpOETc9wsDwOPMOJ073fJpx6eeorvg7e4MO23YwZfqOuo6HTM29ds1DqdlKfMpxzlddICdBVVFZfuKz+ptYpl/5FjJy08TtISNxNzlVl8gJ+n7+5jsKKKGJu2FE1hdn+6iq/Bbz9CucaNAlHqS0oYaT7mO0D5STXelKIdYmn6H1+lek+X0PVnpLS6gbfLH8+ZafuNjxiOnh51hVf5gmbg8Z6WeoqT4aYD6oAJ8fGrTxu8nOK+O8ITnAc2z0112m/YHrRKKkTdxHtvEbarKhv+4y1x/8wVzQfXQwdZXT9WDI28708COGxqw4nE7397idDOMlKgMegxBCCCGEy7z5KlWtfa62rbsNqdVuJS7xEDnGU+Rl7A55QdQ+cJGsyt+WtQ1XklL1mK6gc1252lgNXU/82p3e9nFJgHaqeP/MP6Gh5jtM0y+j0y8DFiw/0VB/093nwN2230Nu8SVKs+O9c7OuxN5jJKP+OWj/QsfQGtdLEO+wSW6X3mLUYWVs7M9lU6Bp4veQkaCD1E+5ZvAPiE+15JL340u/x1a2jbzbA9QoV0tbnKO/9TvaB8aZtfliAtq4eDIyTpFfcIS0HeGWfPH+sNFfd4V+my1wHEW3i5SUOLS6I0FiKf6iVfdO1GVjuPsKkisZ7gw18nfzi14gUwghhBBCCCGEEEIIIdbJmoaWCyGEEEIIIYQQQgghxEaQQKYQQgghhBBCCCGEEGLTk0CmEEIIIYQQQgghhBBi05NAphBCCCGEEEIIIYQQYtOTQKYQQgghhBBCCCGEEGLTk0CmEEIIIYQQQgghhBBi05NAphBCCCGEEEIIIYQQYtOTQKYQQgghhBBCCCGEEGLTk0CmEEIIIYQQQgghhBBi05NAphBCCCGEEEIIIYQQYtOTQKYQQgghhBBCCCGEEGLTk0CmEEIIIYQQQgghhBBi05NAphBCCCGEEEIIIYQQYtOTQKYQQgghhBBCCCGEEGLTk0CmEEIIIYQQQgghhBBi0/uPpaWlJfWDQgghhBBCvKvsU3201N/ENPkCJwAadIkHyC0q47w+ji3qJ6zKIrMD39Hc8ZDh6Veu99FsJT7xKIVVFziZpFU/ITD7DL2tV2h/MMOcw3W0aLaRmHWO6qq/szdG/YTITDXmktf1koyG37mRrd4qNp1FK+a2Zq7fH2Ha5ikPO0k5cY7qkuMkrbE8eC1McrutmW5FudPodpFx4gsqiw+xY00/khkacgx0Wj+kceIaOerNIS0yO9BMVb0Vw1CkzxVvloMp03fUdfRhmVPUZRnHOV/+Bfq1FaqgFmcf0lB9BavBHFEdtzj7kJbWm/QP/4n3p6bbhd54iUpDMrHqJwQUpfOAeOMW559wvel7TMryEL+HXOMlSnN3E62qd3m506CN3012hO8TjXZOtI5lPUggUwghhBBCvCccmCvyKHnwCk3iGZqaL7g6z/YZeisvUv3sFdrkC3R0niNJ/dRI2J9QfrKCAZt6g4/uWCP3Gw+F7AgsmC9zuuwRwV9mJ8afeyhb7cFOXeXYJ3ewggQy3wZTNyn4/Dssjm1k1F6jMXc3MSwyb/6Okso7TDu3kd3cQ5N+bcGRqQ4jxtbnONQbPDS7KL3dReEqy50neA6RBDJdf2dFzR0sDiJ8rnjjvHWihsSCelpLXMFw+1QfFedrGbZtJaXkBl3G3epnrtri/BNaKmvpnHwNEdVxDkbrjBjvvkCbWkZH899dFwjsM/TWXKR68BVo91H98w3yd6ifqxCl84B487x1ou5D6q5/4wpAL1oxt5ZT3vUnTt0RWnu/Qb+mL9LXPgkqrPeJRjsnWseyfiSQKYQQQggh3gveAErcGXr6v1I14h30FuZQPeZEk17PYNvR1XUu7Q+5+HEVgw5X9k5KShxabMyOKTIq3eIKOnlQEbjjbh+4SFblb2yJP0Jx1RfkJGgBK1P3b1HV+tQX3NSdotN8ib3+Tw+DJyvO9b/wO/nijbA/pOhwFcNODam1/fyYqwpWeoPS2zH8bKIyeA81pKmWPPJ+fAFoiE8+QEIsOKyTWDzZZB6aD2l8fI2cSH8kiuB5uMHIheFvKa++xZhfQCi854rNwFfXBKzz7H18driWMaeGjIZ+bmSvLRDPwgjNlV/TMeYfhAm3jvOeJ5IrGe7827LzgC8QH+JCUpTOA+LN85yLnZp91D2+wUlVgQjdrgiXg/7SXCoGX7uylFOSidOCbXacqbnX/nXvCu8T+njCaedE71jWk8yRKYQQQggh3n3DlynoegloyCoP1PDWcrL2DPGA81kVxg53hC9CQ/W1DC7uwvDDY8bNXfzY0sS1lg7+OTTEWG8ZqYo+urWrnIYp5bM9Rqir/oOkql6emb7hbFo8sbE6YmOTyTQ28aT3UxI9u9r66Bz2f3Y4RqsveoOYYrOz0v55FcNOIP4M9eogJkDSV1RmaYCXdJ69zJB6ezjmb1L14wt06TUMTAzxz84mrrU08WP3AOMT/bSd3unb1/kbVZUPsSufv6Jxqs57gpjhmTd9S7/mFK3m35n8+Qxx6h3EpjdUYXTVNZqDVAYK2MUcp75gJ+BkuLKI9nn1DhGY76N5QEN+8wCTE50YIi0wo19T1PUS2EpuyfIgJkBSRQ25OoAXdJR9S6AqPDrnAfHGzd/EWPkbTiC+oGZZEBMgqaKMLA1gvUNBxYh6c3iGr1A16CSxoI3h0QHutrvq3i6TmfHfu6lI3erb13qHksYZ5bN9otHOidaxrDMJZAohhBBCiHeclebGR65MAu0RzurV2912nONssuvudFszZvX2lcx/S8MDHYbbXVSmLQ82bUn4Oz/+q5IU7yMvMXWN++0DMN/yLZa8DrrygvTCE76k+vQ293+cWIYj7EgMX6bo/haMBR+qt4jNyNzM9WnX3RTDOYKNZtUXHEEL4HxEQ0uADuoKzE3fM5taw/224wHeQ0dmdQ8dJzzlDpzP7jAQQSRzqKIE05ZPMaSrtwS3I/dLzqbFuQJKSXtIUO8gNrf5b2l44Mrh0mafIWjVazzjrhf/5HrTE/Xm8O04TplhPztiAHaTEq/eIRQH3a2/urLdNQfITlNv99hP8Ql3UN96i7oe1SQMUToPiDfP3PQ9rqp3D2eNQc7HHOJstiu453xwleaIA/Gu9klsQQd3K/YvD55viedsu4lqd9sEwHr/J0aV+7gejUI7J1rHsv4kkCmEEEIIId5tlluY5lx3NelHCdo/RYtev8t11/mUdnUHdQVTXY+wHrsUelhvzN8oPeHLaHDMzqmy2qyYrQdoDZS5pLA3zbc9NmG737bQRigvfURCSRtlvp602LQcdHc8dQ/n24U+a3lgxCvtKBka1925+7eYUG8P6SHdgzs5X3t8eedVIa38C0UAZg6LO8C6ouHLlDzYSekPXyqeL951Ex19uKpeDRnZ+9WbfWIOoXenmTsHb9EdQYA8auwPMU267yfsDpDN5rMjY4/rogFg6bnHgmJbdM4D4o2z/0L7oHsgdeLBkHNBpmUfwFX1vsDU4SlEYZq6w4D1CNUhz/la8kv+4i1zOF4wqy4w0WjnROtYNoAEMoUQQgghxDtttOehd07JhKRQDXSITd7t66CaIhk6a2N4TIOh5IB6wzK+Tg9ge6EaahvH2cYvQ3aiAVj0zFS1k9T0EMEtPw76i8sZSKykI2h2idhUlMEVTTyJIZdK3kOaZ84B20N6IkmTGX6KJesLCpenYvpTBJzgNQshFjLxsj+kqPQRSVU3Vn598Q4Zp8e7WMhOkrzlJhAdKYmewN5zTA8iu4gUFc+eYvHc120PvSp52n7f9B7TTzF7TxTROg+IN83+4FdvedDE7w5dHpL3ec/Ztgf3IspQXHg2jqbgApnqDWqKC1VgY1ZVYKLRzonWsWwECWQKIYQQQoh32BxDY65Va2ErSck61XaVRMXw1cmnhD/9pA7DDx2UhROo0el8naK40Jk/wZgHnwOgO3EpvPcE7AOXqRrbQ931wHO/iU1IGVxJ3LdCNqOWhARPMOg1o8Pu9JxwZFxioOGQ+tEAdMR5f0LbSFhx6K6D/spaRlNqaMsLN+Au3gmzI4x64pHa3aSEjARBomIcuMW8yrkG12B26oX6oRB0xHoDOTOMepPwNvY8INbPsNl1jgVIStvjt22ZmHgSPNWb4w+GZlXbQ4gtuEFXaTgXFnXEegvMdhL9Ckx02jnROZaNIYFMIYQQQgjxDpth2pstoEW7UiwlRusbMsULLBEswrAlZqUXXy4uMXTmREBTV2kYdKJNr+d+XYjhmkr2h1RU/0FaXVPABQvE5jRlUQRXtNoVA9BaRQG3Tkcyd6qWmC3qx1aym5QVOrCu4Pk+6ptDD1kX76DpGV+WoVZZrwYWo1UsIjL3POAiOuvJm+QO4HCskI2vDOQ4sVp9GaQbdh4Q62gGi+I6kLJeDUzZtnjJdLhTbgBsWbleX2ZZ4DtK7ZyoHMvGkECmEEIIIYR4d009x5ccEU7mQDwJ3mSGl8xGkNQWNm8Hfzv6ExF2YOd/oeDsHRaPtTLQdjTMToc7Ky61hsbslXo4YjOZnX3pva9bOf2RpETFfKnrEgya8c2LmX6cHNVWP97g+TfkhFdQxTvELwgfTrAjPh5v1WudU9TbGyM2Vrkac2RDvRcUv9OwreU8INbZnGK4dDiZ57tJVCQyzloiuYgUrhmm3McUl3Xc//e04e2cEMeyQVYVyJzqMHIoU096WibHCn9iYlGxcXGO3ooCjumzSc/Usz8tk0OGqwwpZ8AVQgghhBBiI9hsioUYNISVdKbYacEaziSAkekf+MN1J/lTisPtASxaMTcaSf+4AYsTbA9KyNCX0xvGCql2U7krK64h3MCn2BxsKItfeGXXO94VFpRlP0qm+jDbALaRazyq3qrgoLdMgufvswXlBKoaRbkMwVfGbVijXnhDU84biG2c4XV+/1WdB8TGWHipqDvDqnn9q96wJg+O0MBDxgDYQ2GRKvC90e2cUMeyQSIPZA5fxmg+wt0hM896z6AZa8Zw9ibzgH30Cn/NqWU6u4n75gGeDZkZH6onZfoOxTkX6Q+dny2EEEIIIUR0ORzuFZ9XxxHtDon9FzqfAWzHUBXGXJWLk9wuLSD9g5OUdD3HbwkM21OqP86jOVTanf0Ximueo2+5Jllxbx0bC2tZ88Tp8C8vUTDR8xAroEn/iorgy+Ji7ymh2nKQ1rCzhsW7xuFYS837moV1DiQuk3aQVG8w6k96O8PPyYxNUGRChyPS84DYWAu2NdWdTsdanh2Ig+7O3wCIK7hEvrrAbGg7Z4Vj2SARBjIddLeNk13xd9fEtDt2swNg+h6dA1cpqNfQZO6gUh/nC/BuOcTZ7K3g/I32u5F8QEIIIYQQQrxbpm7cwgLEFTRRGU4WzpZkzrZ08Wzi3ww/7qaj9hQpfgluL+gouxpkCLGD7vMNTB1roilDvU2ICNkf0nb/FWg+DJ3da/+F4voZslu+WXn1WyE2jUOcz/MFJOd+rKI7WCLWVB9mRZxz5TkU/UV8HhDvt6nvaZ8E4s7QWvFmMiC9NsmxRBbIXLhHt+0o+Z7l8uyeq3wv6aye4/ztrwKOj/f8sKdHx9WbhBBCCCGEWD9aLeENagxMG7vC6p+RmL9JVddLiPt0FR2ALcTExpOWe4muocd0nFBkAFnv0R5gefX5jiLqrH/hRuMB9SbxVtARG1l8xJ9m5QVWIjFUX8uwU0NGyDkvrbR/3sD8iVYJnr/ntNq11LxbFYvpbJykiiYM3rkOn1N3uIAGs9W78I99fpzbFXmkf35PMZR3D/p0739WtqbzgNgQsbo11Z2aCAPboVlpr7mDle0YmwPH2zaunRPGsWyQiAKZ9sGnWFMP+g548g/31d/QJ7R1mSNACCGEEEKIleh0rpFEqxQbF24DfyUOuiu/Y1p3hNafv1xjB0BLWl0n1cme/zuxDKsWF5j6FmPrawzX/0GIEcBiU9OxpuIXu7ay72f0a6oeQGJJBzdCzHk51VJMi+MMN+r2qzeJ90xs2MGRQHTERa3wRmI3lb3tGJPdC/84/6Sz7CQZez8gee8HZHxcQqfzHF3XT/l+W3F7SAkSB1kumucBsW5it6+p7lxb2fdn76miZXob2c2dlAUrMBvUzgnrWDZIRIFMy6iVjGzfSWlqeNw1Fl93itKgJ7Q5RiddI/bjEuWKgxBCCCGE2EBJe0jw/ucFlsBjsBWUq5VuD2O10vBMNRqom/6Qxt5v0Ifd6Q1FS37FKe8qv1a/ZUdnaC67BTJs8a2XoJh7z/87Dsxvpej4PdEJlNgfUnT+V7YUdHDXGKI/N/UtJT+C4Q1n6ojNISllp+8/c8+DTH+hMDfnWyk8Ll5Rb2+wLcmUdZoZ+1cbjeVnyM46SNbpC9Q1tDHw+xAPWo5jN7nmigWIP3Ym7PIe/fOAWB/xJHgzc8NZ1XsGi2KfhJQQ9WQkpq6SVz9DRkMPTfpg8bYNaueEeywbJKJAZmbjgGKIgI3hsVcAaFIPBP/x2scZswJoSEkL5xMSQgghhBAiWnaT6O2QLPpvCsQ7dRLATlKCNnLDZx+4SEGPjureKC+4k3KQtEDjyab6GLCCtctAsjuTKOCt0jVhP8BwpeLxnGBzboqN5hcMcq68nINDschEdJJIZmj4pIrZ7DZ6VhgGO3X/EVZe0vlJgLKmuFU88zzjNyoUjx9rVGUVi7db4m4iq3pf+/4TrSD8GmzZsZ8cw1c0tTRxrfocJ7P3s2MLwBPa77viILCHs0bvXxnSup0HxDrYTYoidLW4Yvl14Kt6t5OY6L91VewPKTp7j9iq7pBZ8C7r3M6J6Fg2RkSBTH/jjE677iWl7VFv9PEOP99DhsyTIoQQQgghNlQ8manuYYK8wjK5wmqi1hfMe+4nH2StzVe7+TInKl+Qf7uD/B3qrWul884jFxdWSoV466QfxLM8AdPjjPpvXWbe6gkGbSUtY61lYob2fCPd8fX01O0PvriPEIEkHCDNE/OwPccSbOEcN6svRYwU/ead13e+43sG3dcUdCcuhLVq8/qeB8R6yND7YlzTYyut9fKSeU/TQruPzLWmE9ufUH6yitm8DrrywgmUr2M7J+Jj2RirD2SOjmABYBf6rOBRWe/w88QDsmqdEEIIIYTYcGl5R71DsGctobO+7JPP8czunpIbYmXmcExdJa/sOTk/m9ZpiLcnC0RDSoYiWy7pC7oe9zO40q18n/cpqeWKx29/8cazoYRbzFFyPXOhOl4wGzIYNM6YO9EE3VHy1jQ5qoP+YiPXdTUMtoX3O0gq6lhexgLcKlI9z9hHheLxrqLQGZ/ibbOfvGPb3PfnsHjKZkAOLBZflmPuseDxhTfK/gsVrX+67muOUB/OXLDrfh4Q6yHm2F+8F5Ecs3PeBZ8CGh3HW/UeO7XGealnaPikAkt2Jw9WyIJXWp92zuqOZSOsOpA5O/yHKx1Vu5uUoDOL+oafaxP3rGkCUiGEEEIIIVYl5VNy3clpjuFHTKi3ezkYMD133dUcpDBvDZ3pqasc++QhKc2dK3dep65yscOXjRS2qaeMOoC4UxT6pVRoiY3VhXHzjUvf4vf4Gv5uEWVa8o0H3SvSPsf0IESmjeURQ+7N8Sc+Za96e9gc9BfnUGX7gq4Vg5gO+iu+xrwIxKjLV5Cbt9hp/B8P/UbiLbTXeBxX1fuaoYFJ9WYf+0NM7s2arE/DynLceDM0fNLgTubajuH2Nysnam3EeUCsj5i/UZjlrqwmf2UgRCRzYmDEPVR7J7lG7yp8qzBDQ46B/uTGFafygBkaSm/6Miuj3s5Zw7FsgFUGMh2Mjr103U0+ECLi7Bt+npIRxtUKIYQQQgghoi6OsoojrmCQ7Qk9wcbnzt+j292ZTiwuQ6/e7h4i+NdMPX8t/Cn4PJLzv1Bw9h4J4UyKb3/CxfPPyTytHLK1iH3BseJMV0Md97CyXRZXedfpyzjvnnPNYnoYNDNoqLPPlWWjOUJlaaAhgDO0G7JJ1xdQaw4WEHUwWm2gYu4UXd3nVixXUy1FtGhPod+i3iIEsONLKo+5gkG2wXtBp0aYv3vPO9rzfPkh9WbAgbkij/TMPD7rDJ1ttj6sdBuMdFoBXKs2rxiYXPN5QLxp+vIvcFW9oS4ijdDpnjNVc+wrygJNHTB1kwK9nkP5VzAHq8DdZaw7vp77jYdWvIBkLr2IJeMUvreLXjtn7cey/v5jaWlpSf3gyh5StLeKYSCl6jFdwaK4o1+T/vmvONhF6eMuCiUlUwghhBBCvBGuLLOKZ06IO0NPvzr4p9ge/yk9pi+XB3Hsv1DwkScjB3Sn23lSrcq+sD+k6HAVo9o9pKXo3Jl0QTisjI39iSO9nsm2o+4HbdzOz6FxGtBsJ6uqlabceNRxogXTRY7VzKBvDqOTHMzARe+CPxkNv3MjW72D2DSmvuXYJ7ewoiGjoX/5ggtTVzn2yR2sbCWrwcQ19XZgoi4bw13f8N3qf3csy3ybaswlr8tGfOoBEpa/hB/b9AgWqw5DhENm+4s9C/58SOPENXLUOwTVx2d7axmDVTxXvDHuOnHYCXEFAYaoKrbHf9bJP0uXZ3/Ze4xk1LuzyNhG3u0BaryTxwbXW/gB1a4Cs/o6zj5O7dlieuYAzS6M7R2UpahrZJU1nwfEZjHVkkvejy9B8yGNj5cv1OSqM1+C9iCN/2path0mqdUX0uMZy51cyXDn31TBQXf7Y2wrKanJ6EIWLwfWsT+YdgSqA6PQzonasayv1QUyvQHK7SFPXLMtuZz48SXoztBjVn+IQgghhBBCbCRXVk/Jg1doEs/Q1HwB/Y4tYJ+ht/Ii1c9eoUm8EDwTbeEmpw9/550LS3OslfFGxaIU9ocUfVzFcLDEjYA0ZDUPcc2bFmGjPT+HFuV8crp9GCouUJgax/x0H6bWnxjQHKWx5Ssy15IoIIHMt8vUTU6f/Y5p5zYyaq/RmLubGBaZN39HSeUdpp3byA4R2B6qyKT4gWfl8+WJJlMteeT9+ML3QDjiP2XA9GVEmTirDWTaTUVk1fzhWn+BbeT+MEB98KGBYjOxP6H8ZAUDNg2JBfW0lhxixxawT/VRcb6WYZuGxJIO7hqXBzEBFjoKyPLMTYmG7OtDNIVcoQSw9/HZ4VrGvAvztPEknDktvRxMmWopqnmKDdBl1fBjw3ESQgZ2onUeEJvJVEcBBa1/4tR9SN31bziZpIVFK+bWcsq7/sSpO0Jr7zfolwUxAUYoTythwFP1Jl5gsPucYtpFB/3FuVQ88yzUFh5NViPjLcGzl1fXzon2sayfVQUyvRWJ5ghto8HmhnDQbThM3WSARp4QQgghhBBvyILlJxrqb2KefuUOimjQxu8ht/gSpdnLsx+VpjqMGFufsxh3hKaflR2XGZpzDEQ8xZnuFJ3mS/7zGdonuV1/hfZnL7A53Eeo3coWXTwZGafILzhC2o5QRxkmCWS+fRbn6G+9wvX7z5lzlw0020jMOkd1xd/ZGyqw7Q0mbSWl5AZdiqCRfeAiWZW/uX8P4Qs5Oi+IiAKZlp+42PEHDus4Y9PqzrWG+OQDJMRCmrGJs2Fk6Ik3ycZE51XqOp4ybfOU3a3EpxznfNUFckJGCGdoNxTRMukk7lg9PUGHu05yu/QWo54sR9VWTfweMhJ0kPop1wyB5jJ0sGB5jsn0Pd33n2N1aojPukBN+akw69wongfEprI4+5CW+u8xWV7grXp1u9AbL1FpSA65HozdfJkTZY+wafdQ+kMHhYoIojfjMyIrZyWvpp2zXseyHlYVyPSmaKfWMNl+XL3ZzRd5Xs0JTgghhBBCCCGEEGIjzA98TcOAkx2pB9FnHCAlQRsw4COEeLNWsdjPDNPuKwyJWSGyLKdGGHUCbCc1VYKYQgghhBBCCCGE2Jx2ZP+Day3fUGk4SpoEMYXYtFYRyNxNcUMNFbXtdBh06o1eC8/GXavmafeRmaDeKoQQQgghhBBCCCGEEOFbRSATYlKOczY3Oci8FC6jo+7JeJMPIHMwCyGEEEIIIYQQQggh1mJVgcyVjTM86bqXmBbJymBCCCGEEEIIIYQQQgix3PoEMmdHGHUAbCMtPfjwcyGEEEIIIYQQQgghhAjHugQy7WN/YAXQ7CdDsbS8EEIIIYQQQgghhBBCrMa6BDItozOuO4n7SFFvFEIIIYQQQgghhBBCiAitQyBzhuExJwBxqftDLggkhBBCCCGEEEIIIYQQ4ViHQOZW4mIB7YeUGuPVG4UQQgghhBBCCCGEECJi/7G0tLSkflAIIYQQQgghhBBCCCE2k3XIyBRCCCGEEEIIIYQQQojokkCmEEIIIYQQQgghhBBi05NAphBCCCGEEEIIIYQQYtOTQKYQQgghhBBCCCGE1yITjV9ze0H9uBDiTVvbYj+LVsxtzVy/P86s7TVOQKPdSdKx4xTnniItRcsWxinPvIl+6Bo5iqdOdBqpujHDnMOpeHQ1PqRxwv+1hRBCCCHE+2lx/gnXm77HNPwnNnczUxO/h1zjJUpzdxOjfsJqedvBI0x732gnKSfOUV1ynKSw3sjBlOk76joeMjXnakuDBl3iQQqrLnE2Rat+QmD2GXpbr9D+QNG21mwjMesc1VV/Z29YxxLMDA05Bjqt0uZef57y0IdlTvE9ZhznfPkX6HdsUT9h1exTfbTU38Q0+UJR7g6QW1TGeX0c4bxTwN+adicpJy5QX3GIHeonRGLRwcTYPUw9Txkds+LQaEkw1vCjIVm9Z0hTjbnkdb0ko+F3bmSrt4poikaZCkfAcreaOn74MvvPP3IfaxDJlQx3/i3oay5YfuJ64z0Gpl/gqno1aOP3kFt8idLs+LX9zfaHFB2uYjj2DD39X5Gk3i6iJyrn83CsZx3vYH70KZ09fYyOzbCAltiMMm7UHSJWvWsIi/ZJRu/+Srd5nDGrA402nsK6G5xNUe8Zyvq3G1YdyFy0fEtB4S2mnYB2F1knjqNP1GKz9NH/4A+mHbh+yBonDud2DD+bqAzw61u0XOHE2XtYvY9sJ7v8CzJCtNtslnt033+O1YkEMoUQQgghBABTHUaMrc9x6D6k7vo3nEzSujooreWUd/2JU3eE1t5v0K+1UzJ1k4LPv8Pi2EZG7TUac3cTwyLz5u8oqbzDtHMb2c09NOlDNGgXnlCeX8GATb3BJ/6zTv5Zulv9sJ8F82VOlz0i+MvsxPhzD2UB2uHh8ASCpM29zuxPKD9ZwYBNQ2JBPa0lh9ixxRUcqjhfy7BtKyklN+gyhi4PK3Ngrsij5MErNIlnaGq+4Oo822forbxI9bNXaJMv0NF5LkTgZJGJFiPGH/8MHgTSfkjjv66RE+FvbXH+Cddrmukce4lTs52skhoq8/azqv791FWOfXIHK0ggc11Fo0yFJ3p1vINuw2HqJtWPK2nIah7iml79OICV7kIDdWOviT/dyI0K1+91cf4JLZW1dE6+hvhTdNy+RNqKxxKIg/7iHCqeOSFOApnrKhrn83CsVx1vn6G3/msaH/yJg62knL5EdcnRCIOvi8ybv6eq6Q5jVieauIOU1paRn7a6CxAb0m5YWo3/9f8sHU1JW9qTkra0r+ifS/+p3r60tPSfQ//30nH3PntSji1d+V/qPTxml65me/ZLW9qT/d+Xgu7qZ3rpSnba0p6U/7r0L/UmIYQQQgjxXvk//f91aV9K2tKe1P+y9D/+j3rr0tL/ajgRYVsziP/zYOm/pKYt7UnJWPq/eu3qrUtL/+u/u9vJJ4K3fz2vkXF66b/dHlv63/+5sPSf/7mw9D+H/n9L/zVL0S5OObb09YT6yT6ev/nAif/v0q3fZ5f+8z8Xlv7zPy1L/27/b0sHva+RtrQn6/9e+p/qJ4fD+7dIm3t9efo1aUtHG6bVG5eW/s8/l/4vd5n7L/0BylwEQv8O7Ev/w5jh7uM9WArwM1paWlpa+l/Nrtc4aPzvS/+acJXd//zfY0v/o/azpQPKcldwN+hrLLew9Lj8mPu5GUt/a3gWsI8ZPt9nuiclbem/9Ku3i2iJRpkKR1TreHfdti8ja+lAsFve/xPkdexL/ypy/U0Hq8bUG/2278n4r0v/CnCsK/k/vf/F9beG+/eI1YnG+Tws61HH/79L/7PZV+ceLPrn0v/+f9X7hOE/B5f+m6fdkfr/WboytKDeIzIb1G5YxRyZDrrrb7kzKPdQ2XA8YKpqbMYl/vmvCyQC8IrZOfUeHvEkxasfC8duKssPolE/LIQQQggh3i/zNzFW/oYTiC+o4WSATISkijKyNID1DgUVI+rNYbLS/nkVw04g/gz1uQEyNJK+ojJLA7yk8+xlhtTbgaH6WkYTKxkY6qHJsJ+EWB2xsTr2Zpzjmrkbo6sBDbzC1BnsWEeoq/6DpKpenpm+4WxaPLGxOmJjk8k0NvGk91N3Oxyw9dE57P/slY1Tdd6VzSbW11CFkU4roDlIZUWAbJyY49QX7AScDFcW0T6v3iFMw5cp6HrpyjQrD5ThpeVk7RniAeezKowdAb79+ZtU/Qi5PzzmSftX5KS4ym5swn5OVncw2Kzon03eoyec+QUXnlCuz6HkwStgO7k/9HO34kDAPma4Rqsvuj5Tsb6iUabCEeU63nzjHlbdKTqGzDwLduv+MsDfA/aeElemJHs4X75fvRnQktNQRgqA4zeqKh9iV+8Siv0Ximv+CJ7tLKIkOufzcES9jl+cpDn/MIYfn+NAQ0pVL0/ajpMQYfrkgvkyhw67R4bE/YWOx11UZujUu0Vg49oNqwhkjmD2pGDH7SElQCXiteMcHbX70AAL1uADXlZNf4Q09WNCCCGEEOK9Ym76nmkA9nDWGKfe7HaIs9lbAXA+uErzSh2FQMzNXHe9ESmGc0HnANQXHEEL4HxEQ4uqST//LS2Tp+jq/FuQ58dTVnUKT1fCOTnClGoPgPmWb7HkddCVF+TvTfiS6tPb3P9xYhmeUe0Q2lBFCaYtn2JIV28RUTX/LQ0PXCELbfYZAo5iBXYYz7gCI/zJ9aYn6s1hsNLc6J4PUHuEs0Hf6Bxn3dNQTrc1Y1ZtNjf9RGxDJ/VpATr9wBZ9DZXeaSz/ZHTMf/sy879QkOOZYsE1HVmw1w7b8GWK7m/BWPCheouIquiUqXBEtY63/0L7oJOU4gvsVW9b0SQtbc9ddxMPBh/CHvM3CrNcIX3ns6u0WNQ7BGOl/fMGptI/JTfYnymiIxrn83BEu463j1N1spCOaSegIaOhP3g7IIT5HiPHPNPSxJ2hp/8fq5wGwWcj2w2RBzKnnjPrub9gY6WLbDG5NRjiwbGwDoFMDlDafM79hQshhBBCiPeOu1MKK3QsgbTsA+5ssReYOkJOjhaAg+6Op+4smV3os0IEW9KOkuFOS5u7f4sJxab5wZdkNAfKXFJI2efbrtvJ8i6KFbP1AK2BMjsU9qb5tscmbPfbFtLwZUoe7KT0hy+lnb3OJjr6cA1c05CRHSi7yy3mEHp3iq1z8BbdEaV4AZZbmNwj5DTpR0Mkg2jR63e57jqf0t7jUGwbYUjzFY3ZIco+WlJSPGVtK7GhknvsDyk62YDFibtD3hlwTYXIjFBe+oiEkjbKpPCur6iUqTBEuY6faP0ei/YghSdCleMgRu955zXWxO8OmTWcmuGpf0Nl1vub7yinZfYIrW1HXcEzsU6icz4PR3Tr+BkaPinG5I6nxhV0cCNkfRyYfeAiJ+qfu/5+zYc0/rxCmyQcG9xuiDyQuUUxmNv5lHbTShVRHIWGPViDjy1fAy1J+v1Bo+dCCCGEEOLdZn/wK55kl5U6liT7AoS2B/cYVW0Oyf4Qk6dfrIknMeQb7SHNM67b9pAexRvtMHwTxsI7Thbd9+JTDwRYMTeOs42Bhz36WfQMTtxJanqYnR37Q4pKH5FUdYNCaWSvs3F6Hrxy399JkncugEB0pCS6ss3gOaYHK/XB/I32PPQuCJWQFDoAHpu82xtEsZiUw2IPUNN4NEB5VHOXXs1+9EGjWw66z7uHdQKa1EsrBEjD4aC/uJyBxEo6gmbtiWiJTplaWXTr+Ce0338FjqeUfPAB+zOzOV14hfbhmbCOaXb4Dzy/vNiQUXqISd7jy6x/9jDAsahMfYux1Ubu9W/IVG8T0RWl8/nKolvH+02ZEXdmxYuZAdl/odg9TQNoSK36JuJF2ZZ5A+2GyAOZCftJ8cYynYzVGKgaXf4hK8Ucu0SrcY/64TWw0V/3U8TRcCGEEEII8W4ZNruH+QFJaSu0N2PiSfD0ph1/MOQdZhSGZ0+9nWkS962QcaAlIcHTIXnN6HCEF/TN7vfS/YWa0tUHZMyDrs9Gd+ISZWF1Lhz0V9YymlJDW95ag0piRbMjeLtR2t2khOxMQ2KKb2EBizm8DC+XOYbGXrvvbyUpOXQAhsQ9JHjuTz4lsulVrfQPuzruKRU1QYdR2gcu0+BNmNuJofZ4GAHS0OwDl6ka20Pd9b+t+bXESjauTEWzjp9v+Q5PcieA0/GK6bF7tJw3kLFXT0HjSMgRp1PTL9UPBRer8wVdHTNYQr0wMzSU3YKCa9QHDf6LqNmo83k06/ipq1Td9wRFg81JuxIH/ZXNvr892NygEXkz7YbIA5kcID/bM98OwEtMn+dS0DLpvXK8TMxu9Gmrb4QtN0L33ZENmURUCCGEEEJsVjNYFH0KrXalRrQW3y4vmXbPjxWOKcsL33+02hUDJcpjsU5HMj/lDA1NT3FqP6Sx9x8hhmuuYOoqDYNOtOn13K8LMZxNwRUI2kd989qDSiIM0zO+/oxWu+JQ0hitpzMNzD0POHdqYDNM+95I8RsIIkZ5LC+whP9G2Aeu0DkH8Z910hW0UztDW6snIwhIPrP2LB77Qyqq/yCtringQjAi2jaqTEWzjrdifqaox5d5jaWrhCz9ZcxhpGc6HKGTuYjdrsgefclsiAtnU43ldLLKDDsRsQ07n0etjnfQ33pP8Voh5qQNZep7Wp75Ivmh5gYN15tqN6wikAlp5V955wlweY3lx0JS9eX0zgYNZ0aP5yq1EEIIIYR4j80x623ZbyPBl8wQxG4SFdfWZy3hd0hmZ32ZOLqV34ikRMWclGEHnax0G4x0Lh6h7V/XVj/ca/4XCs7eYfFYKwNt4QwFVgaCojDMTITFrzMdt3vl7Jr4eO9QVaxzvnULVqJc44DtJK78RiR43+gl4c4QZh/9mrzKP0gq6eZuaYiAzOhP3jneABL1h9gy/4TmwjzS0z4gea/rtl9fwMWW0BlyLu6MoNSaKAxPF2HZoDIV3To+jrPdvzM58Ttj/+7n/g81GLJ2LQ8u2R5RcvIyQwGCmVqtLwjisEaQnclrgi4ZMnWVki4wrDR3soiajTmfR7GOtz+kUxGA1KQfJc0+Q29FAYeUdWZmHgV1fQQLyY129SmSAXehz9Iwb/6Wz3L17He/RvLeTA7ll9M8HKzAKrzBdsOqApnEHOVGfw0Z6l+97SnVJz/iUGnwD29tHMybr3K60jMxqxBCCCGEeG8tvFQEObb4bQpGOd37QtCepZoNq2LXsN7J741WWiBzkXnzVQoyT1I36QTbI4o/yuaiMtoTjkUr5kYj6R+7FlCxPSghQ19Ob7DVe70c9JZJIGij+ZU/jV+WSFC+smfDGrpQ+diU5U8TZvn13V1QFv5A7DP0lmaT8fmvWHFiac0ny3CV0QCBIIDR+0+98wzCVhYHCkg/eYVh4knNOEhq4jY0gNP2J4M/lpCVWUR3iDJsN5W7MoIawgzai7Vb7zLlsU51/JYYHQlpx6ls6eLZxGN6ag/6Aki4g5mVy+fyTFEsoIZlhCHlxlWZoaHsDnzWFIWFrkR41vt87hOtOl45TyyAdu5b0g8X0W6NIyXjIFnJO111puMFlru1nPggj9pl0z+OYxr0TAcBaJ305x/mRP0IJOwnI2sfiToN4MQ2/ZSO8zmkF/5C8Kr3zbYbVhfIBIg9zo3H3VSkKtJf3WyDtZz4YBWNLwDrHfK80WD17TDZZXeYliimEEIIIYRYsCkCIpFzrjQ00MvGQri7BuJ0BDnORSY6yzmd+RHZZXew+O30isGak/y1JYys0cVJbpcWkP7BSUq6nvu/l+0p1R/n0RwihcTeU0K15SCt4WZviqhwONbSqXnNQri9aYdjTUkgjiDBIBYeUmvIZf9HBqoHPXO3uTgm72D8+CL96kgQNizTis40GpKKuhgfHeBuexPXWpr4sXuA8cet5Hoy6xx/UHcy0Gu5F66oeY6+ZQ0ZzCJy61Wm1DakjteSlNvEk3+3+coc4Hx2lRbVMNCY9H148/ecT+k2+28PbiuB1gYarb5Ip/YCHaEymEWUrdf5fLlo1fGWUWU7QENs+iUGR838s9NVZ17r7GH8924qkj3B0hf0fG6gQXneX3jOlPLANbs53z3EuLmLH1uauNZyg7vmIQav/wVv1TvWwIni5QF9NkG7YfWBTIAt8ZxtNzN4/Qwpy4KwrsbXoYonYUesAdDuw1hbQ12AW0XBEVK9KzkJIYQQQgjxNtvCXkMTd4d8Qx3zkv3bunM/lvt3RgLZkszZli6eTfyb4cfddNSeUrXNX9BRdjXwcDj7LxTXz5DdIivligjFHqWm08T4xGMGH7fTVnKQOGXSkeM3qpZltSmHCoP2xDc06QNEeGIPUP9zvW86M+dvVNWrFzhy0H2+galjTTRlqDYJEamY/f5ljlcM9Iz777PjHOfTvYWSwfqvg65Gbh/oU2zTolMv9DL6NeX3dZQ2r32eQvEuc2C1KgKiyWV0lCYvzyTdEs/Zzg4M3mD8SzprbvoyKmfnFMPKt5Lb8A16dZkEYjP+QU/Dh3hL+bNa6tSrc22CdsPaAplusRlf0TXUT1vBnmVzTNgeVHAsSBQ3IO1ucnKPczLA7WzFN/zYbaanQDFHgRBCCCGEeD/F6pa1PSOhWXHhCA8dseHuGohm5Un+PUMdazrNDP/gy4iAl3R3qAM4wWwhJjaetNxLdA09puOEos1svUe7ujOClfbPG5g/0SqBoDdAOd9e5LYSG6ATGpBW6+2UroY2UCqZHy2xsclkGpt4MNpLtTcrCJzPbtLjl9Xinw2VmBpiIaqYo1QX7PT+1znY5zeUd76jiDrrX7jReEDxqNgQ616m3DasjneLOUpjnS+Is3weTC05DTW+YKftV4z6i/RaHO6FjxexWx7SUJhNVvUfiqftI9O7bDvACOXnf2VH1Y21L3QlIrT+53OP6NTxL5lVJDDrUpJDZEDuprL8oO+3Of2QAU/9a1NmN+8mNcRKgjHZlzD4Uo8xm5RtkM3RbohKINNFR2ZFB88eN5Ktqpecz6rIC2dYTJiSij4lRf2gEEIIIYR4v/itChu52HA70+iIC3fXQGJ1ER1nTNo/6Kna4/2/c3IkcDZlSFrS6jqpTvb834ll2L89PtVSTIvjDDfCXNVcRFf45S8QHXHhFipdZOVPLTaiwh9Hfmcrud6n/MnomP8eSluWpRX525F9wBfUdz5n2PNDmPoWY+trDNf/QYj+uFgvG1WmNqyO94nJPkeOJ1JlnVle98Yc5Ua/IuZh+43qs4dJ3fsByXs/IuPsFSyJ/+B+1T7f8PvkA4py6qC/uBxzSg1teeGGxET0bNz5fDXlzydwHb9ClQn6I4qyFqz+XWle2zhyMnwXQpVtkM3SbohiINMt9hBN5n5aj23ze9j64xW6w07LXEFMMqmJ2hU+fCGEEEII8W6LJ0ExjGrllXBnsCj2SUgJf16yhARfo9668hv5r1Yav2fl1UpVYvLKyPP0gSJZodqPlvyKU95FLPyOe+pbSn6UlXLfpKQUX7ZhWCvhzimGBsbF45fgFUrSHsW+L7Cs/EaK4d/bw1gpWm0/FcW+QLz/ytHK1avD4Hfsnt/4DM1lt6BAFkh5YzasTG1cHe+zn9RE9WMqsYdoMv/O8M+t1JWcIivrINkFZdRd72R4wkxXxR6Ge35z76whK++o96n2gcuuxamaj4fIrBPraaPO59Gp43eTqJi7dWX++3vrX+WK6GHwO3ZPG2QTtRsiC2TaZzAPh7OAjw59Yw91qcpU2uf0Dyr+uya7Kev+Br36YSGEEEII8R7ZTYqiQ7zoGtsXggPf2g/bSVyps6rg16h3rjyBv0OxyERc4mo608no/drSq5RykLQALzN1/xFWXtL5iXpxTf9bxTPPM36jQvH4scbojbZ6byXu9mUbrlh2we5QLJITQWfav2Mb1hsphiDuJCX8N/KKyTpI4J/XdkVgKpzfrDKQ5TbVx4AVrF2GZeXV71bpCSTBcKXi8Zwg88WKCGxUmdq4Ol7Ju0i1NnT2XUzSAU4aL3GtpYmmir9zMmO3Kzg5f5Pbk+6ddMcpVAQuhk2/4XT+RsVHAcqs92ag0xN2US2GXDTgey2xOht2Po9SHb8jzjd39sovE09SoAsFcTsVc7E6V36d+HjFFDcum6ndEFkgM2aG2+erwsys1HKy6Ijf/AHW6egduBBCCCGEEBl6X+bX9JhqYYZlXjLv6Y8sm7NsBekHfVMbTY8HXeDBY97q6ZBsJS0jUK9iZd5haZFk3y2j886lGBd+GpTYCAkHSPN0lmzPsazQx7IqVslJ0UcyL2Q8mamejvArLJMrrLlrfeFbICL5IKuaBk0xJNg/K05LQoKvUz4bUf9wWwSZfGJ9bVyZ2rA6XmHRHdvSJu4JGcgMZqj1Dp48v5TiC+xVbRdv2Eadz6NUxycqovm2iOpMReA1Jp4Eb3BujulIrubo1tIGWR+RBTLZTZLuOe03wvzw0g74zWUZ9qS+EbL3GEk2/BL+gkJCCCGEEOKdEHPsL972pmN2LnR7cHScafdd3bFTkc2tF3OUXM98k44XzIZ8o3HGvG90lLyI3sjHkwWiST4QQfadmidDSUNKhi+glFTUweDj/hVvFameZ+yjQvF4V1EEWSkiiP3keafjmsPiKTMBObBYXrnv7yH3WGRz66XlHfUOK/Qf6r2cffI5nrUlUnKPrm74qzcDbxdp3jLkkpZ9wLsYhc0yGfo3izIFabcrky/pC7oClNVlt/J93pdILVc8fvuLNfyehMdGlakNq+O9PPW3hozsVcwDOPo1VQ/ckdDECzSq5sHUNwQoq8tuinlmdX+hTbGtMcvv5cRqbNj5PDp1vF+GexiBV08gHraT5H3ifrLTPTVvGBcflFVvois7dDO1GyIMZLqGAli7vqbde0klFGXK6jZSUtcjkDlOY9tzEvWHIqoQhRBCCCHEOyDmbxRmuRvnk78yEKJDMjEw4g6u7CTX6F0FJ0xa8o2e1UCfY3oQohNgecSQe3P8iU9XmY0zg3nsNbCdfGMk2XcqU08ZdQBxpyhUpkHF6IiNDePmHZau8X9cGt5Rsdd4HFeuzWuGBjxjUQOwP8Tk3qzJ+pT8SD//lE/JdSf1OIYfMaHe7uVgwPTcdVdzkMLVLkby7CkWQJN+jjx1SlvGGV+QZoXfLMww5YmApR8nB9yrpAcoq8tuvjkVtvg9vsq/SfjbqDK1YXW8m6f+TvyC0khSR3H9TovO/+oK2mo+pPGHc4rhvC5bwqx7tZ4FQbb4l/cYWSgkCjbufB6VOj72FPnewOsI/RbFtmVmmPZMqh13kFzFVZtMw3HvxQeL6WHoiwLTM96LDxm57jlewyy7G9FuiDCQqSUuTgP8ScvnK88tYu+5h3eRpMS/Uxj1pcYd9BeXYLJtJy19PYKkQgghhBBis9OXf+HOVgjVIRmh874r20Fz7CvK1L1LgKmbFOj1HMq/gjlQC19fxnl3dkOoTsBQZ5+7I3uEylL1LFOwaLdhX2mCquGbdFshLuiCJovYFxwrznM11HEPK9s3xeT8IoAdX1J5zNXrsw3eC5ppM3/3Hq6+6y7Olx9SbwYcmCvySM/M47POQNlxcZRVHHF13G1P6An6RvfodnemE4vLAqxJ4GBhIdhvzMNKe8dvoPmQ+oZA2XfJlJbs8wYRQo72M7sCorAdQ4lvwRSxGUSrTIHdfJm/Zur5a+FPAWMM0ajjF2dH6DX1MTQV7PkADnpb+7CxHUPt8iBkSPZxqj6pYtgJaHZRevsaOcsLv9gsonQ+hxnaDdmk6wuoNQcoW1Gp47XkV51xz1n5ClNb8ONl/iFDrgMmo0SVfZ5ygVLP3NuTt2gL9GNzMw+6Lz7EnaE0W731zYswkAk7PGvVW++Qp7+MeUG9h9tCHxWN7j+enRiDVgQ2rJ5QbyQW57hdmEvFMydo96GXlpkQQgghxPtpxznqP3OtQmppvEx/gBb+VOMVBpyA9iD1VYEyHCepPf8dFttrbNP3KDkfaNqiOAprP3V1JiabqRgI0GmZukrdAyewlay6S2SqNi90FpD6UQ4ZH2RyrLSP2UCRyIU+ikofoT3WSE9FoKFYNm7nf0TG4cOkpuVy0TQXMKC5YLpIyYOtZDd3BgmGis0gs6qGDA1g+5WqQIsh2B9S1/YnAPGf/YPCAJ0qe08JJQ9e4HC8YKzpIrWBMnYyLlGfrnF1hGsCJaU46K//3jU0N/5T6o3qTvsI5WmHyTp8mORMIw3DgTpxi0w0FtMyGzqQE5Pb5D4WsHaV07D8YIAZGpqe4iRUQF+8UWsuU4D9F4rLHjHneM3cWDNFdQGy1tZcx49QlV9CdU0txZ8cJt1wldFlr+FgtNpA9dh2DLe7Iytv87/w2cfFmKyA7git/V0URvJ88Qas/XwOMFF3kZbJVzhsf9JTVhJwPZlo1PEkfUVrges34HxWG/h4cdBf75qfVZNeQ2O2OvtZy8lm97Hwks6yQL9Z19/dMOh0XUDapBdBIw5kJiS5V3jSaNDYHlFyOJNjhVe5PTDO7IKNBcsIt+uMpB+udV2N0O6j+l89lAX56xct39OtnCvAeo/yipv0mvoC3zqu8Fl+Nvs/yKdxzD3pavKBVc5/IYQQQggh3gVJpSZ6Snahcf5GxcmL9HqybhatmBsLKOh66epg/qspSHDltWK1W8D5moBrmSZ9yYOfL5CocTJcmUeRacYd8Fxk3nyV02fvYGUb2c0mri3rRIDvRZ1YB2s58UE2nzU+ZMLdjm6vK+DQyXsktPTzpDH41Em+l3nJYE0+qfoiGgYmWViwMTF8k9r8bE70xNP6eIAmfYDjEJtHzFFuPG4kWwfWLiOnG58w745M26f6KDpZxbBTQ2JJJ/8sDRTYBqdDGcpWlWUvLTlt/bQe2wbWOxTkX8XsfaMZeovzqHjmRJN4gR7Tl6E7r47ndJ7PIT33MrdH51hYmGPUdJWLuTmUWL/g/tBKgRzFsfCSzk+yKeoc9/3d809oyDfSaYX4021BAvrizYtCmXK+9rsQ41Cu3Kywtjp+K1pFNeiYvIPxo2wudowwsTDJUOdVPtPnUDJ7kLbHPVSmhDl+e9GKudFI+scNjDm2klLQyqD5G/Tq6RTE5rTW8/my8rqII1DDIQp1PEBShYmekj1ocTJcmcPpuodMuQOni/ZJ7+9Nm1rJ/bZA2fD+x+JKTrzI7VGr+zfoUPzdO8n7YfNeBP2PpaWlJfWDIU1d5VjNdnq6/04MDuZHn9LZc4+hZ3NYHa4Gn0a7lbj4A2QavqA0O55A1cBEYx7F91/iCPhNRyal6jFdkc61IYQQQggh3jmLsw9pqf8ek+WFt0Oh0e1Cb7xEpSE55Aq0dvNlTpQ9wqbdQ+kPHaEDMYtz9Lde4fr958x532gbiVnnqK74O3uDvpGDic4r1HWMMGtzB0s1W9Fu0ZGQfoC8vDPkpMUFbD/7sU9yu/4K7c9eYHO/v0a7lS26eDIyTpFfcIS0HSu+yor6iz+g4hnAhzROXHPPUSjWh42JzqvUdTxl2uYpU1uJTznO+aoL5CSE+j5naDcU0TLpJO5YPT0hguAAC5afaKi/iXn6lTsorkEbv4fc4ktB+28AzD+hoeY7TNO+fpxGuxVt3G702efIP32ApFBvHEDA36x2Gwmpxzlf/gX61ZbjgYskV/4GQEbD79zYhMMj3yWrLlPAVIcRY+tzFuOO0PTzN+hDlKGA5SWcOn5xjv7W72gfGPeve+MirDMXHcxantLd9ROmwT9xaLaRcuIrqkuORlz2g5uhIcdAp9U1tLenf3Nmxb0zVn0+B+xPKD9ZwYBtKyklN+gyBg9Erq2OV1iY5Haj//kfzVbiE49SWHWBk0nhxMYWmR34jtq2Pixzngu3GrS6naSe+ILK4kOE83MIZCPaDZEHMoUQQgghhBBCCCHeM6Md5dy26NibdZDUjD3slcWjhNhwEsgUQgghhBBCCCGEEEJsehHPkSmEEEIIIYQQQgghhBAbTQKZQgghhBBCCCGEEEKITU8CmUIIIYQQQgghhBBCiE1PAplCCCGEEEIIIYQQQohNTwKZQgghhBBCCCGEEEKITU8CmUIIIYQQQgghhBBCiE1PAplCCCGEEEIIIYQQQohNTwKZQgghhBBCCCGEEEKITU8CmUIIIYQQQgghhBBCiE1PAplCCCGEEEIIIZwrF6YAAFfgSURBVIQQQohNTwKZQgghhBBCCCGEEEKITU8CmUIIIYQQQgghhBBCiE1PAplCCCGEEEIIIYQQQohNTwKZQgghhBBCCCGEEEK8FxaZaPya2wvqx98O/7G0tLSkfnDtrDTnnmTM8JiuPK16oxDCaxH77HPMPXfoHBghtmKIG9nqfYQQQgixXhZnH9JQfQWrwbyGc7CNic4rlPRs54bpK5LUm9fBon2S0bu/0m0eZ8zqQKONp7DuBmdT1Hu6LVoxtzVz/f4I0zan6zHNTlJOnKO65DhJMeoniM0vOuUuOr+BSDiYH31KZ08fo2MzLKAlNqOMG3WHiFXvCmCfobf1Cu0PZphzeMruNhKzzlFd9Xf2Stl9Cy0yO9BMVb0Vw9A1ctSbw7Uwye36crrjrvHPit3qrWuzhnI335JH9o8v1A+Hll7PZNtR9aNiM4pKuYvSbyCY4cvsP/8Id8kNLLmS4c6/EbQob+J2w/pkZFpuYZoDS+dN5tXbhBDAJM352ezf+xEZJ4up7nrqqxyEEEIIse4W55/QYNCTerKKnsnX6s1hcjBlKudYWg6Gpqes/6l8kXnzt3yWk0nqR4WU9NhIK2ll0DzAE1OIIObUTQoOn6Tkx0liSzoYnvidyYl/M9BwgMX7teR9lE252aF+lti0olPuovMbiIB9ht6KAtL3Hib786tYtKeo7zXzxGzibpAg5oL5Moc+MlB997kvmATgfMX0g2YMH+XRPKV8htjcFpk3X6Ug8yNOVN7Dstpqxz5Db2ku+w8X0jj4KnSwZhXWVu6sdA9GGMQEUvQH1A+JzSYq5S5Kv4GQHHS3rRDEREOWMUQQc5O3G9YlkGnu6MMGMNdHu0W9VQgByZR1DzD+ezt5ceptQgghhFg3CyM0F2aT+nEFnasO3iwya7rMXzMPk1fzFGvo3kJ0LDyhXP8R2WW3GFvYieF6P+P9TZxNi2OLel8l+0OKzn6HxaEhtbaHG7m73R2XLezQf8Xd22eI4xUDZQYagnbMxeYQpXIXld9AJBaZaDGS/pGB6gd/okmv4f7vZrqqj4bM6LEPXORY2SOc8Ueo+KGbwcf9DD5up63kIDrvXi/oOH+FCb9nis1oYfhbPtN/RHbZndUHbxbn6K3Ic5WlwZcrBGpWZ83lzp3UBVtJTD1IVlaIW+p2NADsIfeYjGTdtKJU7qLyGwjH1Pe0T4JGuxVtsFviGc7r1U90ewvaDesQyHxI96Dnq32FqeOJarsQwmtLMmnx6geFEEIIsS7m+2ge0JDfPMDkRCeGVV1MXGS083umEi5xd+h3hmv3uTui62fBfJlDhysYsAFxf6HjcReVGb4udXBW2j+vYtgJxJ+hPjdARznpKyqzNMBLOs9eZki9XWwSUSp3UfkNRGBxkub8wxh+fI4DDSlVvTxpO05CyOg7wAh11X+QVNXLM9M3nE2LJzZWR2xsMpnGJp70fkqiZ1dbH53D/s8Wm8u86Vv6NadoNf/O5M9nWFWxWxzndtsMCVWdPJt4TF3qqn4BK1h7uTN39OFIrmRgwszd9iautQS/1WfrXEGx5L+QHSKoL96gKJW7qPwGwmS+cQ+r7hQdQ2aeBbt1fxlkOpK3o90Q9UCmvecOyt+zc/AW3XbFA0IIIYQQQrwJO45TZtjPjhiA3aSs6mLiFtIMX5KTomULEJO4O+CQ2GiZ7zFyrOyRa7RT3Bl6+v9BWrgdXnMz16ddd1MM59ih3u6mLziCFsD5iIYWq3qz2BSiVO6i8hsIk32cqpOFdEw7AQ0ZDf10hTkUab7lWyx5HcH3T/iS6tPb3P9xYhmeUe0gNpMduV9yNi3OldWVtIcE9Q7h2LKfs6VH2RuzBdCSlBjOxZzIrLnc2X+h3XKEG51/C1rf+jgYMD0HICX3aPAhvuLNilK5i8pvIBz2X2gfdJJSfIG96m3heEvaDVEOZFpp73wOyR/iC1Q/p/2GnFiEEEIIIYSIhH3gIifqn7sydjQf0vhzJAu6OOjueOoeArcLfVaArAqPtKNkuNvuc/dvBR4uKUREZmj4pBiTu38bV9DBjewQZdCPFbP1AK0rLKKxN823PTZhu982ISIXjXK3m4rb/yBN9WhA9oeYJlm5fhYiAhOt32PRHqTwxGrK1NvTbohuINNyC9OchizjNQqzfCm31p7vMfvtKIQQQgghhAjK/gvFlb+5OxQaUqu+ISeSlB1vJxnQxJMYMn1vD2me8ZK2h/SMqjYLEaHR6ot0epJ04s6sGBzyF8fZxmDDHhUWPdOZ7SQ1PUSHW4iwRKHcxSSzN1gKm4r9wa9YABKPkhuyfhYiXE9ov/8KHE8p+eAD9mdmc7rwCu3DM4Q1SPotajdENZBp7ujDpjtOoR4yDcd9k+E6n9Les56zmQohhBBCCPGucNBf2ezq5BJinqpQnj31PT9xH8EWNHfRkpCw1X3/NaPDc6rtQkRg6ipV91+5/6MhqzySTOLwmQddw3J1Jy5RFmbwSIi1ik658w0rj08/srppIoRQmW/5Du9yNYDT8YrpsXu0nDeQsVdPQeMIC8onqL1F7YboBTLdY/HjT3zqGouf8im5ijlXLJ03mVfs7sfyE5/l6kne+4HfbX+OkdoBm/++Cw+pNeSy37tfNgWdnrCxko2JzisU5OpJT/uA5L2ZpGfmUVDXx1SIcPTi/Di9jZcpyM3kr43uIfHzfZTnu48vs5x+9fMXJrldZ+SvmXrSM13vtz8zm9MVPzERsqT4LFh+ojw/2/d3pek5lF9OQ+cIE/ZF9e4BLc4+pKG0gEOZmX6v0Wy2Et4rBLaqzySi47HRX52n+E6Xf/8LA1co0PtvT977Afv1BXym+v4nOo0cS/Ptc6gxQPlY5Xe22s/CtdJZAYe8x5XJXwu/xTy/lm9GCCGEEO+kqe9peebrjYSapyqYKcsL33+02hXnX9NqfYFS67RMCyVWy0F/6z28M6Zpj3A22Mq4azF1lYZBJ9r0eu7X7VdvFWJ9RK3cjWCeBNhOZnaQ+TiFiIgV8zPFeX+Z11i6SsjSX8YcKF7xlrUbohbInO+4g4U9nDV6fohxFBr2+HaY66PdG95VSfk7P5r66TjmmTgX4EPq+zuoyVZNphp7lJpOE10F24Bt5P4wQJch2W8X++hVTqflUDK2HUNVB/f7u+koP4hu8QWWu7XkfZRH7agyQ9TBaEcRf037gNSPi6nueoRlzukayjN1lWMf1zIw/dq961Pqmsa9z7SbL3PocCGNz/ZQ/y/3ClCj/6bjtI7ZB80Ycgq4HXJJeivdhXqyzn6H9cQ1Bid+Z/L3Xlqztdimn9LZVILho4/8gnfHPAE0xWv0FmeTevYOi6lf0tprYvB2PYYUDbbpp3SUnSSr8JfggeSAVv+ZRH48OnLqemg9plgBTPsXbii+/9jsS3SZeyn1LhMHJJYxaO7iR9X3v9fQwYPbZ9ABmvR67leoykfE39laPgv3+32QT/VYHKXtjxmb+J3J37upyZqh9uMc6sb8dhdCCCHEe260q88XCGIX+iwN8+Zv+SxXr7jwm+m6QDysuujvNjv70ntfl7Dyii5JiYq53uaeE7L5KkQw9od0KoLwmvSjpNlnVBf0P2C/O8FkdjXX9Od/oeDsHRaPtTLQJoukiA0SzXI30OdaIDnuILnrka4s3kNxnO3+ncmJ3xn7dz/3f6jBkLXLtSCPku0RJScvMxQgmPk2tRuiFMicpP3+CzRZn5Kv+EXH5H2Kb6rMV5g6nvg2LrOFtKovFOmrL5kKEXmbnX0FyV9QoZ5Jd+oqeZ/fgeJenrScIyctntjYeNIM3/DP3gu44mAv6Pm8RLGaupY04w3+OdrvHyhb6KPo/Dj65m46PtuF50+J83ypU9+S515FMqPkK/Z6//Yt7C39B/lxgPNPGut/CTIngYP+4nzqxl6jyaqny7DbVSFuiUNf10mdb8UkNImnqKutoa62hsoTykmFXa9RPZ1M6786qDEcYG+sjtiUo1S2D9DmDg46xhooqPYPsIW2ys9kDceTWXIG789l0RkgizSOwqKD3vdc+SrBVnKMqpPMqr6z1X4Wrkn6s8oeYYs7Q4+5iZPulSbZEkea4Rr3G/b4plkRQgghhGAc06D7AimA1kl//mFO1I9Awn4ysvaRqNMATtcF4vM5pC+7YG3DqohvblFuCmaL4oLygi308DMhgvDO++emnfuW9MNFtFvjSMk4SFbyTjSA0+FKMDnxgTrBJIRFK+ZGI+kfN2Bxgu1BCRn6cnpD9BmFWLN1KHf9pt8AiMs6vi7TLoj325YYHQlpx6ls6eLZxGN6ag/6pn3EHcysfKiKUb1d7YboBDLNtzDZtpFrPKTacIjCE74sS+fgLUXwMICYv1Hszcp7gakjwJBgAJ7QP6Yhy/g3VSBrhPKzd7DqTlHtzQxV2HGOwnTPf55zvVX9+joyUn1BQuuDERKud1GpjyettItnva3UNbRzw+gqBqNdvmETDof6BLybFE88a/Kp64qLmuU7GtxXLFOy1J+dlpO1vsCe07rIjtzjnMw9jj7JF1ef7yii4pmTlOIa9AGiepnGU3g+Cdv970J//gFF9pms6Xh2/J2TnkChcxxzoAxe/RlyPH++5WnQRaTmB0aw6Y6Spwp0r+07i+yzwP6QiurfcLKN3NrAcwPFZH/pCp4KIYQQQgAsPGdK2UTR7OZ89xDj5i5+bGniWssN7pqHGLz+F2+byjHWwIliZafExoK6mRMJp4O1PF28vyyjypFjGmLTLzE4auafnU1ca2niWmcP4793U5Hs6/P1fG6gIVQqz+Ikt0sLSP/gJCVdz/3Lpu0p1R/n0Rzq+UKsxrqVu4eYngFsIyM7kkWwhFgNLUm5TTz5dxu5iriD89lVWvziLW9XuyEKgUz3Eu26Q+QGmA10r/G4L8uO57TfUA+L9qfMyrPdvxUwUGXvucXgluXzrcy3XGXACdqMI655OgNIS9vlvW97cI9QiytpT1yiUhF92pJwgJPZyd7JeDUaRQQ6pBdYAlRys+YRPEHvLYFC3juOkultoc5gWRbifkJD25/AHnKPLUsadkk6QIr3MJ9jerC24hX6M1nr8ejIy/NMR/AKs3fJLKX95Ga5J5UNuoiUle7BF775WhXW+p0phf4sYKL1KsNOIO4oBnXmsJcieCqEEEIIMTunGFa+ldyGb9AHWAkiNuMf9DR86B0R4nxWS93yq7BCbCAHVqtiqFFyGR2lycsze7bEc7azA4O3U/2SzpoQ6ylsSeZsSxfPJv7N8ONuOmpPkeLX1XhBR9nVDR3WKN4D61XuzI9cMQjtAXICxE+EWBcx+6n/uZ4MbzjkFQM9kYzY3VzWHsicv8ntSQIGjcCVBXlWMUWhtef7gMFJL+X+AQNVrhW+dMdO4R8bsjHgntzUcb942aIwnltW65++pzheMBsiQ1E5eWkge6s7qDt9kOzP2mjLC71vIFPTvjkIlmcHAuwmw3u18jUL6kDm8CNXoIzn1H20/G913UoYULQnZi2hA8krCfmZROF4lNMR2O7fYchvq0uczpcYbTGpU6IByy1Mc8r5Wn3W+p0phfwseEK7e7VGTfKBgNmYQgghhBDL2GyKrIbdpAa9GAox2ZcweC+IOjGbRtz3dcSGaqasRKNdPq+WECt6yaxiaKIuJTnENFC7qSxXTBk1/ZABdV9nmS3ExMaTlnuJrqHHdCin27Leo10C+WJdRLfcme+P4AS0WcdV8Qwh1lnMURrrfBdAHVZfPOptazesOZA50dHHnN8iP2pa8o2Kk1TA4KSSlvySv3jH8C9b7Xz+Jrcnd5Jr9F/ABcYZnXbdSy3vZ/BxOLcmsoOfXcMQx8nqJppK9/udpBfnx7ldUUDdM8WDAWi1vuxAdUDPIzbW80lsJVZ1NX5q+LlrwRndX2hb9rcFvt0vVyzAFGXROR7FdATOp3Qvi3qP0NKlWE1r8g7tqsu35o4+HKr5Wn3W9p2FbfQpY+6Are87FEIIIYSIhGZ5NpufOHIyfJ1q5+SIOztIR9xamh+xOu8IEyFWK3TZBfRHFIGcPxmNaAFMLWl1nVR7u4ROLMOB+1NCRM9ay90I/cNOQENG9lpWPRdidWKyz/mm6rPOKDKK3652wxoDmZ6ss1AZeB+QXPbUFeByWxacVEv7glzP1WXVaucTHX3MJZ+hcIfvMQBmZ5h137UuOIiN1YV1CxjrWhUHUwNX+SxXz+map8QablDhnY8zsMzsA75o+PAjJlTbUWZqxu0nQ1UyvKtK2Ww4AvxtAW8xKzYpVi1ax+ObjsDJYIf/Qkn2nu8ZcO7EUOAJgL5goEtx8rD/Qvvg1gDztQYS+XcWLvvciw2dI0IIIYQQ74j4eP9J+VeQlLLT9x/rnLc9nJCgmNd7ds57P5gpi+JCcfweGU0iVmE3icFyWwLy3z9YYkdwWvIrTnl/L+GUcyHWbg3lbrgPsxPQHCQ3Q71RiI2wn1TlAsYKb1O7YU2BTHvPLQad28goca2mHepWmu5b9EcdnFwujkJDoLkSn9B+/3WARX5cq1x7WKcjPQmuxSKzpnKOpR3G2AmF7Wb+2f4VOZ7VqUPRf+GbG8bWR4tJHfqapH/4NaAhuyrwYjEuL5jytFo3hTUej3J6Ab+My0la2p6jybpAZYVvCLp14J43CDzfcQdL/HEKQ843sobvLExW5bgaIYQQQohwxe3Ed73eyaLfxgDi472L/ij5BTidypSCwJTTHMUlygIUYnV2xLnnsoeVyy7xJK11rviUg6SFOwW+ENGyynI3ZHIleGmyjpOp3ijEBvEuNq71z6J8m9oNawhkWmnvfA7xx6k2ulbTDnUrrFIu+vMKU8cTv1dT858r0bXoj73nFoPa4xSqFvkBV6PP+yVMjoRcxCdqFidpyP2IEzVPIa+dwc6vyIwon3Y3Zb3tGJO3Ak7GavIoMs24MhAXrZirq+ixbSO72URTgCs2sbGehsJLxsbUQdCNF73j0ZJv+NB937d6vX3ge0y2nRjKD/kPQbf10W4GmKT9/gtSDOcUHQCVNX9n4fFWDhseWBdCCCHEWy0mngTvRFNzTEeykoQungTP/fSDeK/rTo+v2Daet75239tKWsZao0vifZWoWMXSFmEbeHUdYZ13+q24BCm3YqOsptyNYBr0DCs/oN4oxIbx5ABqE/f4Dwd/i9oNqw9kjn6PaY7QQSMl1aI/zsFbdC9bpUXJf67E9p4ZenqeB19UKCaOOO847UfcXja3YgD2PopKH4ZxtTAQK+1nC+mcc6WGV1YEWJEvHFuSKes00Zq1FW18PItdF8nO1HPobC1DCZe4//sATfrAA4yUqb8rDtd3m2q8SEMkDeIIRPV4sk/5AtmDvzKBlfa23yDrAmXuAqccgj58/wmL5luYHAcpDLqIT5S+szAkJCmuZoRRCQghhBBCuOwnO93TqH2FZXLli8PetmyiYmhXzFFyPW3vFRa4hHHG3HPNoztKnqxAIVYpJusg3lGLYbSBfYPqtpMUZLhjaA5cSUEaUjJWEwgVYjVWUe5GH7oXxt1HTqDELCE2hOd8H2Ce1reo3bDKQKaD7tZfsbGH3GPBgkZqqkV/eM71Vs+Q8cB8gSqwtBbRPr2Lk96x2GoH0Kd67jsZbLqqmLg0kBkaPrmKNu/o6oJZU3fo9nxxsdsDDukJjwNzhZH2lBs8M93gx+4Bng2ZedJ9gxrjARJCHFxs+n7f+87doWrZ0HR/9oGLGMf2Ywg+Rn1Nons8/hmXbRVX6JzbxflyxdyXiuC4c/B7Cm48RXviU4KeF6L2nYVBeTUj3MC6EEIIIQSQaTjuW/jS9NBvvvBlpmfwTGiTkXtUsUHZ9n6O6UGIdpnlEUPuzUGTBoQIR+wp8r0d4RH6Q04nNsO0ZzqquIPkBuwTrGDqKaMOIO4UhQFGsAmxLlZR7kbvP3WtoZB+nBz1RiE2iud8n/gFpcvK7tvTblhdIHPqe9onQRN0Zegg9J+Sq0gu9AwZD0qZxel4jSP5FHkhhgHnGI74AqXWOxTkf8tEoHTLhREa8o10x1+ietmXF6a5Oaye+4qJ1X2sTHl3CMZBf3EuJXOnaDOGeSVHKekM+d4rl66h6eXmQHMzLjJrusiJyhfk1oaZQbsaUT4ev4zLB7/BsS9Vizwpf2h/Mj29nZw89Wr2ClH5zsKkvJqBk8HKi/QH7IVE8T2FEEII8ZaYod2QTbq+gFpzgI5CygVKU92t2slbtIW4Om8efO66E3eG0mzVRn0Z591ts1AB0aHOPlcwVHOEytJ1vdQr3gF282X+mqnnr4U/BUgc0ZJfdcadMPAKU1vwcsf8Q4ZcBY+Mki9U6wEsYl9wrDhybqjjHla2Y2gOtZ6AEB4r1L3rVu7GMQ26huGm6GVYuVgNB+aKPNIz8/isc/m0HYuzI/Sa+hiaClSuPRz0tvZhYzuGYHGYt6TdsIpApoP+1ntYgZSscFaGVkomJ8M3AbRryHioD1oZqNIEXuRHKeMS9d6hOOCcvoXhAz2nS69y29RHr+kmtYZc9h8uodNxiq62oyFfL2QFlrhbkdH3G1WGn5iyA4sOZkd/4mKOkR5vDO+le1iQg6nhcRbcj9p7Sqh49hpm71HX0ceQxcbCgu8WrND4xFFY62koALxioCyH/TlGajv66DX1cbuxnNOZH3Gi5g+SGjqpDK+mDSrkZxLt4/GbjmAX50sCVPrK4Hj8kSDZnW5R+M6UQn8WWvKrPvW9n/M3Kk5epNevYrExVF1Ch2JBsNnRyRVeVwghhBDRolgrck0iPXdP1F2kZfIVDtuf9JSVBJhuScvJ5hoyNAAv6SwLMtJo6ioNg04I2qGOo7DW3R6ZbKZiIEC7e+oqdQ+cwFay6i7JAhRvkUjLXSAR/wbsv1Bc9og5x2vmxpopqgswwi7pK1oLXFNOOZ/VBi53OOivv8McoEmvoTFbOcrPxu38j8g4fJjUtFwumuYC/q0LpouUPNhKdvMKfQqxyYSxiFlYIn+V0HXvOpY7b/ZaJCNaxeYUqFREKvLfgL2nhJIHL3A4XjDWdJFav2z3EaryS6iuqaX4k8OkG64yuqxd4WC02kD12HYMt7tDlN23o90QcSDTPnCZqmeuM95CGEuyL6P6xiyNl+kNFCXy8ASqdEEW+fGjJaetm+pURbCU10wP3qGxppbqmu/omXwJiZ/S2RuosefAYnnp/Z9tsC9woxEg4RylyqDpZDN5H31A8geHOVH2iIQGE/eNu7zbLfWHSd57mJJhrXdCVeei+8NwvmCgtZbiszlkHfbdMvZ+QPLeD0jem0l6bhHNwwGyG5O+oueHU4qFlMBpfU5Pay3VNbU0dj1l2uFaMOiGXwMhXBF8JkT7eHyBbM2ybEyPZApPuOajXHG+1jV/Z5F+Fl/6fxa236j+5DDJaXrSM/Xs35tDycIXVKT7nmK9W0hqWjanWwI0CoUQQggRPfY+TIqOwNTwuHJr2KbuP/UO7cb6HMuyzsNyDodngnyARRyBgkkxR7nxuJFsnWukUZ7+IrdHre6mtIN581VOn72DlZ3k/RCiQ530JQ9+vkCixslwpWJhSRYVr+Fqm11bsW0mNovVlLtlVvMbcL726875l2WfpAoTPSV70OJkuDKH03UPXQkEwKJ9kt7iPCqeOdGmVnI/QHKJ9yfhfMlgTT6p+iIaBiZZWLAxMXyT2vxsTvTE0/p4gCa9lNu3id3Uh6/YzTC80kSqAc1gGnzl/Z/VMhlGEpC6vC6ve9er3E2Ynrh+r8l/IVtd2MVbZHXlTm01vwGnQ1nzvnbP0eqxFa2iODom72D8KJuLHSNMLEwy1HmVz/Q5lMwepO1xD5UpIeYv5O1oN/zH0tLSkvrBgBYecrGwlsE5/1+7RreLFOMlfjSEGNLLJLdLbzEwO4JF9XwXDfHJF6jv/HvAsfXzHQWU0MRdY7gpq4vMm7+n4UYfY7OvXBWUZiu6hAMUVn3F2RT14jmT3C68QrvlT2zqw9NsJyVjN4nZl6jJVj/PxlDLZRq6/mDOCRrtTlJOf0VT6QF34GuG5lwjHXNO0Gwnq6qNa7nKv8HBaGMJJV3PXfNlrEhDRkN/4ACgfYbe1iu0P5hhzl0ja7Q7STnxBTUlR0POtRnYaj8Tt6gdzwzNuVfYcbsj+DQG9l8oOPknFeZLAcuPv9V8Z7a1fRaLc/S3XuH6/efuz0KDNn4PucWXKM2Ox1z8AVXTu8jI/jtnCw6StiPA9yuEEEKIKHC1SUcdVsbG/lzW/tLE7yEjQQepn3ItRNt2YeAKtQM2bNMjWKyqxoFmG4kpycRpdeRUXSIn0LRI9ieUn6xgwLaVlJIbdIWcYmiR2YHvqG3rwzL32t3R1qDV7ST1xBdUFh9iRzjtqmXtEfexZp2juuLv7A10nGJTWXO5g6j8BqY6jBhbn7MYd4Smn79BH6yNDrAwye3GK7Q/e4HNW+62Ep94lMKqC5xMCtLutU9yu97/eRrtVrbo4snIOEV+wRHSwir4YlOw/MTFjj9wWMcZm1YHvzXEJx8gIRbSjE2c9S40oGajv+4K/TYb08PPWfYT0O0iJSUOre4INdVH/Vdj9lip7l2XcjdJrb6QHhukVD2mK+jCtGJzikK5Ixq/gRnaDUW0TDqJO1ZPT+Mh/wtAi3P0t35H+8A4szZ3W0GzFW3cGsruJm43hB/IFOvCPnqFgnoNTbe/INY5x9TwC79hzDbLUyZs4LBOYpl+hVN3is6wAnZCCCGEEEIIIYQQQrw7JJD5BtkHLpJVaeP8v7qCDJtWsf9CwUe3SO01UZag3iiEEEIIIYQQQgghxLsr4jkyRZRMXSWv8jfI+iK8ICZATDIpcVuJkWx0IYQQQgghhBBCCPGekUDmG2Hjds0drIA2Ltx5P4H5hwxpDpD9BuciEEIIIYQQQgghhBDiTZBA5hsxzvC0656t51v6w1nqauEJ5WfvkVTxZeiVuYUQQgghhBBCCCGEeAdJIPONOIDeswig8zcqPsrmYscIEwsOFhV7LdptzI720VCYy/7/f3v3ExPVuf9x/H0346bDorARF8KiwkIwqWCq0FQxVbjXimmFtgFrLt4mYBsEEwaTAk0BE4EExLRC0quNlyG14s+A13tBG8HmipqCTRxYAF2AC8YN44Jxw2z6W8y/M3+ZAVSsn1dCAuecGc4MhzPP832e5/vdewbqBmjLMRwgIiIiIiIiIiLymlCxn5dl8Q41hywMOYJ3hErM+ozmli/J1ZJyERERERERERF5TSmQ+VItMT92jQud1xiae4LT6XJvNr1BYuoW8vKPUnx4J+kJwY8TERERERERERF5vSiQKSIiIiIiIiIiIuuecmSKiIiIiIiIiIjIuqdApoiIiIiIiIiIiKx7CmSKiIiIiIiIiIjIuqdApoiIiIiIiIiIiKx7CmSKiIiIiIiIiIjIuqdApoiIiIiIiIiIiKx7f/njjz/+CN4YsyU7w10dnL/+kFnHM1yAybyZ9P0HqCj8kOxMMxt4SE3uJfLunqMg+PHrzNLiBGNX/0PXwA0Wcy7yb8uW4ENiM/UjJf/owOZ8k/yOPtryzMFHPH/r4RxeEUuLc9hGrtHTe4vRxJM87NoXfIiIiIi85h5Za2jtvY/N7grYnlxi5WYMbcaFoW8ob/3F12Y2Mpk3k17eQG9pRtAekTWwcIvG2ksMjf+O07jd9DZNt7s5lGDcGM4EPaWNdE0/xhly8b5BYup71J7/moKkoH0iK/DIWkZd5yRzwdeah8m8mfSs7ZTWnQp7zS0MnaHR+pDRiceh99qU92i+0Bb2cSKrtnCLuuPtDE4/Dbn23Ewkpm0l8+AXnAv7eT9BT9V3DNgmmXYEPYPpTdJK2rhaFe5xr58VBzKXbN9ScuxfTLsA81vsOXiAvDQzDtsNBm/+xrQTwITZ5MLp2kjpTwPUpgc/y/rw6GwJJ3p/x3itxNooDeeuJZeKm54nS/uCkStHedH3yvVwDutduL87u5qZUCBTREREIlgYqGR/wwNDJ8VETssg3fkxDhov3qJ8bx2jLoCNlPZcoTZzQ/BRImtvaYKWQ8ew2g3bkj+hb/AksXbTploLKep9AoBpVwM3uw6ojyHPwRKPWosp9VxrPsmfcX3wS1IDt4Y31c7+jy9jB0h8n84rp8nTxSovwsINygsaPZ/zXiZyOu7SnWfcFtlgxQ4s9wBMpP29i96qDNRS8FvZ0vKpbzl4xB3ENO1qYORuL+csn3Ko8ADH6ru5evdXRs5/SAouz6jdUvAzrCvbqnq5MzaIZY2C26nJG/0/JG58KR/u6+Ec1jv33/1/WA8b3isRERGRKJIKz9FbYmw7uBitLaVlyrApmoR9NFe8BYBp/ykFMeXF2ZBB7U8NZJkM2+yXKam4xaJhUzTpllPkmwDe4niTgpjyvGxgm8VK6y7jxQo4n7AQuCUyp8M9A9n0Dq39CmLKC5R0gO6eT0gO2OhiwR4wJz4KJwsO93fJJRe5qiBmiBUEMp1caf6Xe2SDrdS2hP8AS8o5xb//+wVpADxldi74iPUmkezMtQlobarqpuvv75Nf0sz1s89pdt/iQ8aiNJhfyDmskcWxh0R5Kc/ZBrZlbw7eKCIiIhJRemZw2+EJ1ur2mNszSRlbMAPp2VuDd4k8XwlbSA/qvLnuNXJiINYO9lay0wDzFjLDdQJF1oyZgq6LlBqjQc6fablonFIciZ0LbT/jZCOlPecoWDZ9gsgaSz9JX8s7GEPx051nuGv4OaLRM5ydBlNWA30rXCX8Z7eCQOZ9hic83yZvJTPaTWHTUS42vo0JWLB7QsqvhURyq07TZtlH6nMJnTsZrD3BhajB4ed9Dmtk8RaW45eYDd4uIiIisq6ZMK10ZpvZjBkwm2Ncji6y1kwmQwfbxXhDrLOKzZjdFy+6euX520JtR+DMtunOOq4sc6NdHGjk/DQkl7St2/R28ueXkH+aZuOsYtfP1NU/NB4SxgwtzT/jMr1NfccBooXbXmfxBzKnJv1BpwXHslO7EwobKE0Bp3durKza4kANdffCp499tTjprw7OHSEiIiLyKkik+HwzOcY+yr06ilpnjAeJrE9Zp4JSJDzBeqSSwWUCRCIvXPpJOv9uvFYnaam+EXnQaPEWlubfcCX+jWbNZpOXykxBS0NAO8FxvTHqoNHU2Rqsdsi0tMVQiO31FX8gc4OxtfYLF5ZdhpDMsdKt2Nf/2vJXw1Q7RQ2/RaiC9WqZai2lfvzP8EpERETktWTeF5IHy95bSd2YYYPIumQiPTgHoesBluP/FzlAJPKSpFe1UWa40brGz2AZCh+HGGtrZ9RlIr/pa7KDd4q8aAn7aG0yLjGPkopm8f9o+uEJpH1Ba5HmvEcTfyAzdTuZvr+CexlC3Vj4m4hXwv5TdJYpB9BqLdna+cBbee2VtsSj1iJfxUMRERGRV1ZIHqynDBzXzDZ5FYTJQTjRolnFsg5toTpgibmL0fqvQu+zU+3UXX+KaVcD9TlB+0RekpAl5vbLnDgbfJ910l/dgY2NlDUeZVPQXgkUfyCTnRTnv2n4+QkD/yik5OxE5NrkCVvIyw6s2RTKwSPrGUoK89i+bQcZ23aQsS2XXXklVLbeYjbik8PS4gR3L3ofW8mgeyuzA19xOC/X81w72J5XQs1AnGHApTn6m8r4INfzPNn5HLb8yKPgm6bRop2xgXYqi/PIKIgQbQfDOeaxK9fzlVdCZeuP9LdW0jjqP3K+r5w9Ry5jnNc6Wut9n3aE/p6Yz8Ftaf4OHVUl7Pa+Ts/7Vdl6i6lorxVYsP1IY2mR7zVs9/zdaqwTYVIP2LlyrIDS3seGbQ+w+P7mO9gfofHk/z3uc9yem8cHpWfon4oeSHcLcz0UltMxbI983YqIiIjEICH/HN0HDe1j1wMsHy/f/lreErND7VQW5xvaxzvYnltESdOPPAptaInEaQu1P9WSadhi7y2jPMJst7gsTNBj7Edt20FGdh67i2toGZpTG1zik36STmM6BNcD6prvGw6wc6HhMnbT29S37Fs2t+CK+5ZLc/RbStjt7b/neq5p6w1aKmIs5iKvmdAl5vYfvuHCvOGQ0TM0jbtILmmjerm8rktzDLbWcDjPGzvzxM3O3mE+6o019vjTereCQCZk15wM+CPAM2w/HCMrr4b+aBHHCJZs31KSW0Bp5wRpFd2MPPqViUf/Y7TnFFn8zkhvHQd35FMeHIS0fcvhvFyy3j1GRec1bHPP3EuulyZoKXyXgw0/M+3wL112OX5nqOEQu2JMxL44doYPdhRTf3UGX4ZP11Omb3ZQujd4pN3JVN8ZSgpzyXj3EGUNlxmZfmY8IMgMF4r3crDZSWnPIPfuDru/rnxJwkgH9b0PsBvuoZv2n+b67UEsWf5tWTWDjNz2fPV8Tnrc5wDgYNiST9ZfGxlPPEr3f+8y8ehXJv53geIN7ve+6N3CCLNunQxb8tlzpIPRzAaGPK/h4a9dFCU9ZqjtGPuLfwxqxCeT39LHyO1q/C/lbSze13F7kN7yoFwmiw9pKc5lT9VvbCo9RW//ANf/WU1eoou5iWvUf7yXD5oeRv6bLt6hJu9dDjY8JPlEF6O/uq+v63XvMd18iD3NvwU/QkRERCQu2U3nAme22S9TvmxS/ygWPO2X2lu4Dp7m+q+/MvHoV0b/20pxigPb1Q5K9+ZyuDVKG0gkFgkf0RUwq9jFaO2JZQuqRLbEo7Nl7Np7jLMTWzj+z0F3/+LX21jrtsP0L1hri8nKq6Tf2JEXWUa6pS3gPuu6+Y0vlcdiXx1np01k1S2TW3A1fcupSxzOLabJ+Sm9tz3997vDXD3xBsNtjVjv2QnXaxYhYR+tde5C2G6/c7bWm8rjIXX1P+NK/oTOZfK6zg9UsntHGdalt6k628fN2xdoLdmKyfE7Iz9YyN9bzpWw99X44k/r3YoCmSTso3uwgZzgZfuOX6g/9C67q25EnUEZYKqdg0f+hc35FmVXemnI3+IZPdlAQuYBzg0PYskAeMpow6HA2XqZX3J1+C4TPxmnmT/m7KEKBpM+obXHG+RrpijjDd8Rznt1FIVM5Q20NP0tRccfkt3Rz/iju9y7e5eJ250Uen+R6wFnu43PYSb14Cl6B+4ycuItw/bw5i9+w9lpF5mW0xzaZCgrnrST5qBRUQASEklKSiTJEEDekOTZlpRIUpI57nMAJ4MVhZy4uYH8fw7QW7+PdO9NPyGDCl86gCcMHA8dXZo6W8qJm0+Bd6iyZPhHvTZkUN34IcmAa7qDpr7A/4gEzzn7X7XJ8DoSSQr44Jmh5eMKrHzO0HAbx/K3k5qUSGr2p7QNXKEqzX3U3NUKKoJ+D7iTPZfvtTDk2EjpT0OcK8wgYQPABjZlf0p3fzOZS8rTKSIiIqu1hdqfAov/OK6fWNnMtsVblBdYGHKY2NMxQHfpdrzNxYRNu6m1DnJx/5uAi+neCvbEOEgvEklC/rmg4j+TNK1wVvFUazGlP0ziTPuMq1dOUZDu6TRuMLOtsI07t6vdfR3HA+r/Whi18IVIoOAq5k8ZaGhnavEWltZJyKimszA4SGG0mr6lnQsN3zHt2kptywHfPRkgKedr+uqUSk+iSyhsoz7L0EiY6ODEgJOp1kYGHG9S2HiSaJMxF4cqOdgwQ2bHAL31n5KbmUhSUgYFlm7unH/fHSR1/kbTkW8ITtUdd/xpnVtZIBMg6QDdt69gyfIHCL0cI40c3JFPZfAMyhD3qTnizvmYePgU1anB+wESOXLe/8bae2tCP+zSt+J/6BPMRVe4c+EkBZmewFjmPhqsAwHJrO0/nIk6yuiwQdXtPhrykv0Bt6SdNNe854ui20du+Su4Axs8Bybt2h6Q9D2Ug6Gh3wEwmcLcaBM+4tiegCmvMYv9HNyBSMs9F4kHG2jLDj2PhP1/81/QrklGA973h1ivenNcPsMZ/F4a/ia2YeOU//jctZRhtb9JUV24PBHJHCt7x/eTres7HgXsdzJY666Knniwgdpwd4WEfVQVGRttIiIiIiuUEFz8x8VobWlo2zUqOxf+UceoC8iopjnP0OHw2UB262kKE90/ue41cmLZApwi0YUU/7FfpiTeIPnoV5T0PgHepKjuS0MfzSDpU7p8QZ8ohS9EwgleYm6/TNlfGxl1vUVVy0dRl5Svqm+58DOD0wAmTGF+SULRZ6ywCy+vDTOHOk7hj2W6GG8upKz3Cab9X9McrTrV/CXKah/gyvic5rzQ2A05Ryn2Nj4c/+FsQCD++cWfXpaVBzIBNqRw5MIwI+c/ITPk/XjKSMMhdlvuhMmT6DZ/tp0hF8CbFBRlBO/2S/iIqv3egOkTrM3Rqum9wzFjSTMfMwVdzYabyyQDNyM3+JKLvqQgzA2KvPf8wT37zAo/dB0seH71eHf4D+68ovcIeUvXkrciFhspKNkevNct4SPqT2zFbDKRsr+aioBAoAlTrNf63GTY17is+W9puekC804KIg0RZG3HM3AGjlv0GYcebN/Rcs8V/TUC6ZmbgzeJiIiIrExI8Z8nWI+Hzo6IaLiD89Pub7OKonXKt2Mp867AcTHeGTygKxKv0OI/rnt1YWamRWKno/Vnd6qvxH0UR2q/AwlFX5Dv7ezYL4es4BKJJniJudPpIvnvX3MsNDrpt9q+5YLDs2z8N7rC1nTYTfGe59qDlz+DhAN0GpeYu57hNL1Dc93OwOOCDLd9zzSQWRgp/+sWcjL8LQ/bgHEQah3En9bY6gKZHkk5J+m9O0hXydaQF++4aWF/2JG8Gaw3vQVftpAZbracQXbhTv8fe+IXVpaHdDfFhkjzymYKmgxLolfKcJHZL1MULrdozmna8gM3raWFq9ewAZi2khPlvU8vu8i9sbv8u3V30D9MBg09DRTteZ+yf3ZSHP6/aVUWbt53Fzdy/ocyQ4L7gK+93+Fp6wPPmJ3zN4KGL95w5zZd5jWKiIiIrKWQCqWO/1Aetj0carDvF3cgiI2k+3rU4SXk7zN0uu8zFK53IhKXLdR2fBawssvWHOOs4qnLDHkrk6ZtjbpEErZTaPgfWVm/TF5fW6gtf9vw80by8qPnFlxt35L0nWR6u/C9pWHT6eW2nqYgcJNIiITCkxR7VlQAkHUg/CQ6n/sMjrpbBrbmvaHXreer4qYhZd7cpOFafvnxp7W2JoFMt0RyLRe5d7uVfOMfxTOSF5qTcoap5VaeG2W8bfgwnMEWy4dpGLl5hhve3EzA0vAXKffE54aG5wpyi67S2Jh7ajFJiSQF74zVpgM0nD1NdcCy9CXmx36kpvjMCoPNfr5zzKr2FzVa5qtzv/dcHjI87vlHXs1rFBEREYlb+JltRWFn8RjNYPP3PJaXtBVv+kF4wlQ8jxWJJP3L0FnFR4ILnYYxPUM83bvMbEPgaXqFK7jk9bUh1uWBbqvrWwLspKrCX4fCn05vjhfUhZc/k3hmx03dx+ZZyVx4PvQ6DfvVfzIg7+XLjj+ttTUMZHok7aZteJDO/W8GbA7JSTll/KBzLf/Pn5BBpi9A+pRZ72hfvFJSAvIWLft7n5dNR7n4zw9JMWx6cTfDOaZW+v5FsjjDYGs5H+SWUjeSSOk/T5ITfExcDOdod+AMKGwU5cs7krE4x6xWqIiIiMhLE1r8x95b6auwG94csw7v97G0BreTZZi1aZ9eLlAqEpuQ4j+uB1iOR0vvBVPT3vz5gGv5YpoJGVvxde8ccy9tgom8DlbZt/TYVNbNxcPGtGRPGWkoJivcDDeRtTI354mdPWXBGeY6DftlDoyVvtT409qLL5C5OMPwaCzjbInktfbRZKzIxCSDI4YfAzxhOpYhuHii1rFI3LxsQZznKSH7FP++3UmpoaK672ZYeIaxaC2FVXF5liwB9lU2Gpbm6K8qZPu75Vg5yg93+/jBso9tCfGNkIUynuMKcpHaH0fMzSoiIiLyQoQU/3nKwPFKBmMabI1t4D5gUlLMCcxFlhdS/GeihaLWmdg6vDG239e6eycS3ir7lj5msuv7QmuEeGa4fdD0MGqwX2S1ZlcxI+3lxZ/WXnyBzIQZeo7XRa327WfmUPn7ATkzA0aJgyqNx7cUZiNpy+QMioU5NSVCotQXKGkntdZhRnqq2WNckj93jbKPwydiXb1Eknx/mBnGbIF7Y7Vka+eDHcXUj0BxzyC9lp1ruIR7I6m+92OS0aizF8IwtupX9WElIiIisgrpJ+nzVWj2zmy7FmHANYVUwyj7lC2+GZap6ca5FiKrZaagq5NCQx/F3ltG07jxGL+AAprxtr+TtyyTU1NkNVbZtwzirRFirXnPP6sYmLtaEUMKEZE4JSb64mr28VUGy19K/GntxRfIZAvpiZNc6I7xnzN7Z8C6fHOS8Z3aTrYhGDk9/tCwLxwHC94WX+JO8vxR0Pj4puWayMmPXMn6+XIwaL0V0IBNyvyUc8P/43rjO/6bof0yZ4cMB62ZRNJSvIG+pwxcvBO0P4zFW3RYDdH/+UuUHLnMHGDaU01t5lqPp5pJTvae4zMGe2M4R5z0V9QwuASkbjEEymcYX+WHlYiIiMhKJRR1Bs5scxlmBwUIrDrqsE0s02FxYPctRd9K3q7AvSKrt53m88ZZxa7Iq8aNFZ9jaX87HL7+UOKu9wxtd5G1tsq+JcDCLXqGfDdcIJFtpW3c+fUKTbv8afXsvd8yaDhKZNVSDekRJy5zYT5wd1hT7ZT7guovO/609uIMZG4kNRnsvd/E9uYF5KB8k8wsYyAzkfx8f7Jc58gNon7WLcww6/nQTDn4GduC98dobHTS/U3iAUpXl8RxFRzYesO93g2kFp7jeuPbvuTas3GOxMcqN99fBd41UkflcLRFIg76a7/HkeYf5Z/qveargpWU/HwW6BsLM7lGOpatljjVWkqr+UMKNgDsJC/DuyfWDysRERGR5yG0+E8kuYXv+YusTPyHoaiRzBmmPDmCTHs+o/ilLzWSP6X0k0HFfyJIep8CXyTzGcPXo09UWZie8wT0N1NY5mu4izwXq+tbAguTWAfCXNMbUjjUZUyr93jFhYlFwkraSbav/fAYa8ON6IOci7co/8dDsku8BdVefvxprcUZyPSOZPzO2X8sP+10se8avpUHaZ9yzDg9E9hUdtK/VMH5MxeGIicMmrfecAfOTO9TWxVDKzCsO/QMPQMgs+KLFQdD18YDrH3hX29C4Ydke75PTjNU8wPMZn8TwukM//iY5H1mWCbiYqS6kPJwSV6XJugoLqTJfJJm70kBs7P+ZN72cAmc5meIHus2438pz3CG+0/M/5R83zFPsB4pocMWcoaAg7utJZT0baa+bqdnm5n8Qv8yLtdIHeURrq/5KUNichEREZFlLDqfAU7ia4qFFv8JK+cUtb6YzjIroYavMewCeIvjNbuD94qE4blunc7oHeEgIcV/wkrmWM3ffLN7nEOXolQ6t9Mz4K4ibdp/kupNwftF1tiq+pYe9y5HSLNn5lCRN1C6kTTlSZA1tYXSIv8kQNd4Iwctd8KmqFmavUH5oTpmD37NsYD76sriT+tVnIFM2JTs+WiyX6Yo7yuGw717AAs3sLR6Zj+ymbLGo4R+PhmXKrgYrf8q/Ifd4g3qeh8DGyntOU1u8P4Av3HhbLgGn5MxSwcjLjDtaqaryJi9M1S4W5pbbJXOYznGdvH78MHgRSdOANM7FO8J3JWe7s89Y+u75gsWLgx/xeGmCd8+lj2HDBoClok8ZbShmKzsIkqqaqisquHvxfls33GMi84P6W0NvImnpxkaMvcaKbHOsAgsLc4xZq1h/5Fr+Cbe2yexLbqLRd0d827dQrpv/cgkV656i0g5GLaU0GgD2El9k2H01/U7F4+8y67iGlqsN+gfuMGFpjL2ZxdQ0fuM4p5zFBhmIiQUnaLM9wJdjNYWUT7gPk+vhdFvKP/hsX/D3G88iv7GiYiIyGvONjYDPGNqwrjMMAYhxX/CMVN83h/wtPfWRJg5NENL2y+4MJHT0h3UYRGJYGGSKScw/RvxpskPKf4TTvbXdHsDnq4H1NXeChswXRxoxDoHJH8S0s8QiYV7QMkrloGl1fUt3SIPLnnPx7TrQ/KCd4oECLpeYxhY2lT2dcCqDsdNC3uyCylpukT/wA36re1UFueRdaiRsbRm+iyhAcmVxJ/Wq7gDmaneQJrJhMnxMyf25rL/WDs9Qw+ZXXCwYLtPT1MZu/Y2MuoCzG9T/98+qiONSqSf5OZ/a8kye5Kf/7WMlmG75w/pZH64ncN7GxnfsJWqnwaojfQ8BvarpewqPUP/2BwLCw4WbLdoLC2k7OYTzFm1XO/aF6bIj5Oxcf/MPMforfAzCod/MXzoTzIcOj+X+aH7hiDew8jVn+yXKSlu564xGLw0R8/xDmxspPD86ZCbZ9LBA/7cM9PfkZ+dx67cXPZ3bqS53r8kI6ZzSD9JX8f7AQmKcT3GNvILIyO/MD79FFfKJ1j7T4Yk304t+8Iwo8CFra2UnG07yHq3mBNDm2kd7OOY70QnaXp3Bxnv1jBq9v62RAoP+kcVpjsPsT03j13ZhXQkf02DZ/ZuQv45rte9HVA0yjn9C9a2RuobGjl7dRI7b1HWcyXMtbGF6p+6KPKtiH/KaEMpOdty2ZWbx67sHeypcnC85h3/Q+zXKN2Ry+7ib3nk3yoiIiLiNn+JszfdC2Knu74JPwgfTfpJOpeb2Zawj+7b3jbME6wf51M5MMHiEsASi7YblOeVYrW/SX7HIN350QfoRdycDDf/6F7l5vqZpriLkpgpaGlYdlZxumWAIU/73XWvjvzSdobnPb32RTvDrSXsafiNDRlf0DcY2s8QWd4MXRe9k6ZwpxK7GD5obrS6vqWbvbeMw633A2bDLc3+SEXrJCT/je6WcLEGEb/FoUsMGgOZE/+iK2yE0WgLtQGxDcD1BNvV76hvaKS+7TIj089I3N/KzbDxrpXFn9arv/zxxx9/BG+Maqqd/Q0b6bvyKQk4mR/7BWvfNe7em8PufIYLMJnfIDllJ7mln1OVn0JsZWCcTA18R9PFW0zNuZ8HTJhTtpBfVM3x0owoFbFvUb6tjlEA3qH115Ms1dbQOvoYpwvARGLaexyrO8mRzICwHQCPrOU0XZxk2hGUudr8Fln7j9JWv48k249Utl5mdOJJUHJ2E8kZX9Bq3Ye96QxXJh4yPm0cHQJ4g7Ss7RSeaONIJu4R9OIzUPIhydP3GRp9yLzTmzjbRPKuo9RbPmVbhBe8ONZORe01bA4XmDaTVXKStqqdJOFgMOZzMFiYoKergyvXJ5nznIM5ZSuFFaei//0W7tNR2451/DEuz2OKLKepzvG8x1Pf8sGRfzHnAlPye9T/s41DAbMFnIy1nqCmbxKHC0wpb1NqfLzB0vwdzrd9z8D4YxxOl/scEzeTU3aK2qjXBsASs0Pf0dh1A5vn2jKZN5N58HMaTuwjdaSSjPoZ0nL2UVryCXnZyeH/8UVEROS19chaRl33DHPuxqWBp71a0UZDfmgbJjwngxUFDBTepTs/eJ/REvPD39PSfYPx2ae+dq05cTNZ+UepPrGP1IgNNRGPhVvUHW9n2HcNGZjeJC3zKPUXPo097dZUO/uroXO5IOTiDP2dZ7hw0/B/Y3qDlLR9FFs+D9svE4nM3de1jj80xAuCmN4gJW07qWnv01C/L2IfcUV9y6l2DjdDadFGpkd/5u64Hae3cJtpY/THith+pLLzBrZp7zUXypT4FpmZyeSVhYnZ+ISJm5neICXzAMfrvqAgbKNgdfGn9Sj+QOa6FBTIfHSOguBDRERERERERERE5JUV99JyERERERERERERkRdNgUwRERERERERERFZ9xTIFBERERERERERkXVPgUwRERERERERERFZ9/6EgUwXS8GbRERERERERERE5JX2pwhkLg3fYMz30yQDA86A/SIiIiIiIiIiIvJq+8sff/zxR/DGV8XC0BlqLt5ifPpZ8C7MaW+Tlfwex85+yrbgnSIiIiIiIiIiIvJKeaUDmSIiIiIiIiIiIvJ6+FMsLRcREREREREREZE/NwUyRUREREREREREZN1TIFNERERERERERETWPQUyRUREREREREREZN1TIFNERERERERERETWPQUyRUREREREREREZN37yx9//PFH8MYVWZzh7tVrXBi6w7T9GU6ny7PDhDlxM2lZ2yks+pC8zBQSNsDScA27+t7nYde+oCeSWC3OP2Tg4ndcue4kt6eP2vTgI0RERERkLTyy1tDaex+b3dvGdUsusXLTsiVgWzgLQ99Q3voLs45nBD4DmMybSS9voLc0I2iPyAos3KLueDuD009DrjU3E4lpW8k8+AXnwl5zE/RUfceAbZJpR9AzmN4kraSNq1XhHiey1iboqerAOjpJ4K13I6U/DcTQ/3UwWF9Jy8hjHL74hJcJc8oWKpouciQzaJfISth+pKT+O2xzwdeah+kNUtK2k116iob8xOC9sHCLxubLjI1OEvIUps3saermXLjHvYZWH8hcmKCnuYbWkaeeDSaSM3aSk/cemYmAc4bRofuMTj/Ge+8wmU24nC5I/ozrg1+Sanw+iWpx7BJNnTcYnnhsaJjEeiMXERERkdVYGKhkf8MDQzvMRE7LIN355oDjIlq8RfneOkZduNtwPVeozdwQfJTI6i3coLyg0XOteZnI6bhLd55xW2SDFTuw3AMwkfb3LnqrMtDVKi+eg/6KQurvGS5m0zu03j5HQYLxuMgWhyrZU+u5dyd/grX/JNt0MctzsGRr5+CRy9gDtm6krH+A6piCXzO0FJRitQO8SX5HL215CmAarWpp+cLwV+zee8wXxEzZ38z1X+9y09pGQ9kBDhUe4FDpSdqsfdwbu01f4zskgjuICYCLpYBnlOUkZB+lzdrHw9vVaOBIRERE5MVKKjxHb8lGwxYXo7WltEwZNkWTsI/mircAMO0/pSCmPD9JB+ju+YTkgI0uFuzOgC2ROVlwuL9LLrnIVQUx5aVJ5FDXRUqNF7PrAZaP24n51pv/NcfTAEzk1ymIKc/PhsyT9LW8gylgqxP7QsCGKJwsOPEMlPYpiBnGigOZ831l7K/+Gfdn20YK/3mbf7fuIzXiDcFMeuE57vz0GSnBu9a7xYeMxXqHfFGStpMZ2CoRERERkRcgPXNz0JYnWKtj71AnZWzBDKRnbw3eJbK20kM71NOdZ7hr+Dmi0TOcnQZTVgN9MaRPEHm+tpAZHEiwX+ZE60zQxkgSyUx7A9hCtjIjyHOWkB886PmMobZLzBu2RDJ/sZ0hp3sAKebVHq+ZFQUyF4cqOdg86VlSYyKnxUpzdoxvcPqX/Pv8+0HR6fXMyWDtCS7MBW8XERERkdeXCZOxQWu/TEnFLRYNmyIymzEDZnOM7WeRVUjIP03zLsPF6vqZuvqHxkPCmKGl+Wdcprep7zhAjKt3RZ4/kykglmDvLaN8KLZZxu577huYdUHLC5BuaQucRTz9HZa+Za7VxRvUdf0OyZ/QqQGkiOIPZC7ewlJvyAuUUU1rvFHinNO07TGBfY7Z4H3rzOJADXXGXBwiIiIiIiRSfL6ZHGN86F4dRTHPDhJ5UcwUtDQEXKuO641R0yFMna3BaodMSxuHFPSR9STpQ7oDZhnHmd5D5IXZQm3HZwHpPWytNfRHHPF0Mlh7hnHXmxQ2nkQlUCKLO5A51f2dIWH0GxSe+GhFI3R5ZQdY9yv9p9opavgtQrU/EREREXmtmfeF5CC091ZSN2bYILIeJOyjtckY/ImSDmHx/2j64QmkfUFrUZwTVkReAHPIst0nWI9/g269su6kf0nn3w3Xqus3mmojrN4Ya6flngvT/q9pzg7eKUZxBjIfYr3+xP+j+T0KV/oGZ/6NghTzuk0YvWRr54OPgytNiYiIiIgYhOQgfMrA8UoGw/ZSRF6ekCXm9sucOBs8g9hJf3UHNjZS1niUTUF7RdaLdIuVVuP17PgP5bGm9xB5gdKrApeYu+41YglJhzBDS8N/cJjeobluZ9A+CRZfIHPsBsPG9ztjJyuNY0IGtQOnyQve7OPgkfUMJYV5bN+2g4xtO8jYlsuuvBIqW28xG63c+ZKTR6OXaCwtYld2JYPezbM3qCnO9zxfLruLv6I/TLbV+b5y9hy5jDEt5mit9xx2kFFgHL1cYn7sBi2WMj7ILvJNaZ8f+IrDue7jd1WFv6Euzd6ipaqE3dmG587O44PSM/TYPCUC18DC6Lf8vTCPXbneryJKmi7Rb62h5uLa/R4RERGR11FC/jm6D77p3xBnNd3IlpgdaqfS1351f23PLaKk6UcexVwBVYSwS8ztP3zDBWN/aPQMTeMukkvaqF5uXePSHIOtNRzO8/bXPH21s3eYj9ZXU/9E1oSZgq5OCg3LPNcuvccqYhEiIbZQ22FcveFitD6w6Nr8xW+w2k1k1Z2mYLklzyu+9y4xO/AVh/MM9968Eipbf6S/tZLG0eDj16+4ApkLEzMY45jJqcFlw9bGku1bSnILKO2cIK2im5FHvzLx6H+M9pwii98Z6a3j4I58ygeC50tOcOFYIbtz91J6/Dv6Jh7jdAEs8ai1iKxDjQxNP/UsFXfhmP6Z+r8W0hHUyty0/zTXbw9iyfJvy6oZZOS256vnc9IXH3LhWBHbt71L/j8asd6cZM7lfuap1kLyG35m2vNmOUfO0Bowz93BsCWfrEN1DC4doK3/f0w8+pWJ//XTWZSCY+IarUcK2F7czli4CGjMnAxb8tlz/GfSmwa4d3fY/XW7jfzp76lv+wXbghoKIiIiIquV3XQuMKm//TLlyxZUiWLhDjV573Kw9haug6e5/uuvTDz6ldH/tlKc4sB2tYPSvbkcbn0YdsBcJKyEfbTWvW2YQfw7Z2v/z3MNPaSu/mdcMRSZmB+oZPeOMqxLb1N1to+bty/QWrIVk+N3Rn6wkL+3nCthJoyofyJrazvN59c2vcfKYxEiUaSfpNOYDsFYdG3x/7B0/o4p6xSdhdHTeaz83jvDheK9HGx2Utoz6L/3XvmShJEO6nsfYA+eJLqOxRXInJ01LCsHktOif8CtyFQ7B4/8C5vzLcqu9NKQv8WTg3MDCZkHODc8iCUD4CmjDYfYHzDiksGxCwPcGWsmx7fNwaClkIrxnXT+1xMw/PUKlgzvx/cTLjZ7P7w9EhJJSkokyTBauSHJsy0pkaQkMyRs59iFPh7e/oI0w0MXrldSPv4enf1dlKV5n2AjqaneI5wMVhRy4uZTTHtaudn1KdmbPAvsE5LJs1xk5J/vkwi4pi9TtncVS5NGz1Bz8ynmgw3UZhr+ITakcMQaOHolIiIiIquxhdqfAov/OK6fiLmaboDFW5QXWBhymNjTMUB36XZ8zcVNu6m1DnJx/5uAi+neCvZoOaXEIaGwjfosw4U60cGJASdTrY0MOJYvMrE4VMnBhhkyOwborf+U3MxEkpIyKLB0c+f8++4gqfM3mo6EyVmo/omstbVM77GqWIRIdMFVzN1F15wM1nZgYyu1HQei1p9Zzb13/uI3nJ12kWk5zSFvgwIgaSfNP9WSaTz4FRBXIHNh4VnAzxvWPMHlfWqOuPNSJh4+RbUv+GeUyJHz/jfa3lsTpkJZCqm+C+R3bJxi6MpJ8rx/sA0pHDlf7f9jTfzCimfRJu0k2/e7njA0mkL3lZPkpW6n+sptrp9voLXnHMeS3EfMXyzHcs8FbKW2cXfYHKEbsk/T5l2e5HpAXfWNFTVO7w78ggswmcNF9bdTcXBz8EYRERERWamE4OI/K6mma+fCP+rcxTUzqmnOC9taJLv1tC/o47rXyImBFQRM5TVl5lDHKfyxTBfjzYWU9T5ZvsjE/CXKah/gyvic5rwwfYycoxR7/wEc/+FsX+B1qf6JPA8JwcV/VpTeY61iESKRBC8xf4L1H4XU3XORdqKZ4mhRzFXdex0MDf0OgMkU5rEJH3Fsj2Fw6xUQVyDzeZs/286QC+BNCooygnf7JXxE1f43PD88wRo8ozLARgrKdodGthMyyPRdQY+Zmg3cvTJvUFhnHMHcQGrOAQoyvUOLd2jpcl9AZH0Y9ULNrjnqm+npGv+Ws7agA2LgdK+rx9H3bdgRqU2lB165yLuIiIjIuhYyOyjOarrDHZyfdn+bVfRRaBvWZzuWsrc837sY7/yOR0FHiESUcIBO4xJz1zOcMRSZGG77nmkgs3BfhGtzCzm+lW9gGwicLaz+iTwvIcV/4kzv8XxiESJBgpeYO5/hSv6M5jJjgoRQq7v3OljwxDXHu8MH+POK3iNMiHPdiiuQaTYHRmmXoiYSjdcM1puPPd9vITPaegYgu3Cn/4N3NTMqPVxr8lrMhB1c9Bq6xoj7s3v5ZfkJ+yjwrVl/yuhQ/NPWs7M9jVvXAyx/LaNlNCjfTNJR2pbJfyMiIiIi8QmpDh1HNd3BPveMNdhIujF/URgJ+fv8KY4c9xkK1zsRiSCh8CTFxqXcWQeWKTJxn8FR99Vpa97rL1Ya9FVx09PhAZibxBOXB/VP5LkKLWYVe3qPlxuLkNdLuuVzDOVYSN6zL2o6j9Xfew1BTvtlivJq6A+uWJVzmrb8wE3rWVyBzE3JgUlL7NPxB9cim2Eqnny5GW8b/tgz2F6BhtuULZ73K5HMNO9Iz8re66SyL8n33mGdk1iPF7CrtJ27qnApIiIi8hyZKei6GJALK7ZqujPYjFGf5SRtJd03iP6EqXgeKwKEzXMVydR9bJ4Za4XnDYVQo331nwyYYan+iTxXK07v8eePRch6Yorr1rsW997cE58bBj5/of7Qu+yuukFwPPNVEVcgMzV7q2GZzMqCaxFNzeC/d7hY9v1MyMC3YpunzM4F7l6PZmef+r5f9vUB2VmG0Uj7TNgpwNHtpK2/lizDLFHnxGUq9uZR0noftRdEREREnpfQ4j/LV9OdY9Y3QS2W1uJ2sgyzNte0bS4SbG7O0197yoLTWAg12pc5qMOu/ok8ZytJ7/EaxCLkFbYW995NR7n4zw9JMWxyjDRycEc+lQNzy1/z60xcgUxy3iMg97PtF4aNP6+ZJ0zHErWLK4y9vjhiudttMIaN44zae236iB9uX6Fpj6d4EADPsPWeYE9uOVfmDZtFREREZO2EzA7yVNONZaVjjJ3jwOZiYBookedldiqGizMS9U/kOQsp/uNJ7xHTrfc1iEXIq2s1996E7FP8+3YnpRn+lb/wlJGGYrIKzzAWS/6bdSK+QCb7KDZWM3Ldp3+tIpnpW/EXBot3acxG0pbJIbQepKYabqbTk/HNsEzZYnh/4rQhhUNnhxjvb6bIeNE6f6PpUGXYRNsiIiIisgbST9JXt9X/s+sBluPXIsw8SyHVsBw9vrREkJpunGshssYSE33FIOzjD2PK+RqR+ifynKVbrNQbava47tVR3heUk9XrNYhFyCtsLe+9STuptQ4z0lPNHmPmyLlrlH0cvhDQehRnIBPyygNzToy0rdWL3U624QYwPb5chTEHC94WYOJO8lYc5Xtx0nMMS/Mdk9iWuQIX7P4bbWZe9AqC4Tyy/hhQvXJD6j4arMOMnP+ENO+JuB5wtju+RrKIiIiIxC6hqDOwmq7L5SnoEyyw6qjDNrFMh8WBv7m4lbxdgXtF1lRqir8fOHGZC7HMnJxqp9yQG1b9E3lxzBSfD0zv4XKFv/O+DrEIeYWt+t7rYNB6K2AANSnzU84N/4/rje/gi2faL3N2yHDQOhZ3IJP0LwPLxdsvc2LZxOXh2LlSWkjlsHc1fiL5+Z4qdoBz5Eb0PBYLM8x67kMpBz9jW/D+9SjnAHm+G+kkAzejT26fmvJUTjO9x7GiaOXQw7OPXg5bvTIp5yRXDcuc7LGsWxIRERGRFQot/hNJbuF7hmq4/2EoaiRzhqlZ93emPZ9RHLXitMgqJe0k23cNP8bacCN6oH3xFuX/eEh2iT/vv/on8kKFpPeI5DWIRcira9X3Xge23nDX9AZSC89xvfFtX7tjNs6VIC9L/IFMzzRt46iyvbeUD1onYk4QujR7g/K8Q7SYv6A5z59cYlPZSQq94WDnz1wYihzom7fecJeTN71PbdXyt6aVMJv9r9HpjHwusdtJvcW/tMh28fsos1nvcGXEfXdMq6gmL3h3TJ4w2DcRvNEt/QB5nrctMVXLkERERERiteh8BjiJr3kYWvwnrJxT1PqWQ05yIdrMtOFrDLsA3uJ4ze7gvSJrbAulRf5gj2u8kYOWO2HTJCzN3qD8UB2zB7/m2CbjHvVPZKU891ynM8Zclx4hxX/CW2+xCBG/tbj3PsDaF/6aTij80FcLJznNUHB6HVtRINM9qjxA535/gua53mPsKT3D4FT4Nwdgaf4hPVX5ZB1qZH5PFyNd+wgcON5O83nviImL0fqvwudHWbxBXe9jYCOlPafJDd4fq2Uir+npm33f2/qu4Z3BuzD8FYebwn0AL/OEwUuLosxmnWrtYMQFpl3NXCxb+c3Rcf07+sO9h77G90YKD74aF6uIiIjIemAbmwGeMTURId9aJDHNDgpcDmnvraEl7Mj3DC1tv+DCRE5Ld1CHRSQWQcF4pzP6LB9gU9nXATOLHTct7MkupKTpEv0DN+i3tlNZnEfWoUbG0prps4T2M9Q/kZWZZGwacM5gCxfBiSKk+E9YLzgWIa+vxcBgfCyT5tbi3htxIp33fEzvULwneOf6tMJAJkAiea1DjJz/hEzPqmfnxDUsH+8lIzufw8dqqKzyfJUWsSt7B1l/reDsdAZN/f/j3/Xbg4KYHuknufnfWrLMnmTofy2jZdju+VB1Mj/czuG9jYxv2ErVTwPUpgc/AbA4gc1dnx5wMO/73mD+Fnd9bc8n2CZCL56kgwfwpcqY/o787Dx25eayv3Mjzd7MwQG/6ynD18MHJv3MFHQNcvGwO0hq7y1ld9UNHi26g6BLixP0V+RT1PuExP2tYYK9HrO3uOv7veHPHwDXb9QfqqR/1hhkdXC3vpEBp4nMui6qw72HIiIiIhJq/hJnb7pXzUx3fRO+oxtN+snANE3hJOyj+3YXRSkAT7B+nE/lwATu5uISi7YblOeVYrW/SX7HIN358acgElkcusSgsQsx8S+6wvZyjbZQ+5P32vRwPcF29TvqGxqpb7vMyPQzEve3cjNSP0b9E1mB+YvfMuQC+J3z9beWDboHS7e0LZ/eYy1iESLLmOr+FzbDz86hSzG0Jdbg3mu/TElxO3eNAwFLc/Qc78DGRgrPn6Yg7APXn7/88ccffwRvXInFqfv09V1icGSGWcczfwJz0xuYzRvJyv+UIyXvk73Jv5Q8OidTA9/RdPEWU3Pe5zNhTtlCflE1x0szSAp+CBP0VHVgHZ3EHpDH10Ryxk5KLW0cyXQfc2FkksAxdOMx/q2LY+1U1F7D5nCBaTNZJSdpq9pJku1H/t58Cdv005Bk7abkreSkbaGg7hQFoSfpszR/h/Nt3zMw/hiH0/MKzW+SmrWPYye+oCA19L1aGDpDo/UhoxOPg36v+/zT0t6noX4fScBgRSHDOZ+T45pkYOg+swtLvgTHiWkHOF4X/neIiIiISKBH1jLqumeY87TZ/Dzt04o2GvKNJUCjcTJYUcBA4V2684P3GS0xP/w9Ld03GJ99ivtXmzAnbiYr/yjVJ/ahppzExfYjlZ03sE37+x/BTIlvkZmZTF5ZYL8oUJi+mukNUjKj9zHUP5H4TNBT2kjX9GPP/c/A9AYpafs4fjZ6nzvA4i3K996gcOwcBcH7AoS5vpeNRYhE5o3jjIe7lsF3fWWlLhdHCnNtLnvvnaGl+AyUfEjy9H2GRh8y73ThvvWaSN51lHrLp2yL+DvXnzULZIqIiIiIiIiIiIg8L6tYWi4iIiIiIiIiIiLyYiiQKSIiIiIiIiIiIuueApkiIiIiIiIiIiKy7imQKSIiIiIiIiIiIuueApkiIiIiIiIiIiKy7imQKSIiIiIiIiIiIuueApkiIiIiIiIiIiKy7imQKSIiIiIiIiIiIuueApkiIiIiIiIiIiKy7imQKSIiIiIiIiIiIuueApkiIiIiIiIiIiKy7imQKSIiIiIiIiIiIuueApkiIiIiIiIiIiKy7imQKSIiIiIiIiIiIuueApkiIiIiIiIiIiKy7imQKSIiIiIiIiIiIuve/wP5NJPNq1X3MwAAAABJRU5ErkJggg=="
    }
   },
   "cell_type": "markdown",
   "id": "dab6d976-3d92-415c-b58c-71c3a3dfc2fd",
   "metadata": {},
   "source": [
    "![image.png](attachment:36cf6773-6c0c-41cb-8ecd-783aaf376389.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb94e5e3-f219-4846-a9c4-973b7429f539",
   "metadata": {},
   "source": [
    "#### 4、Dube、Manning和Naidu实验"
   ]
  },
  {
   "attachments": {
    "65156c77-a6fd-4cc0-80f5-906714a5b519.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "79860da8-0cc7-4bcd-87e1-44585bcfd155",
   "metadata": {},
   "source": [
    "![image.png](attachment:65156c77-a6fd-4cc0-80f5-906714a5b519.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91490446-0fe9-4037-b042-ed70f34bb3e6",
   "metadata": {},
   "source": [
    "#### 5、简单OLS回归结果"
   ]
  },
  {
   "attachments": {
    "e4c87c1d-8a1d-42bf-99a9-89139c7ca63b.png": {
     "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmkAAADxCAYAAACQ2yDVAAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAAAJcEhZcwAADsMAAA7DAcdvqGQAAJrHSURBVHhe7N15XE35/wfwV3sR0YIIWca+S8QUsmXf9xpbyJZsQ8ZYxpaxjN0IwzAYZB0J2SWESiWFyhKVkvbtLu/fH9/u+XXOvTe3kJs+z8fjPmbu+/P+3Jv7+ZzP/dxzPuccDSIiMAzDMAzDMGpFUxhgGIZhGIZhvj02SWMYhmEYhlFDbJLGMAzDMAyjhtgkjWEYhmEYRg2xSRrDMAzDMIwaYpM0hmEYhmEYNcQmaQzDMAzDMGqITdIYhmEYhmHUEJukMQzDMAzDqCE2SWMYhmEYhlFDbJLGMAzDMAyjhtgkjWEYhmEYRg2xSRrDMAzDMIwaYpM0hmEYhmEYNcQmaUyZJpFI8PbtW2G4UFKptMh1mM/z6tUrYeiTXr9+LQwxpUhKSgrS0tKE4UKxbfP7U9b7AZukMWWWSCSCs7MzRCKRsKhQmpqa2Lp1Kx49eiQsYr6C33//HY8fPxaGP8nPzw/79u0ThplSIDY2FrNnz4aenp6wqFBs2/y+sH4AaBARCYMMUxZMnz4dffv2Rd++fYVFAID4+HhcvnwZP/30k7AIubm5GDZsGHbv3o3q1asLi5kv5NixYwgMDMS6det48czMTJw5cwZhYWGwsLBA165d0aRJE14OALi5uaFv377o0aOHsIhRU9nZ2Rg4cCD27duHmjVr8sri4uJw8uRJJCYmwtjYGIMGDULt2rV5OWzb/D4U1g+Epk6dik2bNqF8+fJc7LvpB8QwZdClS5do0qRJwjBFR0fTP//8Q/PmzSMLCwvq0qWLMIUTHBxMgwcPFoaZL+T9+/fUvn17EolEvHhkZCSNGzeOHj58SHFxcbRv3z6qUKECzZ8/n5dHRJSTk0NWVlaUkZEhLGLUlLu7Ox06dEgYpjNnztDs2bMpLi6OiIh8fHzIwMCAdu3aJUxl2+Z3QFk/EDp8+DABoKSkJGHRd9EP2CSNKXMkEgk1adKEwsLChEX07NkzunTpEqWlpVGXLl0KnaQREfXs2ZOuXbsmDDNfgIuLC+3cuVMYpv79+3Nf1DLbtm0jALR//35enIhozZo1tHTpUmGYUUMvX76kunXrUl5eHi8ulUqpVq1aNG/ePF7cwcGBNDU1FX5Bs22z9FLWD4Tev39Pbdu2VTpJo++gH7A1aUyZc+3aNVSpUgVNmzYVFuGHH35Az549UaFCBWGRQlOnTsWOHTuEYeYzpaWl4dSpU3BycuLF37x5g2vXrmHXrl28+OjRowEAhw4d4sUBYPLkydizZw/EYrGwiFEze/bswU8//QQdHR1eXCQSITU1FefOnePFq1WrBqlUipcvX/LiYNtmqaasHwj98ccfmDRpkjDMU9r7AZukMWXO0aNH0b17d2G4WOzs7PDff/8hIyNDWMR8hrNnz6JFixYwNDTkxSUSCXJycuDn58eLGxsbQ0tLC9HR0bw4AJiamsLExARXr14VFjFqRtm2qauri2fPnuHBgwe8eGBgIExMTBSuR2TbZumlrB8UdObMGfTq1QvlypUTFvGU9n7AJmlMmXPz5k20b99eGC4WU1NT1K1bF3fu3BEWMZ9BWRtZWloiMjISp0+f5sWjoqIgkUgUflkDwI8//ogbN24Iw4waiY2NxevXr9GmTRthEQCgSpUqMDIy4p7fv38fT548wfbt22FgYMDLBds2S61P9QMA+PjxI0JDQ9G5c2dhkZzS3g/YJI0pU0QiEaKiopR+mRdH/fr1i3WJCEa5iIgIpW1Ur149VKxYkReTHeZctGgRLy7D2kj9RUREoE6dOgonXDJEhKNHj2LJkiWYM2cOfH19MWrUKGEah7V76aNKP9i0aRPc3NyEYaVKcz9gkzSmTElMTATyD499KcbGxsW62Cqj3Pv371Vuo4iICKxfvx6rVq2Cra2tsBhgbVQqqNLmGhoasLe3x4gRI2Brawt3d3eEhIQI0zis3UufT/WDixcv4scff1R53TBKeT9gkzSmTElMTISOjg709fWFRcVmbGxc5CtiM4VLTEzkHdpSRiQSwcnJCXPnzsUvv/wiLOawNlJ/qrZ51apV0aJFC6xbtw5Vq1ZFx44dERUVJUwDWLuXSoX1g7S0NNy9exe9evUSFhWqNPcDNkljyhSJRAKpVCoMfxapVPrJxatM0UgkEkgkEmGYh4gwefJkODk5YdWqVcJiHtZG6k+VNhfq378/MjMzsXbtWmERwNq9VCqsH/zxxx+YM2eOMPxJpbkfsEkaU6ZUqlQJEokEWVlZwqJiS0lJQZUqVYRh5jNUqlTpk798f/31Vzg4OMDV1ZWLeXt783JkWBupv8La/OLFi2jUqBF8fHx4cTMzMwBAeHg4Ly7D2r30KawfxMfHY9asWXBycuIemzZtAgC4uLjAyckJHz9+FFYr1f2ATdKYMqVmzZrQ0tJCQkKCsKjYkpKSULVqVWGY+QyWlpaFttGff/4JKysruUXjyi6zwdpI/RXW5r6+voiMjERgYCAvHhsbCwAKr3kI1u6lUmH9YNeuXTh06BDvMWTIECB/TDh06BAqV64srFaq+wGbpDFlio6ODpo3b46goCBhkZyPHz8iJSVFGJYTFBRU6OniTNG1bdtWaRudOHECnp6euHr1KmbNmoVZs2ZhxowZcHR0RF5enjAdYG1UKrRu3RqxsbH48OGDsAj9+vXDyJEjMX/+fF7c19cX+vr6mD17Ni8uw9q99CmsHyiSnp4OAIVeB61U9wPhLQgY5ns3Z84cWrx4sTBMRESPHj2iiRMn0pAhQ8jIyIiMjIxo6NChNHHiRAoKChKm05s3b8jIyIhyc3OFRcxnOHv2LHXs2FEYpqioKNLT0yMACh/btm0TViEionr16tG9e/eEYUbNtG7dmi5fviwMExGRp6cnubm50blz5yg0NJSWLl1KNWrUIG9vb2EqEds2S7XC+oHM2bNnafTo0VSjRg2qUKECdezYkRwdHSknJ4eXV9r7gQYRkXDixjDfs+DgYIwaNQoRERHCoiLbuXMnQkND5W5TxHwekUiEWrVq4cGDB7CwsBAWF0l4eDiGDRumdN0Soz42b96MiIgI/Pnnn8IiIH/v9u3bt/H27Vs0aNAAHTp0QPny5YVpANs2S7VP9YOiKO39gE3SmDLJ3t4ey5YtU+mK1YVp2bIljh8/joYNGwqLmM/022+/gYiwbNkyYVGRTJs2De3atcPEiROFRYya+fjxI1q3bo2wsDC5W4IVFds2Sy/WD/4fW5PGlElbt27F77//js/5jXLmzBl07dq11G786m7BggW4ePGiymtTFImNjcWTJ08wfvx4YRGjhipXroxFixZhy5YtwqIiYdtm6cb6wf9jkzSmTGrWrBl69uzJnb5dVG/fvsWuXbuUXp+J+XwGBgbYvHkzpk2bJixSiVgshouLC/bu3QtNTTbUlRZTp05FSEgI7t27JyxSCds2vw+sH/wPG7mYMmv27NnIyckp8iAgkUiwevVqHDhwoND7yzGfr3379hg3blyx1qZs3LgRixYtQoMGDYRFjBrT0NDA/v37cfDgwSLvRWXb5veD9YP/YWvSmDJPLBZDW1tbGC5UceowxVecz7s4dRj1QUQgoiLvBWXt/n0p6/2ATdIYhmEYhmHUUNGmpgzDMAzDMEyJ4O1J09DQ4JcyDMMwDMMwJabgAU52uJNhGIZhGEYNscOdDMMwDMMwaohN0hiGYRiGYdQQm6QxDMMwDMOoITZJYxiGYRiGUUNsksYwDMMwDKOG2CSNYRiGYRhGDbFJGsMwDMMwjBpikzSGYRiGYRg1xCZpDMMwDMMwaohN0hiGYRiGYdQQm6QxDMMwDMOoITZJYxiGYRiGUUNsksYwDMMwDKOG2CSNYRiGYRhGDbFJGsMwDMMwjBpikzSGYRiGYRg1xCZpDMMwDMMwaohN0hiGYRiGYdQQm6QxDMMwDMOoITZJYxiGYRiGUUNsksYwDMMwDKOG2CSNYRiGYRhGDbFJGsMwDMMwjBpikzSGYRiGYRg1xCZpDMMwDMMwaohN0tRYTk4O3r17h7y8PGERwzAMwzDfOQ0iImFQnaxcuRKPHj2Cn58fJBIJWrdujZo1a0IkEkEikUBDQwOTJk1Cjx49hFVLtcWLF+Pw4cN4/fo1wsLC0LRpU2FKmfHmzRucPn0aYrEYZmZmGD58OPT19YVpSqlaX9U8mYCAAGRmZqJr167CIo63tzceP34MTU1N2Nvbw9raWpjCiY6OxrVr1xAXF4e2bduiT58+wpRSJSMjA8ePH0daWhq0tbUxfPhwVK1aVZimVHHr//nnn2jatClsbW25WFpaGg4dOoQ+ffrA0tISIpEIL1++xKVLl+Di4gIdHR3eawBAXl4eduzYgTlz5giLmEIUdTsSUrX+mzdvcOHCBbx69QoNGjRA3759YWZmJkxDdnY2Tpw4gZcvX6JixYoYOnQoatasycvx9PSEhoYG2rdvDwMDA2hq8vdfGBoaqtT3yipV20yZR48e4caNG5BIJGjVqhV69uwpTAFUfB83Nzf06tULtWvXhq6uLjQ0NHjlZmZmqFixIi8mo2jsUETVvC+CSolu3boRAIqPj+fFHzx4QFWqVKF+/fpRbm4ur6y0u3PnDgGgsLAwYVGZ4ePjQ3Z2dly7+/r6UocOHSghIUGYqpCq9VXNCwgIoD179tDUqVNJR0eHli9fziuXycnJIVdXV/L39yepVErp6em0cuVKmj59ujCViIjWr19Pjo6OFB8fT1KplH7//XfauHGjMK3UiImJoXbt2lFAQAD33MbGhvz8/ISpChW3/vPnz8nAwIC8vLx48eDgYAJAAEhLS4s0NTVJR0eHdu7cyctLTU2lEydO0IoVK8jKyopK0RCpFlTdjpRRtf6ZM2do7ty5FBUVRVFRUbRgwQKqVKkS/fvvv7y8Fy9e0Jw5cyg6OpqIiN68eUNjxoyhQ4cO8fLGjBnD9Q9Fj3Xr1vHymf+napsps3LlSnJ2dqbs7GySSCTk4eFBo0aNIqlUystT9X2qV68u136yh6amJt29e5eXL6Ns7BBSNe9LKTUj0LBhwwgAJSUlCYto8+bNBIDmzp0rLCrVZF8sZXWSlpycTGZmZnTv3j1e3N3dnYYMGcKLKaJqfVXziIj8/f3Jz8+PRCIRAVA6SVu+fDk3wSho7NixdPnyZV5syZIlNGDAAO65WCwmfX196tq1Ky+vNOnevTt5eHjwYpcuXaKaNWtSZmYmL65IcepLpVL66aefCIDcABocHEzdunWjkSNHUt++fWnRokX04sULXg4R0cePH+ncuXMUGxtLy5cvJ7BJmsqKsh0pomr9+Ph4GjhwIEkkEl7e0KFDSV9fn8LDw7nYoEGDKC8vj5eXl5dHjRo1ovT0dC7m4OBAHh4etHXrVtq+fTv3WLNmDdna2pJYLOa9BvM/qraZMrdv36ZKlSrJ7WCxsbGhrVu3cs9VfZ/U1FRq3749bdy4kbZt28Zry8mTJ9PPP//Mqy9T2NhRkKp5X1KpGYEKm6TdvXuXAFDdunWFRaVaWZ+k7d27l8zMzIRhun37NmlpadGHDx+ERTyq1lc1T6iwSVrHjh3p8ePHwjBt27aN96v85cuXpKenRw8fPuTl7d69m65evcqLlRZRUVEK+61EIiFdXV06e/YsLy5U3Pp79+6l8+fPKxxAg4ODafPmzbzYp7BJWtEUdzuSUbX+wYMHydzcnM6cOcPL8/LyIgD022+/ERFRVlYWmZubK5xgDR06lO7fv0+U/8W7YMECYQoREc2aNYuioqKEYSafqm2mjKOjIw0bNkwYppUrV1Lr1q2556q+z7179+jEiRPCNMrKyqKxY8fKTQZlChs7ClI170v6Lk4cyMnJAQBYWFgIizhSqRRJSUnC8BeRlpaGlJQUYViOqsv/VM373l26dAnGxsbCMMzNzSGRSODr6yss4lG1vqp5RWFgYABnZ2fExsby4v7+/mjfvj33fPXq1TA0NETbtm15eVOmTIG9vT0vVlpcvHgRAGBiYsKLa2pqokqVKvDx8eHFhYpT//Xr10hPT0ezZs2ERUwJ+dztSNX6GhoaiIuLQ0hICC9Pth4tOjoaAKCjo4Pk5GRMmTIF2dnZXJ5IJMLz58/RqFEjAEBubi4cHR25chkvLy+0bdsWdevWFRYx+VRtM0WICJcvX5bbzpFfPzg4GPHx8UAR3sfMzAxdunQRpuHXX3/FL7/8Al1dXWGRymOHqnlf2ncxSfP09ESFChWwefNmYRHS0tLg7OyM5cuXw8vLC0OGDMHBgwcBAAkJCRg0aBDs7e3RpUsXDB48GLGxsRg6dCi6deuGzp07Y+nSpQCAvXv3ws7ODvb29nB2dgYAREREYN68eThy5AiOHDkCBwcHXLt2jff+ly5dQrt27WBoaAhPT08cOHAA8+fPR8uWLXlf4B8+fMCsWbOwYMECbN68GWvXrpX7gi9rQkJCUL58eWEYlStX5soLo2p9VfOKYtq0aXjw4AGaNm2KXbt2gYiwYcMGNGzYEJ07d+by7t+/j4YNGyIpKQm//fYb1q1bh23btiErK4v3eqWJ7PNS9pl+6vMsTv0dO3ZgxowZwrCchw8fYvPmzfjjjz8QFBQkLGY+w+duR6rWd3R0RGhoKNzd3Xl5z549AwA0adIEAKCtrY3Jkyfjr7/+QosWLXD9+nVkZ2dj6tSpWLVqFbd4XF9fHy1atOC9VlxcHM6dO4dx48bx4gyfqm2mSEJCAt6/f6+0PhEhNDQUKML71K1bF6amprycixcvwtzcHI0bN+bFZVQdO1TN+9JK3SQtODiYO9vzwIEDGDJkCJDfSK1bt+blikQi2Nraon79+vjtt9/g4uKCAwcO4JdffoG3tzeqVq2KM2fOoFy5cnjx4gW8vLxgYWEBLy8vaGhowMTEBL/99hsAwNnZGba2tmjYsCE8PT2B/MHC3NwcLi4umD59On7//Xf06tULT5484f6GXr164d69ezAyMsKjR49Qp04djBkzBmFhYVwHfPPmDVq0aIG+ffti/fr1mDNnDhYsWIBjx45xr1MWpaWlKdwwtbW1AQCpqanCIh5V66uaVxRDhw7Frl27kJeXh+nTp8PS0hL6+vpYtmwZlyOVSvHs2TNUrFgR+/btw6JFi7Bw4UL88MMPsLa2xps3b3ivWVqkpaUBAMqVKycsgra29ic/z6LWP3ToEEaOHKnwDM2Cjh8/jsTERLi6umLy5MlYuHAh1q5dK0xjiulzt6Oi1G/WrBkXlzl06BBMTU25H9EAsGHDBkyZMgUvXryAvb09WrRogRkzZqB///68ukLu7u6YPn26MMwIFKXNhGTbuSr1i/s+IpEIK1asgIuLi7AIKMLYoWre11DqJmk5OTnIycmBWCzG69evERMTg+HDh8PS0lKYiq1btyIsLAwzZ87kYhUrVsSwYcOwceNGLjZjxgy8ffsWL1++BPJ3p1tZWeHevXuQSqVcHvI3etnp2ZmZmbh69SpX1qJFC5ibm3N76mS0tLRgbGyM0NBQdO7cGW3atEF6ejp69+4N5E8AGzVqBAcHB66Otra2wl3wZUlWVpbC3dOyNsnMzBQW8ahaX9W8orK3t8fw4cPRsWNHvH79GgsXLsSuXbu48nfv3iEnJwc3b97E2LFjub/BwcEBJiYmcHV1LfBqpUdWVha0tLSgpaUlLIJUKv3k51mU+nFxcYiLi0ObNm14eUK1atXC9u3b0bt3b2hqasLQ0BDr1q3D4sWL4efnJ0xniuFzt6PPqX/w4EHcv38fR48e5fauAICenh4GDRoEJycn1KxZEy9evMDgwYNx+/ZtXv2CgoODERERgQ4dOgiLGIHPaTPZ0QJV6hf3fXbu3AlbW1uFEzxVxw5V876WUjdJ69ChAzp16oQuXbpg6dKl+PnnnzFkyBCF61QuXLiAGjVq4O3bt4iMjOQeRkZGvL1dPXr0QJUqVXD48GEulpWVhfT0dO7wpUQiQV5eHq+xQ0JC4O3tDQCIjIzEtWvXoKWlhY8fP3I5BbVs2ZL7f9legg8fPuDy5csKr/Omp6cnDJUphoaGkEgkwnChv8AKUrW+qnlFcfr0afz222/Yu3cv/Pz8sGvXLujo6GD69OncHlLZoFO7dm259ZRWVlY4c+YM3r9/z4uXBso+TxTyi7igotTfunUrZs+ezctRpHLlynJ72lu1agU9PT2FyySYolPWbqpuR8Wt/+rVK/z888/w8vJC9+7deWXu7u4ICwvDwYMHER4eDldXV7x9+xa9evVCTEwML1dm27ZtpXY9aEkrbpshvy7yv1uFhPWL8z5EhG3btsn1CRlVxw5V876WUjdJExo9ejR0dHQUXnAyKioK5cqVw8uXL3kPGxsbeHl5cXna2toYOXIk/vnnHyB/nVCXLl0wZMgQbuJ2/fp1uQ3348ePcHV1xYABA3Dr1i0YGBjAwMBA6cJ/4bFyAAgLCwMAVKpUSVhU5hkZGXEnhRQk2zCNjIyERTyq1lc1T1XJyclwc3PDzp07uYspuri44PHjx2jevDkWL14M5Le5lpaWwgtwyibxsv5Rmsg+r9zcXGER0tLSPvl5qlr/+PHj6N+/v0o/Zq5fv46EhAReTENDAxUqVOCWHTCf53O3o+LUT0lJgZOTE06cOIF+/frxyq5evYr79+9jwYIFQP4X/ZYtW+Dr6wt9fX2sWrWKl4/8H+fHjx9XeGSGkVecNpORlalSvzjvc/v2bURFRSlsS1XHDlXzvqZSP0lD/pddZGQk0tPTefEGDRpAU1MTvXr1knsIrxQ8duxYPH/+HAEBAfD29kbfvn0xduxYnDx5EtnZ2fD19eXt7UpISICVlRWysrJw5swZTJ48GTY2NoU2pvDKx8g/DIMCu36Z/2dlZaXwjFzZhmllZSUs4lG1vqp5qvL390ebNm3krmpdu3ZteHl5ITo6Gjk5OdDV1UXjxo0VDj6y3fjC1ygNZJ+Xss/0U5+nqvXj4+Oxa9cuODk5cY/JkycDALZs2QInJyf4+/sjPDwc9vb2mDJliuDV/rdmpUKFCsIwUwyfux0VtX5ubi6mTp3KHdKSkR3d8PHxwcCBAwvU+B97e3t4eHggPDxcWIS7d+8iIyODd8iUUa6obVaQmZkZateurbS+pqYmt/e7OO8jO+NTUVuqOnaomvdVCa/Joa4Ku05a/fr1CQDv4qG5ubm0YcMG0tDQoLdv3/LyiYjOnTsnDFH9+vVp2rRptHjxYqL8i4pWq1aN/v77b/rll194ub/99hsBoLi4OF7cwsKCnJ2difKvsyTTrFkzWrJkSYHM/1evXj0aO3asMEyXLl1SeL2osuL06dNUrlw5EolEvPjJkydJW1ubUlJSePHk5GTec1Xrq5onBCXXSbt+/Tp16dJFGCbK75cNGjTgni9cuJAqVqwod3XtSZMmkb6+PmVnZ/PipUFSUhJpaWnRnTt3ePEPHz4QALpw4QIvLmy3otYv6MaNG3LXMEpISKCWLVvS9evXebnx8fGkoaFBM2fO5MVl2HXSiqao25Gw3YtSXyKR0OzZsykyMpKXm5yczF0nbdmyZQq3TyKiq1ev0sSJE4VhWrVqFQEgX19fYRGjQFHaLC8vj3cBYSKi2bNnU48ePXgxyr8+nbW1Nfe8KO8j0717dwIgdzFjZRSNHYqomvellJo9abIZs3BvGfJPu0X+gk8AiImJwenTpzF79my0bt0a69ev5+W/fPkSDx484MUAYMyYMfD09ES3bt2A/AX/o0aNwty5c9G3b19erux+YQUPbT5+/BiVKlXi9owUXPgsEokU/u3Ivw/YuXPn8OrVKy4mlUqxf/9+QMnu4LKgV69eMDU1lVtvePbsWUyYMIG3i3v+/PkwMzPDnTt3uJiq9VXNK0h2XTxF18fr0KEDEhIS8PDhQ2ERjhw5wjuNe8aMGZBKpby/WyQS4erVq/j111/l7ktXGpiYmGDw4ME4efIkL3727Fk0bdqU274A4L///oOJiQk8PDy4WFHqC8m2sYyMDC5WpUoVdO3aVW5N2uHDh2FsbIwlS5bw4jKytaXKzhxj+IqyHX3O9goArq6ueP78ObZt24ZZs2Zh5syZmDZtGoYNG8Zd/2zo0KE4duyYwvY7duyYwjP+ZJc9kq2XYgpXlDazsbGBpaUlb9scP348/P39eXvJxGIxvL29eevAivI+MrGxsdDT01P5jExFY4ciquZ9McJZm7r57bffaPTo0WRqakpGRkZkZ2dH48aNo1evXnE5jx8/pnr16lHHjh0pPj6eFi9eTImJiUT5t4mYMGECjR07lg4fPkw7d+6klStXKrzy8LNnz8jS0pJ3u5FHjx5R/fr1eXlERCkpKTR06FCysbGho0eP0sGDB+nQoUP04MEDqly5Mrm4uNDjx4/J19eXhg4dShUrVqQaNWrQmDFjFF4x/cqVK9SjRw/avXs3nTp1in799VfauXMnAaBGjRrRsmXLhFXKhICAALK2tiY/Pz/KyMigHTt2UI8ePSg1NZWXt3XrVqpZsyY9efKEF1e1vqp5hw8fpokTJ5KdnR0ZGRlRjRo1yNHRkSZMmEA5OTlcXmRkJHXv3p02bdpEgYGBdPfuXVqyZAmtXLmS93pERDdv3qT27dvThQsX6MGDBzR69GiaPXu2yr8A1VFSUhLZ2trSgQMHKCMjg65cuUJWVlZy7ePv7081atSQu5eiqvVlIiMjydHRkZo3b04VK1akhg0b0tixYykoKIiIiN69e0eTJ0+mU6dOUVBQEK1Zs4aaNWtGDx484L1OZmYmN15Ur16djIyMqEuXLjRx4kS5+0Iy8lTdjj5ne/3nn38ICu7LKHuEhoZyuf/99x/Z29vTkSNHKCwsjHx9fcnFxUXpXpBJkyYRAAoJCREWMUqo0mZERKNGjaI2bdrIjWv79u0jBwcHioqKosTERJo4caLCO0Co+j4y9erVI2NjY2FYzqfGjqLmfWkapGyVeykjFovh4+ODuLg4dO/eXe4q0bm5uYiKikK9evUKXTeWkZEh9ysqPT1d6bqV5ORkvH79GhYWFtyJAZmZmdDX11d4CYFPiY2Nhba2NqpVq4b09HS8efMGJiYmMDY2VvkXwfcmIyMDPj4+SEhIQPPmzWFnZ6dwfZ8yqtZXNU9VRMStiapUqRJsbGzkzuKU+fDhA27evIn09HTY2NigQYMGwpRSRyKR4Pr163j69CksLCzQu3fvIu0Z/Nz6QiKRCHfv3kVERAQaN24Ma2vrQscCpng+dzv63PpC2dnZuHnzJmJiYmBpaYlOnTopXesZExMDf39/jB07VljEFOJz2+zdu3e4ePEi8vLy0LlzZ6UXni3K+9y5cwe5ublyJ/yVNt/NJI1hGIZhGOZ7UmrWpDEMwzAMw5QlbJLGMAzDMAyjhtgkjWEYhmEYRg2xSRrDMAzDMIwaYpM0hmEYhmEYNcQmaQzDMAzDMGqITdIYtVLwrgvM/3vz5g3v7hbqRiKR4O3bt8Lwd0vd26OklLXt9fXr18JQmVPW2lxVX6tvsEkaozauXbuGffv2CcNM/gWV3dzc1HJiIBKJ4OzsDJFIJCz6bqlze5SUsri9+vn5lbl/c0Flsc1V9bX6BruYLaMWnj17Bjc3N5w7dw7a2tq8sjdv3uD06dMQi8UwMzPD8OHDi3TleVXrq5onExAQgMzMTHTt2lVYxPH29sbjx4+hqakJe3t7WFtbC1MAAIGBgbh+/TqysrLQsmVL9OvXD5qa/N9QJ06cQFhYGFasWMGLf2vTp09H37595e5vm5GRgePHjyMtLQ3a2toYPnw4qlatysspjCr109LScOjQIfTp0weWlpYQiUR4+fIlLl26BBcXF7m7dHyqPR49eoQTJ05g+PDhMDQ0lOuLWlpasLS0BNS4PUqCOmyvMp/aDlXpR4r8+eefaNq0KWxtbXlxNzc39O3bFz169ODFv3eFtfmjR49w48YNSCQStGrVCj179uSVf4qq9VXtG3FxcTh58iQSExNhbGyMQYMGoXbt2sI0ZGdn48SJE3j58iUqVqyIoUOHombNmrycoowxX6VvCO8TxTDfgp2dHcXExAjD5OPjQ3Z2dhQfH09ERL6+vtShQwdKSEgQpiqkan1V8wICAmjPnj00depU0tHRoeXLl/PKZXJycsjV1ZX8/f1JKpVSeno6rVy5kqZPny5MJQ8PDzp27Bjl5eVRXl4eeXl5Ua9evSgtLU2YSkOHDqXAwEBh+Ju5dOkSTZo0SRimmJgYateuHQUEBHDPbWxsyM/PT5iqkKr1g4ODuXs2amlpkaamJuno6NDOnTt5eaq2h6enp9y9IAs+evfuzctXt/YoKd96e1V1O1S1Hwk9f/6cDAwMFN7jMycnh6ysrCgjI0NY9F1T1uYrV64kZ2dnys7OJolEQh4eHjRq1CiSSqXCVIVUra9q3zhz5gzNnj2b4uLiuHoGBga0a9cuXt6LFy9ozpw5FB0dTUREb968oTFjxsjdR1jVMYa+Ut9gkzTmm/v3339pxIgRwjAlJyeTmZkZ3bt3jxd3d3enIUOG8GKKqFpf1TzKvyG4n58fiUQiAqD0y2H58uXcF0NBY8eOpcuXL3PPr1+/TuvXr+flEBHt2bOHFi9eLAyTv78/2dnZCcPfhEQioSZNmlBYWJiwiLp3704eHh682KVLl6hmzZqUmZnJiyuiav3g4GDq1q0bjRw5kvr27UuLFi2iFy9e8OpREdpj7ty5tHjxYtqyZQtt27aNtm/fTtu3b6dt27ZR8+bNKTY2lldfndqjpHzr7ZWKsB2q2o8Kkkql9NNPPxEAhZM0IqI1a9bQ0qVLheHvlrI2v337NlWqVIlyc3N5cRsbG9q6dSsvpoiq9VXtG1KplGrVqkXz5s3j5Tk4OJCmpiYlJSVxsUGDBsnd7D0vL48aNWpE6enpXEzVMUbmS/cNNkljvrlOnTrRjRs3hGHau3cvmZmZCcN0+/Zt0tLSog8fPgiLeFStr2qeUGFfDh07dqTHjx8Lw7Rt2zZat24d91w2IRAKDQ2V22sj07x5cwoJCRGGS5yvry916dJFGKaoqCgCIDd5k0gkpKurS2fPnuXFhYpSPzg4mDZv3szLU0TV9hAO7jIHDhyg48ePC8NEatQeJeVbb69CyrbDovSjgvbu3Uvnz58vdJKWmJhI5ubmJBKJhEXfJWVt7ujoSMOGDROGaeXKldS6dWthWI6q9VXtG7m5uWRkZEQ//PADL2/8+PEEgB4+fEhERFlZWWRubk5isZiXR/l7x+/fv889V3WMkfnSfYOdOMB8U2/evEFgYCA6deokLMKlS5dgbGwsDMPc3BwSiQS+vr7CIh5V66uaVxQGBgZwdnZGbGwsL+7v74/27dvz8latWgU/Pz+5vA4dOvBiMp07d8aRI0eE4RJ39OhRdO/eXRjGxYsXAQAmJia8uKamJqpUqQIfHx9eXOhz6yuianuMGDGCVw4A0dHRePToEYYPHy4sAtSoPUqCOmyvqipOP3r9+jXS09PRrFkzYRGPqakpTExMcPXqVWHRd0dZmxMRLl++LPf5Ir/NgoODER8fLyziFKW+qn1DV1cXz549w4MHD3h5gYGBMDExQZMmTQAAOjo6SE5OxpQpU5Cdnc3liUQiPH/+HI0aNSpQu2i+dN9gkzTmm7p58ybatGkjtxAVAEJCQlC+fHlhGJUrV+bKC6NqfVXzimLatGl48OABmjZtil27doGIsGHDBjRs2BCdO3fm8pycnJCdnY3OnTvD1dUVGRkZuHLlCm7duoV58+bxXlPmxx9/xI0bN4ThEnfz5k3eBEdG9nkp+0w/9XkWp/7Dhw+xefNm/PHHHwgKChIWq9wewhMJiAgLFizA6tWrefGC1KU9SoI6bK+qKk4/2rFjB2bMmCEMK1RW2l1ZmyckJOD9+/dKP18iQmhoqLCIU5T6RekbVapUgZGREff8/v37ePLkCbZv3w4DAwMAgLa2NiZPnoy//voLLVq0wPXr15GdnY2pU6di1apVqFixIldf5lNjTEFfsm+wSRrzTUVERHC/boTS0tIUbpiywSI1NVVYxKNqfVXzimLo0KHYtWsX8vLyMH36dFhaWkJfXx/Lli3j5dWuXRs+Pj6oXr06tm3bhoYNG2Lfvn04dOiQwr8JAOrXr4/Hjx8LwyVKJBIhKipKYdulpaUBAMqVKycsgra29ic/z6LWP378OBITE+Hq6orJkydj4cKFWLt2LS9H1fYQ+vvvv9GuXTtUqFBBWMRRh/YoKeqwvaqqqP3o0KFDGDlypNwZwcqUlXZX1uayz7e4bVaU+kXtG0SEo0ePYsmSJZgzZw58fX0xatQoXs6GDRswZcoUvHjxAvb29mjRogVmzJiB/v378/Kg4hhT0JfsG2ySxnxT79+/V7gbGwCysrKgq6srDEMqlQIAMjMzhUU8qtZXNa+o7O3tMXz4cHTs2BGvX7/GwoULsWvXLmEaWrRogf79+2P48OF49+4d/v33X7i4uCAvL0+YCgAwNjZGdnY2EhMThUUlRvbeitouKysLWlpa0NLSEhZBKpV+8vMsSv1atWph+/bt6N27NzQ1NWFoaIh169Zh8eLFcoeQVW0PmezsbKxYsQIuLi7CIh51aI+Sog7bq6qK0o/i4uIQFxeHNm3a8PIKY2xsXCYu7KqszbOysoD8Q4xCqrRZUeoXtW9oaGjA3t4eI0aMgK2tLdzd3eX2nOrp6WHQoEFwcnJCzZo18eLFCwwePBi3b9/m5RVljJH5kn2DTdKYbyoxMZG3a7ogQ0NDSCQSYbjQX2AFqVpf1byiOH36NH777Tfs3bsXfn5+2LVrF3R0dDB9+nQcO3aMy3v27BkGDx6MX3/9FcePH8e1a9fwww8/wNPTE7Nnz+a9poxswJT9fd9CYmIidHR0FF6jSNnniUJ+ERdUlPqVK1dG69ateTmtWrWCnp4eNm/ezMVUbY+CvLy8YG5ujkqVKgmLeNShPUqKOmyvqlL2elDQj7Zu3ap0e1PG2Ni4TLe5oaEhkH+3ESFV2qwo9ZW1pTCvoKpVq6JFixZYt24dqlatio4dOyIqKoord3d3R1hYGA4ePIjw8HC4urri7du36NWrF2JiYrg8VceYgr5k32CTNOabkkgkCjc+ADAyMkJOTo4wzHV+RQNHQarWVzVPVcnJyXBzc8POnTuhq6sLDQ0NuLi44PHjx2jevDkWL17M5U6aNAnLli2Dubk5AKBr1654/PgxRo4cCU9PT4W/xmS/HhUdxikpEomE+zuEZJ9Xbm6usAhpaWmf/DyLUv/69etISEjg5WhoaKBChQrcepaitEdB+/fv5y5cWxh1aI+Sog7bq6pU7UfHjx9H//79oaenJ0wrlFQqLdNtLvv8ittmRan/uX2jf//+yMzM5A5RXr16Fffv38eCBQuA/Engli1b4OvrC319faxatYqrq8oYI/Ql+wabpDHfVKVKlZT+4rCyskJSUpIwzOVbWVkJi3hUra9qnqr8/f3Rpk0bucWntWvXhpeXF6Kjo5GTk4O0tDSEh4fDzs6Ol2dgYIBDhw7BwsICERERvDIASElJgYaGBkxNTYVFJaZSpUqQSCTcIYuCZJ+Xss/0U5+nqvXDw8Nhb2+PKVOmCNMgEom4dWSqtkdB2dnZ8PPz4xYmF0Yd2qOkqMP2qipV+1F8fDx27doFJycn7jF58mQAwJYtW+Dk5AR/f3/BK/yv3atUqSIMf3eUtbmZmRlq166t9PPV1NSU2wNVUFHqq9o3Ll68iEaNGsmduWtmZgbkjxkA4OPjg4EDB/JykL8kwsPDg8tTdYwR+pJ9g03SmG/K0tJS7leKzODBg/Hu3TuIxWJePD4+Htra2rC3t+fFP378yHuuan1V81RlaGiIlJQUYRjI//c2aNAA+vr60NXVhVgsVrj2TEdHB7Vr11a4YDcpKQnGxsYqL3D+GmrWrAktLS2FbTdgwABoaWnJ7QVMTk6GSCSCg4MDLy5sN1Xrm5qaomXLlpgzZw4vLyEhAWlpabCxsQGK0B4FBQYGQiQSqTRJU4f2KCnqsL2qStV+5OrqikOHDvEev/zyCwBg9uzZOHToEDp27Mh7DeS3uyq3lyrtCmvzQYMGyX2+yG8zKysr3g8XkUiEjIwMXp6q9VXtG76+voiMjERgYCAvT3bpnaZNmwKfGBPq16/PjbuqjjFCX7JvsEka8021bdtW6enMvXr1gqmpqdyvorNnz2LChAm8Xdzz58+HmZkZ7ty5w8VUra9qXkGyDVzRht6hQwckJCTg4cOHwiIcOXKEO8VfX18f/fv3x59//ilMQ0REBCwsLOTuIwcAQUFBRVrg/DXo6OigefPmCtvOxMQEgwcPxsmTJ3nxs2fPomnTpujWrRsX+++//2BiYgIPDw8upmr9KlWqoGvXrnK/1g8fPgxjY2MsWbIEKEJ7FCQb1GXrZgqjDu1RUtRhey2osO1Q1X6kSHp6OpB/309lykq7F9bm48ePh7+/P28vl1gshre3t9waPxsbG1haWvI+U1Xrq9o3+vXrh5EjR2L+/Pm8PNlhTNlrDh06FMeOHZM7KxQAjh07xp0spOoYI/RF+4bw6rYMU5KSkpJIX1+fsrKyhEVE+ffos7a2Jj8/P8rIyKAdO3ZQjx49KDU1lZe3detWqlmzJj158oQXV7W+qnmHDx+miRMnkp2dHRkZGVGNGjXI0dGRJkyYQDk5OVxeZGQkde/enTZt2kSBgYF09+5dWrJkCa1cuZL3epmZmTR69Ghyc3OjO3fuUHBwMG3dupWmTZtGHz9+5OXKTJo0Se5WN9/CnDlzFN66ivLb1dbWlg4cOEAZGRl05coVsrKykmsff39/qlGjhtz98lSt/+7dO5o8eTKdOnWKgoKCaM2aNdSsWTN68OABL0/V9pA5dOgQAVDp1jbq0h4lQV22V1W3Q1X7kUxkZCQ5OjpS8+bNqWLFitSwYUMaO3YsBQUFCVOpXr16crcp+h59qs337dtHDg4OFBUVRYmJiTRx4kRasGCBMI1GjRpFbdq0kbsVk6r1Ve0bnp6e5ObmRufOnaPQ0FBaunQp1ahRg7y9vXl5//33H9nb29ORI0coLCyMfH19ycXFRe4uE6qOMQV9yb6hQf+7rQbDfDODBg3CqFGj5K5jI5ORkQEfHx8kJCSgefPmsLOzg4aGhjBNKVXrq5qnKiKCv78/wsPDUalSJdjY2MDCwkKYBuTvOXv48CHEYjHatm2L5s2bC1OA/F+Z9erVg7+/P2rUqCEsLlHBwcEYNWqUwnVzyF9wfP36dTx9+hQWFhbo3bu33GHFwqhaXyQS4e7du4iIiEDjxo1hbW2tcBF4UdojKysL//77L4YOHapwD46MOrVHSVGX7VVVqvajoggPD8ewYcO4tUvfu0+1+bt373Dx4kXk5eWhc+fOaNy4sTClUKrWV7VvfPz4Ebdv38bbt2/RoEEDdOjQQeEZoNnZ2bh58yZiYmJgaWmJTp06ya1dRRHGGHyFvsEmacw3d/PmTSxfvhzXr18XFjECx44dg7e3Nw4ePCgs+ibs7e2xbNky3lX7yxJ1a4+SwLbX/93Bol27dpg4caKw6LvE2lx1X7pvsDVpzDfXuXNnVKtWTemFAZn/EYvF2LVrV6FXui5pW7duxe+//46y+FtPHdujJJT17TU2NhZPnjzB+PHjhUXfrbLe5qr6Gn2D7Ulj1EJycjKGDRuGkydPqnRGXVnk7u6OVq1aYeTIkcKib2rLli0Qi8VK7zX6vVLX9igJZXV7FYvFGDRoEDZt2oQGDRoIi79rZbXNVfW1+gbbk8aoBWNjY+zZswcrVqwQFjEALl++jBo1aqjlhGD27NnIycnBvXv3hEXfLXVuj5JQVrfXjRs3YtGiRV/0S7i0KKttrqqv1TfYnjRGrYjFYu6mucz/Kw2fS2n4G7+UsvRvLUxZ+xzK2r9XEfYZKPa1Phc2SWMYhmEYhlFD7HAnwzAMwzCMGuLtSVN0vRGGYRiGYRimZBQ8wMkOdzIMwzAMw6ghdriTYRiGYRhGDbFJGsMwDMMwjBpihzvz/fPPP/Dx8UFQUBDi4uLg6OiIbdu28XKuXr2KdevWcfcqbNKkCX799Vd06tSJl8eor9zcXNy+fRsPHjyAnp4enJycYGZmxsuRSqU4f/48Xrx4AalUCgcHBzRr1oyXU5Q8pnABAQHIzMxE165dhUUcb29vPH78GJqamrC3t4e1tbUwBQDw6NEj3LhxAxKJBK1atULPnj2FKQCAN2/e4PTp0xCLxTAzM8Pw4cM/+36OTPEFBwfjypUryMjIQO3atTFs2DBUqFBBmIa4uDicPHkSiYmJMDY2xqBBg1C7dm1hGlCEPsN8G4GBgbh27RrS09PRvHlzDBgwALq6urwcNzc39OrVC7Vr14aurq7cunkzMzPuXpvfbd8ocLN1hojWrFlDHTt2JADk7e0tLCYiomXLltH69euFYUbNxcTEUPfu3enUqVMkFospNjaWunbtSqmpqVxObm4u9enThzw9PUkqlVJaWhqNHDmStm3bxnstVfMYxQICAmjPnj00depU0tHRoeXLlwtTiIgoJyeHXF1dyd/fn6RSKaWnp9PKlStp+vTpwlRauXIlOTs7U3Z2NkkkEvLw8KBRo0aRVCrl5fn4+JCdnR3Fx8cTEZGvry916NCBEhISeHlMyVi2bBnt2LGDUlNTSSwW09KlS8nY2Jju37/Pyztz5gzNnj2b4uLiiPLb0cDAgHbt2sXLK0qfYb4NWZvHx8dTYGAgOTg4UIMGDSgkJISXV716dQKg8KGpqUl3794l+s77BpukCXh4eFBISAiZmZmRubk5JScnC1Po9OnT5OvrKwwzaiw+Pp6qVKlCDx484GKrV68mAHTz5k0utmrVKnJwcOCeExGlpKRQhQoVKDAwsMh5jGL+/v7k5+dHIpGIACidpC1fvpwCAgKEYRo7dixdvnyZe3779m2qVKkS5ebm8vJsbGxo69at3PPk5GQyMzOje/fu8fLc3d1pyJAhvBjz9YWFhZG5uTkdPHiQi0kkEipfvjy1bNmSi0mlUqpVqxbNmzePixEROTg4kKamJiUlJXExVfsM8234+PjQ0qVLebHc3FyqXr06NWzYkLKzs4mIKDU1ldq3b08bN26kbdu20fbt27nH5MmT6eeffyYqA32DrUlToEqVKvjzzz8RFxeHmTNnCouhoaEht9uVUW/Lli2DtbU1rKysuNioUaOwdOlSdOjQgYvt3r0b/fr1454DgJGREaytrXHo0KEi5zGK2djYoFOnTp+8Qvfly5ehp6cnDKNDhw4ICgrinu/evRvdu3eXO1zSp08f7N+/n3t+6tQpAED79u0LZP0v7+zZs0hOTubFma8rMzMTcXFxuH37NhfT1NSEmZkZoqKiuJhIJEJqairOnTvHxQCgWrVqkEqlePnyJRdTtc8w38aJEydw5swZvHjxgovp6upiyJAhiIyMxIMHDwAAT58+xfz58zF37lzMnDkTM2bMwIwZMzBx4kRkZWVh5cqVQBnoG2ySpsSQIUMwduxYHDlyBCdPnhQWM6XI69evsXfvXvTq1YsXr1u3LlasWMF9sYeHh+PNmzcwMTHh5QGAubk5fHx8ipTHfD4DAwM4OzsjNjaWF/f39+cmWkSEy5cvK22P4OBgxMfHAwAuXboEY2NjYRrMzc0hkUjg6+srLGK+Imtra0RHR2Pnzp1cLDExEW/evIGdnR0X09XVxbNnz7gvcJnAwECYmJigSZMmXEyVPsN8OxoaGggJCUFcXBwvLlsbHB0dzT3v0qULLwcAfv31V/zyyy/cuP299w02SSvEtm3bUL16dUybNg3v378XFjOlxKNHjyCRSNCwYUOcPn0av/32Gzw8PHDnzh1eXkhICACgfPnyvDgAVK5cGRERERCJRCrnMZ9v2rRpePDgAZo2bYpdu3aBiLBhwwY0bNgQnTt3BgAkJCTg/fv3StuDiBAaGgrkt7GyPFk5U7Lq1KnD26P6119/oXLlytiwYQMvr0qVKjAyMuKe379/H0+ePMH27dthYGDAxVXpM8y3s337doSHh8PW1pYXf/bsGZB/Qh7yf0Sbmpryci5evAhzc3M0btyYF/+e+wabpBWicuXK2Lt3LxITE+Hi4iIsZkoJ2dm4wcHBMDY2xtKlS+Hm5obly5fj999/5/LS0tIAJZMv2ZdIamqqynnM5xs6dCh27dqFvLw8TJ8+HZaWltDX18eyZcu4nKK0R1pamkp5TMn6+PEj9uzZg2nTpuHWrVu4d++e3Bcx8veaHj16FEuWLMGcOXPg6+uLUaNG8XJU6TPMt6Ovry/XtmlpaTh79iy6deuGdu3a8cpkRCIRVqxYofS7+HvtG2yS9gm9e/eGs7MzTp8+jX/++UdYzJQCsrUtr1+/5n4t6evrY/HixXB3d0dgYCAAICsrC8jffS4klUqB/DU0quYxX4a9vT2GDx+Ojh074vXr11i4cCF27drFlRelPbKyslTKY0pWpUqV0KtXLzg6OkJHRwfu7u4K1wdqaGjA3t4eI0aMgK2tLdzd3RXu/fxUn2HUi5ubG0xNTXHgwAFhEWfnzp2wtbVV+CML33HfYJM0FWzatAm1a9fGrFmz8PbtW2Exo+ZkX8o//vgjL25lZQWpVIq9e/cCAAwNDQEAEomElwfB3hpV85jPJzs8vXfvXvj5+WHXrl3Q0dHB9OnTcezYMaAI7Yb8XFXymJKloaGBWrVqoVOnTjh27Bhu3LiBLl26KFw2ULVqVbRo0QLr1q1D1apV0bFjR95JBqr0GUZ9nD59GteuXcPVq1dhYWEhLAby95Jt27YN3bt3FxbxfI99g03SVFChQgXs378fqampcHZ25t38lFF/snUNwovWlitXDgAQFhYG5J+dCQA5OTm8PBT4Eq9YsaLKecznSU5OhpubG3bu3MldyNLFxQWPHz9G8+bNsXjxYkDFdpPlGBkZqZTHfDt6enro2bMnQkNDP/nF2b9/f2RmZmLt2rVAEfoMox6CgoKwceNG+Pv7o27dusJizu3btxEVFQVLS0thkVLfS99gkzQVde3aFTNnzsTFixexZ88eYTGjxlq2bAko+BKXHeKSTahkl+dISkri5SH/S7xFixbQ1dVVOY/5PP7+/mjTpo3chLd27drw8vJCdHQ0cnJyYGZmhtq1ayttD01NTbRu3RrIb2NlebJypuSsWrUKLVq0kDvbTvaDKjw8HMhfMN6oUSO5M6eFear2Gebbi4mJwerVq+Ht7Y3q1asD+Wf2Cs/SBMCddS07waeg771vsEmaQP4FfoVhAICHhwd++OEHXLhwQVjEqLFu3bpBT0+PO4FAJiEhASjwxVynTh20bNkSr1694uUBQHx8PBwcHIqUx3weQ0NDpKSkCMMAAEtLSzRo0IC7ldOgQYOUtoeVlRW3N3Xw4MF49+4dxGKxXJ62tjbs7e15cebrOn36NEJDQ+XaTjZpa9q0KZD/JR0ZGcmtH1WWV5Q+w3w7SUlJ8PDwwN9//83be+3v78+tMS3o3r17QP7aRaHvvm8Ir25b1o0bN45u3LghDHP8/f1JU1OTrly5Iixi1Njs2bOpW7duvJinpydVqVKFd1eJ7du3U9u2bXl5UVFRVK5cOXr+/HmR85jCffz4kQCQm5ubsIiys7OpcePGvLtEyOzfv5+2bNnCPQ8KCqLy5ctTYmIiFxOJRFS3bl06fPgwF8vKyqJatWrRuXPnuBgR0U8//USTJ0/mxZivb/ny5fTHH3/wYpmZmWRubk4NGzakjIwMIiK6du0ajRw5knJycni5AwcOJH19fQoNDSUqYp9hvo3MzEyysbGhiRMn0syZM2nmzJk0Y8YMmjJlCjVp0oTev38vrEKNGjUiPT09YZioDPQNNknLt3fvXmrfvj1VqFCBTE1NqU+fPhQdHS1MIyKiX3/9lW7duiUMM2osJyeHxo0bR3PnzqXg4GA6fPgwtW3bVu7+gFKplKZMmUKurq6UnJxMT58+pS5dutCJEyeKlccodvjwYZo4cSLZ2dmRkZER1ahRgxwdHWnChAm8wTYyMpK6d+9OmzZtosDAQLp79y4tWbKEVq5cyXs9IqJ9+/aRg4MDRUVFUWJiIk2cOJEWLFggTKOAgACytrYmPz8/ysjIoB07dlCPHj1493BlSoZYLKb58+fTihUr6Pr16xQYGEgDBw6kDh06UGRkJC/X09OT3Nzc6Ny5cxQaGkpLly6lGjVqyN1juSh9hil5zs7OcvfhlD1MTEyE6UREVK9ePTI2NhaGOd9z39AgZcf2GOY7FBAQgMePH6NOnTro2LEjd/KA0OPHj3Hnzh2UL18effr0kTvpQEbVPKb4iAj+/v4IDw9HpUqVYGNjo/QssHfv3uHixYvIy8tD586d5a7HJJORkQEfHx8kJCSgefPmsLOzY7d6+4ZiYmJw//59pKeno0WLFmjXrh00NeVX43z8+BG3b9/G27dv0aBBA3To0EHhGblF6TOM+rtz5w5yc3MLXY7wvfYNNkljGIZhGIZRQ/I/VRiGYRiGYZhvjk3SGIZhGIZh1BCbpDEMwzAMw6ghNkljGIZhGIZRQ2ySxjAMwzAMo4bYJI1hGIZhGEYNsUkawzAMwzCMGmKTNIZhGIZhGDXELmbLlEoZGRk4fvw40tLSoK2tjeHDh6Nq1arCNKXevHmD06dPQywWw8zMDMOHD1fp5rpTp07Fpk2bFF7J+sKFCwgODoaenh769euHhg0b8sofPXqEEydOYPjw4TA0NIS2tjavXEtLC5aWlrxYafa5baRKfU9PT2hoaKB9+/YwMDCQu0q9oaEhVyczMxNnzpxBWFgYLCws0LVrVzRp0oSXr8iDBw/g5+eHOXPmCIsYFanSlqo4evQofvzxR9SsWVNYxBMQEIDMzEx07dpVWIS0tDQcOnQIffr0gaWlJUQiEV6+fIlLly7BxcUFOjo6wipMMRR3jJV59OgRbty4AYlEglatWqFnz57CFM6HDx9w/fp1hIeHw8LCAo6OjtDV1RWmAZ/oGwAglUpx/vx5vHjxAlKpFA4ODmjWrJkwreQI7xPFMOouJiaG2rVrRwEBAdxzGxsb8vPzE6Yq5OPjQ3Z2dhQfH09ERL6+vtShQwdKSEgQpvIcPnyYAFBSUhIvnpKSQn369KFVq1ZRZmYmRUZGkq2tLR0/fpyX5+npKXevuoKP3r178/JLs89tI1XrjxkzRu5zLPhYt24dUf49+8aNG0cPHz6kuLg42rdvH1WoUIHmz5/Pez2h3Nxcatq0Kc2cOVNYxKhI1bZU5vz587R582YaMGAAAaAbN24IU4jy78m6Z88emjp1Kuno6NDy5cuFKUREFBwczPUPLS0t0tTUJB0dHdq5c6cwlSmm4o6xMitXriRnZ2fKzs4miURCHh4eNGrUKJJKpcJU8vX1pe7du1NQUBBR/g3XR48ezctRtW/k5uZSnz59yNPTk6RSKaWlpdHIkSNp27ZtwtQSwyZpTKnTvXt38vDw4MUuXbpENWvWpMzMTF5cKDk5mczMzOjevXu8uLu7Ow0ZMoQXK+j9+/fUtm1bgoJJ2k8//URWVla82KNHj0hfX5+io6O52Ny5c2nx4sW0ZcsW2rZtG23fvp22b99O27Zto+bNm1NsbCzvNUqzz2kjKkJ9BwcH8vDwoK1bt3Kf5/bt22nNmjVka2tLYrGYiIj69+9PcXFxBV6NaNu2bQSA9u/fz4sXtGHDBqpUqRKbpH0GVdtSmfPnz1NISAhdv3690Emav78/+fn5kUgkIgBKv4iDg4OpW7duNHLkSOrbty8tWrSIXrx4IUxjiqm4Y6zM7du3qVKlSpSbm8uL29jY0NatW3mxS5cukaWlJaWkpHCxHj16kI6ODrftUxH6xqpVq8jBwYEXS0lJoQoVKlBgYCAvXlLYJI0pVaKioggAhYWF8eISiYR0dXXp7NmzvLjQ3r17yczMTBim27dvk5aWFn348EFYRJQ/wOzcuVNukvbq1SsCQIsXL+blExEZGRnRwoULuefz5s3jlcscOHBAbq9bafa5baRqfalUSgsWLODlyMyaNYuioqKIiOj169dUvnx5Wrp0KS8nKSmJAJC9vT0vLhMcHEz79+8nS0tLNkkrJlXbUhU3btwodJJWUGFfxMHBwbR582ZhmPlCijvGyjg6OtKwYcOEYVq5ciW1bt2aey4Wi6lp06a0YcMGXt7Vq1fpzz//5MUKKqxv1KxZk7Zv3y4MU7du3WjOnDnCcIlgJw4UAVu+9+1dvHgRAGBiYsKLa2pqokqVKvDx8eHFhS5dugRjY2NhGObm5pBIJPD19RUW4cyZM+jVqxfKlSsnLEJISAgAoHLlysIiVKtWDVevXuWejxgxglcOANHR0Xj06BGGDx8uLCq1PreNVK2fm5sLR0dHXg4AeHl5oW3btqhbty4AQCKRICcnB35+frw8Y2NjaGlpITo6mhcHALFYjMOHD2P8+PHCIqYIVG1L5vtRnDFWhohw+fJluf6C/PrBwcGIj48HABw7dgxPnjxBr169eHn29vaYOnUqL6aK8PBwvHnzRul7f6u+yiZpCly4cAFbtmzB4MGD8fHjR4SEhGDVqlX4/fff0b17dxw8eFBYhSkhskmRooX7lStX5sqVCQkJUVpXVl7Qx48fERoais6dO/PiMlKpFACgoaEhLIKuri7CwsK459bW1rxyIsKCBQuwevVqXry0+xJtBBXq6+vro0WLFrzyuLg4nDt3DuPGjeNilpaWiIyMxOnTp3m5UVFRkEgkCk8e2LlzJ6ZNmyYMM0Wkalt+Cw8fPsTmzZvxxx9/ICgoSFjMFFNRx9iCEhIS8P79e6X1iQihoaEAgPv37wMA6tati61bt2LNmjVYv349Xr58Kaipmk/11YiICIhEImHRV8cmaQJSqRS3bt3C7NmzkZaWBldXVwQGBmLJkiVYuHAhFi5ciKlTpyI3N1dYlSkBaWlpAKBwr5a2tjZSU1OFYZ60tDSFG6HsTEth/U2bNsHNzY0XK6hly5aAgnoA8O7dO+Tk5CjtK3///TfatWuHChUqCItKtS/RRihmfXd3d0yfPl0YRr169VCxYkVe7NChQwCARYsW8eIRERHQ19dHnTp1eHGm6D6nLb+m48ePIzExEa6urpg8eTIWLlyItWvXCtOYYijqGFuQrL+oUj8iIgLlypXDP//8g+HDh2Px4sUYOXIkHBwccOXKFUHtTyvKe5ckNkkTuHXrFjp27AgAePHiBfLy8uQOeeTk5CAjI4MXY0pGVlYWtLS0oKWlJSyCVCpFZmamMMyTlZWl8NRs2R6xgvUvXryIH3/8sdBJVO3atTFq1Ci5Q2n+/v7c/0skEl4ZAGRnZ2PFihVwcXERFpV6X6KNilM/ODgYERER6NChg7BITkREBNavX49Vq1bB1taWi0ulUuzbtw/Ozs68fKZ4ituWX1OtWrWwfft29O7dG5qamjA0NMS6deuwePFiue2YKbqijLFCWVlZQP5RCCFh/aioKOTl5aFSpUowNzcH8tt25MiRmDBhQpG/o4vy3iWJTdIEGjRogN69e+PVq1d4/fq13JdoQEAATE1NFR63Zr4+Q0NDhZMeFPILriBl9YW/otLS0nD37l259Q6KbN26FRKJBAcOHAAR4fnz5wgKCkLDhg1hbm6ucC+Cl5cXzM3NUalSJWFRqafsM8ZnthE+UX/btm2wt7cXhuWIRCI4OTlh7ty5+OWXX3hlnp6ecHZ2lrveGlM8xW3Lr6ly5cpo3bo1L9aqVSvo6elh8+bNvDhTdMraXDjGKmJoaAgo+WErrK+rqwuxWCy3FMXKygqxsbG4cOECL/4pRXnvksRGIoHq1atDR0cH169fh76+PmxsbHjlN2/elOsUTMkxMjIC8heNC6WlpXHlyhgZGSEnJ0cY5jZCWf0//vhD5YuXmpmZ4dq1a6hatSo2bdqE+/fvw8XFBampqfjhhx+E6QCA/fv3f1cXri3oS7QRilg/KysLx48f/+RnSkSYPHkynJycsGrVKl5ZdHQ0xGKx3EWImeIrTlt+bdevX0dCQgIvpqGhgQoVKnDrnZjiU3WMVURWpkp9U1NTIH/8LUj2o7jgemBVqPLewiUTJYFN0pS4ceMGOnTowLtCskgkgr+/P7p06cLLZUqOlZUVACApKUlYhLS0NK5cGSsrK6V1ZeUAEB8fj1mzZsHJyYl7bNq0CQDg4uICJycnfPz4kauvpaWF3r17Y968eXB0dAQRISoqCnZ2dlyOTHZ2Nvz8/BSeEfo9+BJthCLWv3v3LjIyMj75mf76669wcHCAq6srF/P29gbyD5/cv3+f1+ZOTk54+fIlLl++DCcnJ+zbt6/AqzGfUpy2/JrCw8Nhb2+PKVOmCIsgEokKXdrAqEbVMVYRMzMz1K5dW2l9TU1Nbi+obD2wcFIlOzRZ1AnVp/pqixYtFB4K/drYJE2J69evy+0xe/jwYaG3k2C+vgEDBkBLSwuvXr3ixZOTkyESieDg4MCLF5xIAcDgwYPx7t07iMViXjw+Ph7a2trc4bJdu3bh0KFDvMeQIUMAAH/++ScOHTrETQh2796N5cuX817vxo0b0NXVVbg3LjAwECKR6JMTitLqc9uoqPUB4N69e4CSS6HI/Pnnn7CyssKoUaN4cdllUnr06CHX5rKTC3r27IlDhw5h0qRJvLpM4YralsK+8KWZmpqiZcuWcttlQkIC0tLS5I6cMEWn6hgrI2zzQYMGyfUX5Ne3srLi9qD17dsXyF9fWpBsL2lhk0FF6tSpg5YtWyp9b2FfLSlskqZATEwMXr9+LTdJu3nzJszMzBSess+UDBMTEwwePBgnT57kxc+ePYumTZuiW7duXGz+/PkwMzPDnTt3uFivXr1gamoqd82bs2fPYsKECYXuik9PTwfy70NYkKenJ44dO8Y9F4vFWLlyJVasWKHwekGxsbFAgTUQ35uitNF///0HExMTeHh4cLGi1Jf51Gd64sQJeHp64urVq5g1axZmzZqFGTNmwNHREXl5ecJ0jqythW3OqKYobaloey1I9mWekpIiLOKRlSvKq1KlCrp27Sq3Ju3w4cMwNjbGkiVLeHGm6Ioyxipq8/Hjx8Pf35+3R0ssFsPb2xuzZ8/mYj179kTr1q3l1p75+Pige/fuCo94FdY3AGDy5Mk4deoULxYdHY2oqChMnjyZFy8xwqvbMkQnT54kIyMjysrK4sV79epFw4cP58WYkpeUlES2trZ04MABysjIoCtXrpCVlRU9efKEl7d161aqWbOmXDwgIICsra3Jz8+PMjIyaMeOHdSjRw9KTU3l5cmcPXuWRo8eTTVq1KAKFSpQx44dydHRkXJycojy78n5888/U2hoKN24cYO6detGu3fvFr4M59ChQwRA7hYn3xNV28jf359q1KhBhw4d4sVVrS8zadIkAkAhISHCIoqKiiI9PT2Cgnt7AlB6X75x48ZRly5dqEKFClS1alUaOXIkHT16VJjGfIKqbalse126dCmNHz+emjZtSkZGRtSsWTOaMGECrVixgpd3+PBhmjhxItnZ2ZGRkRHVqFGDHB0dacKECdy2SkT07t07mjx5Mp06dYqCgoJozZo11KxZM3rw4AHv9ZjiU3WMVdbm+/btIwcHB4qKiqLExESaOHGiwruLvHnzhmxtbWn37t30+PFjWr16NXXv3l3uFnCq9g2pVEpTpkwhV1dXSk5OpqdPn1KXLl3oxIkTvNcrSRrELqMvJzc3F0lJSahRowYXE4vFqFy5MtatW6fwOkxMyZJIJLh+/TqePn0KCwsL9O7dm7d+8FMyMjLg4+ODhIQENG/eHHZ2dgovSKuq8PBw3LlzB1WqVEGXLl0K3SOXlZWFf//9F0OHDi00r7T73DYqSv2YmBj4+/tj7NixwiJGDRSlLUuCSCTC3bt3ERERgcaNG8Pa2hp6enrCNOYzfO4Y++7dO1y8eBF5eXno3LkzGjduLEwB8r+vb926hZcvX6JFixawtrYu0vso8vjxY9y5cwfly5dHnz595E5OKElskqai+/fvo0OHDnjy5Ak73MkwDMMwzFfH1qSp6ObNm6hSpQqboDEMwzAMUyLYJE1Ft2/fVrhgmWEYhmEY5mtghztVdPfuXdSvX/+bHptmGIZhGKbsYJM0hmEYhmEYNcQOdzIMwzAMw6ghNkljGIZhGIZRQ2ySxjAMwzAMo4bYJI1hGIZhGEYNlfkTB+Lj4/Hw4UMAQPv27WFmZobc3FwkJibCwsJCmM4wDMMwDFMiyuwkTSqVYsmSJUhKSsLo0aOhoaGBGzduoFKlSoiPj0fjxo0xbtw4ZGRkYPr06YiNjUVMTAwAwNraGuXKlQPyby/y7t07vHnzBmKxGAsWLGC3jSoBGRkZOH78ONLS0qCtrY3hw4ejatWqwjSl3rx5g9OnT0MsFsPMzAzDhw+Xu01NcHAwIiIi0KNHD5iYmCAjIwMRERF48uQJxo0bx8uVSqU4f/48Xrx4AalUCgcHBzRr1oyXg//dKxcXL15EUFAQxGIxWrZsif79+0NT8/vbqf25bVSU+hcuXEBwcDD09PTQr18/NGzYUJgi588//0TTpk1ha2srLOJ58OAB/Pz8MGfOHGERo4Aq21Zhilt/6tSp2LRpE8qXLy8sAgAEBAQgMzMTXbt2FRbB09MTGhoaaN++PQwMDOS2R0NDQ6V9j1GsuO0o8+jRI9y4cQMSiQStWrVCz549hSkAgMDAQFy7dg3p6elo3rw5BgwYAF1dXWEasrKycOrUKbx48QLVq1fHsGHDYGxsLExTeSwvMbw7eZYhmzZtonHjxgnDdOzYMdLU1KQDBw7w4mlpaaSpqUm1a9fmxWXevn1LvXv3pmnTpgmLmC8sJiaG2rVrRwEBAdxzGxsb8vPzE6Yq5OPjQ3Z2dhQfH09ERL6+vtShQwdKSEjg5W3evJm7CbeOjg4BIFNTU/L39+fl5ebmUp8+fcjT05OkUimlpaXRyJEj5W7cnZ2dTY6OjnTp0iXKzc2l1NRU6tOnD7Vs2ZKSkpJ4uaXd57aRqvVTUlKoT58+tGrVKsrMzKTIyEiytbWl48eP8/KEnj9/TgYGBuTl5SUs4snNzaWmTZvSzJkzhUWMAqpuW8oUt/7hw4cJgNx2FBAQQHv27KGpU6eSjo4OLV++nFcuM2bMGG5bV/RYt26dsApTiOK2o8zKlSvJ2dmZsrOzSSKRkIeHB40aNYqkUikvb9myZbRjxw6Kj4+nwMBAcnBwoAYNGlBISAgvLzQ0lFq1akXnz58nkUhE169fp5YtW1JoaCgvT9WxvCSV2Ula9erV6dKlS8IwERENGTJEbpJGRKSvr0+NGjUShjnx8fE0dOhQYZj5wrp3704eHh682KVLl6hmzZqUmZnJiwslJyeTmZkZ3bt3jxd3d3enIUOG8GKbN28mJycn6t+/Pw0fPpx+//13SklJ4eUQEa1atYocHBx4sZSUFKpQoQIFBgZyse3bt1OzZs0oKCiIi927d48A0OzZs7nY9+Bz2oiKUP+nn34iKysrXt6jR49IX1+foqOjeXEZqVRKP/30EwH45CRtw4YNVKlSJTZJU0FRti1Filv//fv31LZtW4WTNH9/f/Lz8yORSEQAlE7SHBwcyMPDg7Zu3Urbt2/nHmvWrCFbW1sSi8XCKowSxW1Hmdu3b1OlSpUoNzeXF7exsaGtW7dyz318fGjp0qW8nNzcXKpevTo1bNiQsrOziYgoKyuLGjZsSPPnz+flbty4kRo3bsxrW1XH8pJUJidpKSkpBIBOnjwpLCIiopMnTxZrkkZENGvWLGGI+YKioqIIAIWFhfHiEomEdHV16ezZs7y40N69e8nMzEwYptu3b5OWlhZ9+PCBi23evJmCg4N5eYrUrFmTtm/fLgxTt27daM6cOdzzdevWEQA6fPgwF3v58iUBoH79+nGx0u5z20jV+q9evSIAtHjxYl4eEZGRkREtXLhQGCbK7wPnz5//5CQtODiY9u/fT5aWlmySpoKibFuKFLe+u7s77dy5U+EkrSBlkzSpVEoLFiwQhonyx/OoqChhmClEcdtRxtHRkYYNGyYM08qVK6l169bc84kTJ1KLFi3o+fPnvLyZM2cSALp16xYRER08eJAA0OXLl3l5jx49IgDk4+PDxVQdy0vS97cQRgUVK1aEoaEh1q5di8zMTGExbG1tUb9+fWFYoaioKPzzzz/c87Zt2/LKmS/r4sWLAAATExNeXFNTE1WqVIGPjw8vLnTp0iWF6xDMzc0hkUjg6+srLCpUeHg43rx5I/f3IP81C/49CxYswIsXLzBmzBguFhgYCACws7PjYqXd57aRqvVDQkIAAJUrV+blAUC1atVw9epVYRivX79Genr6J9eYiMViHD58GOPHjxcWMUp87rZVnPpnzpxBr169uDXCxZGbmwtHR0dhGF5eXmjbti3q1q0rLGIKUZx2lCEiXL58WW7bR3794OBgxMfHAwA0NDQQEhKCuLg4Xp7s1o3R0dEAgMePHwMKxonq1asDADdOFGUsL0llcpKmoaGBKVOm4OHDh2jevDl+++033Lx5E9nZ2UB+I3fq1ElYTaGQkBDk5uZyz4ULypkvS/bFrGhxcOXKlblyZUJCQpTWlZUXRET477//sGHDBuzevRtv3rzhlX/q74mIiIBIJALy+129evV4OXv27IGVlRVmzpzJi5dmn/pMhJ+xkKr1pVIpkP+5Cunq6iIsLEwYxo4dOzBjxgxhWM7OnTsxbdo0YZgpRFG3LaGi1v/48SNCQ0PRuXNnXryo9PX10aJFC14sLi4O586dY+N5MRS1HQtKSEjA+/fvldYnIoSGhgIAtm/fjvDwcLkTf549ewYAaNKkCVDIOCE7ueDJkyeACuNOwbG8JJXJSRoArFmzBoMGDUJMTAyWLVuGLl26oFKlSnBycsLbt2+F6Zz379/D3d0dCxcuxIQJE9hGXMLS0tIAQOEvZ21tbaSmpgrDPGlpaQo3Qm1tbQCQq79hwwZYWlpi/vz56NGjB3r27IlLly5x5bK/pyivGRERga1bt6J///5o0KABrl27BgMDA15OafYl2ggq1G/ZsiWg4PMFgHfv3iEnJ4f3A+rQoUMYOXIkdHR0eLlCERER0NfXR506dYRFTCGKum0JFbX+pk2b4Obmxot9Ke7u7uws/WIqajsWVJTxVF9fH40bN+blpKWl4ezZs+jWrRvatWsHFDJOyL7nP378CBTxvUtSmZ2k6enp4fTp07h58ybmzJmDdu3aQSqV4p9//sGPP/6IpKQkYRUAgLGxMdzc3ODm5gZXV9fv6jBVaZCVlQUtLS1oaWkJiyCVShUevi4oKytL4enZsl9bBet37doVmzdvRvPmzQEAdevWxZQpU+Do6IiUlBQg//VQ4FdZQYpeEwDq1KmD/v37w8XFBX5+fli3bh0kEgkvpzT7Em2kSv3atWtj1KhR8PPz4+X4+/tz/y/7XOPi4hAXF4c2bdoUyJQnlUqxb98+ODs7C4uYTyjKtqVIUepfvHgRP/74IypUqFAg88uQXXqnQ4cOwiJGBUVpR6HijKcFubm5wdTUFAcOHOBiI0aMQJ06deTGibt37wIFXvdz3/trKbOTNBk7Ozts2rQJAQEBiI+Px+TJk/Hy5UusW7dOmArkz6irVq0Kc3NztG7dGsuWLROmICoqShhivhBDQ0OlExplv+AKUlZf0a+oFi1awNTUtEDW/y54nJSUxK1DNDQ0BApMBgpS9JrI/4FQp04d9O3bF3v27MHq1au/q8Odyj5jfGYbQUH9rVu3QiKR4MCBAyAiPH/+HEFBQWjYsCHMzc25vXFbt27F7NmzC7ySYp6ennB2dpa7ThbzacraTdl2IKRq/bS0NNy9exe9evUSZH4Z27Ztg729vTDMqEjVdlSkOOOpzOnTp3Ht2jVcvXqVdyF6AwMDHD9+HCdPnkRgYCC37s3c3BwAuCUon/PeX1OZHInS09Nx+/ZtYRgmJibw9PREly5dcPnyZWGxQvXr1+edLBAbG4vz58/zcpgvx8jICMhf7CuUlpbGlStjZGSEnJwcYZjbCAu+/sWLF+VyZeWydRGy58I8FHjNihUrCos4rVu3Ro0aNbB79268fv1aWFwqfYk2gor1zczMcO3aNVStWhWbNm3C/fv34eLigtTUVPzwww8AgOPHj6N///7Q09Mr8EryoqOjIRaLVboQLiNP1W1LGVXr//HHH1/twsJZWVk4fvw4LC0thUWMilRtR0VUGU8V1Q8KCsLGjRvh7++v8EQPKysr3Lx5E8+ePcOGDRugo6MDGxsbAODGCVXeu7Cx/Gspk5O0tLQ0XLhwQRjmDBw4kGuUT6lcuTJatWrFPQ8ICOAWLDJfnpWVFQAoPBydlpbGlStjZWWltK6sHAD27t2L3r17Y9euXbw82cJR2WGWT/09LVq04Haf9+vXD/369ROmwczMDESEiIgIYVGp9KnPRJU2QhHqa2lpoXfv3pg3bx4cHR1BRIiKiuKWIsTHx2PXrl1wcnLiHpMnTwYAbNmyBU5OTvD390dUVBTu37/Py3NycsLLly9x+fJlODk5Yd++fbz3Zv6fqtuWMqrWj4+Px6xZs3httGnTJgCAi4sLnJycuHVGRXX37l1kZGTInQnIqE7VdlTEzMwMtWvXVlpfU1MTrVu35sVjYmKwevVqeHt7c2dsJiYm4sGDB7y8SpUqYdSoUViwYAG6du3KjbeyceJT407BsbxECa/JURbExsZSy5Yt5a5eLLNq1SoaOHCgMKzSddJ69epFsbGxwjDzhSQlJZGWlhbduXOHF//w4QMBoAsXLvDiycnJvOenT5+mcuXKkUgk4sVPnjxJ2tra3MVqjx07RoMGDZK7IOqxY8fkrq/VsmVLWr16NS+PiKh58+b0888/E+Vfm09DQ4MqVqwodzFXU1NTAvDd9JvPbaOi1P/zzz9p2bJlvDxfX1+qWLFioddjunHjhlw7KgOAXSdNBapuWzLCdi9q/YKWL19e7OukFbRq1SoCQL6+vsIiRkVFbUdhP5g9ezb16NGDF6P8a9ZZW1vzYomJiTRlyhTKyMjgxc+cOUM3btzgnk+fPp1OnTrFy/nll1+oU6dOvJgqY3lJK7OTNADk7u4uLKLc3Fxq2LCh3O1nsrOzSUtLi+rWrcuLy4jFYlq1ahVVrFhRWMR8YcOGDaO5c+fyYn/99Rc1bdqUd5XqefPmkZaWFq8ts7KyqFatWnTu3DkuRvlXrp88eTL3PC0tTeFdAAYMGEC2trYkkUi42Pbt26lt27a8vKioKCpXrhzvQou9evWiu3fv8vKCgoIIADk6OvLipZ2qbXTu3DnS0NCgtWvX8nJVrd+mTRveDyeRSER2dnb0xx9/cDFF/vvvPwKg8KLVBaWnpxMAGj9+vLCIEVB126LP3DYVmTdvHgGgly9fCouIiOjjx48EgNzc3IRFPC4uLgRAbjtlVFeUdlTUD4KCgqh8+fKUmJjIxUQiEdWtW5d3IfDMzEyysbGhiRMn0syZM2nmzJk0Y8YMmjJlCjVp0oTev39PRESpqakEgFxcXLi67969IwsLC7lb/Kk6lpekMjtJa9KkCXl7e9NPP/1Ef//9N92/f59OnTpF3bp1I09PTy43PT2dRo8eTTY2NgSANDU1aejQoeTo6EiOjo40ZswY6t+/P1lYWBAAat++Pe+9mC8vKSmJbG1t6cCBA5SRkUFXrlwhKysrevLkCS9v69atVLNmTbl4QEAAWVtbk5+fH2VkZNCOHTuoR48elJqaysvz8/OjadOm0Y0bN8jf35/GjRtHffv25e5HJyOVSmnKlCnk6upKycnJ9PTpU+rSpQudOHGClxcfH0/jx4+nHTt20IMHD+jq1avUpEkTcnJyovT0dF5uaadqG/n7+1ONGjXo0KFDvLiq9T09Pennn3+m0NBQunHjBnXr1o12797NyykoMjKSHB0dqXnz5lSxYkVq2LAhjR07lnerLplx48ZRly5dqEKFClS1alUaOXIkHT16VJjGFKDqtvW526bM2bNnafTo0VSjRg2qUKECdezYkRwdHSknJ4co/56eEydOJDs7OzIyMqIaNWqQo6MjTZgwgcspaNKkSQRA7t6PTNGo2o7K+sG+ffvIwcGBoqKiKDExkSZOnCh3VwhnZ2eCgvusAiATExNe7tSpU8nT05PCw8PJy8uL2rZtK3fbKirCWF6SNOh/u4HLlJycHLx8+RKNGjWCWCzG06dPERQUhHLlyqFTp07cWR+M+pJIJLh+/TqePn0KCwsL9O7dG/r6+sI0pTIyMuDj44OEhAQ0b94cdnZ2chc7RP51cW7fvo3379+jbdu23DV3FHn8+DHu3LmD8uXLo0+fPtyVr4UePnyIkJAQ6OnpwcrK6rtdqP65baRq/fDwcNy5cwdVqlRBly5dFC4sZkqOqtuWMp9b/3PExMTA398fY8eOFRYxRfS57fju3TtcvHgReXl56Ny5s9w10Yrqxo0bePr0KZo0aQIbG5tC15epOpaXhDI5SWMYhmEYhlF3ZfLsToZhGIZhGHXHJmkMwzAMwzBqiE3SGIZhGIZh1BCbpDEMwzAMw6ghNkljGIZhGIZRQ2ySxjAMwzAMo4bYJI1hGIZhGEYNfbVJ2tWrVxEVFSUMM2pELBYjMTFR5ZvJMwzDMAxTcr7axWybNGkCW1tb7N69W1ikVsLCwuDh4YGwsDC8evUKFSpU4K6MTERIS0tD27ZtMXPmTJiYmAirl1pHjx7F+vXrERQUhO3bt2PGjBnClFInOzsbJ06cwMuXL1GxYkUMHToUNWvWFKYhOzsbXl5eiImJgZ6eHrp06YL27dsL05SKi4vDyZMnkZiYCGNjYwwaNAi1a9cWpn32+zCq+/PPP9G0aVPY2toKixg1EhAQgMzMTHTt2lVYBORfpf748eNIS0uDtrY2hg8fjqpVqwrTlCpufdZ/SkZgYCCuXbuG9PR0NG/eHAMGDFB45f83b97gwoULePXqFRo0aIC+ffsW66r/n+pvpWKMFt4n6kt4/PgxASBjY2PKy8sTFqul27dvy92ElfJvuO7i4kLly5cnX19fXllpJxaLSV9fn7Zv3y4sKnVevHhBc+bMoejoaCIievPmDY0ZM0bunpBRUVE0YsQIevLkCUmlUnrx4gXVrl2bfvrpJ95N05U5c+YMzZ49m+Li4oiIyMfHhwwMDGjXrl28vM99H0Z1z58/JwMDA/Ly8hIWMWogICCA9uzZQ1OnTiUdHR1avny5MIWIiGJiYqhdu3YUEBDAPbexseHdfLswxa3P+k/JWLZsGe3YsYPi4+MpMDCQHBwcqEGDBnL3ST1z5gzNnTuXoqKiKCoqihYsWECVKlWif//9l5enjKr9rbSM0V9lkrZo0SLq06cPAaDz588Li9VSWFgYAaCZM2cKi0gqlVLlypWpXLlycjfXLu0qVar0XUzSBg0aJPeDIC8vjxo1asS7efmwYcPIwcGB0tLSuJiHhwcBoNOnT3MxRaRSKdWqVYvmzZvHizs4OJCmpiYlJSVxsc95H0Z1UqmUfvrpJwLAvmTVlL+/P/n5+ZFIJCIASr80u3fvTh4eHrzYpUuXqGbNmpSZmcmLK1Kc+qz/lAwfHx9aunQpL5abm0vVq1enhg0bUnZ2NhERxcfH08CBA+UmSUOHDiV9fX0KDw/nxRVRtb+VljH6q6xJe/78OZYtWwbkH1Yr7TQ0NGBtbY2srCxcvnxZWMx8Y9nZ2bh//z40NfndWUdHB02bNkV4eDgXy8zMxOXLl5GSksLFqlWrBgCfXEMpEomQmpqKc+fO8eLVqlWDVCrFy5cvudjnvA+jur/++gsjRowQhhk1YmNjg06dOkFbW1tYxImOjsaVK1fQr18/Xrx79+5ISEjAlStXeHGh4tZn/adknDhxAmfOnMGLFy+4mK6uLoYMGYLIyEg8ePAAAHD58mUEBATgv//+K1AbGD16NHJycuDl5cWLK6JKf0MpGqO/+CTt3r176NChA6ytrVGvXj2cPXsW2dnZwrRiKbh8TiqVIjQ09Iu99qfk5OQAACwsLIRFnI8fPyIvL08Y/mxSqRRxcXGQSqXCIh5Vlxeqmlda6OjoIDk5GVOmTOH1B5FIhOfPn6NRo0Zc7OTJk3j16hVvrVpgYCAAfHI9iq6uLp49e8YNKDKBgYEwMTFBkyZNuNjnvA+jmtevXyM9PR3NmjUTFjGlzMWLFwFAbt2vpqYmqlSpAh8fH15cqDj1Wf8pORoaGggJCUFcXBwvLltnFh0dzeXFxcUhJCSk0LwvobSM0V98knbs2DGMHDkSADBq1ChkZGTg/PnzXPnt27cxZMgQdOvWDZ07d8bs2bO5smXLlqFLly7o2rUrdu7cycVPnjyJ4cOH49dff8XIkSPxxx9/wMPDAwEBAejevTuX97WEh4fDz88Pjo6OChcgXrhwAcOHD8fp06exdOlSjBgxAomJiQCA7du3o0ePHrC3t0f37t1x8uRJbN68GT179oS9vT169+6NsLAw5Obmwt7eHl27dkWXLl1w584dAMDGjRuxdu1aXL16FTNnzsTMmTORnp7OvXdsbCy6desGY2NjjBkzBrdu3cKKFSvQokULbuBC/pmca9euxaxZs7B+/Xps3LgRt2/f5spLM21tbUyePBl//fUXWrRogevXryM7OxtTp07FqlWrULFiRS7XwMCAN9FOTU3FsWPHMGPGDFhbW3NxZapUqQIjIyPu+f379/HkyRNs374dBgYGXPxz34f5tB07dnwXJ7ww4L6Uy5cvLyxC5cqV5b60hYpTn/WfkrN9+3aEh4fLTX6ePXsG5J9oCACOjo4IDQ2Fu7t7oXlfQqkZo4XHPz+HRCKhESNGcM9l67wGDx7MyxOJRGRlZUUtW7aUi7du3Zru3LnDxS5evEjlypWjjx8/EhFRSkoKGRsb09GjRyk7O5vu379f4BWKT/a3jhgxgh4+fEgPHjygc+fO0cqVK8nGxoY8PT1JKpUKq9HRo0fJ3NyckpOTudjGjRupXbt23POAgAACQLt37+Zit27dIgD0+PFjLvbhwweqXr06RUREEOUvoGzatCm9fv2ayxkyZAiNHDmSey4zYsQI6tevH/35558kEonI1NSUFi5cSJT/udrZ2ZG7uzuvzo4dO0hLS+u7WJOWk5NDU6ZMIQAEgOrXr08PHz4UpnGuXbtGHh4e1LFjR7lF/58ilUrpyJEj9Msvv5CNjQ1du3ZNmML5nPdhlDt48CA9evSIiIhevnzJ1hSVEsrWCI0ePZoAkFgsFhZR69atqWnTpsIwT1Hrs/7z7aWmppKhoSF169ZNWCTHzs6OTE1Ned+zqlDW3wpS9zH6i+5Ju3nzJjp37sw9b9q0KZo1a4YLFy4gNTWVi2tra2Pu3LkICQlBTEwMF5dIJOjevTs6duzIxfbt24emTZuiUqVKAAAjIyNYWVnB09MT+vr6X3zGKxaLkZOTg5ycHIjFYvj6+qJFixYYOHAgNDQ0eLmZmZlwc3ODo6MjKleuzMUnTJiAR48e4datWwCAdu3awdraGn5+flxO69atoa2tDX9/fy4mlUoxbdo0NGzYEMhfaxUZGYk3b95wOX379sXx48eRlZXFxZC/h+fq1asYMWIEtLW18fr1a6xduxYAsH79egQGBmLJkiW8Os7OzpBIJLxYaaWnp4dBgwbByckJNWvWxIsXLzB48GClewvbtGmDwYMHY8KECdi2bRuOHTsmTFFKQ0MD9vb2GDFiBGxtbeHu7q7wlzo+830YxeLi4hAXF4c2bdoIi5hSKisrC1paWtDS0hIWQSqVIjMzUxjmKUp91n/Ug5ubG0xNTXHgwAFhEc/Bgwdx//59HD16lPc9+6Wo+xj9RSdpR48ehYGBAby9vblHo0aNkJubi9OnT/Nyhw4dChMTE+zbt4+LyQ5rFqSrqwuxWMyLyeJfQ/Xq1dGpUyf8+OOPGDx4MK5evQo/Pz8MHDhQbk1YYGAgEhISYGpqisjISO7x/v17VK5cGU+ePOFyx44di1OnTnGDxZkzZzB48GD8888/XM7x48e5Q8XIP1ycnp6Ojh07IjU1Fffv30dMTAyIiLfYUaZWrVpcJzYwMOAmlUePHkWnTp1Qrlw5Xv7X+gy/BXd3d4SFheHgwYMIDw+Hq6sr3r59i169evF+CMgYGRmhQYMGcHZ2hrOzM0aNGoV///1XmKZU1apV0aJFC6xbtw5Vq1ZFx44dFS42/dz3YeRt3bqVt0yCKf0MDQ2V/mBMS0tTeBizoKLUZ/3n2zt9+jSuXbuGq1evFrrO+9WrV/j555/h5eX11ZY2qfsY/cUmaSKRCG/fvkW5cuWQkZHBPXr16gUAcv9oXV1djB8/Hn/99Rc3CQsICEC7du14eVOmTEFERARiY2OB/OPGDx48wMyZM3l5X4u2tjbGjBmDe/fu4fjx47wy2ZdyXl4eXr58yXscPnwYgwYN4nJHjRqFnJwcnD17FshfQ+Hh4QF/f39uEvHixQv88MMPXB0A8Pb2hoODA9asWYP4+HhUqVIFULL439TUVBiCVCrF06dPuT2R36OrV6/i/v37WLBgAZA/YG/ZsgW+vr7Q19fHqlWrhFV4+vfvDwByexpV1b9/f2RmZnJ7LpX53Pdh/vdDpn///tDT0xMWMaWYbJ1nbm6usAhpaWm8daCKqFqf9Z9vLygoCBs3boS/vz/q1q0rLOakpKTAyckJJ06ckDtr92tRxzH6i03SLl++jBEjRmDkyJG8h7OzM9q3b4+rV69yi+llpkyZgvj4eJw/fx4REREKFwXWrVsXkyZNwuLFi/Hrr7/C1dUVf//9d4k1GgBugvPo0SNevEGDBtx/e/XqJfcwNzfncqtUqYIePXrgn3/+QWJiIqpWrYq6deuiQ4cOOHLkCF69eoU6deoUeHVg7dq1+Omnn7Bx40asW7cOAwcORK1atXg5BQkPxyL/7Kbq1avLHR79nvj4+GDgwIHCMOzt7eHh4cFdgiMuLg7NmjWTm7TJzhyKiopSOMjLXLx4EY0aNZI7U0xW/0u9D6NcfHw8du3aBScnJ+4xefJkAMCWLVvg5OTEW0LAlA5WVlYAgKSkJGER0tLSuHJlVK3P+s+3FRMTg9WrV8Pb2xvVq1cHACQmJsqdMZ+bm4upU6di586dvJMNvL29eXnFVarGaOEiteJydnam1NRUYZiIiDZv3kwAaMeOHcIisre3p969e9OSJUt4F5WT2bdvX6ELswvKy8vjXbi0KAq7mO0///xDAKhPnz5cLDc3lzIzM6lKlSpydymg/JMAhFe6PnToEGlpadGvv/5Kr169IspfvN+4cWP6/fffeRfKzc3NJQMDA5o6dWqBVyDau3cvAaDY2Fjas2cPxcbGEhHRzJkz6ccff+TlykycOJEsLCzkTnzIzc0lAKX+xIFly5YpXRx69epVmjhxIhERnTt3jgBQ9+7deTmytq9fvz4vnpqayluIPHfuXAJAq1at4uVt376dAJCzszNRMd6H+Tw3btxgC79LCWULuZOSkkhLS4t30hjlj6MA6MKFC7y4cAF5UesXxPpPyUhMTKQpU6ZQRkYGL37mzBm6ceMG91wikdDs2bMpMjKSl5ecnEy//fabXKwwyvpbaRqjv8ietKdPn+Ly5cvQ19cXFgEAt5dj//79cuu6pk6dikuXLiE3NxcVKlTglSH/umRz587FkSNHcPLkSXh7e8PPz0/hLNfGxgaWlpbIyMgQFn2S7CbjBS9vISPbJRscHMzFNm3ahHLlymHnzp04ceKE3PVbfv/9d1haWvJigwYNgp6eHvz8/Lg9YiNGjMCLFy8QHBzMu8echoaGwjVjsgum5uTkID09nduNLxKJFP7tyN8jl52djZMnT/Lie/fuBQpcA660Gjp0KI4dO8Y7OUXm2LFjcHFxAQD8+OOPsLa2xpEjR3g5vr6+AIBFixZxsYSEBFSvXh19+/blYv369cPIkSMxf/58Lob8+vr6+tw6l6K8D/P5ZP2+ONs9U3Jk62gVrac1MTHB4MGD5caos2fPomnTpujWrRsX+++//2BiYgIPDw8uVpT6Qqz/fH1ZWVkYMGAAxGIxFi1ahFmzZmHmzJmYOnUqFi9ezDuK5urqiufPn2Pbtm1c3rRp0zBs2DDeNS8V9YOCCutvpWqMFs7aiiIlJYW6du1KpqamZGhoSD/88APdvn2bl7N27Vrq1KkTVaxYkSpUqED29vbk6urKlefl5VH16tW506GF8vLyqEWLFlSrVi2qU6cOVaxYkQBQ+fLlydXVlbd3aNSoUdSmTRu52wMVJiQkhMaNG0fW1tZkZGRE1atXJ0dHR9qyZQsvb86cOaSlpUUnT56kR48e0aZNm7gyHx8fsrOzo9WrV9OJEydo8eLFdO/ePV59GScnJ9qzZw8vNmDAALl7TBIRnTp1imrXrk3u7u508eJFWrNmDb19+5aGDx9OHTt2pDVr1tCbN29o7NixVL16dTIyMqIhQ4bI3RqFiCg6Opp69+5Nq1evJm9vb/r999/p9OnTBIBMTU1p+PDhcrfiKE3+++8/sre3pyNHjlBYWBj5+vqSi4uL3K/jO3fu0IQJE+jw4cMUEhJCBw8epGrVqsl9ZqmpqdSoUSOaMWMGL+7p6Ulubm507tw5Cg0NpaVLl1KNGjXI29ubl6fq+zDFFxkZSY6OjtS8eXOqWLEiNWzYkMaOHUtBQUHCVOYbOnz4ME2cOJHs7OzIyMiIatSoQY6OjjRhwgTKycnh8pKSksjW1pYOHDhAGRkZdOXKFbKysqInT57wXs/f359q1KghN2aqWl+G9Z+S4+zsTMi/PJLwYWJiwuXJjlope4SGhnK5yvqBqv2ttIzRGqRoBXoJS09PV7gXLTs7Gx07dsSWLVtgZ2fHxfPy8nDnzh04Ojpi06ZNvDMiv6bnz5/j1q1bMDExwYABA+RuQ/T27VtIpVLeFYyFMjMzUa5cOd76sYyMDBgaGvLyZKRSKZ4/fw6JRIKGDRtyp5inpaXxLtKqqtTUVCQmJqJ+/fpA/gkMxsbGMDEx4V2MtTTKzs7GzZs3ERMTA0tLS3Tq1EnhZyQSiXDz5k28ePEC5ubm6NChA28v5qd8/PgRt2/fxtu3b9GgQQN06NBB4dlnn/s+DFPWSCQSXL9+HU+fPoWFhQV69+6t9AiNIp9bnylbSsMYrRaTNGVOnTqF3bt349KlS8IiAMD8+fOhqamJ33//XVjEMAzDMAxTqn2RNWlfS7t27fDixQu8evVKWIS0tDRcu3YNvXv3FhYxDMMwDMOUemq9Jw0AwsLCsGnTJpibm6Nly5bQ0dFBeHg4nj59ip9++gk9e/YUVmEYhmEYhin11H6SJpObm4vY2FiIRCJYWFgoXcPFMAzDMAzzPSg1kzSGYRiGYZiyRK3XpDEMwzAMw5RVbJLGMAzDMAyjhtgkjWEYhmEYRg2xSRrDMAzDMIwaYpM05psRiUR49OgRjh8/jvv370N2DsuLFy+EqWXO+/fvcfnyZXh5eSEmJgbIv9OBt7c3d/9WpmgOHTpU7PvUZmRkIDY2VhhmGEYNicVivH//Xun9rIuKiPDx40e8f/9eWPTVfbWzO3/55ReEhYUhNDQURISGDRuiWrVq0NDQgFQqxfv37/H69WtkZWXB1tYWBw8eFL6E2rp58yZq164tdwN1RnWPHz/Gzz//jFGjRqFp06aIjo7GtWvXMG7cOMycORNBQUHCKmpj5cqVePToEfz8/CCRSNCuXTtUr14dGhoaSExMxLt379C+fXvMmzePu/2WkLI+lJubi5kzZ8LAwADOzs6oVKkSfv75Z2RnZ0MikWDVqlXo0aMHDh48+E0u5Pz8+XMMGTIEGhoaMDMzg6mpKXJychAdHQ0AqFGjBipXroyPHz8iISEBYrEYa9asQf/+/YUvVaLi4uJgYWGBf/75B6NHjxYWKyUSiTBs2DDcuHEDurq6SExMFKZ8M6tXr8bDhw/h5+cHsVjM3dJGQ0MDYrEYHz58QPXq1bFw4UL88MMPwupfTGRkJD5+/IgOHToIi8qkDx8+ICAgAD179uRu41cWKBsXkT+uZWRkoGXLlpg/fz4qVaokrP7F7N+/H3/88QdCQ0Nx4MABjBs3TphSJCEhIZg7dy6uX7+OIUOG4MSJE8KUr4t3J8+voF27dgSAYmJihEWUnZ1NCxcupMaNGwuL1FZERAQBoNatWwuL1NLFixdJJBIJw99Uamoq1atXjyIiInjx9PR06tChA1laWvLiX9Pz58/l/g5VdevWjQDQ27dvefG8vDzat28fmZub08mTJ3ll9Ik+NG7cOJo0aRIvVqdOHdLQ0KDY2Fj68OEDNW7cmI4fP87LKSnXr1+nhg0byt20unHjxgSAMjMzuVhCQgL17t2bNm3axMv9FrZs2UIAqH///sIilaxevZpMTU2FYbXQq1cvAkCpqam8uEQiIRcXF9LW1qbz58/zyr6katWqkZaWFiUnJwuLvqj//vtPGFJLo0aNIgB09uxZYVGZoGxczMrKooEDB5KJiQmFhYXxyr60nJwc0tDQoAMHDgiLiq1Hjx40bNgwYfir++qHO01MTABA4c279fX14eHhAVNTU2GR2qpbty6cnZ0xc+ZMYZFaOnXqFCQSiTD8TR07dgxVqlRBw4YNeXFDQ0N4enryYl/bgwcPin34sHLlygAAPT09XlxHRwcTJ07Enj17MHToUJw+fZpXrqwPiUQinDx5EiNGjODFXV1dUb16ddSoUQPGxsYIDw/H8OHDeTklJTExEYsWLUKTJk14cdlnUPCzqFKlCjZu3IiEhIQCmd/GrVu30LJlS1y6dAkfP34UFn9S+fLlhSG1oawfampqYtOmTahYsSIcHR0hFot55V/KggULMHPmTO7v+FpKfA9GMU2YMAFjx45F+/bthUVlgrL+aGBggD179iAlJQXDhg3jlX1penp6X3wv5rcaA776JE0VPXr0UKvDCIXR0dHBnj17MHHiRGGRWrp8+bIw9M09efIEGRkZwjAAoHnz5mjevLkw/NVcunRJGPpi+vbtizZt2mDOnDnIzs7m4sr6UFpaGjIyMlC1alVeXCKRoEKFCrzYt5KYmFikw1qNGzfm/du/hZcvX8LS0hJjxoxBXl4eTp48KUz5bhkYGKBBgwZISUlBZGSksPiLmDt3LjZv3iwMf1ExMTF49uyZMKyWevbsiX/++UduO2YAMzMzVK9eHREREYiKihIWMwp8s0na8uXLuf/v0qXLZy3wK7isTtUldh8/fkReXp4wzPnU6ygrLxiXSqW8sqJITExU+h5Q8d/8+++/F3sv0ddkYWGB0NBQHDt2TFgEAHKTF6j471WksM/Rz88PR48eFYa/KGdnZ7x69Qp79uwRFin9u9RZ+fLlUbt2bWG4UI0bN+b+Py0tDSkpKbxyZYTbUmhoaLEmfP/++y9GjRqFUaNGQUNDA//++68w5bN8+PABSUlJAFDsExO+luzsbERGRqJy5coK10d+qg/m5uaqtCdU2esUZbvNysrC27dvgfz3lZFKpXB1dS2QqZxUKuXaQplP/R3CcuFzZTFVFOXzkCmYl5SUhOfPn/PKS5u8vDxoamoq3POakpLCa/vCFDa2f0p2djbS0tKEYTnFff0v6audOCDTu3dvXLx4EfHx8dwvi/fv32PhwoXYv38/L/fatWvw9PREUlIS8vLy0L59e6xfvx7Pnj2Ds7MzdHR0IJVK4e7uDiLC0qVL8fTpU7i6uqJq1aqIiIiAnp4eXrx4gUmTJmHgwIG81weACxcuYP/+/ejduzeePXuG6Oho7NixA2ZmZrh06RKWLFmCp0+fYuPGjdDT00NYWBh8fX3h7e2N9PR0TJkyBWFhYRg0aBD39+/evRvbtm1DVFQUzpw5g+TkZO6kiCtXrmDLli1o3Lgxtm3bBj09PTx//hwfP37Enj17ePcgJSKsW7cOL1++RIcOHeDv748KFSpg3bp10NbWVvo+IpEI165dw/r169G2bVukpqbCxcUFN2/eRFxcHEaPHg0tLS2UK1cOu3fvLvBpfBvx8fGoV68ecnNzMWTIEPTr1w92dnZyi+gBwNHRETdv3kR8fDyCgoKwe/duGBgYID4+Hnp6eli/fr3cIlSxWIzffvsNIpEIDRo0QGxsLN6+fYt169bByMgIyD+x5eTJk4iMjIS9vT23wHX16tWoVasW7/WUGT58OLy8vJCUlMQd1he6efMmunTpgrFjx+Kff/7B06dPFfahzZs3486dO/Dy8kKvXr1gZmbGvUZ4eDiePXuGQYMGAfl/e6NGjbhyddC6dWsEBwdDLBYrPMwQERGBPXv24IcffoBUKsW5c+fw888/w97eXpiKkydP4t9//0XDhg3x/PlzdOjQAdnZ2ahatSr++usv3LlzR1ilUMOGDYOXlxcA4Mcff8Tdu3fx9u1bVKtWTZgKAAgNDcUff/wBc3NzVKtWDXl5eRCLxdiwYQNvj/+///6LmJgYNG3aFMnJyXj+/DmuXLmC+/fv817vaxs9ejT+/fdf5OTk8A4xSSQSzJw5E0eOHMGxY8fg4OAA5O89Lmycs7CwQGZmJlasWAFzc3MYGxvjzJkz6NGjB6ZNmwYNDQ3uPfr27YuHDx/C0NCQ2zPi7++PefPmITw8HNOnT8eAAQNw7do1aGtr48aNGxgzZgycnJy41wgMDMTx48fRpk0baGpq4tmzZ9i/fz/u3LmDt2/f4ueff8aDBw+go6PD/Rvatm0LNzc37jWSkpKwaNEi1KtXD1WrVkVYWBjMzMywcOFCaGr+b1/E2LFjcf36dWhqauLevXvYvXs37ty5g+7du2Px4sWYMWMGzp8/j3fv3iE1NRU7d+4EESE6Ohpv3rzB/v37kZKSguPHj0NPTw/3799Hs2bNsGzZMu7v+PXXX3H48GHExsbi+fPnqF27NlJTUzFy5Eg8evQIP/zwA06dOgVPT0+UK1cOwcHB3LKAgp9rUlISFi5ciIoVK0IqlSIzMxMtW7aEgYEBjh8/jvnz56Nnz55cvjopbFx8/PgxWrVqhdGjR+PIkSNc/NixY7h27RratGmDtLQ0hIaGYvHixXLjnCpju4yOjg727t3LO3Hg2bNncHd3h52dHXJzc3H79m0sX74cbdu25dU9ffo0zp8/D0tLS1SuXBkVKlTA6dOnoaOjU/KH3YWL1L40BwcHAkAzZ86khQsXkouLC9WpU4ccHR2FqZwVK1YQAAoNDeVivXr1okWLFlFWVhYXE4vFZGxsTBYWFnTv3j0u/uzZMzIxMaGNGzdyMSKio0ePkrm5OW+B68aNG6ldu3bcc7FYTNWrV6fJkyfTjRs36NGjR6SpqUkXLlzgclq1akXjx4/nnhMRJSYmEgBavHgxPX78mIsvWLCAmjVrRlu2bOEtqq5VqxatXbuWe05E5OLiQr169eLFBgwYQPPnz+eeF/Y+bdu25Z4TER04cIAAUE5ODi+uDi5evEhGRkYEgHs0aNBA4ULPP/74gwDQ1KlTSSKRcHFXV1eytLSUW7Ds4OBAq1ev5sXOnDlD9evXp/T0dC728uVLAkAXL17k5apq2LBhBICSkpKERZwnT54QAGrRogUvrqgPJSUlEQC6cuUKL75hwwaysLDgxdRNq1atCACJxWJhERERtW3bltavX889f/z4MWlra8stIL548SKVK1eOPn78SEREKSkpZGxsTEePHqXs7Gy6f/8+L/9TwsPD6ddff+Web9++nQDQli1beHky58+fJ0tLS96JTvHx8dSyZUveiQPR0dHUs2dP7jkRUUZGBnXs2JEXKwmyhepr166lDRs20IYNG2jevHnUsmVLmjRpEr1+/VpY5ZPjnJubGw0aNIjb3jIzM8nCwoJ27doleKX/5So62adZs2Y0btw48vLy4mLe3t5kYGBA79+/5+UJx6iePXtSfHw893z8+PHUoUMHXo5MYmIi1a5dm27dusWLu7m50ciRI3mxnTt3UrVq1Wjz5s0kFotp0KBB1L59e678xIkTBIA8PT0pJSWFi7dr144mTJhA27Zt42LR0dEEgO7evcvFKH+sAUAvX77kxWfMmEHt2rWj3bt3c59reno6aWho8E6KkEql1KlTJ3J3d+diK1eupBYtWlBubi4FBQXx/jZ1o2hczMzMpMuXL1OtWrVozJgxlJ2dzZWtXbuW+vTpQ3l5eVwsKiqKatasSY8ePeJiVISxnYhIW1ub933y/PlzqlixIvn5+XGxBw8eUIUKFXh9bfHixdS1a1fe33j37l2qVKnSNzlxoMQmaSEhIRQXF0fh4eG0ePHiQidpREQjR46k9u3bU25uLt27d49+//13YQpR/gY+ffp0YZiWL19O+vr6FBUVRZQ/gFatWpUWLFjAy0tOTiZNTU26efMmF2vWrBlvQCg4uSIi6t69u9wXLP1vjySNGzeOF/v7778JAJ07d44X7927N/Xu3Zt7/uDBA9LQ0CBvb29e3pkzZ8jAwIA3iBX2PgX/VnWepFH+Z79t2zYaOnQoVa1alZA/WduwYQMvz8vLiwDwBnbKP0u0YsWKNHnyZC524MAB0tfXp4yMDF4uEVGjRo3Izc2Ne14SkzTZQF63bl1eXFEf+p4naY0aNSIHBwderGbNmvTzzz/zYsOHD+f9aKL8L+yuXbvyYqpaunQp70zUhIQE0tLSUviFn5ycTFWrVqXffvtNWETu7u68SZqvry9ZWFjwBnfKb6uSJpukCbfzFy9ekLOzM1lbW8t92dEnxjkXFxcyNjbm/Sh2cnIia2tr7rnMqlWrFE7SunTpQnXq1CGpVMrFXr16RQC4cS4nJ4e0tLTo9u3bBWoS/fXXX7wfX4VN0saPH0+2trbCML179440NDTozJkzXMzLy4u0tLS49xeLxbzP7caNGwSA9u/fz8WIiCZMmECampq8yZFUKqVy5crRunXreLl+fn4EBZO05cuXk4aGBkVHR/PiderU4X0vyX7YFfwu8Pf3JwC87yl1JRsXJ02aRPPnz6d58+bRvHnzaOfOnbwdL0REkZGRpKurS1evXuXFKb8PtmnThus/RRnbScEkrV+/fnJjC+WPXStWrCDKbzsNDQ25CT8RkY2NzTeZpJXYmrQqVaqgWrVqaNy4MVauXCm3EFq4iHDv3r1ISUnBxIkTcezYMSxYsIBXXpBsd3ZBvXv3Rk5ODry9vYH8XeoJCQkwNTVFZGQk93j//j0qV66MJ0+e8Oq3bNmS+/9y5crxygrTokUL3nPZGSEFX08WL7h+xcfHB0SEcuXK8f4+HR0dZGdnc9ehklH2Puq2JqYwlStXxsyZM+Hl5YW4uDhcuXIFVatWxdKlSxVeNFDYzhUrVkSnTp14C8GPHz+ORo0aKTwTx9rausQXjcvWPQjbq6wJCQnhtsXIyEhcu3YNWlpacmda6urqKjwLUVdXVxhSyfXr1xETEwNvb294e3vjwYMHqF+/Pu7du8ddJLhgbkJCAnr06MGLQ8GZau3bt4eWlhbq1KmDPn36YNOmTXj+/DnmzZvHy/uW6tWrhz179sDAwACdO3dWeOKAsnFu165dePfuHQwMDPD27Vvcvn0bKSkpcu31Kc2aNeMdxhOOU3p6ehg4cCA6d+6M9u3bY+nSpfDz88OECRMUrlkSIiJ4eXnJHa4CAHNzc9SsWVNum5dIJGjTpg0AQEtLS65toWB7la3FLHhITUNDA+XKlSvSmGtoaIg6derwYsLvAllf/5Lbwbfg7u6O9evXY8OGDdiwYQOmTZuGZs2a8XLOnj2LvLw8he1nbW2NwMBAbjv9nLFdLBbD19cXtWrV4n2/RkZGwtzcnPv+P3bsGPT09PDjjz8KX0JhPykJ8rObEqCpqSl3CYE///yT99zQ0BBHjhzB4cOH0apVK16ZKmrWrAkAePr0KVBgEpiXl4eXL1/yHocPH+bW+8gU97IgijoQlMQLLgeU/X1paWm8v01LSwuXLl2SW6+l6PUgeE11JfuyLkhDQwPdunXDv//+i6ysLJXXHdWsWRPJycncpC48PFzh5V6Q/yX05s0blRaMfimyL8bi9OHvycePH+Hq6ooBAwbg1q1bMDAwgIGBgVx/nTJlCiIiIrir+6empuLBgwdylytRRWBgIH744QdkZGTwHn369MH/tXfmQVWVbxz/qqEZ3IuYmbhUmpkWWmOK4gJXYxnKHXOJi5VLYjqUQFC4VBImQi4wqKhlIiKmgBbmwmgzDtokLrEEoo6lkBuoiMR4uXm/v384ZzjnHhR+SiC9nxmGe573veec+77vec7zLs/zoloh1yQ3NxcArNY4aqHT6ZCZmQk/Pz9kZ2cjKCgIL730EqKiotRZG51p06ahoqICK1asUCfVqueqqqqwevVqeHh4ICkpCSaTCe3bt7eqr/tRFz2VmJiIJUuW4Pbt2/jyyy8xfPhwvPXWW5pGipqLFy+ioqLins98Xl6eWlzr75bQum8tGeqpc+tyjp49e8Ld3R379u2TZRkZGRg8eDAGDBggy5oD+fn5QC0huqROg1R/D6Lbi4uLYTKZ0LJlS6v3/4cffojFixcD1TrA3t5e0bFobBrFSAOAESNGyJ+vX7+u2UNIS0tDREQE5s6dKxtbdeXy5ctAdUwqAOjVq5f838vLy+rP0dFR8f1/u5Kk+xs8eLDVvXl6etbaOOtDfn4+Tp48qRb/6+zevbtWLz2DwQB7e/taHzY1ly9fhk6nk5Xuc889h8rKSnU2oNp7zMHBAXq9Xp0kk5iYqBY9EImJiWjXrh38/f3VSf8Zrl69igEDBqCyshK7du3CrFmz4OLiotkz7dGjB2bMmIGwsDAsWrQIAQEB2Lx5M0aNGqXOel+Sk5OxcOFCTJ48WfG3ePFitGnTxsqzV3IYqa391OTPP/+EnZ0d4uPj8ddff6GoqAiBgYEIDQ1tcttHSUan1n1p6TmSGDNmDLZs2YLU1FR8/PHHcHd3r9PIVn0xm804f/48FixYgPz8fNy8eRMbN27Evn37rIzommzfvh1msxmOjo5o3bp1rXVWWVmp6Y2s9bubEu7u7rC1tUVAQABCQ0NRUlKCPXv24LHHHlNnfaSRBh+06k+SSfX3ILq9W7duaNu2LTp06GD1fvXy8sLLL78MVOuA2q7RWDSakVaTDRs2WAXH3Lp1K0aMGIGwsDD4+fnBx8en1thaWj2ZI0eOoGXLlnB3dweqRzI6duyIn3/+WZ0VN27cqPPITUPh4eGBFi1aaN7fsWPHNKf/7of0EpTK59q1a/WermgISCp6iTW5e/cuTCaT1fQwNOq5qqoKx48fh4eHhzwV6unpiYKCAs2QLllZWXJ7gEb5WCyWh+refuLECaSnp+Orr75qsJhJTaE+78f69etRVFSEpUuXKqasa4ZK+OKLL4DquH4TJkxAQkICwsPDsXnz5v9rSymSuHjxotXUEqqNFm9vb+Tk5Mg9eQBwc3ODjY2NZkdGHRbgxIkT2Lp1q3zctWtXREZGYujQocjJyVHkbWwOHjwIVHeA6kJmZib279+PBQsWKJalaNXXg1JeXq4Ix2Rvb48ZM2bgo48+QnZ2tixv06aN4vk/ffo0WrRogdatW8NgMCArK0tOk7h69SqKioo0p6+bOrm5uYiKikJMTAwiIyMRGxuL9u3bq7M98kh1o1V/WVlZ6Ny5s2xA1Ue3q2nVqhVef/11HDp0SJ0EAEhPTweqjePbt29r7h+t1gH/Fg1upEkjIrXFJNu1axciIyMVRlpqair27t0ru+evXLkSZrMZ06dP14yef/jwYcXIy82bNxEVFYWgoCB5mumJJ57AmjVrsGPHDqv1XcuXL1dMJ5rNZs2GIGE2m62sbWlo3mw2K+TSsZa8ZpkMHDgQ8+bNw6pVqxTrE8xmMzZs2CCPFN3vOjXPKa2rkOb0z549qxkrqTGYN2+e1ZogVI88ubq6ak4P/vjjj4rj2NhY3LlzBzExMbIsKCgIvXv3RmxsrCLvDz/8gCtXrmDlypWyrFOnTujYsaN8H+fOnatX+dyrbe/Zswfjx49HdHQ0Zs+erU7WbEP3aisVFRVWRmpwcDCeeuqpRu9goIYC0yqLxx9/HFAZ2dnZ2WjXrp3c1qWwHV27dkVgYCCSkpKQkpKCPXv2IDMzs94KctOmTff8jhSeZ+PGjbKsR48e+OSTT7Bu3TrFd2/cuIG0tDSYTCbFb1izZo1VXbVq1cpqPVNDc692mJKSgvXr12PIkCGKkBW4h56T6qsmFRUVuH79ulxfNY1trbYsydXlo6Wn0tPTrXSy2WyGs7OzfNyvXz9cuHBBjj1pNpvlUaW4uDjk5eUhMzNTzo9qvT5o0CDF8yddX+t34z7PoFomydXlLuVTl0l9znHhwgUsXrwYO3fuRFpaGg4cOGBVRk0VqT3WVsY1GTJkCGbPno1Vq1Ypprf/+OMP7Ny5E+vXr5fruT663WKxwGKxKMo7NjYWly5dwu7du2UZqte6Sc+10WiEm5ubVXDmkydP4rfffqvX+sOHhtqT4GERGhrKN998k61atSIAurq60tfXl0ajkb6+vpwwYQL79u1LAGzRogX//vtvbtu2jYMHD6adnR0dHR1lb74DBw7QwcGBOp2Ozs7OXLhwoXwdJycnGo1GhoaGMikpiYmJiXRzc2NcXJzCq0hi7969dHV1ZUREBHfs2MGwsDA5fEdGRgZ9fHyo1+vZpUsXvv3224r9144dO8YpU6awffv2fPrppzl16lRWVVVx06ZN9PLyok6n44svvkg/Pz+S5Jw5c+jk5ESdTkeDwcCYmBgWFBRw6tSp7NChA3U6HceNGye7cN+9e5fR0dH09PTk2rVrmZCQwNDQUF6+fJkk63SdQYMGceXKlfI9BwQEcOTIkdyyZYum11pjMHPmTK5du5bBwcEMCwtjRkYGjxw5wvDwcLq7u1vt+SZ5d8bFxTEyMpI//fQTQ0JC6OXlZeUpRZI3b97ke++9x7lz5zIpKYmhoaEcPXq07Olbk6SkJPbu3ZvfffcdAwMDNT2H1Hz22WccPXo0bWxsCIAGg4FGo5FGo5Hjxo3jkCFDOHHiRE2PutraUExMDA0GA3U6Hfv378/g4GDeuXOHRqORzz//PHU6Hb29vTl//nz5XDExMezWrZvVPpr/FhEREZw+fTrfeOMN6vV62tvb08XFhe+++y7ff/99OV9ZWRl9fHzo4uLCbdu2MSEhgVu2bGFWVhYdHBzo7+8vh5Opqqpiv379+Mwzz7B79+7U6/UEQFtbWwYEBGg+0zXJzMzkwIEDaW9vT1tbWzo7O1uFK/Dz82OfPn1ob29PvV5PHx8fObSExWLh6tWrOX78eO7YsYMJCQlctGgR58+fTwAcPnw4v//+e+7cuZOjRo1iYGAgU1NTuW/fPoaEhHDr1q2KazUkS5Ys4ZgxY9i6dWsCoLu7u9wOJ0+eTBcXFzo7OzM6OloR3uB+es5isXDhwoXs1asXV69ezd27d3PZsmUsKytj9+7dOWXKFCYnJ/P27ds0Go3s3r077ezsOG7cOGZnZ/OXX37h5MmT6eDgwI4dO3Lq1KksKChQtPEXXniBs2bNYmlpKXv16sWQkBBu2rSJBw8eZFRUlELHs9o7f9iwYfT392dcXByTk5MV6QUFBfT29ubnn3/OxMREzpgxg/7+/oqwDJKe1Ov1NBgMVh7yISEh7N+/P/V6PYcOHcqlS5eyqKiIvr6+7NKlC/V6PSdOnMiMjAympqZy9OjR1Ol0dHR05KRJk1hWVsZPP/2Ur732GnU6HYcNG8bk5GSWlZXR19eXzz77LHU6HceOHcvU1FRFPXTo0IGTJk1iUVERSXL79u20s7Njz5496ejoKOsaJycnHj9+XHHfTYUlS5bI7zZJF7zzzjssLCxUZ1Xwzz//MDIykhMmTOC3337LZcuW0dPT08rLnXXU7Zs3b6a3tzd1Oh379OnDmTNnymmFhYX08PBgUFAQU1JSuHTpUiYkJMjprG5rs2bN4ty5c5mens5169YxOjqarq6utLGx4ZgxY6xCBzUkDWak/Vs4OTlx3rx5ZLV7t9aLWIvi4mLN+EFNAYvFwsLCQqv4X/8vxcXFPHv2rFrcaJw6dUr+XFJSwv379zM+Pp5Hjx7VDOEgGWmlpaWsrKxkbm5unYwpk8nEvLw8q/g5asrKypibm6t5bcHD4/r16zx16hRLSkpkWUVFhVzulZWVfPXVV63CDJhMJh46dIidO3e2ejk3FNIzKLWdS5cu8cyZMywtLeXdu3dZXl7OqqoqOV9hYSHNZrP6NI80lZWVzMnJUcSMM5vNViGJHgSLxSLrueLiYubk5Nzz/AUFBVZhT2py69Yt/v777wqj9FHjm2++4ZQpU3jr1i2F/Nq1a5wzZw579+6tkDcXLBYLz5w5c8/6lairbq+NsrIynj59WhF3U82dO3eYn58vP9dnzpzh+fPnreqloWnwHQcamr59+8JgMFgNgQqaDykpKZg4caJmBGtB8yE1NRXx8fG17qcaHByMli1bYvny5eokgaDZ0K9fP8THx8PFxUWdhPLycjg4OKC8vLxWT1FB86LB16Q1NFVVVZrz/ILmg7ReQ9Rz82bgwIE4d+4cLly4oE5CeXk5Dh06BG9vb3WSQNCsGDlyJNLS0tRioDrigZubmzDQ/kM8siNpBw8exIYNG3D48GHY2tpi6NChiIiIQJcuXdRZBY8wAQEBOHr0KC5duoS+ffti7Nix+OCDD9TZBM2EvLw8rFixAo6OjnjllVdgY2OD/Px8FBQUYNq0aU12v0KB4GFhsVjw9ddfIz8/H87OzujWrRtKS0vx66+/om3btggPDxdG2n+IR9ZIEwgEzReTyYTi4mKYzWZ07doVdnZ26iwCQbOnpKQEV65cwZNPPolOnTpZ7boiaP4II00gEAgEAoGgCSLMcoFAIBAIBIImiDDSBAKBQCAQCJogwkgTCAQCgUAgaIIII00gEAgEAoGgCSKMNIFAIBAIBIImiDDSBAKBQCAQCJog/wPQnJHZOM1QVQAAAABJRU5ErkJggg=="
    }
   },
   "cell_type": "markdown",
   "id": "5f614df0-32aa-4038-b04c-e803a96b188f",
   "metadata": {},
   "source": [
    "![image.png](attachment:e4c87c1d-8a1d-42bf-99a9-89139c7ca63b.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e41d7a4a-35fa-4acc-aa81-a4ee2911a598",
   "metadata": {},
   "source": [
    "#### 6、DML劳动力弹性与先前实验中的估计值"
   ]
  },
  {
   "attachments": {
    "18ce72a8-5cb7-4a55-abf3-d0dd9ba5ca9d.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "eced1158-e600-4a09-8507-681e7f3cf3c3",
   "metadata": {},
   "source": [
    "![image.png](attachment:18ce72a8-5cb7-4a55-abf3-d0dd9ba5ca9d.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
