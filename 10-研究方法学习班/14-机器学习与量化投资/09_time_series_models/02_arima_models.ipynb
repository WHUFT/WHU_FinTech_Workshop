{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Univariate ARIMA Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-15T20:41:31.646708Z",
     "start_time": "2021-04-15T20:41:31.643793Z"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-15T20:41:32.354590Z",
     "start_time": "2021-04-15T20:41:31.651035Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from tqdm import tqdm\n",
    "from itertools import product\n",
    "import pandas as pd\n",
    "import pandas_datareader.data as web\n",
    "import numpy as np\n",
    "from numpy.linalg import LinAlgError\n",
    "\n",
    "import statsmodels.tsa.api as tsa\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from statsmodels.tsa.stattools import acf, q_stat, adfuller\n",
    "from scipy.stats import probplot, moment\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-15T20:41:32.357347Z",
     "start_time": "2021-04-15T20:41:32.355498Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.set_style('whitegrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-15T20:41:32.367707Z",
     "start_time": "2021-04-15T20:41:32.358384Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_correlogram(x, lags=None, title=None):    \n",
    "    lags = min(10, int(len(x)/5)) if lags is None else lags\n",
    "    fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(14, 8))\n",
    "    x.plot(ax=axes[0][0], title='Residuals')\n",
    "    x.rolling(21).mean().plot(ax=axes[0][0], c='k', lw=1)\n",
    "    q_p = np.max(q_stat(acf(x, nlags=lags), len(x))[1])\n",
    "    stats = f'Q-Stat: {np.max(q_p):>8.2f}\\nADF: {adfuller(x)[1]:>11.2f}'\n",
    "    axes[0][0].text(x=.02, y=.85, s=stats, transform=axes[0][0].transAxes)\n",
    "    probplot(x, plot=axes[0][1])\n",
    "    mean, var, skew, kurtosis = moment(x, moment=[1, 2, 3, 4])\n",
    "    s = f'Mean: {mean:>12.2f}\\nSD: {np.sqrt(var):>16.2f}\\nSkew: {skew:12.2f}\\nKurtosis:{kurtosis:9.2f}'\n",
    "    axes[0][1].text(x=.02, y=.75, s=s, transform=axes[0][1].transAxes)\n",
    "    plot_acf(x=x, lags=lags, zero=False, ax=axes[1][0])\n",
    "    plot_pacf(x, lags=lags, zero=False, ax=axes[1][1])\n",
    "    axes[1][0].set_xlabel('Lag')\n",
    "    axes[1][1].set_xlabel('Lag')\n",
    "    fig.suptitle(title, fontsize=14)\n",
    "    sns.despine()\n",
    "    fig.tight_layout()\n",
    "    fig.subplots_adjust(top=.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load monthly industrial production and daily NASDAQ stock market index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-15T20:41:32.868333Z",
     "start_time": "2021-04-15T20:41:32.368753Z"
    }
   },
   "outputs": [],
   "source": [
    "industrial_production = web.DataReader('IPGMFN', 'fred', '1988', '2017-12').squeeze().dropna()\n",
    "nasdaq = web.DataReader('NASDAQCOM', 'fred', '1990', '2017-12-31').squeeze().dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-15T20:41:32.872763Z",
     "start_time": "2021-04-15T20:41:32.869748Z"
    }
   },
   "outputs": [],
   "source": [
    "nasdaq_log = np.log(nasdaq)\n",
    "industrial_production_log = np.log(industrial_production)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Differencing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-15T20:41:32.887976Z",
     "start_time": "2021-04-15T20:41:32.874056Z"
    }
   },
   "outputs": [],
   "source": [
    "nasdaq_log_diff = nasdaq_log.diff().dropna()\n",
    "\n",
    "# seasonal differencing => yoy instantanteous returns\n",
    "industrial_production_log_diff = industrial_production_log.diff(12).dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Univariate Time Series Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Autoregressive (AR) Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on module statsmodels.tsa.api in statsmodels.tsa:\n",
      "\n",
      "NAME\n",
      "    statsmodels.tsa.api\n",
      "\n",
      "CLASSES\n",
      "    builtins.object\n",
      "        statsmodels.tsa._stl.STL\n",
      "        statsmodels.tsa.ar_model.AR\n",
      "        statsmodels.tsa.arima_process.ArmaProcess\n",
      "        statsmodels.tsa.forecasting.stl.STLForecast\n",
      "    statsmodels.tsa.base.tsa_model.TimeSeriesModel(statsmodels.base.model.LikelihoodModel)\n",
      "        statsmodels.tsa.ar_model.AutoReg\n",
      "            statsmodels.tsa.ardl.model.ARDL\n",
      "                statsmodels.tsa.ardl.model.UECM\n",
      "        statsmodels.tsa.holtwinters.model.ExponentialSmoothing\n",
      "            statsmodels.tsa.holtwinters.model.Holt\n",
      "            statsmodels.tsa.holtwinters.model.SimpleExpSmoothing\n",
      "        statsmodels.tsa.vector_ar.svar_model.SVAR\n",
      "        statsmodels.tsa.vector_ar.var_model.VAR\n",
      "        statsmodels.tsa.vector_ar.vecm.VECM\n",
      "    statsmodels.tsa.exponential_smoothing.base.StateSpaceMLEModel(statsmodels.tsa.base.tsa_model.TimeSeriesModel)\n",
      "        statsmodels.tsa.exponential_smoothing.ets.ETSModel\n",
      "    statsmodels.tsa.regime_switching.markov_switching.MarkovSwitching(statsmodels.tsa.base.tsa_model.TimeSeriesModel)\n",
      "        statsmodels.tsa.regime_switching.markov_regression.MarkovRegression\n",
      "            statsmodels.tsa.regime_switching.markov_autoregression.MarkovAutoregression\n",
      "    statsmodels.tsa.statespace.mlemodel.MLEModel(statsmodels.tsa.base.tsa_model.TimeSeriesModel)\n",
      "        statsmodels.tsa.statespace.dynamic_factor.DynamicFactor\n",
      "        statsmodels.tsa.statespace.dynamic_factor_mq.DynamicFactorMQ\n",
      "        statsmodels.tsa.statespace.sarimax.SARIMAX\n",
      "            statsmodels.tsa.arima.model.ARIMA\n",
      "        statsmodels.tsa.statespace.structural.UnobservedComponents\n",
      "        statsmodels.tsa.statespace.varmax.VARMAX\n",
      "    \n",
      "    class AR(builtins.object)\n",
      "     |  AR(*args, **kwargs)\n",
      "     |  \n",
      "     |  The AR class has been removed and replaced with AutoReg\n",
      "     |  \n",
      "     |  See Also\n",
      "     |  --------\n",
      "     |  AutoReg\n",
      "     |      The replacement for AR that improved deterministic modeling\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class ARDL(statsmodels.tsa.ar_model.AutoReg)\n",
      "     |  ARDL(endog: 'Union[Sequence[float], pd.Series, _ArrayLike2D]', lags: 'Union[None, int, Sequence[int]]', exog: 'Optional[_ArrayLike2D]' = None, order: '_ARDLOrder' = 0, trend: \"Literal[('n', 'c', 'ct', 'ctt')]\" = 'c', *, fixed: 'Optional[_ArrayLike2D]' = None, causal: 'bool' = False, seasonal: 'bool' = False, deterministic: 'Optional[DeterministicProcess]' = None, hold_back: 'Optional[int]' = None, period: 'Optional[int]' = None, missing: \"Literal[('none', 'drop', 'raise')]\" = 'none') -> 'None'\n",
      "     |  \n",
      "     |  Autoregressive Distributed Lag (ARDL) Model\n",
      "     |  \n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  endog : array_like\n",
      "     |      A 1-d endogenous response variable. The dependent variable.\n",
      "     |  lags : {int, list[int]}\n",
      "     |      The number of lags to include in the model if an integer or the\n",
      "     |      list of lag indices to include.  For example, [1, 4] will only\n",
      "     |      include lags 1 and 4 while lags=4 will include lags 1, 2, 3, and 4.\n",
      "     |  exog : array_like\n",
      "     |      Exogenous variables to include in the model. Either a DataFrame or\n",
      "     |      an 2-d array-like structure that can be converted to a NumPy array.\n",
      "     |  order : {int, sequence[int], dict}\n",
      "     |      If int, uses lags 0, 1, ..., order  for all exog variables. If\n",
      "     |      sequence[int], uses the ``order`` for all variables. If a dict,\n",
      "     |      applies the lags series by series. If ``exog`` is anything other\n",
      "     |      than a DataFrame, the keys are the column index of exog (e.g., 0,\n",
      "     |      1, ...). If a DataFrame, keys are column names.\n",
      "     |  fixed : array_like\n",
      "     |      Additional fixed regressors that are not lagged.\n",
      "     |  causal : bool, optional\n",
      "     |      Whether to include lag 0 of exog variables.  If True, only includes\n",
      "     |      lags 1, 2, ...\n",
      "     |  trend : {'n', 'c', 't', 'ct'}, optional\n",
      "     |      The trend to include in the model:\n",
      "     |  \n",
      "     |      * 'n' - No trend.\n",
      "     |      * 'c' - Constant only.\n",
      "     |      * 't' - Time trend only.\n",
      "     |      * 'ct' - Constant and time trend.\n",
      "     |  \n",
      "     |      The default is 'c'.\n",
      "     |  \n",
      "     |  seasonal : bool, optional\n",
      "     |      Flag indicating whether to include seasonal dummies in the model. If\n",
      "     |      seasonal is True and trend includes 'c', then the first period\n",
      "     |      is excluded from the seasonal terms.\n",
      "     |  deterministic : DeterministicProcess, optional\n",
      "     |      A deterministic process.  If provided, trend and seasonal are ignored.\n",
      "     |      A warning is raised if trend is not \"n\" and seasonal is not False.\n",
      "     |  hold_back : {None, int}, optional\n",
      "     |      Initial observations to exclude from the estimation sample.  If None,\n",
      "     |      then hold_back is equal to the maximum lag in the model.  Set to a\n",
      "     |      non-zero value to produce comparable models with different lag\n",
      "     |      length.  For example, to compare the fit of a model with lags=3 and\n",
      "     |      lags=1, set hold_back=3 which ensures that both models are estimated\n",
      "     |      using observations 3,...,nobs. hold_back must be >= the maximum lag in\n",
      "     |      the model.\n",
      "     |  period : {None, int}, optional\n",
      "     |      The period of the data. Only used if seasonal is True. This parameter\n",
      "     |      can be omitted if using a pandas object for endog that contains a\n",
      "     |      recognized frequency.\n",
      "     |  missing : {\"none\", \"drop\", \"raise\"}, optional\n",
      "     |      Available options are 'none', 'drop', and 'raise'. If 'none', no nan\n",
      "     |      checking is done. If 'drop', any observations with nans are dropped.\n",
      "     |      If 'raise', an error is raised. Default is 'none'.\n",
      "     |  \n",
      "     |  Notes\n",
      "     |  -----\n",
      "     |  The full specification of an ARDL is\n",
      "     |  \n",
      "     |  .. math ::\n",
      "     |  \n",
      "     |     Y_t = \\delta_0 + \\delta_1 t + \\delta_2 t^2\n",
      "     |           + \\sum_{i=1}^{s-1} \\gamma_i I_{[(\\mod(t,s) + 1) = i]}\n",
      "     |           + \\sum_{j=1}^p \\phi_j Y_{t-j}\n",
      "     |           + \\sum_{l=1}^k \\sum_{m=0}^{o_l} \\beta_{l,m} X_{l, t-m}\n",
      "     |           + Z_t \\lambda\n",
      "     |           + \\epsilon_t\n",
      "     |  \n",
      "     |  where :math:`\\delta_\\bullet` capture trends, :math:`\\gamma_\\bullet`\n",
      "     |  capture seasonal shifts, s is the period of the seasonality, p is the\n",
      "     |  lag length of the endogenous variable, k is the number of exogenous\n",
      "     |  variables :math:`X_{l}`, :math:`o_l` is included the lag length of\n",
      "     |  :math:`X_{l}`, :math:`Z_t` are ``r`` included fixed regressors and\n",
      "     |  :math:`\\epsilon_t` is a white noise shock. If ``causal`` is ``True``,\n",
      "     |  then the 0-th lag of the exogenous variables is not included and the\n",
      "     |  sum starts at ``m=1``.\n",
      "     |  \n",
      "     |  See Also\n",
      "     |  --------\n",
      "     |  statsmodels.tsa.ar_model.AutoReg\n",
      "     |      Autoregressive model estimation with optional exogenous regressors\n",
      "     |  statsmodels.tsa.ardl.UECM\n",
      "     |      Unconstrained Error Correction Model estimation\n",
      "     |  statsmodels.tsa.statespace.sarimax.SARIMAX\n",
      "     |      Seasonal ARIMA model estimation with optional exogenous regressors\n",
      "     |  statsmodels.tsa.arima.model.ARIMA\n",
      "     |      ARIMA model estimation\n",
      "     |  \n",
      "     |  Examples\n",
      "     |  --------\n",
      "     |  >>> from statsmodels.tsa.api import ARDL\n",
      "     |  >>> from statsmodels.datasets import danish_data\n",
      "     |  >>> data = danish_data.load_pandas().data\n",
      "     |  >>> lrm = data.lrm\n",
      "     |  >>> exog = data[[\"lry\", \"ibo\", \"ide\"]]\n",
      "     |  \n",
      "     |  A basic model where all variables have 3 lags included\n",
      "     |  \n",
      "     |  >>> ARDL(data.lrm, 3, data[[\"lry\", \"ibo\", \"ide\"]], 3)\n",
      "     |  \n",
      "     |  A dictionary can be used to pass custom lag orders\n",
      "     |  \n",
      "     |  >>> ARDL(data.lrm, [1, 3], exog, {\"lry\": 1, \"ibo\": 3, \"ide\": 2})\n",
      "     |  \n",
      "     |  Setting causal removes the 0-th lag from the exogenous variables\n",
      "     |  \n",
      "     |  >>> exog_lags = {\"lry\": 1, \"ibo\": 3, \"ide\": 2}\n",
      "     |  >>> ARDL(data.lrm, [1, 3], exog, exog_lags, causal=True)\n",
      "     |  \n",
      "     |  A dictionary can also be used to pass specific lags to include.\n",
      "     |  Sequences hold the specific lags to include, while integers are expanded\n",
      "     |  to include [0, 1, ..., lag]. If causal is False, then the 0-th lag is\n",
      "     |  excluded.\n",
      "     |  \n",
      "     |  >>> ARDL(lrm, [1, 3], exog, {\"lry\": [0, 1], \"ibo\": [0, 1, 3], \"ide\": 2})\n",
      "     |  \n",
      "     |  When using NumPy arrays, the dictionary keys are the column index.\n",
      "     |  \n",
      "     |  >>> import numpy as np\n",
      "     |  >>> lrma = np.asarray(lrm)\n",
      "     |  >>> exoga = np.asarray(exog)\n",
      "     |  >>> ARDL(lrma, 3, exoga, {0: [0, 1], 1: [0, 1, 3], 2: 2})\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      ARDL\n",
      "     |      statsmodels.tsa.ar_model.AutoReg\n",
      "     |      statsmodels.tsa.base.tsa_model.TimeSeriesModel\n",
      "     |      statsmodels.base.model.LikelihoodModel\n",
      "     |      statsmodels.base.model.Model\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, endog: 'Union[Sequence[float], pd.Series, _ArrayLike2D]', lags: 'Union[None, int, Sequence[int]]', exog: 'Optional[_ArrayLike2D]' = None, order: '_ARDLOrder' = 0, trend: \"Literal[('n', 'c', 'ct', 'ctt')]\" = 'c', *, fixed: 'Optional[_ArrayLike2D]' = None, causal: 'bool' = False, seasonal: 'bool' = False, deterministic: 'Optional[DeterministicProcess]' = None, hold_back: 'Optional[int]' = None, period: 'Optional[int]' = None, missing: \"Literal[('none', 'drop', 'raise')]\" = 'none') -> 'None'\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  fit(self, *, cov_type: 'str' = 'nonrobust', cov_kwds: 'Dict[str, Any]' = None, use_t: 'bool' = True) -> 'ARDLResults'\n",
      "     |      Estimate the model parameters.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      cov_type : str\n",
      "     |          The covariance estimator to use. The most common choices are listed\n",
      "     |          below.  Supports all covariance estimators that are available\n",
      "     |          in ``OLS.fit``.\n",
      "     |      \n",
      "     |          * 'nonrobust' - The class OLS covariance estimator that assumes\n",
      "     |            homoskedasticity.\n",
      "     |          * 'HC0', 'HC1', 'HC2', 'HC3' - Variants of White's\n",
      "     |            (or Eiker-Huber-White) covariance estimator. `HC0` is the\n",
      "     |            standard implementation.  The other make corrections to improve\n",
      "     |            the finite sample performance of the heteroskedasticity robust\n",
      "     |            covariance estimator.\n",
      "     |          * 'HAC' - Heteroskedasticity-autocorrelation robust covariance\n",
      "     |            estimation. Supports cov_kwds.\n",
      "     |      \n",
      "     |            - `maxlags` integer (required) : number of lags to use.\n",
      "     |            - `kernel` callable or str (optional) : kernel\n",
      "     |                currently available kernels are ['bartlett', 'uniform'],\n",
      "     |                default is Bartlett.\n",
      "     |            - `use_correction` bool (optional) : If true, use small sample\n",
      "     |                correction.\n",
      "     |      cov_kwds : dict, optional\n",
      "     |          A dictionary of keyword arguments to pass to the covariance\n",
      "     |          estimator. `nonrobust` and `HC#` do not support cov_kwds.\n",
      "     |      use_t : bool, optional\n",
      "     |          A flag indicating that inference should use the Student's t\n",
      "     |          distribution that accounts for model degree of freedom.  If False,\n",
      "     |          uses the normal distribution. If None, defers the choice to\n",
      "     |          the cov_type. It also removes degree of freedom corrections from\n",
      "     |          the covariance estimator when cov_type is 'nonrobust'.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      ARDLResults\n",
      "     |          Estimation results.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      statsmodels.tsa.ar_model.AutoReg\n",
      "     |          Ordinary Least Squares estimation.\n",
      "     |      statsmodels.regression.linear_model.OLS\n",
      "     |          Ordinary Least Squares estimation.\n",
      "     |      statsmodels.regression.linear_model.RegressionResults\n",
      "     |          See ``get_robustcov_results`` for a detailed list of available\n",
      "     |          covariance estimators and options.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Use ``OLS`` to estimate model parameters and to estimate parameter\n",
      "     |      covariance.\n",
      "     |  \n",
      "     |  predict(self, params: '_ArrayLike1D', start: 'Union[None, int, str, dt.datetime, pd.Timestamp]' = None, end: 'Union[None, int, str, dt.datetime, pd.Timestamp]' = None, dynamic: 'bool' = False, exog: 'Union[None, np.ndarray, pd.DataFrame]' = None, exog_oos: 'Union[None, np.ndarray, pd.DataFrame]' = None, fixed: 'Union[None, np.ndarray, pd.DataFrame]' = None, fixed_oos: 'Union[None, np.ndarray, pd.DataFrame]' = None)\n",
      "     |      In-sample prediction and out-of-sample forecasting.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : array_like\n",
      "     |          The fitted model parameters.\n",
      "     |      start : int, str, or datetime, optional\n",
      "     |          Zero-indexed observation number at which to start forecasting,\n",
      "     |          i.e., the first forecast is start. Can also be a date string to\n",
      "     |          parse or a datetime type. Default is the the zeroth observation.\n",
      "     |      end : int, str, or datetime, optional\n",
      "     |          Zero-indexed observation number at which to end forecasting, i.e.,\n",
      "     |          the last forecast is end. Can also be a date string to\n",
      "     |          parse or a datetime type. However, if the dates index does not\n",
      "     |          have a fixed frequency, end must be an integer index if you\n",
      "     |          want out-of-sample prediction. Default is the last observation in\n",
      "     |          the sample. Unlike standard python slices, end is inclusive so\n",
      "     |          that all the predictions [start, start+1, ..., end-1, end] are\n",
      "     |          returned.\n",
      "     |      dynamic : {bool, int, str, datetime, Timestamp}, optional\n",
      "     |          Integer offset relative to `start` at which to begin dynamic\n",
      "     |          prediction. Prior to this observation, true endogenous values\n",
      "     |          will be used for prediction; starting with this observation and\n",
      "     |          continuing through the end of prediction, forecasted endogenous\n",
      "     |          values will be used instead. Datetime-like objects are not\n",
      "     |          interpreted as offsets. They are instead used to find the index\n",
      "     |          location of `dynamic` which is then used to to compute the offset.\n",
      "     |      exog : array_like\n",
      "     |          A replacement exogenous array.  Must have the same shape as the\n",
      "     |          exogenous data array used when the model was created.\n",
      "     |      exog_oos : array_like\n",
      "     |          An array containing out-of-sample values of the exogenous\n",
      "     |          variables. Must have the same number of columns as the exog\n",
      "     |          used when the model was created, and at least as many rows as\n",
      "     |          the number of out-of-sample forecasts.\n",
      "     |      fixed : array_like\n",
      "     |          A replacement fixed array.  Must have the same shape as the\n",
      "     |          fixed data array used when the model was created.\n",
      "     |      fixed_oos : array_like\n",
      "     |          An array containing out-of-sample values of the fixed variables.\n",
      "     |          Must have the same number of columns as the fixed used when the\n",
      "     |          model was created, and at least as many rows as the number of\n",
      "     |          out-of-sample forecasts.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      predictions : {ndarray, Series}\n",
      "     |          Array of out of in-sample predictions and / or out-of-sample\n",
      "     |          forecasts.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods defined here:\n",
      "     |  \n",
      "     |  from_formula(formula: 'str', data: 'pd.DataFrame', lags: 'Union[None, int, Sequence[int]]' = 0, order: '_ARDLOrder' = 0, trend: \"Literal[('n', 'c', 'ct', 'ctt')]\" = 'n', *, causal: 'bool' = False, seasonal: 'bool' = False, deterministic: 'Optional[DeterministicProcess]' = None, hold_back: 'Optional[int]' = None, period: 'Optional[int]' = None, missing: \"Literal[('none', 'raise')]\" = 'none') -> 'ARDL' from builtins.type\n",
      "     |      Construct an ARDL from a formula\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      formula : str\n",
      "     |          Formula with form dependent ~ independent | fixed. See Examples\n",
      "     |          below.\n",
      "     |      data : DataFrame\n",
      "     |          DataFrame containing the variables in the formula.\n",
      "     |      lags : {int, list[int]}\n",
      "     |          The number of lags to include in the model if an integer or the\n",
      "     |          list of lag indices to include.  For example, [1, 4] will only\n",
      "     |          include lags 1 and 4 while lags=4 will include lags 1, 2, 3,\n",
      "     |          and 4.\n",
      "     |      order : {int, sequence[int], dict}\n",
      "     |          If int, uses lags 0, 1, ..., order  for all exog variables. If\n",
      "     |          sequence[int], uses the ``order`` for all variables. If a dict,\n",
      "     |          applies the lags series by series. If ``exog`` is anything other\n",
      "     |          than a DataFrame, the keys are the column index of exog (e.g., 0,\n",
      "     |          1, ...). If a DataFrame, keys are column names.\n",
      "     |      causal : bool, optional\n",
      "     |          Whether to include lag 0 of exog variables.  If True, only\n",
      "     |          includes lags 1, 2, ...\n",
      "     |      trend : {'n', 'c', 't', 'ct'}, optional\n",
      "     |          The trend to include in the model:\n",
      "     |      \n",
      "     |          * 'n' - No trend.\n",
      "     |          * 'c' - Constant only.\n",
      "     |          * 't' - Time trend only.\n",
      "     |          * 'ct' - Constant and time trend.\n",
      "     |      \n",
      "     |          The default is 'c'.\n",
      "     |      \n",
      "     |      seasonal : bool, optional\n",
      "     |          Flag indicating whether to include seasonal dummies in the model.\n",
      "     |          If seasonal is True and trend includes 'c', then the first period\n",
      "     |          is excluded from the seasonal terms.\n",
      "     |      deterministic : DeterministicProcess, optional\n",
      "     |          A deterministic process.  If provided, trend and seasonal are\n",
      "     |          ignored. A warning is raised if trend is not \"n\" and seasonal\n",
      "     |          is not False.\n",
      "     |      hold_back : {None, int}, optional\n",
      "     |          Initial observations to exclude from the estimation sample.  If\n",
      "     |          None, then hold_back is equal to the maximum lag in the model.\n",
      "     |          Set to a non-zero value to produce comparable models with\n",
      "     |          different lag length.  For example, to compare the fit of a model\n",
      "     |          with lags=3 and lags=1, set hold_back=3 which ensures that both\n",
      "     |          models are estimated using observations 3,...,nobs. hold_back\n",
      "     |          must be >= the maximum lag in the model.\n",
      "     |      period : {None, int}, optional\n",
      "     |          The period of the data. Only used if seasonal is True. This\n",
      "     |          parameter can be omitted if using a pandas object for endog\n",
      "     |          that contains a recognized frequency.\n",
      "     |      missing : {\"none\", \"drop\", \"raise\"}, optional\n",
      "     |          Available options are 'none', 'drop', and 'raise'. If 'none', no\n",
      "     |          nan checking is done. If 'drop', any observations with nans are\n",
      "     |          dropped. If 'raise', an error is raised. Default is 'none'.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      ARDL\n",
      "     |          The ARDL model instance\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      A simple ARDL using the Danish data\n",
      "     |      \n",
      "     |      >>> from statsmodels.datasets.danish_data import load\n",
      "     |      >>> from statsmodels.tsa.api import ARDL\n",
      "     |      >>> data = load().data\n",
      "     |      >>> mod = ARDL.from_formula(\"lrm ~ ibo\", data, 2, 2)\n",
      "     |      \n",
      "     |      Fixed regressors can be specified using a |\n",
      "     |      \n",
      "     |      >>> mod = ARDL.from_formula(\"lrm ~ ibo | ide\", data, 2, 2)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties defined here:\n",
      "     |  \n",
      "     |  ar_lags\n",
      "     |      The autoregressive lags included in the model\n",
      "     |  \n",
      "     |  ardl_order\n",
      "     |      The order of the ARDL(p,q)\n",
      "     |  \n",
      "     |  causal\n",
      "     |      Flag indicating that the ARDL is causal\n",
      "     |  \n",
      "     |  dl_lags\n",
      "     |      The lags of exogenous variables included in the model\n",
      "     |  \n",
      "     |  fixed\n",
      "     |      The fixed data used to construct the model\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from statsmodels.tsa.ar_model.AutoReg:\n",
      "     |  \n",
      "     |  hessian(self, params)\n",
      "     |      The Hessian matrix of the model.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : ndarray\n",
      "     |          The parameters to use when evaluating the Hessian.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      ndarray\n",
      "     |          The hessian evaluated at the parameters.\n",
      "     |  \n",
      "     |  information(self, params)\n",
      "     |      Fisher information matrix of model.\n",
      "     |      \n",
      "     |      Returns -1 * Hessian of the log-likelihood evaluated at params.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : ndarray\n",
      "     |          The model parameters.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      ndarray\n",
      "     |          The information matrix.\n",
      "     |  \n",
      "     |  initialize(self)\n",
      "     |      Initialize the model (no-op).\n",
      "     |  \n",
      "     |  loglike(self, params)\n",
      "     |      Log-likelihood of model.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : ndarray\n",
      "     |          The model parameters used to compute the log-likelihood.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      float\n",
      "     |          The log-likelihood value.\n",
      "     |  \n",
      "     |  score(self, params)\n",
      "     |      Score vector of model.\n",
      "     |      \n",
      "     |      The gradient of logL with respect to each parameter.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : ndarray\n",
      "     |          The parameters to use when evaluating the Hessian.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      ndarray\n",
      "     |          The score vector evaluated at the parameters.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from statsmodels.tsa.ar_model.AutoReg:\n",
      "     |  \n",
      "     |  deterministic\n",
      "     |      The deterministic used to construct the model\n",
      "     |  \n",
      "     |  df_model\n",
      "     |      The model degrees of freedom.\n",
      "     |  \n",
      "     |  exog_names\n",
      "     |      Names of exogenous variables included in model\n",
      "     |  \n",
      "     |  hold_back\n",
      "     |      The number of initial obs. excluded from the estimation sample.\n",
      "     |  \n",
      "     |  period\n",
      "     |      The period of the seasonal component.\n",
      "     |  \n",
      "     |  seasonal\n",
      "     |      Flag indicating that the model contains a seasonal component.\n",
      "     |  \n",
      "     |  trend\n",
      "     |      The trend used in the model.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from statsmodels.base.model.Model:\n",
      "     |  \n",
      "     |  endog_names\n",
      "     |      Names of endogenous variables.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from statsmodels.base.model.Model:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class ARIMA(statsmodels.tsa.statespace.sarimax.SARIMAX)\n",
      "     |  ARIMA(endog, exog=None, order=(0, 0, 0), seasonal_order=(0, 0, 0, 0), trend=None, enforce_stationarity=True, enforce_invertibility=True, concentrate_scale=False, trend_offset=1, dates=None, freq=None, missing='none', validate_specification=True)\n",
      "     |  \n",
      "     |  Autoregressive Integrated Moving Average (ARIMA) model, and extensions\n",
      "     |  \n",
      "     |  This model is the basic interface for ARIMA-type models, including those\n",
      "     |  with exogenous regressors and those with seasonal components. The most\n",
      "     |  general form of the model is SARIMAX(p, d, q)x(P, D, Q, s). It also allows\n",
      "     |  all specialized cases, including\n",
      "     |  \n",
      "     |  - autoregressive models: AR(p)\n",
      "     |  - moving average models: MA(q)\n",
      "     |  - mixed autoregressive moving average models: ARMA(p, q)\n",
      "     |  - integration models: ARIMA(p, d, q)\n",
      "     |  - seasonal models: SARIMA(P, D, Q, s)\n",
      "     |  - regression with errors that follow one of the above ARIMA-type models\n",
      "     |  \n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  endog : array_like, optional\n",
      "     |      The observed time-series process :math:`y`.\n",
      "     |  exog : array_like, optional\n",
      "     |      Array of exogenous regressors.\n",
      "     |  order : tuple, optional\n",
      "     |      The (p,d,q) order of the model for the autoregressive, differences, and\n",
      "     |      moving average components. d is always an integer, while p and q may\n",
      "     |      either be integers or lists of integers.\n",
      "     |  seasonal_order : tuple, optional\n",
      "     |      The (P,D,Q,s) order of the seasonal component of the model for the\n",
      "     |      AR parameters, differences, MA parameters, and periodicity. Default\n",
      "     |      is (0, 0, 0, 0). D and s are always integers, while P and Q\n",
      "     |      may either be integers or lists of positive integers.\n",
      "     |  trend : str{'n','c','t','ct'} or iterable, optional\n",
      "     |      Parameter controlling the deterministic trend. Can be specified as a\n",
      "     |      string where 'c' indicates a constant term, 't' indicates a\n",
      "     |      linear trend in time, and 'ct' includes both. Can also be specified as\n",
      "     |      an iterable defining a polynomial, as in `numpy.poly1d`, where\n",
      "     |      `[1,1,0,1]` would denote :math:`a + bt + ct^3`. Default is 'c' for\n",
      "     |      models without integration, and no trend for models with integration.\n",
      "     |      Note that all trend terms are included in the model as exogenous\n",
      "     |      regressors, which differs from how trends are included in ``SARIMAX``\n",
      "     |      models.  See the Notes section for a precise definition of the\n",
      "     |      treatment of trend terms.\n",
      "     |  enforce_stationarity : bool, optional\n",
      "     |      Whether or not to require the autoregressive parameters to correspond\n",
      "     |      to a stationarity process.\n",
      "     |  enforce_invertibility : bool, optional\n",
      "     |      Whether or not to require the moving average parameters to correspond\n",
      "     |      to an invertible process.\n",
      "     |  concentrate_scale : bool, optional\n",
      "     |      Whether or not to concentrate the scale (variance of the error term)\n",
      "     |      out of the likelihood. This reduces the number of parameters by one.\n",
      "     |      This is only applicable when considering estimation by numerical\n",
      "     |      maximum likelihood.\n",
      "     |  trend_offset : int, optional\n",
      "     |      The offset at which to start time trend values. Default is 1, so that\n",
      "     |      if `trend='t'` the trend is equal to 1, 2, ..., nobs. Typically is only\n",
      "     |      set when the model created by extending a previous dataset.\n",
      "     |  dates : array_like of datetime, optional\n",
      "     |      If no index is given by `endog` or `exog`, an array-like object of\n",
      "     |      datetime objects can be provided.\n",
      "     |  freq : str, optional\n",
      "     |      If no index is given by `endog` or `exog`, the frequency of the\n",
      "     |      time-series may be specified here as a Pandas offset or offset string.\n",
      "     |  missing : str\n",
      "     |      Available options are 'none', 'drop', and 'raise'. If 'none', no nan\n",
      "     |      checking is done. If 'drop', any observations with nans are dropped.\n",
      "     |      If 'raise', an error is raised. Default is 'none'.\n",
      "     |  \n",
      "     |  Notes\n",
      "     |  -----\n",
      "     |  This model incorporates both exogenous regressors and trend components\n",
      "     |  through \"regression with ARIMA errors\". This differs from the\n",
      "     |  specification estimated using ``SARIMAX`` which treats the trend\n",
      "     |  components separately from any included exogenous regressors. The full\n",
      "     |  specification of the model estimated here is:\n",
      "     |  \n",
      "     |  .. math::\n",
      "     |  \n",
      "     |      Y_{t}-\\delta_{0}-\\delta_{1}t-\\ldots-\\delta_{k}t^{k}-X_{t}\\beta\n",
      "     |          & =\\epsilon_{t} \\\\\n",
      "     |      \\left(1-L\\right)^{d}\\left(1-L^{s}\\right)^{D}\\Phi\\left(L\\right)\n",
      "     |      \\Phi_{s}\\left(L\\right)\\epsilon_{t}\n",
      "     |          & =\\Theta\\left(L\\right)\\Theta_{s}\\left(L\\right)\\eta_{t}\n",
      "     |  \n",
      "     |  where :math:`\\eta_t \\sim WN(0,\\sigma^2)` is a white noise process, L\n",
      "     |  is the lag operator, and :math:`G(L)` are lag polynomials corresponding\n",
      "     |  to the autoregressive (:math:`\\Phi`), seasonal autoregressive\n",
      "     |  (:math:`\\Phi_s`), moving average (:math:`\\Theta`), and seasonal moving\n",
      "     |  average components (:math:`\\Theta_s`).\n",
      "     |  \n",
      "     |  `enforce_stationarity` and `enforce_invertibility` are specified in the\n",
      "     |  constructor because they affect loglikelihood computations, and so should\n",
      "     |  not be changed on the fly. This is why they are not instead included as\n",
      "     |  arguments to the `fit` method.\n",
      "     |  \n",
      "     |  .. todo:: should concentrate_scale=True by default\n",
      "     |  \n",
      "     |  Examples\n",
      "     |  --------\n",
      "     |  >>> mod = sm.tsa.arima.ARIMA(endog, order=(1, 0, 0))\n",
      "     |  >>> res = mod.fit()\n",
      "     |  >>> print(res.summary())\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      ARIMA\n",
      "     |      statsmodels.tsa.statespace.sarimax.SARIMAX\n",
      "     |      statsmodels.tsa.statespace.mlemodel.MLEModel\n",
      "     |      statsmodels.tsa.base.tsa_model.TimeSeriesModel\n",
      "     |      statsmodels.base.model.LikelihoodModel\n",
      "     |      statsmodels.base.model.Model\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, endog, exog=None, order=(0, 0, 0), seasonal_order=(0, 0, 0, 0), trend=None, enforce_stationarity=True, enforce_invertibility=True, concentrate_scale=False, trend_offset=1, dates=None, freq=None, missing='none', validate_specification=True)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  fit(self, start_params=None, transformed=True, includes_fixed=False, method=None, method_kwargs=None, gls=None, gls_kwargs=None, cov_type=None, cov_kwds=None, return_params=False, low_memory=False)\n",
      "     |      Fit (estimate) the parameters of the model.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      start_params : array_like, optional\n",
      "     |          Initial guess of the solution for the loglikelihood maximization.\n",
      "     |          If None, the default is given by Model.start_params.\n",
      "     |      transformed : bool, optional\n",
      "     |          Whether or not `start_params` is already transformed. Default is\n",
      "     |          True.\n",
      "     |      includes_fixed : bool, optional\n",
      "     |          If parameters were previously fixed with the `fix_params` method,\n",
      "     |          this argument describes whether or not `start_params` also includes\n",
      "     |          the fixed parameters, in addition to the free parameters. Default\n",
      "     |          is False.\n",
      "     |      method : str, optional\n",
      "     |          The method used for estimating the parameters of the model. Valid\n",
      "     |          options include 'statespace', 'innovations_mle', 'hannan_rissanen',\n",
      "     |          'burg', 'innovations', and 'yule_walker'. Not all options are\n",
      "     |          available for every specification (for example 'yule_walker' can\n",
      "     |          only be used with AR(p) models).\n",
      "     |      method_kwargs : dict, optional\n",
      "     |          Arguments to pass to the fit function for the parameter estimator\n",
      "     |          described by the `method` argument.\n",
      "     |      gls : bool, optional\n",
      "     |          Whether or not to use generalized least squares (GLS) to estimate\n",
      "     |          regression effects. The default is False if `method='statespace'`\n",
      "     |          and is True otherwise.\n",
      "     |      gls_kwargs : dict, optional\n",
      "     |          Arguments to pass to the GLS estimation fit method. Only applicable\n",
      "     |          if GLS estimation is used (see `gls` argument for details).\n",
      "     |      cov_type : str, optional\n",
      "     |          The `cov_type` keyword governs the method for calculating the\n",
      "     |          covariance matrix of parameter estimates. Can be one of:\n",
      "     |      \n",
      "     |          - 'opg' for the outer product of gradient estimator\n",
      "     |          - 'oim' for the observed information matrix estimator, calculated\n",
      "     |            using the method of Harvey (1989)\n",
      "     |          - 'approx' for the observed information matrix estimator,\n",
      "     |            calculated using a numerical approximation of the Hessian matrix.\n",
      "     |          - 'robust' for an approximate (quasi-maximum likelihood) covariance\n",
      "     |            matrix that may be valid even in the presence of some\n",
      "     |            misspecifications. Intermediate calculations use the 'oim'\n",
      "     |            method.\n",
      "     |          - 'robust_approx' is the same as 'robust' except that the\n",
      "     |            intermediate calculations use the 'approx' method.\n",
      "     |          - 'none' for no covariance matrix calculation.\n",
      "     |      \n",
      "     |          Default is 'opg' unless memory conservation is used to avoid\n",
      "     |          computing the loglikelihood values for each observation, in which\n",
      "     |          case the default is 'oim'.\n",
      "     |      cov_kwds : dict or None, optional\n",
      "     |          A dictionary of arguments affecting covariance matrix computation.\n",
      "     |      \n",
      "     |          **opg, oim, approx, robust, robust_approx**\n",
      "     |      \n",
      "     |          - 'approx_complex_step' : bool, optional - If True, numerical\n",
      "     |            approximations are computed using complex-step methods. If False,\n",
      "     |            numerical approximations are computed using finite difference\n",
      "     |            methods. Default is True.\n",
      "     |          - 'approx_centered' : bool, optional - If True, numerical\n",
      "     |            approximations computed using finite difference methods use a\n",
      "     |            centered approximation. Default is False.\n",
      "     |      return_params : bool, optional\n",
      "     |          Whether or not to return only the array of maximizing parameters.\n",
      "     |          Default is False.\n",
      "     |      low_memory : bool, optional\n",
      "     |          If set to True, techniques are applied to substantially reduce\n",
      "     |          memory usage. If used, some features of the results object will\n",
      "     |          not be available (including smoothed results and in-sample\n",
      "     |          prediction), although out-of-sample forecasting is possible.\n",
      "     |          Default is False.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      ARIMAResults\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> mod = sm.tsa.arima.ARIMA(endog, order=(1, 0, 0))\n",
      "     |      >>> res = mod.fit()\n",
      "     |      >>> print(res.summary())\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from statsmodels.tsa.statespace.sarimax.SARIMAX:\n",
      "     |  \n",
      "     |  clone(self, endog, exog=None, **kwargs)\n",
      "     |      Clone state space model with new data and optionally new specification\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      endog : array_like\n",
      "     |          The observed time-series process :math:`y`\n",
      "     |      k_states : int\n",
      "     |          The dimension of the unobserved state process.\n",
      "     |      exog : array_like, optional\n",
      "     |          Array of exogenous regressors, shaped nobs x k. Default is no\n",
      "     |          exogenous regressors.\n",
      "     |      kwargs\n",
      "     |          Keyword arguments to pass to the new model class to change the\n",
      "     |          model specification.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      model : MLEModel subclass\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      This method must be implemented\n",
      "     |  \n",
      "     |  initialize(self)\n",
      "     |      Initialize the SARIMAX model.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      These initialization steps must occur following the parent class\n",
      "     |      __init__ function calls.\n",
      "     |  \n",
      "     |  initialize_default(self, approximate_diffuse_variance=None)\n",
      "     |      Initialize default\n",
      "     |  \n",
      "     |  prepare_data(self)\n",
      "     |      Prepare data for use in the state space representation\n",
      "     |  \n",
      "     |  transform_params(self, unconstrained)\n",
      "     |      Transform unconstrained parameters used by the optimizer to constrained\n",
      "     |      parameters used in likelihood evaluation.\n",
      "     |      \n",
      "     |      Used primarily to enforce stationarity of the autoregressive lag\n",
      "     |      polynomial, invertibility of the moving average lag polynomial, and\n",
      "     |      positive variance parameters.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      unconstrained : array_like\n",
      "     |          Unconstrained parameters used by the optimizer.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      constrained : array_like\n",
      "     |          Constrained parameters used in likelihood evaluation.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      If the lag polynomial has non-consecutive powers (so that the\n",
      "     |      coefficient is zero on some element of the polynomial), then the\n",
      "     |      constraint function is not onto the entire space of invertible\n",
      "     |      polynomials, although it only excludes a very small portion very close\n",
      "     |      to the invertibility boundary.\n",
      "     |  \n",
      "     |  untransform_params(self, constrained)\n",
      "     |      Transform constrained parameters used in likelihood evaluation\n",
      "     |      to unconstrained parameters used by the optimizer\n",
      "     |      \n",
      "     |      Used primarily to reverse enforcement of stationarity of the\n",
      "     |      autoregressive lag polynomial and invertibility of the moving average\n",
      "     |      lag polynomial.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      constrained : array_like\n",
      "     |          Constrained parameters used in likelihood evaluation.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      constrained : array_like\n",
      "     |          Unconstrained parameters used by the optimizer.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      If the lag polynomial has non-consecutive powers (so that the\n",
      "     |      coefficient is zero on some element of the polynomial), then the\n",
      "     |      constraint function is not onto the entire space of invertible\n",
      "     |      polynomials, although it only excludes a very small portion very close\n",
      "     |      to the invertibility boundary.\n",
      "     |  \n",
      "     |  update(self, params, transformed=True, includes_fixed=False, complex_step=False)\n",
      "     |      Update the parameters of the model\n",
      "     |      \n",
      "     |      Updates the representation matrices to fill in the new parameter\n",
      "     |      values.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : array_like\n",
      "     |          Array of new parameters.\n",
      "     |      transformed : bool, optional\n",
      "     |          Whether or not `params` is already transformed. If set to False,\n",
      "     |          `transform_params` is called. Default is True..\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      params : array_like\n",
      "     |          Array of parameters.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from statsmodels.tsa.statespace.sarimax.SARIMAX:\n",
      "     |  \n",
      "     |  endog_names\n",
      "     |      Names of endogenous variables\n",
      "     |  \n",
      "     |  initial_design\n",
      "     |      Initial design matrix\n",
      "     |  \n",
      "     |  initial_selection\n",
      "     |      Initial selection matrix\n",
      "     |  \n",
      "     |  initial_state_intercept\n",
      "     |      Initial state intercept vector\n",
      "     |  \n",
      "     |  initial_transition\n",
      "     |      Initial transition matrix\n",
      "     |  \n",
      "     |  model_latex_names\n",
      "     |      The latex names of all possible model parameters.\n",
      "     |  \n",
      "     |  model_names\n",
      "     |      The plain text names of all possible model parameters.\n",
      "     |  \n",
      "     |  model_orders\n",
      "     |      The orders of each of the polynomials in the model.\n",
      "     |  \n",
      "     |  param_names\n",
      "     |      List of human readable parameter names (for parameters actually\n",
      "     |      included in the model).\n",
      "     |  \n",
      "     |  param_terms\n",
      "     |      List of parameters actually included in the model, in sorted order.\n",
      "     |      \n",
      "     |      TODO Make this an dict with slice or indices as the values.\n",
      "     |  \n",
      "     |  start_params\n",
      "     |      Starting parameters for maximum likelihood estimation\n",
      "     |  \n",
      "     |  state_names\n",
      "     |      (list of str) List of human readable names for unobserved states.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from statsmodels.tsa.statespace.sarimax.SARIMAX:\n",
      "     |  \n",
      "     |  params_complete = ['trend', 'exog', 'ar', 'ma', 'seasonal_ar', 'season...\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from statsmodels.tsa.statespace.mlemodel.MLEModel:\n",
      "     |  \n",
      "     |  __getitem__(self, key)\n",
      "     |  \n",
      "     |  __setitem__(self, key, value)\n",
      "     |  \n",
      "     |  filter(self, params, transformed=True, includes_fixed=False, complex_step=False, cov_type=None, cov_kwds=None, return_ssm=False, results_class=None, results_wrapper_class=None, low_memory=False, **kwargs)\n",
      "     |      Kalman filtering\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : array_like\n",
      "     |          Array of parameters at which to evaluate the loglikelihood\n",
      "     |          function.\n",
      "     |      transformed : bool, optional\n",
      "     |          Whether or not `params` is already transformed. Default is True.\n",
      "     |      return_ssm : bool,optional\n",
      "     |          Whether or not to return only the state space output or a full\n",
      "     |          results object. Default is to return a full results object.\n",
      "     |      cov_type : str, optional\n",
      "     |          See `MLEResults.fit` for a description of covariance matrix types\n",
      "     |          for results object.\n",
      "     |      cov_kwds : dict or None, optional\n",
      "     |          See `MLEResults.get_robustcov_results` for a description required\n",
      "     |          keywords for alternative covariance estimators\n",
      "     |      low_memory : bool, optional\n",
      "     |          If set to True, techniques are applied to substantially reduce\n",
      "     |          memory usage. If used, some features of the results object will\n",
      "     |          not be available (including in-sample prediction), although\n",
      "     |          out-of-sample forecasting is possible. Default is False.\n",
      "     |      **kwargs\n",
      "     |          Additional keyword arguments to pass to the Kalman filter. See\n",
      "     |          `KalmanFilter.filter` for more details.\n",
      "     |  \n",
      "     |  fit_constrained(self, constraints, start_params=None, **fit_kwds)\n",
      "     |      Fit the model with some parameters subject to equality constraints.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      constraints : dict\n",
      "     |          Dictionary of constraints, of the form `param_name: fixed_value`.\n",
      "     |          See the `param_names` property for valid parameter names.\n",
      "     |      start_params : array_like, optional\n",
      "     |          Initial guess of the solution for the loglikelihood maximization.\n",
      "     |          If None, the default is given by Model.start_params.\n",
      "     |      **fit_kwds : keyword arguments\n",
      "     |          fit_kwds are used in the optimization of the remaining parameters.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      results : Results instance\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> mod = sm.tsa.SARIMAX(endog, order=(1, 0, 1))\n",
      "     |      >>> res = mod.fit_constrained({'ar.L1': 0.5})\n",
      "     |  \n",
      "     |  fix_params(self, params)\n",
      "     |      Fix parameters to specific values (context manager)\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : dict\n",
      "     |          Dictionary describing the fixed parameter values, of the form\n",
      "     |          `param_name: fixed_value`. See the `param_names` property for valid\n",
      "     |          parameter names.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> mod = sm.tsa.SARIMAX(endog, order=(1, 0, 1))\n",
      "     |      >>> with mod.fix_params({'ar.L1': 0.5}):\n",
      "     |              res = mod.fit()\n",
      "     |  \n",
      "     |  handle_params(self, params, transformed=True, includes_fixed=False, return_jacobian=False)\n",
      "     |      Ensure model parameters satisfy shape and other requirements\n",
      "     |  \n",
      "     |  hessian(self, params, *args, **kwargs)\n",
      "     |      Hessian matrix of the likelihood function, evaluated at the given\n",
      "     |      parameters\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : array_like\n",
      "     |          Array of parameters at which to evaluate the hessian.\n",
      "     |      *args\n",
      "     |          Additional positional arguments to the `loglike` method.\n",
      "     |      **kwargs\n",
      "     |          Additional keyword arguments to the `loglike` method.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      hessian : ndarray\n",
      "     |          Hessian matrix evaluated at `params`\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      This is a numerical approximation.\n",
      "     |      \n",
      "     |      Both args and kwargs are necessary because the optimizer from\n",
      "     |      `fit` must call this function and only supports passing arguments via\n",
      "     |      args (for example `scipy.optimize.fmin_l_bfgs`).\n",
      "     |  \n",
      "     |  impulse_responses(self, params, steps=1, impulse=0, orthogonalized=False, cumulative=False, anchor=None, exog=None, extend_model=None, extend_kwargs=None, transformed=True, includes_fixed=False, **kwargs)\n",
      "     |      Impulse response function\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : array_like\n",
      "     |          Array of model parameters.\n",
      "     |      steps : int, optional\n",
      "     |          The number of steps for which impulse responses are calculated.\n",
      "     |          Default is 1. Note that for time-invariant models, the initial\n",
      "     |          impulse is not counted as a step, so if `steps=1`, the output will\n",
      "     |          have 2 entries.\n",
      "     |      impulse : int, str or array_like\n",
      "     |          If an integer, the state innovation to pulse; must be between 0\n",
      "     |          and `k_posdef-1`. If a str, it indicates which column of df\n",
      "     |          the unit (1) impulse is given.\n",
      "     |          Alternatively, a custom impulse vector may be provided; must be\n",
      "     |          shaped `k_posdef x 1`.\n",
      "     |      orthogonalized : bool, optional\n",
      "     |          Whether or not to perform impulse using orthogonalized innovations.\n",
      "     |          Note that this will also affect custum `impulse` vectors. Default\n",
      "     |          is False.\n",
      "     |      cumulative : bool, optional\n",
      "     |          Whether or not to return cumulative impulse responses. Default is\n",
      "     |          False.\n",
      "     |      anchor : int, str, or datetime, optional\n",
      "     |          Time point within the sample for the state innovation impulse. Type\n",
      "     |          depends on the index of the given `endog` in the model. Two special\n",
      "     |          cases are the strings 'start' and 'end', which refer to setting the\n",
      "     |          impulse at the first and last points of the sample, respectively.\n",
      "     |          Integer values can run from 0 to `nobs - 1`, or can be negative to\n",
      "     |          apply negative indexing. Finally, if a date/time index was provided\n",
      "     |          to the model, then this argument can be a date string to parse or a\n",
      "     |          datetime type. Default is 'start'.\n",
      "     |      exog : array_like, optional\n",
      "     |          New observations of exogenous regressors for our-of-sample periods,\n",
      "     |          if applicable.\n",
      "     |      transformed : bool, optional\n",
      "     |          Whether or not `params` is already transformed. Default is\n",
      "     |          True.\n",
      "     |      includes_fixed : bool, optional\n",
      "     |          If parameters were previously fixed with the `fix_params` method,\n",
      "     |          this argument describes whether or not `params` also includes\n",
      "     |          the fixed parameters, in addition to the free parameters. Default\n",
      "     |          is False.\n",
      "     |      **kwargs\n",
      "     |          If the model has time-varying design or transition matrices and the\n",
      "     |          combination of `anchor` and `steps` implies creating impulse\n",
      "     |          responses for the out-of-sample period, then these matrices must\n",
      "     |          have updated values provided for the out-of-sample steps. For\n",
      "     |          example, if `design` is a time-varying component, `nobs` is 10,\n",
      "     |          `anchor=1`, and `steps` is 15, a (`k_endog` x `k_states` x 7)\n",
      "     |          matrix must be provided with the new design matrix values.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      impulse_responses : ndarray\n",
      "     |          Responses for each endogenous variable due to the impulse\n",
      "     |          given by the `impulse` argument. For a time-invariant model, the\n",
      "     |          impulse responses are given for `steps + 1` elements (this gives\n",
      "     |          the \"initial impulse\" followed by `steps` responses for the\n",
      "     |          important cases of VAR and SARIMAX models), while for time-varying\n",
      "     |          models the impulse responses are only given for `steps` elements\n",
      "     |          (to avoid having to unexpectedly provide updated time-varying\n",
      "     |          matrices).\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      simulate\n",
      "     |          Simulate a time series according to the given state space model,\n",
      "     |          optionally with specified series for the innovations.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Intercepts in the measurement and state equation are ignored when\n",
      "     |      calculating impulse responses.\n",
      "     |      \n",
      "     |      TODO: add an option to allow changing the ordering for the\n",
      "     |            orthogonalized option. Will require permuting matrices when\n",
      "     |            constructing the extended model.\n",
      "     |  \n",
      "     |  initialize_approximate_diffuse(self, variance=None)\n",
      "     |      Initialize approximate diffuse\n",
      "     |  \n",
      "     |  initialize_known(self, initial_state, initial_state_cov)\n",
      "     |      Initialize known\n",
      "     |  \n",
      "     |  initialize_statespace(self, **kwargs)\n",
      "     |      Initialize the state space representation\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      **kwargs\n",
      "     |          Additional keyword arguments to pass to the state space class\n",
      "     |          constructor.\n",
      "     |  \n",
      "     |  initialize_stationary(self)\n",
      "     |      Initialize stationary\n",
      "     |  \n",
      "     |  loglike(self, params, *args, **kwargs)\n",
      "     |      Loglikelihood evaluation\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : array_like\n",
      "     |          Array of parameters at which to evaluate the loglikelihood\n",
      "     |          function.\n",
      "     |      transformed : bool, optional\n",
      "     |          Whether or not `params` is already transformed. Default is True.\n",
      "     |      **kwargs\n",
      "     |          Additional keyword arguments to pass to the Kalman filter. See\n",
      "     |          `KalmanFilter.filter` for more details.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      update : modifies the internal state of the state space model to\n",
      "     |               reflect new params\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      [1]_ recommend maximizing the average likelihood to avoid scale issues;\n",
      "     |      this is done automatically by the base Model fit method.\n",
      "     |      \n",
      "     |      References\n",
      "     |      ----------\n",
      "     |      .. [1] Koopman, Siem Jan, Neil Shephard, and Jurgen A. Doornik. 1999.\n",
      "     |         Statistical Algorithms for Models in State Space Using SsfPack 2.2.\n",
      "     |         Econometrics Journal 2 (1): 107-60. doi:10.1111/1368-423X.00023.\n",
      "     |  \n",
      "     |  loglikeobs(self, params, transformed=True, includes_fixed=False, complex_step=False, **kwargs)\n",
      "     |      Loglikelihood evaluation\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : array_like\n",
      "     |          Array of parameters at which to evaluate the loglikelihood\n",
      "     |          function.\n",
      "     |      transformed : bool, optional\n",
      "     |          Whether or not `params` is already transformed. Default is True.\n",
      "     |      **kwargs\n",
      "     |          Additional keyword arguments to pass to the Kalman filter. See\n",
      "     |          `KalmanFilter.filter` for more details.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      update : modifies the internal state of the Model to reflect new params\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      [1]_ recommend maximizing the average likelihood to avoid scale issues;\n",
      "     |      this is done automatically by the base Model fit method.\n",
      "     |      \n",
      "     |      References\n",
      "     |      ----------\n",
      "     |      .. [1] Koopman, Siem Jan, Neil Shephard, and Jurgen A. Doornik. 1999.\n",
      "     |         Statistical Algorithms for Models in State Space Using SsfPack 2.2.\n",
      "     |         Econometrics Journal 2 (1): 107-60. doi:10.1111/1368-423X.00023.\n",
      "     |  \n",
      "     |  observed_information_matrix(self, params, transformed=True, includes_fixed=False, approx_complex_step=None, approx_centered=False, **kwargs)\n",
      "     |      Observed information matrix\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : array_like, optional\n",
      "     |          Array of parameters at which to evaluate the loglikelihood\n",
      "     |          function.\n",
      "     |      **kwargs\n",
      "     |          Additional keyword arguments to pass to the Kalman filter. See\n",
      "     |          `KalmanFilter.filter` for more details.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      This method is from Harvey (1989), which shows that the information\n",
      "     |      matrix only depends on terms from the gradient. This implementation is\n",
      "     |      partially analytic and partially numeric approximation, therefore,\n",
      "     |      because it uses the analytic formula for the information matrix, with\n",
      "     |      numerically computed elements of the gradient.\n",
      "     |      \n",
      "     |      References\n",
      "     |      ----------\n",
      "     |      Harvey, Andrew C. 1990.\n",
      "     |      Forecasting, Structural Time Series Models and the Kalman Filter.\n",
      "     |      Cambridge University Press.\n",
      "     |  \n",
      "     |  opg_information_matrix(self, params, transformed=True, includes_fixed=False, approx_complex_step=None, **kwargs)\n",
      "     |      Outer product of gradients information matrix\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : array_like, optional\n",
      "     |          Array of parameters at which to evaluate the loglikelihood\n",
      "     |          function.\n",
      "     |      **kwargs\n",
      "     |          Additional arguments to the `loglikeobs` method.\n",
      "     |      \n",
      "     |      References\n",
      "     |      ----------\n",
      "     |      Berndt, Ernst R., Bronwyn Hall, Robert Hall, and Jerry Hausman. 1974.\n",
      "     |      Estimation and Inference in Nonlinear Structural Models.\n",
      "     |      NBER Chapters. National Bureau of Economic Research, Inc.\n",
      "     |  \n",
      "     |  score(self, params, *args, **kwargs)\n",
      "     |      Compute the score function at params.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : array_like\n",
      "     |          Array of parameters at which to evaluate the score.\n",
      "     |      *args\n",
      "     |          Additional positional arguments to the `loglike` method.\n",
      "     |      **kwargs\n",
      "     |          Additional keyword arguments to the `loglike` method.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      score : ndarray\n",
      "     |          Score, evaluated at `params`.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      This is a numerical approximation, calculated using first-order complex\n",
      "     |      step differentiation on the `loglike` method.\n",
      "     |      \n",
      "     |      Both args and kwargs are necessary because the optimizer from\n",
      "     |      `fit` must call this function and only supports passing arguments via\n",
      "     |      args (for example `scipy.optimize.fmin_l_bfgs`).\n",
      "     |  \n",
      "     |  score_obs(self, params, method='approx', transformed=True, includes_fixed=False, approx_complex_step=None, approx_centered=False, **kwargs)\n",
      "     |      Compute the score per observation, evaluated at params\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : array_like\n",
      "     |          Array of parameters at which to evaluate the score.\n",
      "     |      **kwargs\n",
      "     |          Additional arguments to the `loglike` method.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      score : ndarray\n",
      "     |          Score per observation, evaluated at `params`.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      This is a numerical approximation, calculated using first-order complex\n",
      "     |      step differentiation on the `loglikeobs` method.\n",
      "     |  \n",
      "     |  set_conserve_memory(self, conserve_memory=None, **kwargs)\n",
      "     |      Set the memory conservation method\n",
      "     |      \n",
      "     |      By default, the Kalman filter computes a number of intermediate\n",
      "     |      matrices at each iteration. The memory conservation options control\n",
      "     |      which of those matrices are stored.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      conserve_memory : int, optional\n",
      "     |          Bitmask value to set the memory conservation method to. See notes\n",
      "     |          for details.\n",
      "     |      **kwargs\n",
      "     |          Keyword arguments may be used to influence the memory conservation\n",
      "     |          method by setting individual boolean flags.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      This method is rarely used. See the corresponding function in the\n",
      "     |      `KalmanFilter` class for details.\n",
      "     |  \n",
      "     |  set_filter_method(self, filter_method=None, **kwargs)\n",
      "     |      Set the filtering method\n",
      "     |      \n",
      "     |      The filtering method controls aspects of which Kalman filtering\n",
      "     |      approach will be used.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      filter_method : int, optional\n",
      "     |          Bitmask value to set the filter method to. See notes for details.\n",
      "     |      **kwargs\n",
      "     |          Keyword arguments may be used to influence the filter method by\n",
      "     |          setting individual boolean flags. See notes for details.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      This method is rarely used. See the corresponding function in the\n",
      "     |      `KalmanFilter` class for details.\n",
      "     |  \n",
      "     |  set_inversion_method(self, inversion_method=None, **kwargs)\n",
      "     |      Set the inversion method\n",
      "     |      \n",
      "     |      The Kalman filter may contain one matrix inversion: that of the\n",
      "     |      forecast error covariance matrix. The inversion method controls how and\n",
      "     |      if that inverse is performed.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      inversion_method : int, optional\n",
      "     |          Bitmask value to set the inversion method to. See notes for\n",
      "     |          details.\n",
      "     |      **kwargs\n",
      "     |          Keyword arguments may be used to influence the inversion method by\n",
      "     |          setting individual boolean flags. See notes for details.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      This method is rarely used. See the corresponding function in the\n",
      "     |      `KalmanFilter` class for details.\n",
      "     |  \n",
      "     |  set_smoother_output(self, smoother_output=None, **kwargs)\n",
      "     |      Set the smoother output\n",
      "     |      \n",
      "     |      The smoother can produce several types of results. The smoother output\n",
      "     |      variable controls which are calculated and returned.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      smoother_output : int, optional\n",
      "     |          Bitmask value to set the smoother output to. See notes for details.\n",
      "     |      **kwargs\n",
      "     |          Keyword arguments may be used to influence the smoother output by\n",
      "     |          setting individual boolean flags.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      This method is rarely used. See the corresponding function in the\n",
      "     |      `KalmanSmoother` class for details.\n",
      "     |  \n",
      "     |  set_stability_method(self, stability_method=None, **kwargs)\n",
      "     |      Set the numerical stability method\n",
      "     |      \n",
      "     |      The Kalman filter is a recursive algorithm that may in some cases\n",
      "     |      suffer issues with numerical stability. The stability method controls\n",
      "     |      what, if any, measures are taken to promote stability.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      stability_method : int, optional\n",
      "     |          Bitmask value to set the stability method to. See notes for\n",
      "     |          details.\n",
      "     |      **kwargs\n",
      "     |          Keyword arguments may be used to influence the stability method by\n",
      "     |          setting individual boolean flags. See notes for details.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      This method is rarely used. See the corresponding function in the\n",
      "     |      `KalmanFilter` class for details.\n",
      "     |  \n",
      "     |  simulate(self, params, nsimulations, measurement_shocks=None, state_shocks=None, initial_state=None, anchor=None, repetitions=None, exog=None, extend_model=None, extend_kwargs=None, transformed=True, includes_fixed=False, **kwargs)\n",
      "     |      Simulate a new time series following the state space model\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : array_like\n",
      "     |          Array of parameters to use in constructing the state space\n",
      "     |          representation to use when simulating.\n",
      "     |      nsimulations : int\n",
      "     |          The number of observations to simulate. If the model is\n",
      "     |          time-invariant this can be any number. If the model is\n",
      "     |          time-varying, then this number must be less than or equal to the\n",
      "     |          number of observations.\n",
      "     |      measurement_shocks : array_like, optional\n",
      "     |          If specified, these are the shocks to the measurement equation,\n",
      "     |          :math:`\\varepsilon_t`. If unspecified, these are automatically\n",
      "     |          generated using a pseudo-random number generator. If specified,\n",
      "     |          must be shaped `nsimulations` x `k_endog`, where `k_endog` is the\n",
      "     |          same as in the state space model.\n",
      "     |      state_shocks : array_like, optional\n",
      "     |          If specified, these are the shocks to the state equation,\n",
      "     |          :math:`\\eta_t`. If unspecified, these are automatically\n",
      "     |          generated using a pseudo-random number generator. If specified,\n",
      "     |          must be shaped `nsimulations` x `k_posdef` where `k_posdef` is the\n",
      "     |          same as in the state space model.\n",
      "     |      initial_state : array_like, optional\n",
      "     |          If specified, this is the initial state vector to use in\n",
      "     |          simulation, which should be shaped (`k_states` x 1), where\n",
      "     |          `k_states` is the same as in the state space model. If unspecified,\n",
      "     |          but the model has been initialized, then that initialization is\n",
      "     |          used. This must be specified if `anchor` is anything other than\n",
      "     |          \"start\" or 0 (or else you can use the `simulate` method on a\n",
      "     |          results object rather than on the model object).\n",
      "     |      anchor : int, str, or datetime, optional\n",
      "     |          First period for simulation. The simulation will be conditional on\n",
      "     |          all existing datapoints prior to the `anchor`.  Type depends on the\n",
      "     |          index of the given `endog` in the model. Two special cases are the\n",
      "     |          strings 'start' and 'end'. `start` refers to beginning the\n",
      "     |          simulation at the first period of the sample, and `end` refers to\n",
      "     |          beginning the simulation at the first period after the sample.\n",
      "     |          Integer values can run from 0 to `nobs`, or can be negative to\n",
      "     |          apply negative indexing. Finally, if a date/time index was provided\n",
      "     |          to the model, then this argument can be a date string to parse or a\n",
      "     |          datetime type. Default is 'start'.\n",
      "     |      repetitions : int, optional\n",
      "     |          Number of simulated paths to generate. Default is 1 simulated path.\n",
      "     |      exog : array_like, optional\n",
      "     |          New observations of exogenous regressors, if applicable.\n",
      "     |      transformed : bool, optional\n",
      "     |          Whether or not `params` is already transformed. Default is\n",
      "     |          True.\n",
      "     |      includes_fixed : bool, optional\n",
      "     |          If parameters were previously fixed with the `fix_params` method,\n",
      "     |          this argument describes whether or not `params` also includes\n",
      "     |          the fixed parameters, in addition to the free parameters. Default\n",
      "     |          is False.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      simulated_obs : ndarray\n",
      "     |          An array of simulated observations. If `repetitions=None`, then it\n",
      "     |          will be shaped (nsimulations x k_endog) or (nsimulations,) if\n",
      "     |          `k_endog=1`. Otherwise it will be shaped\n",
      "     |          (nsimulations x k_endog x repetitions). If the model was given\n",
      "     |          Pandas input then the output will be a Pandas object. If\n",
      "     |          `k_endog > 1` and `repetitions` is not None, then the output will\n",
      "     |          be a Pandas DataFrame that has a MultiIndex for the columns, with\n",
      "     |          the first level containing the names of the `endog` variables and\n",
      "     |          the second level containing the repetition number.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      impulse_responses\n",
      "     |          Impulse response functions\n",
      "     |  \n",
      "     |  simulation_smoother(self, simulation_output=None, **kwargs)\n",
      "     |      Retrieve a simulation smoother for the state space model.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      simulation_output : int, optional\n",
      "     |          Determines which simulation smoother output is calculated.\n",
      "     |          Default is all (including state and disturbances).\n",
      "     |      **kwargs\n",
      "     |          Additional keyword arguments, used to set the simulation output.\n",
      "     |          See `set_simulation_output` for more details.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      SimulationSmoothResults\n",
      "     |  \n",
      "     |  smooth(self, params, transformed=True, includes_fixed=False, complex_step=False, cov_type=None, cov_kwds=None, return_ssm=False, results_class=None, results_wrapper_class=None, **kwargs)\n",
      "     |      Kalman smoothing\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : array_like\n",
      "     |          Array of parameters at which to evaluate the loglikelihood\n",
      "     |          function.\n",
      "     |      transformed : bool, optional\n",
      "     |          Whether or not `params` is already transformed. Default is True.\n",
      "     |      return_ssm : bool,optional\n",
      "     |          Whether or not to return only the state space output or a full\n",
      "     |          results object. Default is to return a full results object.\n",
      "     |      cov_type : str, optional\n",
      "     |          See `MLEResults.fit` for a description of covariance matrix types\n",
      "     |          for results object.\n",
      "     |      cov_kwds : dict or None, optional\n",
      "     |          See `MLEResults.get_robustcov_results` for a description required\n",
      "     |          keywords for alternative covariance estimators\n",
      "     |      **kwargs\n",
      "     |          Additional keyword arguments to pass to the Kalman filter. See\n",
      "     |          `KalmanFilter.filter` for more details.\n",
      "     |  \n",
      "     |  transform_jacobian(self, unconstrained, approx_centered=False)\n",
      "     |      Jacobian matrix for the parameter transformation function\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      unconstrained : array_like\n",
      "     |          Array of unconstrained parameters used by the optimizer.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      jacobian : ndarray\n",
      "     |          Jacobian matrix of the transformation, evaluated at `unconstrained`\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      transform_params\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      This is a numerical approximation using finite differences. Note that\n",
      "     |      in general complex step methods cannot be used because it is not\n",
      "     |      guaranteed that the `transform_params` method is a real function (e.g.\n",
      "     |      if Cholesky decomposition is used).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from statsmodels.tsa.statespace.mlemodel.MLEModel:\n",
      "     |  \n",
      "     |  from_formula(formula, data, subset=None) from builtins.type\n",
      "     |      Not implemented for state space models\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from statsmodels.tsa.statespace.mlemodel.MLEModel:\n",
      "     |  \n",
      "     |  initial_variance\n",
      "     |  \n",
      "     |  initialization\n",
      "     |  \n",
      "     |  loglikelihood_burn\n",
      "     |  \n",
      "     |  tolerance\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from statsmodels.tsa.base.tsa_model.TimeSeriesModel:\n",
      "     |  \n",
      "     |  exog_names\n",
      "     |      The names of the exogenous variables.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from statsmodels.base.model.LikelihoodModel:\n",
      "     |  \n",
      "     |  information(self, params)\n",
      "     |      Fisher information matrix of model.\n",
      "     |      \n",
      "     |      Returns -1 * Hessian of the log-likelihood evaluated at params.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : ndarray\n",
      "     |          The model parameters.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from statsmodels.base.model.Model:\n",
      "     |  \n",
      "     |  predict(self, params, exog=None, *args, **kwargs)\n",
      "     |      After a model has been fit predict returns the fitted values.\n",
      "     |      \n",
      "     |      This is a placeholder intended to be overwritten by individual models.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from statsmodels.base.model.Model:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class ArmaProcess(builtins.object)\n",
      "     |  ArmaProcess(ar=None, ma=None, nobs=100)\n",
      "     |  \n",
      "     |  Theoretical properties of an ARMA process for specified lag-polynomials.\n",
      "     |  \n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  ar : array_like\n",
      "     |      Coefficient for autoregressive lag polynomial, including zero lag.\n",
      "     |      Must be entered using the signs from the lag polynomial representation.\n",
      "     |      See the notes for more information about the sign.\n",
      "     |  ma : array_like\n",
      "     |      Coefficient for moving-average lag polynomial, including zero lag.\n",
      "     |  nobs : int, optional\n",
      "     |      Length of simulated time series. Used, for example, if a sample is\n",
      "     |      generated. See example.\n",
      "     |  \n",
      "     |  Notes\n",
      "     |  -----\n",
      "     |  Both the AR and MA components must include the coefficient on the\n",
      "     |  zero-lag. In almost all cases these values should be 1. Further, due to\n",
      "     |  using the lag-polynomial representation, the AR parameters should\n",
      "     |  have the opposite sign of what one would write in the ARMA representation.\n",
      "     |  See the examples below.\n",
      "     |  \n",
      "     |  The ARMA(p,q) process is described by\n",
      "     |  \n",
      "     |  .. math::\n",
      "     |  \n",
      "     |      y_{t}=\\phi_{1}y_{t-1}+\\ldots+\\phi_{p}y_{t-p}+\\theta_{1}\\epsilon_{t-1}\n",
      "     |             +\\ldots+\\theta_{q}\\epsilon_{t-q}+\\epsilon_{t}\n",
      "     |  \n",
      "     |  and the parameterization used in this function uses the lag-polynomial\n",
      "     |  representation,\n",
      "     |  \n",
      "     |  .. math::\n",
      "     |  \n",
      "     |      \\left(1-\\phi_{1}L-\\ldots-\\phi_{p}L^{p}\\right)y_{t} =\n",
      "     |          \\left(1+\\theta_{1}L+\\ldots+\\theta_{q}L^{q}\\right)\\epsilon_{t}\n",
      "     |  \n",
      "     |  Examples\n",
      "     |  --------\n",
      "     |  ARMA(2,2) with AR coefficients 0.75 and -0.25, and MA coefficients 0.65 and 0.35\n",
      "     |  \n",
      "     |  >>> import statsmodels.api as sm\n",
      "     |  >>> import numpy as np\n",
      "     |  >>> np.random.seed(12345)\n",
      "     |  >>> arparams = np.array([.75, -.25])\n",
      "     |  >>> maparams = np.array([.65, .35])\n",
      "     |  >>> ar = np.r_[1, -arparams] # add zero-lag and negate\n",
      "     |  >>> ma = np.r_[1, maparams] # add zero-lag\n",
      "     |  >>> arma_process = sm.tsa.ArmaProcess(ar, ma)\n",
      "     |  >>> arma_process.isstationary\n",
      "     |  True\n",
      "     |  >>> arma_process.isinvertible\n",
      "     |  True\n",
      "     |  >>> arma_process.arroots\n",
      "     |  array([1.5-1.32287566j, 1.5+1.32287566j])\n",
      "     |  >>> y = arma_process.generate_sample(250)\n",
      "     |  >>> model = sm.tsa.ARIMA(y, (2, 0, 2), trend='n').fit(disp=0)\n",
      "     |  >>> model.params\n",
      "     |  array([ 0.79044189, -0.23140636,  0.70072904,  0.40608028])\n",
      "     |  \n",
      "     |  The same ARMA(2,2) Using the from_coeffs class method\n",
      "     |  \n",
      "     |  >>> arma_process = sm.tsa.ArmaProcess.from_coeffs(arparams, maparams)\n",
      "     |  >>> arma_process.arroots\n",
      "     |  array([1.5-1.32287566j, 1.5+1.32287566j])\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, ar=None, ma=None, nobs=100)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __mul__(self, oth)\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __str__(self)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  acf(self, lags=None)\n",
      "     |      Theoretical autocorrelation function of an ARMA process.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      lags : int\n",
      "     |          The number of terms (lags plus zero lag) to include in returned acf.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      ndarray\n",
      "     |          The autocorrelations of ARMA process given by ar and ma.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      arma_acovf\n",
      "     |          Autocovariances from ARMA processes.\n",
      "     |      acf\n",
      "     |          Sample autocorrelation function estimation.\n",
      "     |      acovf\n",
      "     |          Sample autocovariance function estimation.\n",
      "     |  \n",
      "     |  acovf(self, nobs=None)\n",
      "     |      Theoretical autocovariances of stationary ARMA processes\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      nobs : int\n",
      "     |          The number of terms (lags plus zero lag) to include in returned acovf.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      ndarray\n",
      "     |          The autocovariance of ARMA process given by ar, ma.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      arma_acf\n",
      "     |          Autocorrelation function for ARMA processes.\n",
      "     |      acovf\n",
      "     |          Sample autocovariance estimation.\n",
      "     |      \n",
      "     |      References\n",
      "     |      ----------\n",
      "     |      .. [*] Brockwell, Peter J., and Richard A. Davis. 2009. Time Series:\n",
      "     |          Theory and Methods. 2nd ed. 1991. New York, NY: Springer.\n",
      "     |  \n",
      "     |  arma2ar(self, lags=None)\n",
      "     |      A finite-lag AR approximation of an ARMA process.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      lags : int\n",
      "     |          The number of coefficients to calculate.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      ndarray\n",
      "     |          The coefficients of AR lag polynomial with nobs elements.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Equivalent to ``arma_impulse_response(ma, ar, leads=100)``\n",
      "     |  \n",
      "     |  arma2ma(self, lags=None)\n",
      "     |      A finite-lag approximate MA representation of an ARMA process.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      lags : int\n",
      "     |          The number of coefficients to calculate.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      ndarray\n",
      "     |          The coefficients of AR lag polynomial with nobs elements.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Equivalent to ``arma_impulse_response(ma, ar, leads=100)``\n",
      "     |  \n",
      "     |  generate_sample(self, nsample=100, scale=1.0, distrvs=None, axis=0, burnin=0)\n",
      "     |      Simulate data from an ARMA.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      nsample : int or tuple of ints\n",
      "     |          If nsample is an integer, then this creates a 1d timeseries of\n",
      "     |          length size. If nsample is a tuple, creates a len(nsample)\n",
      "     |          dimensional time series where time is indexed along the input\n",
      "     |          variable ``axis``. All series are unless ``distrvs`` generates\n",
      "     |          dependent data.\n",
      "     |      scale : float\n",
      "     |          The standard deviation of noise.\n",
      "     |      distrvs : function, random number generator\n",
      "     |          A function that generates the random numbers, and takes ``size``\n",
      "     |          as argument. The default is np.random.standard_normal.\n",
      "     |      axis : int\n",
      "     |          See nsample for details.\n",
      "     |      burnin : int\n",
      "     |          Number of observation at the beginning of the sample to drop.\n",
      "     |          Used to reduce dependence on initial values.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      ndarray\n",
      "     |          Random sample(s) from an ARMA process.\n",
      "     |  \n",
      "     |  impulse_response(self, leads=None)\n",
      "     |      Compute the impulse response function (MA representation) for ARMA process.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      leads : int\n",
      "     |          The number of observations to calculate.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      ndarray\n",
      "     |          The impulse response function with nobs elements.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      This is the same as finding the MA representation of an ARMA(p,q).\n",
      "     |      By reversing the role of ar and ma in the function arguments, the\n",
      "     |      returned result is the AR representation of an ARMA(p,q), i.e\n",
      "     |      \n",
      "     |      ma_representation = arma_impulse_response(ar, ma, leads=100)\n",
      "     |      ar_representation = arma_impulse_response(ma, ar, leads=100)\n",
      "     |      \n",
      "     |      Fully tested against matlab\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      AR(1)\n",
      "     |      \n",
      "     |      >>> arma_impulse_response([1.0, -0.8], [1.], leads=10)\n",
      "     |      array([ 1.        ,  0.8       ,  0.64      ,  0.512     ,  0.4096    ,\n",
      "     |              0.32768   ,  0.262144  ,  0.2097152 ,  0.16777216,  0.13421773])\n",
      "     |      \n",
      "     |      this is the same as\n",
      "     |      \n",
      "     |      >>> 0.8**np.arange(10)\n",
      "     |      array([ 1.        ,  0.8       ,  0.64      ,  0.512     ,  0.4096    ,\n",
      "     |              0.32768   ,  0.262144  ,  0.2097152 ,  0.16777216,  0.13421773])\n",
      "     |      \n",
      "     |      MA(2)\n",
      "     |      \n",
      "     |      >>> arma_impulse_response([1.0], [1., 0.5, 0.2], leads=10)\n",
      "     |      array([ 1. ,  0.5,  0.2,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ])\n",
      "     |      \n",
      "     |      ARMA(1,2)\n",
      "     |      \n",
      "     |      >>> arma_impulse_response([1.0, -0.8], [1., 0.5, 0.2], leads=10)\n",
      "     |      array([ 1.        ,  1.3       ,  1.24      ,  0.992     ,  0.7936    ,\n",
      "     |              0.63488   ,  0.507904  ,  0.4063232 ,  0.32505856,  0.26004685])\n",
      "     |  \n",
      "     |  invertroots(self, retnew=False)\n",
      "     |      Make MA polynomial invertible by inverting roots inside unit circle.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      retnew : bool\n",
      "     |          If False (default), then return the lag-polynomial as array.\n",
      "     |          If True, then return a new instance with invertible MA-polynomial.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      manew : ndarray\n",
      "     |         A new invertible MA lag-polynomial, returned if retnew is false.\n",
      "     |      wasinvertible : bool\n",
      "     |         True if the MA lag-polynomial was already invertible, returned if\n",
      "     |         retnew is false.\n",
      "     |      armaprocess : new instance of class\n",
      "     |         If retnew is true, then return a new instance with invertible\n",
      "     |         MA-polynomial.\n",
      "     |  \n",
      "     |  pacf(self, lags=None)\n",
      "     |      Theoretical partial autocorrelation function of an ARMA process.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      lags : int\n",
      "     |          The number of terms (lags plus zero lag) to include in returned pacf.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      ndarrray\n",
      "     |          The partial autocorrelation of ARMA process given by ar and ma.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Solves yule-walker equation for each lag order up to nobs lags.\n",
      "     |      \n",
      "     |      not tested/checked yet\n",
      "     |  \n",
      "     |  periodogram(self, nobs=None)\n",
      "     |      Periodogram for ARMA process given by lag-polynomials ar and ma.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      w : ndarray\n",
      "     |          The frequencies.\n",
      "     |      sd : ndarray\n",
      "     |          The periodogram, also known as the spectral density.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Normalization ?\n",
      "     |      \n",
      "     |      This uses signal.freqz, which does not use fft. There is a fft version\n",
      "     |      somewhere.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods defined here:\n",
      "     |  \n",
      "     |  from_coeffs(arcoefs=None, macoefs=None, nobs=100) from builtins.type\n",
      "     |      Create ArmaProcess from an ARMA representation.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      arcoefs : array_like\n",
      "     |          Coefficient for autoregressive lag polynomial, not including zero\n",
      "     |          lag. The sign is inverted to conform to the usual time series\n",
      "     |          representation of an ARMA process in statistics. See the class\n",
      "     |          docstring for more information.\n",
      "     |      macoefs : array_like\n",
      "     |          Coefficient for moving-average lag polynomial, excluding zero lag.\n",
      "     |      nobs : int, optional\n",
      "     |          Length of simulated time series. Used, for example, if a sample\n",
      "     |          is generated.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      ArmaProcess\n",
      "     |          Class instance initialized with arcoefs and macoefs.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> arparams = [.75, -.25]\n",
      "     |      >>> maparams = [.65, .35]\n",
      "     |      >>> arma_process = sm.tsa.ArmaProcess.from_coeffs(ar, ma)\n",
      "     |      >>> arma_process.isstationary\n",
      "     |      True\n",
      "     |      >>> arma_process.isinvertible\n",
      "     |      True\n",
      "     |  \n",
      "     |  from_estimation(model_results, nobs=None) from builtins.type\n",
      "     |      Create an ArmaProcess from the results of an ARIMA estimation.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      model_results : ARIMAResults instance\n",
      "     |          A fitted model.\n",
      "     |      nobs : int, optional\n",
      "     |          If None, nobs is taken from the results.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      ArmaProcess\n",
      "     |          Class instance initialized from model_results.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      statsmodels.tsa.arima.model.ARIMA\n",
      "     |          The models class used to create the ArmaProcess\n",
      "     |  \n",
      "     |  from_roots(maroots=None, arroots=None, nobs=100) from builtins.type\n",
      "     |      Create ArmaProcess from AR and MA polynomial roots.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      maroots : array_like\n",
      "     |          Roots for the MA polynomial\n",
      "     |          1 + theta_1*z + theta_2*z^2 + ..... + theta_n*z^n\n",
      "     |      arroots : array_like\n",
      "     |          Roots for the AR polynomial\n",
      "     |          1 - phi_1*z - phi_2*z^2 - ..... - phi_n*z^n\n",
      "     |      nobs : int, optional\n",
      "     |          Length of simulated time series. Used, for example, if a sample\n",
      "     |          is generated.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      ArmaProcess\n",
      "     |          Class instance initialized with arcoefs and macoefs.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> arroots = [.75, -.25]\n",
      "     |      >>> maroots = [.65, .35]\n",
      "     |      >>> arma_process = sm.tsa.ArmaProcess.from_roots(arroots, maroots)\n",
      "     |      >>> arma_process.isstationary\n",
      "     |      True\n",
      "     |      >>> arma_process.isinvertible\n",
      "     |      True\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties defined here:\n",
      "     |  \n",
      "     |  arroots\n",
      "     |      Roots of autoregressive lag-polynomial\n",
      "     |  \n",
      "     |  isinvertible\n",
      "     |      Arma process is invertible if MA roots are outside unit circle.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      bool\n",
      "     |           True if moving average roots are outside unit circle.\n",
      "     |  \n",
      "     |  isstationary\n",
      "     |      Arma process is stationary if AR roots are outside unit circle.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      bool\n",
      "     |           True if autoregressive roots are outside unit circle.\n",
      "     |  \n",
      "     |  maroots\n",
      "     |      Roots of moving average lag-polynomial\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class AutoReg(statsmodels.tsa.base.tsa_model.TimeSeriesModel)\n",
      "     |  AutoReg(endog, lags, trend='c', seasonal=False, exog=None, hold_back=None, period=None, missing='none', *, deterministic=None, old_names=False)\n",
      "     |  \n",
      "     |  Autoregressive AR-X(p) model\n",
      "     |  \n",
      "     |  Estimate an AR-X model using Conditional Maximum Likelihood (OLS).\n",
      "     |  \n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  endog : array_like\n",
      "     |      A 1-d endogenous response variable. The dependent variable.\n",
      "     |  lags : {None, int, list[int]}\n",
      "     |      The number of lags to include in the model if an integer or the\n",
      "     |      list of lag indices to include.  For example, [1, 4] will only\n",
      "     |      include lags 1 and 4 while lags=4 will include lags 1, 2, 3, and 4.\n",
      "     |      None excludes all AR lags, and behave identically to 0.\n",
      "     |  trend : {'n', 'c', 't', 'ct'}\n",
      "     |      The trend to include in the model:\n",
      "     |  \n",
      "     |      * 'n' - No trend.\n",
      "     |      * 'c' - Constant only.\n",
      "     |      * 't' - Time trend only.\n",
      "     |      * 'ct' - Constant and time trend.\n",
      "     |  \n",
      "     |  seasonal : bool\n",
      "     |      Flag indicating whether to include seasonal dummies in the model. If\n",
      "     |      seasonal is True and trend includes 'c', then the first period\n",
      "     |      is excluded from the seasonal terms.\n",
      "     |  exog : array_like, optional\n",
      "     |      Exogenous variables to include in the model. Must have the same number\n",
      "     |      of observations as endog and should be aligned so that endog[i] is\n",
      "     |      regressed on exog[i].\n",
      "     |  hold_back : {None, int}\n",
      "     |      Initial observations to exclude from the estimation sample.  If None,\n",
      "     |      then hold_back is equal to the maximum lag in the model.  Set to a\n",
      "     |      non-zero value to produce comparable models with different lag\n",
      "     |      length.  For example, to compare the fit of a model with lags=3 and\n",
      "     |      lags=1, set hold_back=3 which ensures that both models are estimated\n",
      "     |      using observations 3,...,nobs. hold_back must be >= the maximum lag in\n",
      "     |      the model.\n",
      "     |  period : {None, int}\n",
      "     |      The period of the data. Only used if seasonal is True. This parameter\n",
      "     |      can be omitted if using a pandas object for endog that contains a\n",
      "     |      recognized frequency.\n",
      "     |  missing : str\n",
      "     |      Available options are 'none', 'drop', and 'raise'. If 'none', no nan\n",
      "     |      checking is done. If 'drop', any observations with nans are dropped.\n",
      "     |      If 'raise', an error is raised. Default is 'none'.\n",
      "     |  deterministic : DeterministicProcess\n",
      "     |      A deterministic process.  If provided, trend and seasonal are ignored.\n",
      "     |      A warning is raised if trend is not \"n\" and seasonal is not False.\n",
      "     |  old_names : bool\n",
      "     |      Flag indicating whether to use the v0.11 names or the v0.12+ names.\n",
      "     |  \n",
      "     |      .. deprecated:: 0.13\n",
      "     |  \n",
      "     |         old_names is deprecated and will be removed after 0.14 is\n",
      "     |         released. You must update any code reliant on the old variable\n",
      "     |         names to use the new names.\n",
      "     |  \n",
      "     |  See Also\n",
      "     |  --------\n",
      "     |  statsmodels.tsa.statespace.sarimax.SARIMAX\n",
      "     |      Estimation of SARIMAX models using exact likelihood and the\n",
      "     |      Kalman Filter.\n",
      "     |  \n",
      "     |  Examples\n",
      "     |  --------\n",
      "     |  >>> import statsmodels.api as sm\n",
      "     |  >>> from statsmodels.tsa.ar_model import AutoReg\n",
      "     |  >>> data = sm.datasets.sunspots.load_pandas().data['SUNACTIVITY']\n",
      "     |  >>> out = 'AIC: {0:0.3f}, HQIC: {1:0.3f}, BIC: {2:0.3f}'\n",
      "     |  \n",
      "     |  Start by fitting an unrestricted Seasonal AR model\n",
      "     |  \n",
      "     |  >>> res = AutoReg(data, lags = [1, 11, 12]).fit()\n",
      "     |  >>> print(out.format(res.aic, res.hqic, res.bic))\n",
      "     |  AIC: 5.945, HQIC: 5.970, BIC: 6.007\n",
      "     |  \n",
      "     |  An alternative used seasonal dummies\n",
      "     |  \n",
      "     |  >>> res = AutoReg(data, lags=1, seasonal=True, period=11).fit()\n",
      "     |  >>> print(out.format(res.aic, res.hqic, res.bic))\n",
      "     |  AIC: 6.017, HQIC: 6.080, BIC: 6.175\n",
      "     |  \n",
      "     |  Finally, both the seasonal AR structure and dummies can be included\n",
      "     |  \n",
      "     |  >>> res = AutoReg(data, lags=[1, 11, 12], seasonal=True, period=11).fit()\n",
      "     |  >>> print(out.format(res.aic, res.hqic, res.bic))\n",
      "     |  AIC: 5.884, HQIC: 5.959, BIC: 6.071\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      AutoReg\n",
      "     |      statsmodels.tsa.base.tsa_model.TimeSeriesModel\n",
      "     |      statsmodels.base.model.LikelihoodModel\n",
      "     |      statsmodels.base.model.Model\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, endog, lags, trend='c', seasonal=False, exog=None, hold_back=None, period=None, missing='none', *, deterministic=None, old_names=False)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  fit(self, cov_type='nonrobust', cov_kwds=None, use_t=False)\n",
      "     |      Estimate the model parameters.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      cov_type : str\n",
      "     |          The covariance estimator to use. The most common choices are listed\n",
      "     |          below.  Supports all covariance estimators that are available\n",
      "     |          in ``OLS.fit``.\n",
      "     |      \n",
      "     |          * 'nonrobust' - The class OLS covariance estimator that assumes\n",
      "     |            homoskedasticity.\n",
      "     |          * 'HC0', 'HC1', 'HC2', 'HC3' - Variants of White's\n",
      "     |            (or Eiker-Huber-White) covariance estimator. `HC0` is the\n",
      "     |            standard implementation.  The other make corrections to improve\n",
      "     |            the finite sample performance of the heteroskedasticity robust\n",
      "     |            covariance estimator.\n",
      "     |          * 'HAC' - Heteroskedasticity-autocorrelation robust covariance\n",
      "     |            estimation. Supports cov_kwds.\n",
      "     |      \n",
      "     |            - `maxlags` integer (required) : number of lags to use.\n",
      "     |            - `kernel` callable or str (optional) : kernel\n",
      "     |                currently available kernels are ['bartlett', 'uniform'],\n",
      "     |                default is Bartlett.\n",
      "     |            - `use_correction` bool (optional) : If true, use small sample\n",
      "     |                correction.\n",
      "     |      cov_kwds : dict, optional\n",
      "     |          A dictionary of keyword arguments to pass to the covariance\n",
      "     |          estimator. `nonrobust` and `HC#` do not support cov_kwds.\n",
      "     |      use_t : bool, optional\n",
      "     |          A flag indicating that inference should use the Student's t\n",
      "     |          distribution that accounts for model degree of freedom.  If False,\n",
      "     |          uses the normal distribution. If None, defers the choice to\n",
      "     |          the cov_type. It also removes degree of freedom corrections from\n",
      "     |          the covariance estimator when cov_type is 'nonrobust'.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      AutoRegResults\n",
      "     |          Estimation results.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      statsmodels.regression.linear_model.OLS\n",
      "     |          Ordinary Least Squares estimation.\n",
      "     |      statsmodels.regression.linear_model.RegressionResults\n",
      "     |          See ``get_robustcov_results`` for a detailed list of available\n",
      "     |          covariance estimators and options.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Use ``OLS`` to estimate model parameters and to estimate parameter\n",
      "     |      covariance.\n",
      "     |  \n",
      "     |  hessian(self, params)\n",
      "     |      The Hessian matrix of the model.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : ndarray\n",
      "     |          The parameters to use when evaluating the Hessian.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      ndarray\n",
      "     |          The hessian evaluated at the parameters.\n",
      "     |  \n",
      "     |  information(self, params)\n",
      "     |      Fisher information matrix of model.\n",
      "     |      \n",
      "     |      Returns -1 * Hessian of the log-likelihood evaluated at params.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : ndarray\n",
      "     |          The model parameters.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      ndarray\n",
      "     |          The information matrix.\n",
      "     |  \n",
      "     |  initialize(self)\n",
      "     |      Initialize the model (no-op).\n",
      "     |  \n",
      "     |  loglike(self, params)\n",
      "     |      Log-likelihood of model.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : ndarray\n",
      "     |          The model parameters used to compute the log-likelihood.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      float\n",
      "     |          The log-likelihood value.\n",
      "     |  \n",
      "     |  predict(self, params, start=None, end=None, dynamic=False, exog=None, exog_oos=None)\n",
      "     |      In-sample prediction and out-of-sample forecasting.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : array_like\n",
      "     |          The fitted model parameters.\n",
      "     |      start : int, str, or datetime, optional\n",
      "     |          Zero-indexed observation number at which to start forecasting,\n",
      "     |          i.e., the first forecast is start. Can also be a date string to\n",
      "     |          parse or a datetime type. Default is the the zeroth observation.\n",
      "     |      end : int, str, or datetime, optional\n",
      "     |          Zero-indexed observation number at which to end forecasting, i.e.,\n",
      "     |          the last forecast is end. Can also be a date string to\n",
      "     |          parse or a datetime type. However, if the dates index does not\n",
      "     |          have a fixed frequency, end must be an integer index if you\n",
      "     |          want out-of-sample prediction. Default is the last observation in\n",
      "     |          the sample. Unlike standard python slices, end is inclusive so\n",
      "     |          that all the predictions [start, start+1, ..., end-1, end] are\n",
      "     |          returned.\n",
      "     |      dynamic : {bool, int, str, datetime, Timestamp}, optional\n",
      "     |          Integer offset relative to `start` at which to begin dynamic\n",
      "     |          prediction. Prior to this observation, true endogenous values\n",
      "     |          will be used for prediction; starting with this observation and\n",
      "     |          continuing through the end of prediction, forecasted endogenous\n",
      "     |          values will be used instead. Datetime-like objects are not\n",
      "     |          interpreted as offsets. They are instead used to find the index\n",
      "     |          location of `dynamic` which is then used to to compute the offset.\n",
      "     |      exog : array_like\n",
      "     |          A replacement exogenous array.  Must have the same shape as the\n",
      "     |          exogenous data array used when the model was created.\n",
      "     |      exog_oos : array_like\n",
      "     |          An array containing out-of-sample values of the exogenous variable.\n",
      "     |          Must has the same number of columns as the exog used when the\n",
      "     |          model was created, and at least as many rows as the number of\n",
      "     |          out-of-sample forecasts.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      predictions : {ndarray, Series}\n",
      "     |          Array of out of in-sample predictions and / or out-of-sample\n",
      "     |          forecasts.\n",
      "     |  \n",
      "     |  score(self, params)\n",
      "     |      Score vector of model.\n",
      "     |      \n",
      "     |      The gradient of logL with respect to each parameter.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : ndarray\n",
      "     |          The parameters to use when evaluating the Hessian.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      ndarray\n",
      "     |          The score vector evaluated at the parameters.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties defined here:\n",
      "     |  \n",
      "     |  ar_lags\n",
      "     |      The autoregressive lags included in the model\n",
      "     |  \n",
      "     |  deterministic\n",
      "     |      The deterministic used to construct the model\n",
      "     |  \n",
      "     |  df_model\n",
      "     |      The model degrees of freedom.\n",
      "     |  \n",
      "     |  exog_names\n",
      "     |      Names of exogenous variables included in model\n",
      "     |  \n",
      "     |  hold_back\n",
      "     |      The number of initial obs. excluded from the estimation sample.\n",
      "     |  \n",
      "     |  period\n",
      "     |      The period of the seasonal component.\n",
      "     |  \n",
      "     |  seasonal\n",
      "     |      Flag indicating that the model contains a seasonal component.\n",
      "     |  \n",
      "     |  trend\n",
      "     |      The trend used in the model.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from statsmodels.base.model.Model:\n",
      "     |  \n",
      "     |  from_formula(formula, data, subset=None, drop_cols=None, *args, **kwargs) from builtins.type\n",
      "     |      Create a Model from a formula and dataframe.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      formula : str or generic Formula object\n",
      "     |          The formula specifying the model.\n",
      "     |      data : array_like\n",
      "     |          The data for the model. See Notes.\n",
      "     |      subset : array_like\n",
      "     |          An array-like object of booleans, integers, or index values that\n",
      "     |          indicate the subset of df to use in the model. Assumes df is a\n",
      "     |          `pandas.DataFrame`.\n",
      "     |      drop_cols : array_like\n",
      "     |          Columns to drop from the design matrix.  Cannot be used to\n",
      "     |          drop terms involving categoricals.\n",
      "     |      *args\n",
      "     |          Additional positional argument that are passed to the model.\n",
      "     |      **kwargs\n",
      "     |          These are passed to the model with one exception. The\n",
      "     |          ``eval_env`` keyword is passed to patsy. It can be either a\n",
      "     |          :class:`patsy:patsy.EvalEnvironment` object or an integer\n",
      "     |          indicating the depth of the namespace to use. For example, the\n",
      "     |          default ``eval_env=0`` uses the calling namespace. If you wish\n",
      "     |          to use a \"clean\" environment set ``eval_env=-1``.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      model\n",
      "     |          The model instance.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      data must define __getitem__ with the keys in the formula terms\n",
      "     |      args and kwargs are passed on to the model instantiation. E.g.,\n",
      "     |      a numpy structured or rec array, a dictionary, or a pandas DataFrame.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from statsmodels.base.model.Model:\n",
      "     |  \n",
      "     |  endog_names\n",
      "     |      Names of endogenous variables.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from statsmodels.base.model.Model:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class DynamicFactor(statsmodels.tsa.statespace.mlemodel.MLEModel)\n",
      "     |  DynamicFactor(endog, k_factors, factor_order, exog=None, error_order=0, error_var=False, error_cov_type='diagonal', enforce_stationarity=True, **kwargs)\n",
      "     |  \n",
      "     |  Dynamic factor model\n",
      "     |  \n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  endog : array_like\n",
      "     |      The observed time-series process :math:`y`\n",
      "     |  exog : array_like, optional\n",
      "     |      Array of exogenous regressors for the observation equation, shaped\n",
      "     |      nobs x k_exog.\n",
      "     |  k_factors : int\n",
      "     |      The number of unobserved factors.\n",
      "     |  factor_order : int\n",
      "     |      The order of the vector autoregression followed by the factors.\n",
      "     |  error_cov_type : {'scalar', 'diagonal', 'unstructured'}, optional\n",
      "     |      The structure of the covariance matrix of the observation error term,\n",
      "     |      where \"unstructured\" puts no restrictions on the matrix, \"diagonal\"\n",
      "     |      requires it to be any diagonal matrix (uncorrelated errors), and\n",
      "     |      \"scalar\" requires it to be a scalar times the identity matrix. Default\n",
      "     |      is \"diagonal\".\n",
      "     |  error_order : int, optional\n",
      "     |      The order of the vector autoregression followed by the observation\n",
      "     |      error component. Default is None, corresponding to white noise errors.\n",
      "     |  error_var : bool, optional\n",
      "     |      Whether or not to model the errors jointly via a vector autoregression,\n",
      "     |      rather than as individual autoregressions. Has no effect unless\n",
      "     |      `error_order` is set. Default is False.\n",
      "     |  enforce_stationarity : bool, optional\n",
      "     |      Whether or not to transform the AR parameters to enforce stationarity\n",
      "     |      in the autoregressive component of the model. Default is True.\n",
      "     |  **kwargs\n",
      "     |      Keyword arguments may be used to provide default values for state space\n",
      "     |      matrices or for Kalman filtering options. See `Representation`, and\n",
      "     |      `KalmanFilter` for more details.\n",
      "     |  \n",
      "     |  Attributes\n",
      "     |  ----------\n",
      "     |  exog : array_like, optional\n",
      "     |      Array of exogenous regressors for the observation equation, shaped\n",
      "     |      nobs x k_exog.\n",
      "     |  k_factors : int\n",
      "     |      The number of unobserved factors.\n",
      "     |  factor_order : int\n",
      "     |      The order of the vector autoregression followed by the factors.\n",
      "     |  error_cov_type : {'diagonal', 'unstructured'}\n",
      "     |      The structure of the covariance matrix of the error term, where\n",
      "     |      \"unstructured\" puts no restrictions on the matrix and \"diagonal\"\n",
      "     |      requires it to be a diagonal matrix (uncorrelated errors).\n",
      "     |  error_order : int\n",
      "     |      The order of the vector autoregression followed by the observation\n",
      "     |      error component.\n",
      "     |  error_var : bool\n",
      "     |      Whether or not to model the errors jointly via a vector autoregression,\n",
      "     |      rather than as individual autoregressions. Has no effect unless\n",
      "     |      `error_order` is set.\n",
      "     |  enforce_stationarity : bool, optional\n",
      "     |      Whether or not to transform the AR parameters to enforce stationarity\n",
      "     |      in the autoregressive component of the model. Default is True.\n",
      "     |  \n",
      "     |  Notes\n",
      "     |  -----\n",
      "     |  The dynamic factor model considered here is in the so-called static form,\n",
      "     |  and is specified:\n",
      "     |  \n",
      "     |  .. math::\n",
      "     |  \n",
      "     |      y_t & = \\Lambda f_t + B x_t + u_t \\\\\n",
      "     |      f_t & = A_1 f_{t-1} + \\dots + A_p f_{t-p} + \\eta_t \\\\\n",
      "     |      u_t & = C_1 u_{t-1} + \\dots + C_q u_{t-q} + \\varepsilon_t\n",
      "     |  \n",
      "     |  where there are `k_endog` observed series and `k_factors` unobserved\n",
      "     |  factors. Thus :math:`y_t` is a `k_endog` x 1 vector and :math:`f_t` is a\n",
      "     |  `k_factors` x 1 vector.\n",
      "     |  \n",
      "     |  :math:`x_t` are optional exogenous vectors, shaped `k_exog` x 1.\n",
      "     |  \n",
      "     |  :math:`\\eta_t` and :math:`\\varepsilon_t` are white noise error terms. In\n",
      "     |  order to identify the factors, :math:`Var(\\eta_t) = I`. Denote\n",
      "     |  :math:`Var(\\varepsilon_t) \\equiv \\Sigma`.\n",
      "     |  \n",
      "     |  Options related to the unobserved factors:\n",
      "     |  \n",
      "     |  - `k_factors`: this is the dimension of the vector :math:`f_t`, above.\n",
      "     |    To exclude factors completely, set `k_factors = 0`.\n",
      "     |  - `factor_order`: this is the number of lags to include in the factor\n",
      "     |    evolution equation, and corresponds to :math:`p`, above. To have static\n",
      "     |    factors, set `factor_order = 0`.\n",
      "     |  \n",
      "     |  Options related to the observation error term :math:`u_t`:\n",
      "     |  \n",
      "     |  - `error_order`: the number of lags to include in the error evolution\n",
      "     |    equation; corresponds to :math:`q`, above. To have white noise errors,\n",
      "     |    set `error_order = 0` (this is the default).\n",
      "     |  - `error_cov_type`: this controls the form of the covariance matrix\n",
      "     |    :math:`\\Sigma`. If it is \"dscalar\", then :math:`\\Sigma = \\sigma^2 I`. If\n",
      "     |    it is \"diagonal\", then\n",
      "     |    :math:`\\Sigma = \\text{diag}(\\sigma_1^2, \\dots, \\sigma_n^2)`. If it is\n",
      "     |    \"unstructured\", then :math:`\\Sigma` is any valid variance / covariance\n",
      "     |    matrix (i.e. symmetric and positive definite).\n",
      "     |  - `error_var`: this controls whether or not the errors evolve jointly\n",
      "     |    according to a VAR(q), or individually according to separate AR(q)\n",
      "     |    processes. In terms of the formulation above, if `error_var = False`,\n",
      "     |    then the matrices :math:C_i` are diagonal, otherwise they are general\n",
      "     |    VAR matrices.\n",
      "     |  \n",
      "     |  References\n",
      "     |  ----------\n",
      "     |  .. [*] Ltkepohl, Helmut. 2007.\n",
      "     |     New Introduction to Multiple Time Series Analysis.\n",
      "     |     Berlin: Springer.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      DynamicFactor\n",
      "     |      statsmodels.tsa.statespace.mlemodel.MLEModel\n",
      "     |      statsmodels.tsa.base.tsa_model.TimeSeriesModel\n",
      "     |      statsmodels.base.model.LikelihoodModel\n",
      "     |      statsmodels.base.model.Model\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, endog, k_factors, factor_order, exog=None, error_order=0, error_var=False, error_cov_type='diagonal', enforce_stationarity=True, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  clone(self, endog, exog=None, **kwargs)\n",
      "     |      Clone state space model with new data and optionally new specification\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      endog : array_like\n",
      "     |          The observed time-series process :math:`y`\n",
      "     |      k_states : int\n",
      "     |          The dimension of the unobserved state process.\n",
      "     |      exog : array_like, optional\n",
      "     |          Array of exogenous regressors, shaped nobs x k. Default is no\n",
      "     |          exogenous regressors.\n",
      "     |      kwargs\n",
      "     |          Keyword arguments to pass to the new model class to change the\n",
      "     |          model specification.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      model : MLEModel subclass\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      This method must be implemented\n",
      "     |  \n",
      "     |  transform_params(self, unconstrained)\n",
      "     |      Transform unconstrained parameters used by the optimizer to constrained\n",
      "     |      parameters used in likelihood evaluation\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      unconstrained : array_like\n",
      "     |          Array of unconstrained parameters used by the optimizer, to be\n",
      "     |          transformed.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      constrained : array_like\n",
      "     |          Array of constrained parameters which may be used in likelihood\n",
      "     |          evaluation.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Constrains the factor transition to be stationary and variances to be\n",
      "     |      positive.\n",
      "     |  \n",
      "     |  untransform_params(self, constrained)\n",
      "     |      Transform constrained parameters used in likelihood evaluation\n",
      "     |      to unconstrained parameters used by the optimizer.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      constrained : array_like\n",
      "     |          Array of constrained parameters used in likelihood evaluation, to\n",
      "     |          be transformed.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      unconstrained : array_like\n",
      "     |          Array of unconstrained parameters used by the optimizer.\n",
      "     |  \n",
      "     |  update(self, params, transformed=True, includes_fixed=False, complex_step=False)\n",
      "     |      Update the parameters of the model\n",
      "     |      \n",
      "     |      Updates the representation matrices to fill in the new parameter\n",
      "     |      values.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : array_like\n",
      "     |          Array of new parameters.\n",
      "     |      transformed : bool, optional\n",
      "     |          Whether or not `params` is already transformed. If set to False,\n",
      "     |          `transform_params` is called. Default is True..\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      params : array_like\n",
      "     |          Array of parameters.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Let `n = k_endog`, `m = k_factors`, and `p = factor_order`. Then the\n",
      "     |      `params` vector has length\n",
      "     |      :math:`[n       imes m] + [n] + [m^2    imes p]`.\n",
      "     |      It is expanded in the following way:\n",
      "     |      \n",
      "     |      - The first :math:`n    imes m` parameters fill out the factor loading\n",
      "     |        matrix, starting from the [0,0] entry and then proceeding along rows.\n",
      "     |        These parameters are not modified in `transform_params`.\n",
      "     |      - The next :math:`n` parameters provide variances for the error_cov\n",
      "     |        errors in the observation equation. They fill in the diagonal of the\n",
      "     |        observation covariance matrix, and are constrained to be positive by\n",
      "     |        `transofrm_params`.\n",
      "     |      - The next :math:`m^2   imes p` parameters are used to create the `p`\n",
      "     |        coefficient matrices for the vector autoregression describing the\n",
      "     |        factor transition. They are transformed in `transform_params` to\n",
      "     |        enforce stationarity of the VAR(p). They are placed so as to make\n",
      "     |        the transition matrix a companion matrix for the VAR. In particular,\n",
      "     |        we assume that the first :math:`m^2` parameters fill the first\n",
      "     |        coefficient matrix (starting at [0,0] and filling along rows), the\n",
      "     |        second :math:`m^2` parameters fill the second matrix, etc.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties defined here:\n",
      "     |  \n",
      "     |  param_names\n",
      "     |      (list of str) List of human readable parameter names (for parameters\n",
      "     |      actually included in the model).\n",
      "     |  \n",
      "     |  start_params\n",
      "     |      (array) Starting parameters for maximum likelihood estimation.\n",
      "     |  \n",
      "     |  state_names\n",
      "     |      (list of str) List of human readable names for unobserved states.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from statsmodels.tsa.statespace.mlemodel.MLEModel:\n",
      "     |  \n",
      "     |  __getitem__(self, key)\n",
      "     |  \n",
      "     |  __setitem__(self, key, value)\n",
      "     |  \n",
      "     |  filter(self, params, transformed=True, includes_fixed=False, complex_step=False, cov_type=None, cov_kwds=None, return_ssm=False, results_class=None, results_wrapper_class=None, low_memory=False, **kwargs)\n",
      "     |      Kalman filtering\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : array_like\n",
      "     |          Array of parameters at which to evaluate the loglikelihood\n",
      "     |          function.\n",
      "     |      transformed : bool, optional\n",
      "     |          Whether or not `params` is already transformed. Default is True.\n",
      "     |      return_ssm : bool,optional\n",
      "     |          Whether or not to return only the state space output or a full\n",
      "     |          results object. Default is to return a full results object.\n",
      "     |      cov_type : str, optional\n",
      "     |          See `MLEResults.fit` for a description of covariance matrix types\n",
      "     |          for results object.\n",
      "     |      cov_kwds : dict or None, optional\n",
      "     |          See `MLEResults.get_robustcov_results` for a description required\n",
      "     |          keywords for alternative covariance estimators\n",
      "     |      low_memory : bool, optional\n",
      "     |          If set to True, techniques are applied to substantially reduce\n",
      "     |          memory usage. If used, some features of the results object will\n",
      "     |          not be available (including in-sample prediction), although\n",
      "     |          out-of-sample forecasting is possible. Default is False.\n",
      "     |      **kwargs\n",
      "     |          Additional keyword arguments to pass to the Kalman filter. See\n",
      "     |          `KalmanFilter.filter` for more details.\n",
      "     |  \n",
      "     |  fit(self, start_params=None, transformed=True, includes_fixed=False, cov_type=None, cov_kwds=None, method='lbfgs', maxiter=50, full_output=1, disp=5, callback=None, return_params=False, optim_score=None, optim_complex_step=None, optim_hessian=None, flags=None, low_memory=False, **kwargs)\n",
      "     |      Fits the model by maximum likelihood via Kalman filter.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      start_params : array_like, optional\n",
      "     |          Initial guess of the solution for the loglikelihood maximization.\n",
      "     |          If None, the default is given by Model.start_params.\n",
      "     |      transformed : bool, optional\n",
      "     |          Whether or not `start_params` is already transformed. Default is\n",
      "     |          True.\n",
      "     |      includes_fixed : bool, optional\n",
      "     |          If parameters were previously fixed with the `fix_params` method,\n",
      "     |          this argument describes whether or not `start_params` also includes\n",
      "     |          the fixed parameters, in addition to the free parameters. Default\n",
      "     |          is False.\n",
      "     |      cov_type : str, optional\n",
      "     |          The `cov_type` keyword governs the method for calculating the\n",
      "     |          covariance matrix of parameter estimates. Can be one of:\n",
      "     |      \n",
      "     |          - 'opg' for the outer product of gradient estimator\n",
      "     |          - 'oim' for the observed information matrix estimator, calculated\n",
      "     |            using the method of Harvey (1989)\n",
      "     |          - 'approx' for the observed information matrix estimator,\n",
      "     |            calculated using a numerical approximation of the Hessian matrix.\n",
      "     |          - 'robust' for an approximate (quasi-maximum likelihood) covariance\n",
      "     |            matrix that may be valid even in the presence of some\n",
      "     |            misspecifications. Intermediate calculations use the 'oim'\n",
      "     |            method.\n",
      "     |          - 'robust_approx' is the same as 'robust' except that the\n",
      "     |            intermediate calculations use the 'approx' method.\n",
      "     |          - 'none' for no covariance matrix calculation.\n",
      "     |      \n",
      "     |          Default is 'opg' unless memory conservation is used to avoid\n",
      "     |          computing the loglikelihood values for each observation, in which\n",
      "     |          case the default is 'approx'.\n",
      "     |      cov_kwds : dict or None, optional\n",
      "     |          A dictionary of arguments affecting covariance matrix computation.\n",
      "     |      \n",
      "     |          **opg, oim, approx, robust, robust_approx**\n",
      "     |      \n",
      "     |          - 'approx_complex_step' : bool, optional - If True, numerical\n",
      "     |            approximations are computed using complex-step methods. If False,\n",
      "     |            numerical approximations are computed using finite difference\n",
      "     |            methods. Default is True.\n",
      "     |          - 'approx_centered' : bool, optional - If True, numerical\n",
      "     |            approximations computed using finite difference methods use a\n",
      "     |            centered approximation. Default is False.\n",
      "     |      method : str, optional\n",
      "     |          The `method` determines which solver from `scipy.optimize`\n",
      "     |          is used, and it can be chosen from among the following strings:\n",
      "     |      \n",
      "     |          - 'newton' for Newton-Raphson\n",
      "     |          - 'nm' for Nelder-Mead\n",
      "     |          - 'bfgs' for Broyden-Fletcher-Goldfarb-Shanno (BFGS)\n",
      "     |          - 'lbfgs' for limited-memory BFGS with optional box constraints\n",
      "     |          - 'powell' for modified Powell's method\n",
      "     |          - 'cg' for conjugate gradient\n",
      "     |          - 'ncg' for Newton-conjugate gradient\n",
      "     |          - 'basinhopping' for global basin-hopping solver\n",
      "     |      \n",
      "     |          The explicit arguments in `fit` are passed to the solver,\n",
      "     |          with the exception of the basin-hopping solver. Each\n",
      "     |          solver has several optional arguments that are not the same across\n",
      "     |          solvers. See the notes section below (or scipy.optimize) for the\n",
      "     |          available arguments and for the list of explicit arguments that the\n",
      "     |          basin-hopping solver supports.\n",
      "     |      maxiter : int, optional\n",
      "     |          The maximum number of iterations to perform.\n",
      "     |      full_output : bool, optional\n",
      "     |          Set to True to have all available output in the Results object's\n",
      "     |          mle_retvals attribute. The output is dependent on the solver.\n",
      "     |          See LikelihoodModelResults notes section for more information.\n",
      "     |      disp : bool, optional\n",
      "     |          Set to True to print convergence messages.\n",
      "     |      callback : callable callback(xk), optional\n",
      "     |          Called after each iteration, as callback(xk), where xk is the\n",
      "     |          current parameter vector.\n",
      "     |      return_params : bool, optional\n",
      "     |          Whether or not to return only the array of maximizing parameters.\n",
      "     |          Default is False.\n",
      "     |      optim_score : {'harvey', 'approx'} or None, optional\n",
      "     |          The method by which the score vector is calculated. 'harvey' uses\n",
      "     |          the method from Harvey (1989), 'approx' uses either finite\n",
      "     |          difference or complex step differentiation depending upon the\n",
      "     |          value of `optim_complex_step`, and None uses the built-in gradient\n",
      "     |          approximation of the optimizer. Default is None. This keyword is\n",
      "     |          only relevant if the optimization method uses the score.\n",
      "     |      optim_complex_step : bool, optional\n",
      "     |          Whether or not to use complex step differentiation when\n",
      "     |          approximating the score; if False, finite difference approximation\n",
      "     |          is used. Default is True. This keyword is only relevant if\n",
      "     |          `optim_score` is set to 'harvey' or 'approx'.\n",
      "     |      optim_hessian : {'opg','oim','approx'}, optional\n",
      "     |          The method by which the Hessian is numerically approximated. 'opg'\n",
      "     |          uses outer product of gradients, 'oim' uses the information\n",
      "     |          matrix formula from Harvey (1989), and 'approx' uses numerical\n",
      "     |          approximation. This keyword is only relevant if the\n",
      "     |          optimization method uses the Hessian matrix.\n",
      "     |      low_memory : bool, optional\n",
      "     |          If set to True, techniques are applied to substantially reduce\n",
      "     |          memory usage. If used, some features of the results object will\n",
      "     |          not be available (including smoothed results and in-sample\n",
      "     |          prediction), although out-of-sample forecasting is possible.\n",
      "     |          Default is False.\n",
      "     |      **kwargs\n",
      "     |          Additional keyword arguments to pass to the optimizer.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      results\n",
      "     |          Results object holding results from fitting a state space model.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      statsmodels.base.model.LikelihoodModel.fit\n",
      "     |      statsmodels.tsa.statespace.mlemodel.MLEResults\n",
      "     |      statsmodels.tsa.statespace.structural.UnobservedComponentsResults\n",
      "     |  \n",
      "     |  fit_constrained(self, constraints, start_params=None, **fit_kwds)\n",
      "     |      Fit the model with some parameters subject to equality constraints.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      constraints : dict\n",
      "     |          Dictionary of constraints, of the form `param_name: fixed_value`.\n",
      "     |          See the `param_names` property for valid parameter names.\n",
      "     |      start_params : array_like, optional\n",
      "     |          Initial guess of the solution for the loglikelihood maximization.\n",
      "     |          If None, the default is given by Model.start_params.\n",
      "     |      **fit_kwds : keyword arguments\n",
      "     |          fit_kwds are used in the optimization of the remaining parameters.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      results : Results instance\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> mod = sm.tsa.SARIMAX(endog, order=(1, 0, 1))\n",
      "     |      >>> res = mod.fit_constrained({'ar.L1': 0.5})\n",
      "     |  \n",
      "     |  fix_params(self, params)\n",
      "     |      Fix parameters to specific values (context manager)\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : dict\n",
      "     |          Dictionary describing the fixed parameter values, of the form\n",
      "     |          `param_name: fixed_value`. See the `param_names` property for valid\n",
      "     |          parameter names.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> mod = sm.tsa.SARIMAX(endog, order=(1, 0, 1))\n",
      "     |      >>> with mod.fix_params({'ar.L1': 0.5}):\n",
      "     |              res = mod.fit()\n",
      "     |  \n",
      "     |  handle_params(self, params, transformed=True, includes_fixed=False, return_jacobian=False)\n",
      "     |      Ensure model parameters satisfy shape and other requirements\n",
      "     |  \n",
      "     |  hessian(self, params, *args, **kwargs)\n",
      "     |      Hessian matrix of the likelihood function, evaluated at the given\n",
      "     |      parameters\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : array_like\n",
      "     |          Array of parameters at which to evaluate the hessian.\n",
      "     |      *args\n",
      "     |          Additional positional arguments to the `loglike` method.\n",
      "     |      **kwargs\n",
      "     |          Additional keyword arguments to the `loglike` method.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      hessian : ndarray\n",
      "     |          Hessian matrix evaluated at `params`\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      This is a numerical approximation.\n",
      "     |      \n",
      "     |      Both args and kwargs are necessary because the optimizer from\n",
      "     |      `fit` must call this function and only supports passing arguments via\n",
      "     |      args (for example `scipy.optimize.fmin_l_bfgs`).\n",
      "     |  \n",
      "     |  impulse_responses(self, params, steps=1, impulse=0, orthogonalized=False, cumulative=False, anchor=None, exog=None, extend_model=None, extend_kwargs=None, transformed=True, includes_fixed=False, **kwargs)\n",
      "     |      Impulse response function\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : array_like\n",
      "     |          Array of model parameters.\n",
      "     |      steps : int, optional\n",
      "     |          The number of steps for which impulse responses are calculated.\n",
      "     |          Default is 1. Note that for time-invariant models, the initial\n",
      "     |          impulse is not counted as a step, so if `steps=1`, the output will\n",
      "     |          have 2 entries.\n",
      "     |      impulse : int, str or array_like\n",
      "     |          If an integer, the state innovation to pulse; must be between 0\n",
      "     |          and `k_posdef-1`. If a str, it indicates which column of df\n",
      "     |          the unit (1) impulse is given.\n",
      "     |          Alternatively, a custom impulse vector may be provided; must be\n",
      "     |          shaped `k_posdef x 1`.\n",
      "     |      orthogonalized : bool, optional\n",
      "     |          Whether or not to perform impulse using orthogonalized innovations.\n",
      "     |          Note that this will also affect custum `impulse` vectors. Default\n",
      "     |          is False.\n",
      "     |      cumulative : bool, optional\n",
      "     |          Whether or not to return cumulative impulse responses. Default is\n",
      "     |          False.\n",
      "     |      anchor : int, str, or datetime, optional\n",
      "     |          Time point within the sample for the state innovation impulse. Type\n",
      "     |          depends on the index of the given `endog` in the model. Two special\n",
      "     |          cases are the strings 'start' and 'end', which refer to setting the\n",
      "     |          impulse at the first and last points of the sample, respectively.\n",
      "     |          Integer values can run from 0 to `nobs - 1`, or can be negative to\n",
      "     |          apply negative indexing. Finally, if a date/time index was provided\n",
      "     |          to the model, then this argument can be a date string to parse or a\n",
      "     |          datetime type. Default is 'start'.\n",
      "     |      exog : array_like, optional\n",
      "     |          New observations of exogenous regressors for our-of-sample periods,\n",
      "     |          if applicable.\n",
      "     |      transformed : bool, optional\n",
      "     |          Whether or not `params` is already transformed. Default is\n",
      "     |          True.\n",
      "     |      includes_fixed : bool, optional\n",
      "     |          If parameters were previously fixed with the `fix_params` method,\n",
      "     |          this argument describes whether or not `params` also includes\n",
      "     |          the fixed parameters, in addition to the free parameters. Default\n",
      "     |          is False.\n",
      "     |      **kwargs\n",
      "     |          If the model has time-varying design or transition matrices and the\n",
      "     |          combination of `anchor` and `steps` implies creating impulse\n",
      "     |          responses for the out-of-sample period, then these matrices must\n",
      "     |          have updated values provided for the out-of-sample steps. For\n",
      "     |          example, if `design` is a time-varying component, `nobs` is 10,\n",
      "     |          `anchor=1`, and `steps` is 15, a (`k_endog` x `k_states` x 7)\n",
      "     |          matrix must be provided with the new design matrix values.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      impulse_responses : ndarray\n",
      "     |          Responses for each endogenous variable due to the impulse\n",
      "     |          given by the `impulse` argument. For a time-invariant model, the\n",
      "     |          impulse responses are given for `steps + 1` elements (this gives\n",
      "     |          the \"initial impulse\" followed by `steps` responses for the\n",
      "     |          important cases of VAR and SARIMAX models), while for time-varying\n",
      "     |          models the impulse responses are only given for `steps` elements\n",
      "     |          (to avoid having to unexpectedly provide updated time-varying\n",
      "     |          matrices).\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      simulate\n",
      "     |          Simulate a time series according to the given state space model,\n",
      "     |          optionally with specified series for the innovations.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Intercepts in the measurement and state equation are ignored when\n",
      "     |      calculating impulse responses.\n",
      "     |      \n",
      "     |      TODO: add an option to allow changing the ordering for the\n",
      "     |            orthogonalized option. Will require permuting matrices when\n",
      "     |            constructing the extended model.\n",
      "     |  \n",
      "     |  initialize_approximate_diffuse(self, variance=None)\n",
      "     |      Initialize approximate diffuse\n",
      "     |  \n",
      "     |  initialize_known(self, initial_state, initial_state_cov)\n",
      "     |      Initialize known\n",
      "     |  \n",
      "     |  initialize_statespace(self, **kwargs)\n",
      "     |      Initialize the state space representation\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      **kwargs\n",
      "     |          Additional keyword arguments to pass to the state space class\n",
      "     |          constructor.\n",
      "     |  \n",
      "     |  initialize_stationary(self)\n",
      "     |      Initialize stationary\n",
      "     |  \n",
      "     |  loglike(self, params, *args, **kwargs)\n",
      "     |      Loglikelihood evaluation\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : array_like\n",
      "     |          Array of parameters at which to evaluate the loglikelihood\n",
      "     |          function.\n",
      "     |      transformed : bool, optional\n",
      "     |          Whether or not `params` is already transformed. Default is True.\n",
      "     |      **kwargs\n",
      "     |          Additional keyword arguments to pass to the Kalman filter. See\n",
      "     |          `KalmanFilter.filter` for more details.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      update : modifies the internal state of the state space model to\n",
      "     |               reflect new params\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      [1]_ recommend maximizing the average likelihood to avoid scale issues;\n",
      "     |      this is done automatically by the base Model fit method.\n",
      "     |      \n",
      "     |      References\n",
      "     |      ----------\n",
      "     |      .. [1] Koopman, Siem Jan, Neil Shephard, and Jurgen A. Doornik. 1999.\n",
      "     |         Statistical Algorithms for Models in State Space Using SsfPack 2.2.\n",
      "     |         Econometrics Journal 2 (1): 107-60. doi:10.1111/1368-423X.00023.\n",
      "     |  \n",
      "     |  loglikeobs(self, params, transformed=True, includes_fixed=False, complex_step=False, **kwargs)\n",
      "     |      Loglikelihood evaluation\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : array_like\n",
      "     |          Array of parameters at which to evaluate the loglikelihood\n",
      "     |          function.\n",
      "     |      transformed : bool, optional\n",
      "     |          Whether or not `params` is already transformed. Default is True.\n",
      "     |      **kwargs\n",
      "     |          Additional keyword arguments to pass to the Kalman filter. See\n",
      "     |          `KalmanFilter.filter` for more details.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      update : modifies the internal state of the Model to reflect new params\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      [1]_ recommend maximizing the average likelihood to avoid scale issues;\n",
      "     |      this is done automatically by the base Model fit method.\n",
      "     |      \n",
      "     |      References\n",
      "     |      ----------\n",
      "     |      .. [1] Koopman, Siem Jan, Neil Shephard, and Jurgen A. Doornik. 1999.\n",
      "     |         Statistical Algorithms for Models in State Space Using SsfPack 2.2.\n",
      "     |         Econometrics Journal 2 (1): 107-60. doi:10.1111/1368-423X.00023.\n",
      "     |  \n",
      "     |  observed_information_matrix(self, params, transformed=True, includes_fixed=False, approx_complex_step=None, approx_centered=False, **kwargs)\n",
      "     |      Observed information matrix\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : array_like, optional\n",
      "     |          Array of parameters at which to evaluate the loglikelihood\n",
      "     |          function.\n",
      "     |      **kwargs\n",
      "     |          Additional keyword arguments to pass to the Kalman filter. See\n",
      "     |          `KalmanFilter.filter` for more details.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      This method is from Harvey (1989), which shows that the information\n",
      "     |      matrix only depends on terms from the gradient. This implementation is\n",
      "     |      partially analytic and partially numeric approximation, therefore,\n",
      "     |      because it uses the analytic formula for the information matrix, with\n",
      "     |      numerically computed elements of the gradient.\n",
      "     |      \n",
      "     |      References\n",
      "     |      ----------\n",
      "     |      Harvey, Andrew C. 1990.\n",
      "     |      Forecasting, Structural Time Series Models and the Kalman Filter.\n",
      "     |      Cambridge University Press.\n",
      "     |  \n",
      "     |  opg_information_matrix(self, params, transformed=True, includes_fixed=False, approx_complex_step=None, **kwargs)\n",
      "     |      Outer product of gradients information matrix\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : array_like, optional\n",
      "     |          Array of parameters at which to evaluate the loglikelihood\n",
      "     |          function.\n",
      "     |      **kwargs\n",
      "     |          Additional arguments to the `loglikeobs` method.\n",
      "     |      \n",
      "     |      References\n",
      "     |      ----------\n",
      "     |      Berndt, Ernst R., Bronwyn Hall, Robert Hall, and Jerry Hausman. 1974.\n",
      "     |      Estimation and Inference in Nonlinear Structural Models.\n",
      "     |      NBER Chapters. National Bureau of Economic Research, Inc.\n",
      "     |  \n",
      "     |  prepare_data(self)\n",
      "     |      Prepare data for use in the state space representation\n",
      "     |  \n",
      "     |  score(self, params, *args, **kwargs)\n",
      "     |      Compute the score function at params.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : array_like\n",
      "     |          Array of parameters at which to evaluate the score.\n",
      "     |      *args\n",
      "     |          Additional positional arguments to the `loglike` method.\n",
      "     |      **kwargs\n",
      "     |          Additional keyword arguments to the `loglike` method.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      score : ndarray\n",
      "     |          Score, evaluated at `params`.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      This is a numerical approximation, calculated using first-order complex\n",
      "     |      step differentiation on the `loglike` method.\n",
      "     |      \n",
      "     |      Both args and kwargs are necessary because the optimizer from\n",
      "     |      `fit` must call this function and only supports passing arguments via\n",
      "     |      args (for example `scipy.optimize.fmin_l_bfgs`).\n",
      "     |  \n",
      "     |  score_obs(self, params, method='approx', transformed=True, includes_fixed=False, approx_complex_step=None, approx_centered=False, **kwargs)\n",
      "     |      Compute the score per observation, evaluated at params\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : array_like\n",
      "     |          Array of parameters at which to evaluate the score.\n",
      "     |      **kwargs\n",
      "     |          Additional arguments to the `loglike` method.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      score : ndarray\n",
      "     |          Score per observation, evaluated at `params`.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      This is a numerical approximation, calculated using first-order complex\n",
      "     |      step differentiation on the `loglikeobs` method.\n",
      "     |  \n",
      "     |  set_conserve_memory(self, conserve_memory=None, **kwargs)\n",
      "     |      Set the memory conservation method\n",
      "     |      \n",
      "     |      By default, the Kalman filter computes a number of intermediate\n",
      "     |      matrices at each iteration. The memory conservation options control\n",
      "     |      which of those matrices are stored.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      conserve_memory : int, optional\n",
      "     |          Bitmask value to set the memory conservation method to. See notes\n",
      "     |          for details.\n",
      "     |      **kwargs\n",
      "     |          Keyword arguments may be used to influence the memory conservation\n",
      "     |          method by setting individual boolean flags.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      This method is rarely used. See the corresponding function in the\n",
      "     |      `KalmanFilter` class for details.\n",
      "     |  \n",
      "     |  set_filter_method(self, filter_method=None, **kwargs)\n",
      "     |      Set the filtering method\n",
      "     |      \n",
      "     |      The filtering method controls aspects of which Kalman filtering\n",
      "     |      approach will be used.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      filter_method : int, optional\n",
      "     |          Bitmask value to set the filter method to. See notes for details.\n",
      "     |      **kwargs\n",
      "     |          Keyword arguments may be used to influence the filter method by\n",
      "     |          setting individual boolean flags. See notes for details.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      This method is rarely used. See the corresponding function in the\n",
      "     |      `KalmanFilter` class for details.\n",
      "     |  \n",
      "     |  set_inversion_method(self, inversion_method=None, **kwargs)\n",
      "     |      Set the inversion method\n",
      "     |      \n",
      "     |      The Kalman filter may contain one matrix inversion: that of the\n",
      "     |      forecast error covariance matrix. The inversion method controls how and\n",
      "     |      if that inverse is performed.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      inversion_method : int, optional\n",
      "     |          Bitmask value to set the inversion method to. See notes for\n",
      "     |          details.\n",
      "     |      **kwargs\n",
      "     |          Keyword arguments may be used to influence the inversion method by\n",
      "     |          setting individual boolean flags. See notes for details.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      This method is rarely used. See the corresponding function in the\n",
      "     |      `KalmanFilter` class for details.\n",
      "     |  \n",
      "     |  set_smoother_output(self, smoother_output=None, **kwargs)\n",
      "     |      Set the smoother output\n",
      "     |      \n",
      "     |      The smoother can produce several types of results. The smoother output\n",
      "     |      variable controls which are calculated and returned.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      smoother_output : int, optional\n",
      "     |          Bitmask value to set the smoother output to. See notes for details.\n",
      "     |      **kwargs\n",
      "     |          Keyword arguments may be used to influence the smoother output by\n",
      "     |          setting individual boolean flags.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      This method is rarely used. See the corresponding function in the\n",
      "     |      `KalmanSmoother` class for details.\n",
      "     |  \n",
      "     |  set_stability_method(self, stability_method=None, **kwargs)\n",
      "     |      Set the numerical stability method\n",
      "     |      \n",
      "     |      The Kalman filter is a recursive algorithm that may in some cases\n",
      "     |      suffer issues with numerical stability. The stability method controls\n",
      "     |      what, if any, measures are taken to promote stability.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      stability_method : int, optional\n",
      "     |          Bitmask value to set the stability method to. See notes for\n",
      "     |          details.\n",
      "     |      **kwargs\n",
      "     |          Keyword arguments may be used to influence the stability method by\n",
      "     |          setting individual boolean flags. See notes for details.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      This method is rarely used. See the corresponding function in the\n",
      "     |      `KalmanFilter` class for details.\n",
      "     |  \n",
      "     |  simulate(self, params, nsimulations, measurement_shocks=None, state_shocks=None, initial_state=None, anchor=None, repetitions=None, exog=None, extend_model=None, extend_kwargs=None, transformed=True, includes_fixed=False, **kwargs)\n",
      "     |      Simulate a new time series following the state space model\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : array_like\n",
      "     |          Array of parameters to use in constructing the state space\n",
      "     |          representation to use when simulating.\n",
      "     |      nsimulations : int\n",
      "     |          The number of observations to simulate. If the model is\n",
      "     |          time-invariant this can be any number. If the model is\n",
      "     |          time-varying, then this number must be less than or equal to the\n",
      "     |          number of observations.\n",
      "     |      measurement_shocks : array_like, optional\n",
      "     |          If specified, these are the shocks to the measurement equation,\n",
      "     |          :math:`\\varepsilon_t`. If unspecified, these are automatically\n",
      "     |          generated using a pseudo-random number generator. If specified,\n",
      "     |          must be shaped `nsimulations` x `k_endog`, where `k_endog` is the\n",
      "     |          same as in the state space model.\n",
      "     |      state_shocks : array_like, optional\n",
      "     |          If specified, these are the shocks to the state equation,\n",
      "     |          :math:`\\eta_t`. If unspecified, these are automatically\n",
      "     |          generated using a pseudo-random number generator. If specified,\n",
      "     |          must be shaped `nsimulations` x `k_posdef` where `k_posdef` is the\n",
      "     |          same as in the state space model.\n",
      "     |      initial_state : array_like, optional\n",
      "     |          If specified, this is the initial state vector to use in\n",
      "     |          simulation, which should be shaped (`k_states` x 1), where\n",
      "     |          `k_states` is the same as in the state space model. If unspecified,\n",
      "     |          but the model has been initialized, then that initialization is\n",
      "     |          used. This must be specified if `anchor` is anything other than\n",
      "     |          \"start\" or 0 (or else you can use the `simulate` method on a\n",
      "     |          results object rather than on the model object).\n",
      "     |      anchor : int, str, or datetime, optional\n",
      "     |          First period for simulation. The simulation will be conditional on\n",
      "     |          all existing datapoints prior to the `anchor`.  Type depends on the\n",
      "     |          index of the given `endog` in the model. Two special cases are the\n",
      "     |          strings 'start' and 'end'. `start` refers to beginning the\n",
      "     |          simulation at the first period of the sample, and `end` refers to\n",
      "     |          beginning the simulation at the first period after the sample.\n",
      "     |          Integer values can run from 0 to `nobs`, or can be negative to\n",
      "     |          apply negative indexing. Finally, if a date/time index was provided\n",
      "     |          to the model, then this argument can be a date string to parse or a\n",
      "     |          datetime type. Default is 'start'.\n",
      "     |      repetitions : int, optional\n",
      "     |          Number of simulated paths to generate. Default is 1 simulated path.\n",
      "     |      exog : array_like, optional\n",
      "     |          New observations of exogenous regressors, if applicable.\n",
      "     |      transformed : bool, optional\n",
      "     |          Whether or not `params` is already transformed. Default is\n",
      "     |          True.\n",
      "     |      includes_fixed : bool, optional\n",
      "     |          If parameters were previously fixed with the `fix_params` method,\n",
      "     |          this argument describes whether or not `params` also includes\n",
      "     |          the fixed parameters, in addition to the free parameters. Default\n",
      "     |          is False.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      simulated_obs : ndarray\n",
      "     |          An array of simulated observations. If `repetitions=None`, then it\n",
      "     |          will be shaped (nsimulations x k_endog) or (nsimulations,) if\n",
      "     |          `k_endog=1`. Otherwise it will be shaped\n",
      "     |          (nsimulations x k_endog x repetitions). If the model was given\n",
      "     |          Pandas input then the output will be a Pandas object. If\n",
      "     |          `k_endog > 1` and `repetitions` is not None, then the output will\n",
      "     |          be a Pandas DataFrame that has a MultiIndex for the columns, with\n",
      "     |          the first level containing the names of the `endog` variables and\n",
      "     |          the second level containing the repetition number.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      impulse_responses\n",
      "     |          Impulse response functions\n",
      "     |  \n",
      "     |  simulation_smoother(self, simulation_output=None, **kwargs)\n",
      "     |      Retrieve a simulation smoother for the state space model.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      simulation_output : int, optional\n",
      "     |          Determines which simulation smoother output is calculated.\n",
      "     |          Default is all (including state and disturbances).\n",
      "     |      **kwargs\n",
      "     |          Additional keyword arguments, used to set the simulation output.\n",
      "     |          See `set_simulation_output` for more details.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      SimulationSmoothResults\n",
      "     |  \n",
      "     |  smooth(self, params, transformed=True, includes_fixed=False, complex_step=False, cov_type=None, cov_kwds=None, return_ssm=False, results_class=None, results_wrapper_class=None, **kwargs)\n",
      "     |      Kalman smoothing\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : array_like\n",
      "     |          Array of parameters at which to evaluate the loglikelihood\n",
      "     |          function.\n",
      "     |      transformed : bool, optional\n",
      "     |          Whether or not `params` is already transformed. Default is True.\n",
      "     |      return_ssm : bool,optional\n",
      "     |          Whether or not to return only the state space output or a full\n",
      "     |          results object. Default is to return a full results object.\n",
      "     |      cov_type : str, optional\n",
      "     |          See `MLEResults.fit` for a description of covariance matrix types\n",
      "     |          for results object.\n",
      "     |      cov_kwds : dict or None, optional\n",
      "     |          See `MLEResults.get_robustcov_results` for a description required\n",
      "     |          keywords for alternative covariance estimators\n",
      "     |      **kwargs\n",
      "     |          Additional keyword arguments to pass to the Kalman filter. See\n",
      "     |          `KalmanFilter.filter` for more details.\n",
      "     |  \n",
      "     |  transform_jacobian(self, unconstrained, approx_centered=False)\n",
      "     |      Jacobian matrix for the parameter transformation function\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      unconstrained : array_like\n",
      "     |          Array of unconstrained parameters used by the optimizer.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      jacobian : ndarray\n",
      "     |          Jacobian matrix of the transformation, evaluated at `unconstrained`\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      transform_params\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      This is a numerical approximation using finite differences. Note that\n",
      "     |      in general complex step methods cannot be used because it is not\n",
      "     |      guaranteed that the `transform_params` method is a real function (e.g.\n",
      "     |      if Cholesky decomposition is used).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from statsmodels.tsa.statespace.mlemodel.MLEModel:\n",
      "     |  \n",
      "     |  from_formula(formula, data, subset=None) from builtins.type\n",
      "     |      Not implemented for state space models\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from statsmodels.tsa.statespace.mlemodel.MLEModel:\n",
      "     |  \n",
      "     |  initial_variance\n",
      "     |  \n",
      "     |  initialization\n",
      "     |  \n",
      "     |  loglikelihood_burn\n",
      "     |  \n",
      "     |  tolerance\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from statsmodels.tsa.base.tsa_model.TimeSeriesModel:\n",
      "     |  \n",
      "     |  exog_names\n",
      "     |      The names of the exogenous variables.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from statsmodels.base.model.LikelihoodModel:\n",
      "     |  \n",
      "     |  information(self, params)\n",
      "     |      Fisher information matrix of model.\n",
      "     |      \n",
      "     |      Returns -1 * Hessian of the log-likelihood evaluated at params.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : ndarray\n",
      "     |          The model parameters.\n",
      "     |  \n",
      "     |  initialize(self)\n",
      "     |      Initialize (possibly re-initialize) a Model instance.\n",
      "     |      \n",
      "     |      For example, if the the design matrix of a linear model changes then\n",
      "     |      initialized can be used to recompute values using the modified design\n",
      "     |      matrix.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from statsmodels.base.model.Model:\n",
      "     |  \n",
      "     |  predict(self, params, exog=None, *args, **kwargs)\n",
      "     |      After a model has been fit predict returns the fitted values.\n",
      "     |      \n",
      "     |      This is a placeholder intended to be overwritten by individual models.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from statsmodels.base.model.Model:\n",
      "     |  \n",
      "     |  endog_names\n",
      "     |      Names of endogenous variables.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from statsmodels.base.model.Model:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class DynamicFactorMQ(statsmodels.tsa.statespace.mlemodel.MLEModel)\n",
      "     |  DynamicFactorMQ(endog, k_endog_monthly=None, factors=1, factor_orders=1, factor_multiplicities=None, idiosyncratic_ar1=True, standardize=True, endog_quarterly=None, init_t0=False, obs_cov_diag=False, **kwargs)\n",
      "     |  \n",
      "     |  Dynamic factor model with EM algorithm; option for monthly/quarterly data.\n",
      "     |  \n",
      "     |  Implementation of the dynamic factor model of Babura and Modugno (2014)\n",
      "     |  ([1]_) and Babura, Giannone, and Reichlin (2011) ([2]_). Uses the EM\n",
      "     |  algorithm for parameter fitting, and so can accommodate a large number of\n",
      "     |  left-hand-side variables. Specifications can include any collection of\n",
      "     |  blocks of factors, including different factor autoregression orders, and\n",
      "     |  can include AR(1) processes for idiosyncratic disturbances. Can\n",
      "     |  incorporate monthly/quarterly mixed frequency data along the lines of\n",
      "     |  Mariano and Murasawa (2011) ([4]_). A special case of this model is the\n",
      "     |  Nowcasting model of Bok et al. (2017) ([3]_). Moreover, this model can be\n",
      "     |  used to compute the news associated with updated data releases.\n",
      "     |  \n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  endog : array_like\n",
      "     |      Observed time-series process :math:`y`. See the \"Notes\" section for\n",
      "     |      details on how to set up a model with monthly/quarterly mixed frequency\n",
      "     |      data.\n",
      "     |  k_endog_monthly : int, optional\n",
      "     |      If specifying a monthly/quarterly mixed frequency model in which the\n",
      "     |      provided `endog` dataset contains both the monthly and quarterly data,\n",
      "     |      this variable should be used to indicate how many of the variables\n",
      "     |      are monthly. Note that when using the `k_endog_monthly` argument, the\n",
      "     |      columns with monthly variables in `endog` should be ordered first, and\n",
      "     |      the columns with quarterly variables should come afterwards. See the\n",
      "     |      \"Notes\" section for details on how to set up a model with\n",
      "     |      monthly/quarterly mixed frequency data.\n",
      "     |  factors : int, list, or dict, optional\n",
      "     |      Integer giving the number of (global) factors, a list with the names of\n",
      "     |      (global) factors, or a dictionary with:\n",
      "     |  \n",
      "     |      - keys : names of endogenous variables\n",
      "     |      - values : lists of factor names.\n",
      "     |  \n",
      "     |      If this is an integer, then the factor names will be 0, 1, .... The\n",
      "     |      default is a single factor that loads on all variables. Note that there\n",
      "     |      cannot be more factors specified than there are monthly variables.\n",
      "     |  factor_orders : int or dict, optional\n",
      "     |      Integer describing the order of the vector autoregression (VAR)\n",
      "     |      governing all factor block dynamics or dictionary with:\n",
      "     |  \n",
      "     |      - keys : factor name or tuples of factor names in a block\n",
      "     |      - values : integer describing the VAR order for that factor block\n",
      "     |  \n",
      "     |      If a dictionary, this defines the order of the factor blocks in the\n",
      "     |      state vector. Otherwise, factors are ordered so that factors that load\n",
      "     |      on more variables come first (and then alphabetically, to break ties).\n",
      "     |  factor_multiplicities : int or dict, optional\n",
      "     |      This argument provides a convenient way to specify multiple factors\n",
      "     |      that load identically on variables. For example, one may want two\n",
      "     |      \"global\" factors (factors that load on all variables) that evolve\n",
      "     |      jointly according to a VAR. One could specify two global factors in the\n",
      "     |      `factors` argument and specify that they are in the same block in the\n",
      "     |      `factor_orders` argument, but it is easier to specify a single global\n",
      "     |      factor in the `factors` argument, and set the order in the\n",
      "     |      `factor_orders` argument, and then set the factor multiplicity to 2.\n",
      "     |  \n",
      "     |      This argument must be an integer describing the factor multiplicity for\n",
      "     |      all factors or dictionary with:\n",
      "     |  \n",
      "     |      - keys : factor name\n",
      "     |      - values : integer describing the factor multiplicity for the factors\n",
      "     |        in the given block\n",
      "     |  \n",
      "     |  idiosyncratic_ar1 : bool\n",
      "     |      Whether or not to model the idiosyncratic component for each series as\n",
      "     |      an AR(1) process. If False, the idiosyncratic component is instead\n",
      "     |      modeled as white noise.\n",
      "     |  standardize : bool or tuple, optional\n",
      "     |      If a boolean, whether or not to standardize each endogenous variable to\n",
      "     |      have mean zero and standard deviation 1 before fitting the model. See\n",
      "     |      \"Notes\" for details about how this option works with postestimation\n",
      "     |      output. If a tuple (usually only used internally), then the tuple must\n",
      "     |      have length 2, with each element containing a Pandas series with index\n",
      "     |      equal to the names of the endogenous variables. The first element\n",
      "     |      should contain the mean values and the second element should contain\n",
      "     |      the standard deviations. Default is True.\n",
      "     |  endog_quarterly : pandas.Series or pandas.DataFrame\n",
      "     |      Observed quarterly variables. If provided, must be a Pandas Series or\n",
      "     |      DataFrame with a DatetimeIndex or PeriodIndex at the quarterly\n",
      "     |      frequency. See the \"Notes\" section for details on how to set up a model\n",
      "     |      with monthly/quarterly mixed frequency data.\n",
      "     |  init_t0 : bool, optional\n",
      "     |      If True, this option initializes the Kalman filter with the\n",
      "     |      distribution for :math:`\\alpha_0` rather than :math:`\\alpha_1`. See\n",
      "     |      the \"Notes\" section for more details. This option is rarely used except\n",
      "     |      for testing. Default is False.\n",
      "     |  obs_cov_diag : bool, optional\n",
      "     |      If True and if `idiosyncratic_ar1 is True`, then this option puts small\n",
      "     |      positive values in the observation disturbance covariance matrix. This\n",
      "     |      is not required for estimation and is rarely used except for testing.\n",
      "     |      (It is sometimes used to prevent numerical errors, for example those\n",
      "     |      associated with a positive semi-definite forecast error covariance\n",
      "     |      matrix at the first time step when using EM initialization, but state\n",
      "     |      space models in Statsmodels switch to the univariate approach in those\n",
      "     |      cases, and so do not need to use this trick). Default is False.\n",
      "     |  \n",
      "     |  Notes\n",
      "     |  -----\n",
      "     |  The basic model is:\n",
      "     |  \n",
      "     |  .. math::\n",
      "     |  \n",
      "     |      y_t & = \\Lambda f_t + \\epsilon_t \\\\\n",
      "     |      f_t & = A_1 f_{t-1} + \\dots + A_p f_{t-p} + u_t\n",
      "     |  \n",
      "     |  where:\n",
      "     |  \n",
      "     |  - :math:`y_t` is observed data at time t\n",
      "     |  - :math:`\\epsilon_t` is idiosyncratic disturbance at time t (see below for\n",
      "     |    details, including modeling serial correlation in this term)\n",
      "     |  - :math:`f_t` is the unobserved factor at time t\n",
      "     |  - :math:`u_t \\sim N(0, Q)` is the factor disturbance at time t\n",
      "     |  \n",
      "     |  and:\n",
      "     |  \n",
      "     |  - :math:`\\Lambda` is referred to as the matrix of factor loadings\n",
      "     |  - :math:`A_i` are matrices of autoregression coefficients\n",
      "     |  \n",
      "     |  Furthermore, we allow the idiosyncratic disturbances to be serially\n",
      "     |  correlated, so that, if `idiosyncratic_ar1=True`,\n",
      "     |  :math:`\\epsilon_{i,t} = \\rho_i \\epsilon_{i,t-1} + e_{i,t}`, where\n",
      "     |  :math:`e_{i,t} \\sim N(0, \\sigma_i^2)`. If `idiosyncratic_ar1=False`,\n",
      "     |  then we instead have :math:`\\epsilon_{i,t} = e_{i,t}`.\n",
      "     |  \n",
      "     |  This basic setup can be found in [1]_, [2]_, [3]_, and [4]_.\n",
      "     |  \n",
      "     |  We allow for two generalizations of this model:\n",
      "     |  \n",
      "     |  1. Following [2]_, we allow multiple \"blocks\" of factors, which are\n",
      "     |     independent from the other blocks of factors. Different blocks can be\n",
      "     |     set to load on different subsets of the observed variables, and can be\n",
      "     |     specified with different lag orders.\n",
      "     |  2. Following [4]_ and [2]_, we allow mixed frequency models in which both\n",
      "     |     monthly and quarterly data are used. See the section on \"Mixed frequency\n",
      "     |     models\", below, for more details.\n",
      "     |  \n",
      "     |  Additional notes:\n",
      "     |  \n",
      "     |  - The observed data may contain arbitrary patterns of missing entries.\n",
      "     |  \n",
      "     |  **EM algorithm**\n",
      "     |  \n",
      "     |  This model contains a potentially very large number of parameters, and it\n",
      "     |  can be difficult and take a prohibitively long time to numerically optimize\n",
      "     |  the likelihood function using quasi-Newton methods. Instead, the default\n",
      "     |  fitting method in this model uses the EM algorithm, as detailed in [1]_.\n",
      "     |  As a result, the model can accommodate datasets with hundreds of\n",
      "     |  observed variables.\n",
      "     |  \n",
      "     |  **Mixed frequency data**\n",
      "     |  \n",
      "     |  This model can handle mixed frequency data in two ways. In this section,\n",
      "     |  we only briefly describe this, and refer readers to [2]_ and [4]_ for all\n",
      "     |  details.\n",
      "     |  \n",
      "     |  First, because there can be arbitrary patterns of missing data in the\n",
      "     |  observed vector, one can simply include lower frequency variables as\n",
      "     |  observed in a particular higher frequency period, and missing otherwise.\n",
      "     |  For example, in a monthly model, one could include quarterly data as\n",
      "     |  occurring on the third month of each quarter. To use this method, one\n",
      "     |  simply needs to combine the data into a single dataset at the higher\n",
      "     |  frequency that can be passed to this model as the `endog` argument.\n",
      "     |  However, depending on the type of variables used in the analysis and the\n",
      "     |  assumptions about the data generating process, this approach may not be\n",
      "     |  valid.\n",
      "     |  \n",
      "     |  For example, suppose that we are interested in the growth rate of real GDP,\n",
      "     |  which is measured at a quarterly frequency. If the basic factor model is\n",
      "     |  specified at a monthly frequency, then the quarterly growth rate in the\n",
      "     |  third month of each quarter -- which is what we actually observe -- is\n",
      "     |  approximated by a particular weighted average of unobserved monthly growth\n",
      "     |  rates. We need to take this particular weight moving average into account\n",
      "     |  in constructing our model, and this is what the second approach does.\n",
      "     |  \n",
      "     |  The second approach follows [2]_ and [4]_ in constructing a state space\n",
      "     |  form to explicitly model the quarterly growth rates in terms of the\n",
      "     |  unobserved monthly growth rates. To use this approach, there are two\n",
      "     |  methods:\n",
      "     |  \n",
      "     |  1. Combine the monthly and quarterly data into a single dataset at the\n",
      "     |     monthly frequency, with the monthly data in the first columns and the\n",
      "     |     quarterly data in the last columns. Pass this dataset to the model as\n",
      "     |     the `endog` argument and give the number of the variables that are\n",
      "     |     monthly as the `k_endog_monthly` argument.\n",
      "     |  2. Construct a monthly dataset as a Pandas DataFrame with a DatetimeIndex\n",
      "     |     or PeriodIndex at the monthly frequency and separately construct a\n",
      "     |     quarterly dataset as a Pandas DataFrame with a DatetimeIndex or\n",
      "     |     PeriodIndex at the quarterly frequency. Pass the monthly DataFrame to\n",
      "     |     the model as the `endog` argument and pass the quarterly DataFrame to\n",
      "     |     the model as the `endog_quarterly` argument.\n",
      "     |  \n",
      "     |  Note that this only incorporates one particular type of mixed frequency\n",
      "     |  data. See also Banbura et al. (2013). \"Now-Casting and the Real-Time Data\n",
      "     |  Flow.\" for discussion about other types of mixed frequency data that are\n",
      "     |  not supported by this framework.\n",
      "     |  \n",
      "     |  **Nowcasting and the news**\n",
      "     |  \n",
      "     |  Through its support for monthly/quarterly mixed frequency data, this model\n",
      "     |  can allow for the nowcasting of quarterly variables based on monthly\n",
      "     |  observations. In particular, [2]_ and [3]_ use this model to construct\n",
      "     |  nowcasts of real GDP and analyze the impacts of \"the news\", derived from\n",
      "     |  incoming data on a real-time basis. This latter functionality can be\n",
      "     |  accessed through the `news` method of the results object.\n",
      "     |  \n",
      "     |  **Standardizing data**\n",
      "     |  \n",
      "     |  As is often the case in formulating a dynamic factor model, we do not\n",
      "     |  explicitly account for the mean of each observed variable. Instead, the\n",
      "     |  default behavior is to standardize each variable prior to estimation. Thus\n",
      "     |  if :math:`y_t` are the given observed data, the dynamic factor model is\n",
      "     |  actually estimated on the standardized data defined by:\n",
      "     |  \n",
      "     |  .. math::\n",
      "     |  \n",
      "     |      x_{i, t} = (y_{i, t} - \\bar y_i) / s_i\n",
      "     |  \n",
      "     |  where :math:`\\bar y_i` is the sample mean and :math:`s_i` is the sample\n",
      "     |  standard deviation.\n",
      "     |  \n",
      "     |  By default, if standardization is applied prior to estimation, results such\n",
      "     |  as in-sample predictions, out-of-sample forecasts, and the computation of\n",
      "     |  the \"news\"  are reported in the scale of the original data (i.e. the model\n",
      "     |  output has the reverse transformation applied before it is returned to the\n",
      "     |  user).\n",
      "     |  \n",
      "     |  Standardization can be disabled by passing `standardization=False` to the\n",
      "     |  model constructor.\n",
      "     |  \n",
      "     |  **Identification of factors and loadings**\n",
      "     |  \n",
      "     |  The estimated factors and the factor loadings in this model are only\n",
      "     |  identified up to an invertible transformation. As described in (the working\n",
      "     |  paper version of) [2]_, while it is possible to impose normalizations to\n",
      "     |  achieve identification, the EM algorithm does will converge regardless.\n",
      "     |  Moreover, for nowcasting and forecasting purposes, identification is not\n",
      "     |  required. This model does not impose any normalization to identify the\n",
      "     |  factors and the factor loadings.\n",
      "     |  \n",
      "     |  **Miscellaneous**\n",
      "     |  \n",
      "     |  There are two arguments available in the model constructor that are rarely\n",
      "     |  used but which deserve a brief mention: `init_t0` and `obs_cov_diag`. These\n",
      "     |  arguments are provided to allow exactly matching the output of other\n",
      "     |  packages that have slight differences in how the underlying state space\n",
      "     |  model is set up / applied.\n",
      "     |  \n",
      "     |  - `init_t0`: state space models in Statsmodels follow Durbin and Koopman in\n",
      "     |    initializing the model with :math:`\\alpha_1 \\sim N(a_1, P_1)`. Other\n",
      "     |    implementations sometimes initialize instead with\n",
      "     |    :math:`\\alpha_0 \\sim N(a_0, P_0)`. We can accommodate this by prepending\n",
      "     |    a row of NaNs to the observed dataset.\n",
      "     |  - `obs_cov_diag`: the state space form in [1]_ incorporates non-zero (but\n",
      "     |    very small) diagonal elements for the observation disturbance covariance\n",
      "     |    matrix.\n",
      "     |  \n",
      "     |  Examples\n",
      "     |  --------\n",
      "     |  Constructing and fitting a `DynamicFactorMQ` model.\n",
      "     |  \n",
      "     |  >>> data = sm.datasets.macrodata.load_pandas().data.iloc[-100:]\n",
      "     |  >>> data.index = pd.period_range(start='1984Q4', end='2009Q3', freq='Q')\n",
      "     |  >>> endog = data[['infl', 'tbilrate']].resample('M').last()\n",
      "     |  >>> endog_Q = np.log(data[['realgdp', 'realcons']]).diff().iloc[1:] * 400\n",
      "     |  \n",
      "     |  **Basic usage**\n",
      "     |  \n",
      "     |  In the simplest case, passing only the `endog` argument results in a model\n",
      "     |  with a single factor that follows an AR(1) process. Note that because we\n",
      "     |  are not also providing an `endog_quarterly` dataset, `endog` can be a numpy\n",
      "     |  array or Pandas DataFrame with any index (it does not have to be monthly).\n",
      "     |  \n",
      "     |  The `summary` method can be useful in checking the model specification.\n",
      "     |  \n",
      "     |  >>> mod = sm.tsa.DynamicFactorMQ(endog)\n",
      "     |  >>> print(mod.summary())\n",
      "     |                      Model Specification: Dynamic Factor Model\n",
      "     |  ==========================================================================\n",
      "     |  Model:         Dynamic Factor Model   # of monthly variables:          2\n",
      "     |              + 1 factors in 1 blocks   # of factors:                    1\n",
      "     |                + AR(1) idiosyncratic   Idiosyncratic disturbances:  AR(1)\n",
      "     |  Sample:                     1984-10   Standardize variables:        True\n",
      "     |                            - 2009-09\n",
      "     |  Observed variables / factor loadings\n",
      "     |  ========================\n",
      "     |  Dep. variable          0\n",
      "     |  ------------------------\n",
      "     |           infl          X\n",
      "     |       tbilrate          X\n",
      "     |      Factor blocks:\n",
      "     |  =====================\n",
      "     |       block      order\n",
      "     |  ---------------------\n",
      "     |           0          1\n",
      "     |  =====================\n",
      "     |  \n",
      "     |  **Factors**\n",
      "     |  \n",
      "     |  With `factors=2`, there will be two independent factors that will each\n",
      "     |  evolve according to separate AR(1) processes.\n",
      "     |  \n",
      "     |  >>> mod = sm.tsa.DynamicFactorMQ(endog, factors=2)\n",
      "     |  >>> print(mod.summary())\n",
      "     |                      Model Specification: Dynamic Factor Model\n",
      "     |  ==========================================================================\n",
      "     |  Model:         Dynamic Factor Model   # of monthly variables:          2\n",
      "     |              + 2 factors in 2 blocks   # of factors:                    2\n",
      "     |                + AR(1) idiosyncratic   Idiosyncratic disturbances:  AR(1)\n",
      "     |  Sample:                     1984-10   Standardize variables:        True\n",
      "     |                            - 2009-09\n",
      "     |  Observed variables / factor loadings\n",
      "     |  ===================================\n",
      "     |  Dep. variable          0          1\n",
      "     |  -----------------------------------\n",
      "     |           infl          X          X\n",
      "     |       tbilrate          X          X\n",
      "     |      Factor blocks:\n",
      "     |  =====================\n",
      "     |       block      order\n",
      "     |  ---------------------\n",
      "     |           0          1\n",
      "     |           1          1\n",
      "     |  =====================\n",
      "     |  \n",
      "     |  **Factor multiplicities**\n",
      "     |  \n",
      "     |  By instead specifying `factor_multiplicities=2`, we would still have two\n",
      "     |  factors, but they would be dependent and would evolve jointly according\n",
      "     |  to a VAR(1) process.\n",
      "     |  \n",
      "     |  >>> mod = sm.tsa.DynamicFactorMQ(endog, factor_multiplicities=2)\n",
      "     |  >>> print(mod.summary())\n",
      "     |                      Model Specification: Dynamic Factor Model\n",
      "     |  ==========================================================================\n",
      "     |  Model:         Dynamic Factor Model   # of monthly variables:          2\n",
      "     |              + 2 factors in 1 blocks   # of factors:                    2\n",
      "     |                + AR(1) idiosyncratic   Idiosyncratic disturbances:  AR(1)\n",
      "     |  Sample:                     1984-10   Standardize variables:        True\n",
      "     |                            - 2009-09\n",
      "     |  Observed variables / factor loadings\n",
      "     |  ===================================\n",
      "     |  Dep. variable        0.1        0.2\n",
      "     |  -----------------------------------\n",
      "     |           infl         X          X\n",
      "     |       tbilrate         X          X\n",
      "     |      Factor blocks:\n",
      "     |  =====================\n",
      "     |       block      order\n",
      "     |  ---------------------\n",
      "     |    0.1, 0.2          1\n",
      "     |  =====================\n",
      "     |  \n",
      "     |  **Factor orders**\n",
      "     |  \n",
      "     |  In either of the above cases, we could extend the order of the (vector)\n",
      "     |  autoregressions by using the `factor_orders` argument. For example, the\n",
      "     |  below model would contain two independent factors that each evolve\n",
      "     |  according to a separate AR(2) process:\n",
      "     |  \n",
      "     |  >>> mod = sm.tsa.DynamicFactorMQ(endog, factors=2, factor_orders=2)\n",
      "     |  >>> print(mod.summary())\n",
      "     |                      Model Specification: Dynamic Factor Model\n",
      "     |  ==========================================================================\n",
      "     |  Model:         Dynamic Factor Model   # of monthly variables:          2\n",
      "     |              + 2 factors in 2 blocks   # of factors:                    2\n",
      "     |                + AR(1) idiosyncratic   Idiosyncratic disturbances:  AR(1)\n",
      "     |  Sample:                     1984-10   Standardize variables:        True\n",
      "     |                            - 2009-09\n",
      "     |  Observed variables / factor loadings\n",
      "     |  ===================================\n",
      "     |  Dep. variable          0          1\n",
      "     |  -----------------------------------\n",
      "     |           infl          X          X\n",
      "     |       tbilrate          X          X\n",
      "     |      Factor blocks:\n",
      "     |  =====================\n",
      "     |       block      order\n",
      "     |  ---------------------\n",
      "     |           0          2\n",
      "     |           1          2\n",
      "     |  =====================\n",
      "     |  \n",
      "     |  **Serial correlation in the idiosyncratic disturbances**\n",
      "     |  \n",
      "     |  By default, the model allows each idiosyncratic disturbance terms to evolve\n",
      "     |  according to an AR(1) process. If preferred, they can instead be specified\n",
      "     |  to be serially independent by passing `ididosyncratic_ar1=False`.\n",
      "     |  \n",
      "     |  >>> mod = sm.tsa.DynamicFactorMQ(endog, idiosyncratic_ar1=False)\n",
      "     |  >>> print(mod.summary())\n",
      "     |                      Model Specification: Dynamic Factor Model\n",
      "     |  ==========================================================================\n",
      "     |  Model:         Dynamic Factor Model   # of monthly variables:          2\n",
      "     |              + 1 factors in 1 blocks   # of factors:                    1\n",
      "     |                  + iid idiosyncratic   Idiosyncratic disturbances:    iid\n",
      "     |  Sample:                     1984-10   Standardize variables:        True\n",
      "     |                            - 2009-09\n",
      "     |  Observed variables / factor loadings\n",
      "     |  ========================\n",
      "     |  Dep. variable          0\n",
      "     |  ------------------------\n",
      "     |           infl          X\n",
      "     |       tbilrate          X\n",
      "     |      Factor blocks:\n",
      "     |  =====================\n",
      "     |       block      order\n",
      "     |  ---------------------\n",
      "     |           0          1\n",
      "     |  =====================\n",
      "     |  \n",
      "     |  *Monthly / Quarterly mixed frequency*\n",
      "     |  \n",
      "     |  To specify a monthly / quarterly mixed frequency model see the (Notes\n",
      "     |  section for more details about these models):\n",
      "     |  \n",
      "     |  >>> mod = sm.tsa.DynamicFactorMQ(endog, endog_quarterly=endog_Q)\n",
      "     |  >>> print(mod.summary())\n",
      "     |                      Model Specification: Dynamic Factor Model\n",
      "     |  ==========================================================================\n",
      "     |  Model:         Dynamic Factor Model   # of monthly variables:          2\n",
      "     |              + 1 factors in 1 blocks   # of quarterly variables:        2\n",
      "     |              + Mixed frequency (M/Q)   # of factors:                    1\n",
      "     |                + AR(1) idiosyncratic   Idiosyncratic disturbances:  AR(1)\n",
      "     |  Sample:                     1984-10   Standardize variables:        True\n",
      "     |                            - 2009-09\n",
      "     |  Observed variables / factor loadings\n",
      "     |  ========================\n",
      "     |  Dep. variable          0\n",
      "     |  ------------------------\n",
      "     |           infl          X\n",
      "     |       tbilrate          X\n",
      "     |        realgdp          X\n",
      "     |       realcons          X\n",
      "     |      Factor blocks:\n",
      "     |  =====================\n",
      "     |       block      order\n",
      "     |  ---------------------\n",
      "     |           0          1\n",
      "     |  =====================\n",
      "     |  \n",
      "     |  *Customize observed variable / factor loadings*\n",
      "     |  \n",
      "     |  To specify that certain that certain observed variables only load on\n",
      "     |  certain factors, it is possible to pass a dictionary to the `factors`\n",
      "     |  argument.\n",
      "     |  \n",
      "     |  >>> factors = {'infl': ['global']\n",
      "     |  ...            'tbilrate': ['global']\n",
      "     |  ...            'realgdp': ['global', 'real']\n",
      "     |  ...            'realcons': ['global', 'real']}\n",
      "     |  >>> mod = sm.tsa.DynamicFactorMQ(endog, endog_quarterly=endog_Q)\n",
      "     |  >>> print(mod.summary())\n",
      "     |                      Model Specification: Dynamic Factor Model\n",
      "     |  ==========================================================================\n",
      "     |  Model:         Dynamic Factor Model   # of monthly variables:          2\n",
      "     |              + 2 factors in 2 blocks   # of quarterly variables:        2\n",
      "     |              + Mixed frequency (M/Q)   # of factor blocks:              2\n",
      "     |                + AR(1) idiosyncratic   Idiosyncratic disturbances:  AR(1)\n",
      "     |  Sample:                     1984-10   Standardize variables:        True\n",
      "     |                            - 2009-09\n",
      "     |  Observed variables / factor loadings\n",
      "     |  ===================================\n",
      "     |  Dep. variable     global       real\n",
      "     |  -----------------------------------\n",
      "     |           infl       X\n",
      "     |       tbilrate       X\n",
      "     |        realgdp       X           X\n",
      "     |       realcons       X           X\n",
      "     |      Factor blocks:\n",
      "     |  =====================\n",
      "     |       block      order\n",
      "     |  ---------------------\n",
      "     |      global          1\n",
      "     |        real          1\n",
      "     |  =====================\n",
      "     |  \n",
      "     |  **Fitting parameters**\n",
      "     |  \n",
      "     |  To fit the model, use the `fit` method. This method uses the EM algorithm\n",
      "     |  by default.\n",
      "     |  \n",
      "     |  >>> mod = sm.tsa.DynamicFactorMQ(endog)\n",
      "     |  >>> res = mod.fit()\n",
      "     |  >>> print(res.summary())\n",
      "     |                            Dynamic Factor Results\n",
      "     |  ==========================================================================\n",
      "     |  Dep. Variable:      ['infl', 'tbilrate']   No. Observations:         300\n",
      "     |  Model:              Dynamic Factor Model   Log Likelihood       -127.909\n",
      "     |                   + 1 factors in 1 blocks   AIC                   271.817\n",
      "     |                     + AR(1) idiosyncratic   BIC                   301.447\n",
      "     |  Date:                   Tue, 04 Aug 2020   HQIC                  283.675\n",
      "     |  Time:                           15:59:11   EM Iterations              83\n",
      "     |  Sample:                       10-31-1984\n",
      "     |                              - 09-30-2009\n",
      "     |  Covariance Type:            Not computed\n",
      "     |                      Observation equation:\n",
      "     |  ==============================================================\n",
      "     |  Factor loadings:          0    idiosyncratic: AR(1)       var.\n",
      "     |  --------------------------------------------------------------\n",
      "     |              infl      -0.67                    0.39       0.73\n",
      "     |          tbilrate      -0.63                    0.99       0.01\n",
      "     |         Transition: Factor block 0\n",
      "     |  =======================================\n",
      "     |                   L1.0    error variance\n",
      "     |  ---------------------------------------\n",
      "     |           0       0.98              0.01\n",
      "     |  =======================================\n",
      "     |  Warnings:\n",
      "     |  [1] Covariance matrix not calculated.\n",
      "     |  \n",
      "     |  *Displaying iteration progress*\n",
      "     |  \n",
      "     |  To display information about the EM iterations, use the `disp` argument.\n",
      "     |  \n",
      "     |  >>> mod = sm.tsa.DynamicFactorMQ(endog)\n",
      "     |  >>> res = mod.fit(disp=10)\n",
      "     |  EM start iterations, llf=-291.21\n",
      "     |  EM iteration 10, llf=-157.17, convergence criterion=0.053801\n",
      "     |  EM iteration 20, llf=-128.99, convergence criterion=0.0035545\n",
      "     |  EM iteration 30, llf=-127.97, convergence criterion=0.00010224\n",
      "     |  EM iteration 40, llf=-127.93, convergence criterion=1.3281e-05\n",
      "     |  EM iteration 50, llf=-127.92, convergence criterion=5.4725e-06\n",
      "     |  EM iteration 60, llf=-127.91, convergence criterion=2.8665e-06\n",
      "     |  EM iteration 70, llf=-127.91, convergence criterion=1.6999e-06\n",
      "     |  EM iteration 80, llf=-127.91, convergence criterion=1.1085e-06\n",
      "     |  EM converged at iteration 83, llf=-127.91,\n",
      "     |     convergence criterion=9.9004e-07 < tolerance=1e-06\n",
      "     |  \n",
      "     |  **Results: forecasting, impulse responses, and more**\n",
      "     |  \n",
      "     |  One the model is fitted, there are a number of methods available from the\n",
      "     |  results object. Some examples include:\n",
      "     |  \n",
      "     |  *Forecasting*\n",
      "     |  \n",
      "     |  >>> mod = sm.tsa.DynamicFactorMQ(endog)\n",
      "     |  >>> res = mod.fit()\n",
      "     |  >>> print(res.forecast(steps=5))\n",
      "     |               infl  tbilrate\n",
      "     |  2009-10  1.784169  0.260401\n",
      "     |  2009-11  1.735848  0.305981\n",
      "     |  2009-12  1.730674  0.350968\n",
      "     |  2010-01  1.742110  0.395369\n",
      "     |  2010-02  1.759786  0.439194\n",
      "     |  \n",
      "     |  *Impulse responses*\n",
      "     |  \n",
      "     |  >>> mod = sm.tsa.DynamicFactorMQ(endog)\n",
      "     |  >>> res = mod.fit()\n",
      "     |  >>> print(res.impulse_responses(steps=5))\n",
      "     |         infl  tbilrate\n",
      "     |  0 -1.511956 -1.341498\n",
      "     |  1 -1.483172 -1.315960\n",
      "     |  2 -1.454937 -1.290908\n",
      "     |  3 -1.427240 -1.266333\n",
      "     |  4 -1.400069 -1.242226\n",
      "     |  5 -1.373416 -1.218578\n",
      "     |  \n",
      "     |  For other available methods (including in-sample prediction, simulation of\n",
      "     |  time series, extending the results to incorporate new data, and the news),\n",
      "     |  see the documentation for state space models.\n",
      "     |  \n",
      "     |  References\n",
      "     |  ----------\n",
      "     |  .. [1] Babura, Marta, and Michele Modugno.\n",
      "     |         \"Maximum likelihood estimation of factor models on datasets with\n",
      "     |         arbitrary pattern of missing data.\"\n",
      "     |         Journal of Applied Econometrics 29, no. 1 (2014): 133-160.\n",
      "     |  .. [2] Babura, Marta, Domenico Giannone, and Lucrezia Reichlin.\n",
      "     |         \"Nowcasting.\"\n",
      "     |         The Oxford Handbook of Economic Forecasting. July 8, 2011.\n",
      "     |  .. [3] Bok, Brandyn, Daniele Caratelli, Domenico Giannone,\n",
      "     |         Argia M. Sbordone, and Andrea Tambalotti. 2018.\n",
      "     |         \"Macroeconomic Nowcasting and Forecasting with Big Data.\"\n",
      "     |         Annual Review of Economics 10 (1): 615-43.\n",
      "     |         https://doi.org/10.1146/annurev-economics-080217-053214.\n",
      "     |  .. [4] Mariano, Roberto S., and Yasutomo Murasawa.\n",
      "     |         \"A coincident index, common factors, and monthly real GDP.\"\n",
      "     |         Oxford Bulletin of Economics and Statistics 72, no. 1 (2010): 27-46.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      DynamicFactorMQ\n",
      "     |      statsmodels.tsa.statespace.mlemodel.MLEModel\n",
      "     |      statsmodels.tsa.base.tsa_model.TimeSeriesModel\n",
      "     |      statsmodels.base.model.LikelihoodModel\n",
      "     |      statsmodels.base.model.Model\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, endog, k_endog_monthly=None, factors=1, factor_orders=1, factor_multiplicities=None, idiosyncratic_ar1=True, standardize=True, endog_quarterly=None, init_t0=False, obs_cov_diag=False, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __str__(self)\n",
      "     |      Summary tables showing model specification.\n",
      "     |  \n",
      "     |  clone(self, endog, k_endog_monthly=None, endog_quarterly=None, retain_standardization=False, **kwargs)\n",
      "     |      Clone state space model with new data and optionally new specification.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      endog : array_like\n",
      "     |          The observed time-series process :math:`y`\n",
      "     |      k_endog_monthly : int, optional\n",
      "     |          If specifying a monthly/quarterly mixed frequency model in which\n",
      "     |          the provided `endog` dataset contains both the monthly and\n",
      "     |          quarterly data, this variable should be used to indicate how many\n",
      "     |          of the variables are monthly.\n",
      "     |      endog_quarterly : array_like, optional\n",
      "     |          Observations of quarterly variables. If provided, must be a\n",
      "     |          Pandas Series or DataFrame with a DatetimeIndex or PeriodIndex at\n",
      "     |          the quarterly frequency.\n",
      "     |      kwargs\n",
      "     |          Keyword arguments to pass to the new model class to change the\n",
      "     |          model specification.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      model : DynamicFactorMQ instance\n",
      "     |  \n",
      "     |  filter(self, params, transformed=True, includes_fixed=False, complex_step=False, cov_type='none', cov_kwds=None, return_ssm=False, results_class=None, results_wrapper_class=None, low_memory=False, **kwargs)\n",
      "     |      Kalman filtering.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : array_like\n",
      "     |          Array of parameters at which to evaluate the loglikelihood\n",
      "     |          function.\n",
      "     |      transformed : bool, optional\n",
      "     |          Whether or not `params` is already transformed. Default is True.\n",
      "     |      return_ssm : bool,optional\n",
      "     |          Whether or not to return only the state space output or a full\n",
      "     |          results object. Default is to return a full results object.\n",
      "     |      cov_type : str, optional\n",
      "     |          See `MLEResults.fit` for a description of covariance matrix types\n",
      "     |          for results object. Default is 'none'.\n",
      "     |      cov_kwds : dict or None, optional\n",
      "     |          See `MLEResults.get_robustcov_results` for a description required\n",
      "     |          keywords for alternative covariance estimators\n",
      "     |      low_memory : bool, optional\n",
      "     |          If set to True, techniques are applied to substantially reduce\n",
      "     |          memory usage. If used, some features of the results object will\n",
      "     |          not be available (including in-sample prediction), although\n",
      "     |          out-of-sample forecasting is possible. Default is False.\n",
      "     |      **kwargs\n",
      "     |          Additional keyword arguments to pass to the Kalman filter. See\n",
      "     |          `KalmanFilter.filter` for more details.\n",
      "     |  \n",
      "     |  fit(self, start_params=None, transformed=True, includes_fixed=False, cov_type='none', cov_kwds=None, method='em', maxiter=500, tolerance=1e-06, em_initialization=True, mstep_method=None, full_output=1, disp=False, callback=None, return_params=False, optim_score=None, optim_complex_step=None, optim_hessian=None, flags=None, low_memory=False, llf_decrease_action='revert', llf_decrease_tolerance=0.0001, **kwargs)\n",
      "     |      Fits the model by maximum likelihood via Kalman filter.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      start_params : array_like, optional\n",
      "     |          Initial guess of the solution for the loglikelihood maximization.\n",
      "     |          If None, the default is given by Model.start_params.\n",
      "     |      transformed : bool, optional\n",
      "     |          Whether or not `start_params` is already transformed. Default is\n",
      "     |          True.\n",
      "     |      includes_fixed : bool, optional\n",
      "     |          If parameters were previously fixed with the `fix_params` method,\n",
      "     |          this argument describes whether or not `start_params` also includes\n",
      "     |          the fixed parameters, in addition to the free parameters. Default\n",
      "     |          is False.\n",
      "     |      cov_type : str, optional\n",
      "     |          The `cov_type` keyword governs the method for calculating the\n",
      "     |          covariance matrix of parameter estimates. Can be one of:\n",
      "     |      \n",
      "     |          - 'opg' for the outer product of gradient estimator\n",
      "     |          - 'oim' for the observed information matrix estimator, calculated\n",
      "     |            using the method of Harvey (1989)\n",
      "     |          - 'approx' for the observed information matrix estimator,\n",
      "     |            calculated using a numerical approximation of the Hessian matrix.\n",
      "     |          - 'robust' for an approximate (quasi-maximum likelihood) covariance\n",
      "     |            matrix that may be valid even in the presence of some\n",
      "     |            misspecifications. Intermediate calculations use the 'oim'\n",
      "     |            method.\n",
      "     |          - 'robust_approx' is the same as 'robust' except that the\n",
      "     |            intermediate calculations use the 'approx' method.\n",
      "     |          - 'none' for no covariance matrix calculation.\n",
      "     |      \n",
      "     |          Default is 'none', since computing this matrix can be very slow\n",
      "     |          when there are a large number of parameters.\n",
      "     |      cov_kwds : dict or None, optional\n",
      "     |          A dictionary of arguments affecting covariance matrix computation.\n",
      "     |      \n",
      "     |          **opg, oim, approx, robust, robust_approx**\n",
      "     |      \n",
      "     |          - 'approx_complex_step' : bool, optional - If True, numerical\n",
      "     |            approximations are computed using complex-step methods. If False,\n",
      "     |            numerical approximations are computed using finite difference\n",
      "     |            methods. Default is True.\n",
      "     |          - 'approx_centered' : bool, optional - If True, numerical\n",
      "     |            approximations computed using finite difference methods use a\n",
      "     |            centered approximation. Default is False.\n",
      "     |      method : str, optional\n",
      "     |          The `method` determines which solver from `scipy.optimize`\n",
      "     |          is used, and it can be chosen from among the following strings:\n",
      "     |      \n",
      "     |          - 'em' for the EM algorithm\n",
      "     |          - 'newton' for Newton-Raphson\n",
      "     |          - 'nm' for Nelder-Mead\n",
      "     |          - 'bfgs' for Broyden-Fletcher-Goldfarb-Shanno (BFGS)\n",
      "     |          - 'lbfgs' for limited-memory BFGS with optional box constraints\n",
      "     |          - 'powell' for modified Powell's method\n",
      "     |          - 'cg' for conjugate gradient\n",
      "     |          - 'ncg' for Newton-conjugate gradient\n",
      "     |          - 'basinhopping' for global basin-hopping solver\n",
      "     |      \n",
      "     |          The explicit arguments in `fit` are passed to the solver,\n",
      "     |          with the exception of the basin-hopping solver. Each\n",
      "     |          solver has several optional arguments that are not the same across\n",
      "     |          solvers. See the notes section below (or scipy.optimize) for the\n",
      "     |          available arguments and for the list of explicit arguments that the\n",
      "     |          basin-hopping solver supports.\n",
      "     |      maxiter : int, optional\n",
      "     |          The maximum number of iterations to perform.\n",
      "     |      tolerance : float, optional\n",
      "     |          Tolerance to use for convergence checking when using the EM\n",
      "     |          algorithm. To set the tolerance for other methods, pass\n",
      "     |          the optimizer-specific keyword argument(s).\n",
      "     |      full_output : bool, optional\n",
      "     |          Set to True to have all available output in the Results object's\n",
      "     |          mle_retvals attribute. The output is dependent on the solver.\n",
      "     |          See LikelihoodModelResults notes section for more information.\n",
      "     |      disp : bool, optional\n",
      "     |          Set to True to print convergence messages.\n",
      "     |      callback : callable callback(xk), optional\n",
      "     |          Called after each iteration, as callback(xk), where xk is the\n",
      "     |          current parameter vector.\n",
      "     |      return_params : bool, optional\n",
      "     |          Whether or not to return only the array of maximizing parameters.\n",
      "     |          Default is False.\n",
      "     |      optim_score : {'harvey', 'approx'} or None, optional\n",
      "     |          The method by which the score vector is calculated. 'harvey' uses\n",
      "     |          the method from Harvey (1989), 'approx' uses either finite\n",
      "     |          difference or complex step differentiation depending upon the\n",
      "     |          value of `optim_complex_step`, and None uses the built-in gradient\n",
      "     |          approximation of the optimizer. Default is None. This keyword is\n",
      "     |          only relevant if the optimization method uses the score.\n",
      "     |      optim_complex_step : bool, optional\n",
      "     |          Whether or not to use complex step differentiation when\n",
      "     |          approximating the score; if False, finite difference approximation\n",
      "     |          is used. Default is True. This keyword is only relevant if\n",
      "     |          `optim_score` is set to 'harvey' or 'approx'.\n",
      "     |      optim_hessian : {'opg','oim','approx'}, optional\n",
      "     |          The method by which the Hessian is numerically approximated. 'opg'\n",
      "     |          uses outer product of gradients, 'oim' uses the information\n",
      "     |          matrix formula from Harvey (1989), and 'approx' uses numerical\n",
      "     |          approximation. This keyword is only relevant if the\n",
      "     |          optimization method uses the Hessian matrix.\n",
      "     |      low_memory : bool, optional\n",
      "     |          If set to True, techniques are applied to substantially reduce\n",
      "     |          memory usage. If used, some features of the results object will\n",
      "     |          not be available (including smoothed results and in-sample\n",
      "     |          prediction), although out-of-sample forecasting is possible.\n",
      "     |          Note that this option is not available when using the EM algorithm\n",
      "     |          (which is the default for this model). Default is False.\n",
      "     |      llf_decrease_action : {'ignore', 'warn', 'revert'}, optional\n",
      "     |          Action to take if the log-likelihood decreases in an EM iteration.\n",
      "     |          'ignore' continues the iterations, 'warn' issues a warning but\n",
      "     |          continues the iterations, while 'revert' ends the iterations and\n",
      "     |          returns the result from the last good iteration. Default is 'warn'.\n",
      "     |      llf_decrease_tolerance : float, optional\n",
      "     |          Minimum size of the log-likelihood decrease required to trigger a\n",
      "     |          warning or to end the EM iterations. Setting this value slightly\n",
      "     |          larger than zero allows small decreases in the log-likelihood that\n",
      "     |          may be caused by numerical issues. If set to zero, then any\n",
      "     |          decrease will trigger the `llf_decrease_action`. Default is 1e-4.\n",
      "     |      **kwargs\n",
      "     |          Additional keyword arguments to pass to the optimizer.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      MLEResults\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      statsmodels.base.model.LikelihoodModel.fit\n",
      "     |      statsmodels.tsa.statespace.mlemodel.MLEResults\n",
      "     |  \n",
      "     |  fit_em(self, start_params=None, transformed=True, cov_type='none', cov_kwds=None, maxiter=500, tolerance=1e-06, disp=False, em_initialization=True, mstep_method=None, full_output=True, return_params=False, low_memory=False, llf_decrease_action='revert', llf_decrease_tolerance=0.0001)\n",
      "     |      Fits the model by maximum likelihood via the EM algorithm.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      start_params : array_like, optional\n",
      "     |          Initial guess of the solution for the loglikelihood maximization.\n",
      "     |          The default is to use `DynamicFactorMQ.start_params`.\n",
      "     |      transformed : bool, optional\n",
      "     |          Whether or not `start_params` is already transformed. Default is\n",
      "     |          True.\n",
      "     |      cov_type : str, optional\n",
      "     |          The `cov_type` keyword governs the method for calculating the\n",
      "     |          covariance matrix of parameter estimates. Can be one of:\n",
      "     |      \n",
      "     |          - 'opg' for the outer product of gradient estimator\n",
      "     |          - 'oim' for the observed information matrix estimator, calculated\n",
      "     |            using the method of Harvey (1989)\n",
      "     |          - 'approx' for the observed information matrix estimator,\n",
      "     |            calculated using a numerical approximation of the Hessian matrix.\n",
      "     |          - 'robust' for an approximate (quasi-maximum likelihood) covariance\n",
      "     |            matrix that may be valid even in the presence of some\n",
      "     |            misspecifications. Intermediate calculations use the 'oim'\n",
      "     |            method.\n",
      "     |          - 'robust_approx' is the same as 'robust' except that the\n",
      "     |            intermediate calculations use the 'approx' method.\n",
      "     |          - 'none' for no covariance matrix calculation.\n",
      "     |      \n",
      "     |          Default is 'none', since computing this matrix can be very slow\n",
      "     |          when there are a large number of parameters.\n",
      "     |      cov_kwds : dict or None, optional\n",
      "     |          A dictionary of arguments affecting covariance matrix computation.\n",
      "     |      \n",
      "     |          **opg, oim, approx, robust, robust_approx**\n",
      "     |      \n",
      "     |          - 'approx_complex_step' : bool, optional - If True, numerical\n",
      "     |            approximations are computed using complex-step methods. If False,\n",
      "     |            numerical approximations are computed using finite difference\n",
      "     |            methods. Default is True.\n",
      "     |          - 'approx_centered' : bool, optional - If True, numerical\n",
      "     |            approximations computed using finite difference methods use a\n",
      "     |            centered approximation. Default is False.\n",
      "     |      maxiter : int, optional\n",
      "     |          The maximum number of EM iterations to perform.\n",
      "     |      tolerance : float, optional\n",
      "     |          Parameter governing convergence of the EM algorithm. The\n",
      "     |          `tolerance` is the minimum relative increase in the likelihood\n",
      "     |          for which convergence will be declared. A smaller value for the\n",
      "     |          `tolerance` will typically yield more precise parameter estimates,\n",
      "     |          but will typically require more EM iterations. Default is 1e-6.\n",
      "     |      disp : int or bool, optional\n",
      "     |          Controls printing of EM iteration progress. If an integer, progress\n",
      "     |          is printed at every `disp` iterations. A value of True is\n",
      "     |          interpreted as the value of 1. Default is False (nothing will be\n",
      "     |          printed).\n",
      "     |      em_initialization : bool, optional\n",
      "     |          Whether or not to also update the Kalman filter initialization\n",
      "     |          using the EM algorithm. Default is True.\n",
      "     |      mstep_method : {None, 'missing', 'nonmissing'}, optional\n",
      "     |          The EM algorithm maximization step. If there are no NaN values\n",
      "     |          in the dataset, this can be set to \"nonmissing\" (which is slightly\n",
      "     |          faster) or \"missing\", otherwise it must be \"missing\". Default is\n",
      "     |          \"nonmissing\" if there are no NaN values or \"missing\" if there are.\n",
      "     |      full_output : bool, optional\n",
      "     |          Set to True to have all available output from EM iterations in\n",
      "     |          the Results object's mle_retvals attribute.\n",
      "     |      return_params : bool, optional\n",
      "     |          Whether or not to return only the array of maximizing parameters.\n",
      "     |          Default is False.\n",
      "     |      low_memory : bool, optional\n",
      "     |          This option cannot be used with the EM algorithm and will raise an\n",
      "     |          error if set to True. Default is False.\n",
      "     |      llf_decrease_action : {'ignore', 'warn', 'revert'}, optional\n",
      "     |          Action to take if the log-likelihood decreases in an EM iteration.\n",
      "     |          'ignore' continues the iterations, 'warn' issues a warning but\n",
      "     |          continues the iterations, while 'revert' ends the iterations and\n",
      "     |          returns the result from the last good iteration. Default is 'warn'.\n",
      "     |      llf_decrease_tolerance : float, optional\n",
      "     |          Minimum size of the log-likelihood decrease required to trigger a\n",
      "     |          warning or to end the EM iterations. Setting this value slightly\n",
      "     |          larger than zero allows small decreases in the log-likelihood that\n",
      "     |          may be caused by numerical issues. If set to zero, then any\n",
      "     |          decrease will trigger the `llf_decrease_action`. Default is 1e-4.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      DynamicFactorMQResults\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      statsmodels.tsa.statespace.mlemodel.MLEModel.fit\n",
      "     |      statsmodels.tsa.statespace.mlemodel.MLEResults\n",
      "     |  \n",
      "     |  impulse_responses(self, params, steps=1, impulse=0, orthogonalized=False, cumulative=False, anchor=None, exog=None, extend_model=None, extend_kwargs=None, transformed=True, includes_fixed=False, original_scale=True, **kwargs)\n",
      "     |      Impulse response function.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : array_like\n",
      "     |          Array of model parameters.\n",
      "     |      steps : int, optional\n",
      "     |          The number of steps for which impulse responses are calculated.\n",
      "     |          Default is 1. Note that for time-invariant models, the initial\n",
      "     |          impulse is not counted as a step, so if `steps=1`, the output will\n",
      "     |          have 2 entries.\n",
      "     |      impulse : int or array_like\n",
      "     |          If an integer, the state innovation to pulse; must be between 0\n",
      "     |          and `k_posdef-1`. Alternatively, a custom impulse vector may be\n",
      "     |          provided; must be shaped `k_posdef x 1`.\n",
      "     |      orthogonalized : bool, optional\n",
      "     |          Whether or not to perform impulse using orthogonalized innovations.\n",
      "     |          Note that this will also affect custum `impulse` vectors. Default\n",
      "     |          is False.\n",
      "     |      cumulative : bool, optional\n",
      "     |          Whether or not to return cumulative impulse responses. Default is\n",
      "     |          False.\n",
      "     |      anchor : int, str, or datetime, optional\n",
      "     |          Time point within the sample for the state innovation impulse. Type\n",
      "     |          depends on the index of the given `endog` in the model. Two special\n",
      "     |          cases are the strings 'start' and 'end', which refer to setting the\n",
      "     |          impulse at the first and last points of the sample, respectively.\n",
      "     |          Integer values can run from 0 to `nobs - 1`, or can be negative to\n",
      "     |          apply negative indexing. Finally, if a date/time index was provided\n",
      "     |          to the model, then this argument can be a date string to parse or a\n",
      "     |          datetime type. Default is 'start'.\n",
      "     |      exog : array_like, optional\n",
      "     |          New observations of exogenous regressors for our-of-sample periods,\n",
      "     |          if applicable.\n",
      "     |      transformed : bool, optional\n",
      "     |          Whether or not `params` is already transformed. Default is\n",
      "     |          True.\n",
      "     |      includes_fixed : bool, optional\n",
      "     |          If parameters were previously fixed with the `fix_params` method,\n",
      "     |          this argument describes whether or not `params` also includes\n",
      "     |          the fixed parameters, in addition to the free parameters. Default\n",
      "     |          is False.\n",
      "     |      original_scale : bool, optional\n",
      "     |          If the model specification standardized the data, whether or not\n",
      "     |          to return impulse responses in the original scale of the data (i.e.\n",
      "     |          before it was standardized by the model). Default is True.\n",
      "     |      **kwargs\n",
      "     |          If the model has time-varying design or transition matrices and the\n",
      "     |          combination of `anchor` and `steps` implies creating impulse\n",
      "     |          responses for the out-of-sample period, then these matrices must\n",
      "     |          have updated values provided for the out-of-sample steps. For\n",
      "     |          example, if `design` is a time-varying component, `nobs` is 10,\n",
      "     |          `anchor=1`, and `steps` is 15, a (`k_endog` x `k_states` x 7)\n",
      "     |          matrix must be provided with the new design matrix values.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      impulse_responses : ndarray\n",
      "     |          Responses for each endogenous variable due to the impulse\n",
      "     |          given by the `impulse` argument. For a time-invariant model, the\n",
      "     |          impulse responses are given for `steps + 1` elements (this gives\n",
      "     |          the \"initial impulse\" followed by `steps` responses for the\n",
      "     |          important cases of VAR and SARIMAX models), while for time-varying\n",
      "     |          models the impulse responses are only given for `steps` elements\n",
      "     |          (to avoid having to unexpectedly provide updated time-varying\n",
      "     |          matrices).\n",
      "     |  \n",
      "     |  loading_constraints(self, i)\n",
      "     |      Matrix formulation of quarterly variables' factor loading constraints.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      i : int\n",
      "     |          Index of the `endog` variable to compute constraints for.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      R : array (k_constraints, k_factors * 5)\n",
      "     |      q : array (k_constraints,)\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      If the factors were known, then the factor loadings for the ith\n",
      "     |      quarterly variable would be computed by a linear regression of the form\n",
      "     |      \n",
      "     |      y_i = A_i' f + B_i' L1.f + C_i' L2.f + D_i' L3.f + E_i' L4.f\n",
      "     |      \n",
      "     |      where:\n",
      "     |      \n",
      "     |      - f is (k_i x 1) and collects all of the factors that load on y_i\n",
      "     |      - L{j}.f is (k_i x 1) and collects the jth lag of each factor\n",
      "     |      - A_i, ..., E_i are (k_i x 1) and collect factor loadings\n",
      "     |      \n",
      "     |      As the observed variable is quarterly while the factors are monthly, we\n",
      "     |      want to restrict the estimated regression coefficients to be:\n",
      "     |      \n",
      "     |      y_i = A_i f + 2 A_i L1.f + 3 A_i L2.f + 2 A_i L3.f + A_i L4.f\n",
      "     |      \n",
      "     |      Stack the unconstrained coefficients: \\Lambda_i = [A_i' B_i' ... E_i']'\n",
      "     |      \n",
      "     |      Then the constraints can be written as follows, for l = 1, ..., k_i\n",
      "     |      \n",
      "     |      - 2 A_{i,l} - B_{i,l} = 0\n",
      "     |      - 3 A_{i,l} - C_{i,l} = 0\n",
      "     |      - 2 A_{i,l} - D_{i,l} = 0\n",
      "     |      - A_{i,l} - E_{i,l} = 0\n",
      "     |      \n",
      "     |      So that k_constraints = 4 * k_i. In matrix form the constraints are:\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |      \n",
      "     |          R \\Lambda_i = q\n",
      "     |      \n",
      "     |      where :math:`\\Lambda_i` is shaped `(k_i * 5,)`, :math:`R` is shaped\n",
      "     |      `(k_constraints, k_i * 5)`, and :math:`q` is shaped `(k_constraints,)`.\n",
      "     |      \n",
      "     |      \n",
      "     |      For example, for the case that k_i = 2, we can write:\n",
      "     |      \n",
      "     |      |  2 0   -1  0    0  0    0  0    0  0  |   | A_{i,1} |     | 0 |\n",
      "     |      |  0 2    0 -1    0  0    0  0    0  0  |   | A_{i,2} |     | 0 |\n",
      "     |      |  3 0    0  0   -1  0    0  0    0  0  |   | B_{i,1} |     | 0 |\n",
      "     |      |  0 3    0  0    0 -1    0  0    0  0  |   | B_{i,2} |     | 0 |\n",
      "     |      |  2 0    0  0    0  0   -1  0    0  0  |   | C_{i,1} |  =  | 0 |\n",
      "     |      |  0 2    0  0    0  0    0 -1    0  0  |   | C_{i,2} |     | 0 |\n",
      "     |      |  1 0    0  0    0  0    0  0   -1  0  |   | D_{i,1} |     | 0 |\n",
      "     |      |  0 1    0  0    0  0    0  0    0 -1  |   | D_{i,2} |     | 0 |\n",
      "     |                                                  | E_{i,1} |     | 0 |\n",
      "     |                                                  | E_{i,2} |     | 0 |\n",
      "     |  \n",
      "     |  simulate(self, params, nsimulations, measurement_shocks=None, state_shocks=None, initial_state=None, anchor=None, repetitions=None, exog=None, extend_model=None, extend_kwargs=None, transformed=True, includes_fixed=False, original_scale=True, **kwargs)\n",
      "     |      Simulate a new time series following the state space model.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : array_like\n",
      "     |          Array of parameters to use in constructing the state space\n",
      "     |          representation to use when simulating.\n",
      "     |      nsimulations : int\n",
      "     |          The number of observations to simulate. If the model is\n",
      "     |          time-invariant this can be any number. If the model is\n",
      "     |          time-varying, then this number must be less than or equal to the\n",
      "     |          number of observations.\n",
      "     |      measurement_shocks : array_like, optional\n",
      "     |          If specified, these are the shocks to the measurement equation,\n",
      "     |          :math:`\\varepsilon_t`. If unspecified, these are automatically\n",
      "     |          generated using a pseudo-random number generator. If specified,\n",
      "     |          must be shaped `nsimulations` x `k_endog`, where `k_endog` is the\n",
      "     |          same as in the state space model.\n",
      "     |      state_shocks : array_like, optional\n",
      "     |          If specified, these are the shocks to the state equation,\n",
      "     |          :math:`\\eta_t`. If unspecified, these are automatically\n",
      "     |          generated using a pseudo-random number generator. If specified,\n",
      "     |          must be shaped `nsimulations` x `k_posdef` where `k_posdef` is the\n",
      "     |          same as in the state space model.\n",
      "     |      initial_state : array_like, optional\n",
      "     |          If specified, this is the initial state vector to use in\n",
      "     |          simulation, which should be shaped (`k_states` x 1), where\n",
      "     |          `k_states` is the same as in the state space model. If unspecified,\n",
      "     |          but the model has been initialized, then that initialization is\n",
      "     |          used. This must be specified if `anchor` is anything other than\n",
      "     |          \"start\" or 0 (or else you can use the `simulate` method on a\n",
      "     |          results object rather than on the model object).\n",
      "     |      anchor : int, str, or datetime, optional\n",
      "     |          First period for simulation. The simulation will be conditional on\n",
      "     |          all existing datapoints prior to the `anchor`.  Type depends on the\n",
      "     |          index of the given `endog` in the model. Two special cases are the\n",
      "     |          strings 'start' and 'end'. `start` refers to beginning the\n",
      "     |          simulation at the first period of the sample, and `end` refers to\n",
      "     |          beginning the simulation at the first period after the sample.\n",
      "     |          Integer values can run from 0 to `nobs`, or can be negative to\n",
      "     |          apply negative indexing. Finally, if a date/time index was provided\n",
      "     |          to the model, then this argument can be a date string to parse or a\n",
      "     |          datetime type. Default is 'start'.\n",
      "     |      repetitions : int, optional\n",
      "     |          Number of simulated paths to generate. Default is 1 simulated path.\n",
      "     |      exog : array_like, optional\n",
      "     |          New observations of exogenous regressors, if applicable.\n",
      "     |      transformed : bool, optional\n",
      "     |          Whether or not `params` is already transformed. Default is\n",
      "     |          True.\n",
      "     |      includes_fixed : bool, optional\n",
      "     |          If parameters were previously fixed with the `fix_params` method,\n",
      "     |          this argument describes whether or not `params` also includes\n",
      "     |          the fixed parameters, in addition to the free parameters. Default\n",
      "     |          is False.\n",
      "     |      original_scale : bool, optional\n",
      "     |          If the model specification standardized the data, whether or not\n",
      "     |          to return simulations in the original scale of the data (i.e.\n",
      "     |          before it was standardized by the model). Default is True.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      simulated_obs : ndarray\n",
      "     |          An array of simulated observations. If `repetitions=None`, then it\n",
      "     |          will be shaped (nsimulations x k_endog) or (nsimulations,) if\n",
      "     |          `k_endog=1`. Otherwise it will be shaped\n",
      "     |          (nsimulations x k_endog x repetitions). If the model was given\n",
      "     |          Pandas input then the output will be a Pandas object. If\n",
      "     |          `k_endog > 1` and `repetitions` is not None, then the output will\n",
      "     |          be a Pandas DataFrame that has a MultiIndex for the columns, with\n",
      "     |          the first level containing the names of the `endog` variables and\n",
      "     |          the second level containing the repetition number.\n",
      "     |  \n",
      "     |  smooth(self, params, transformed=True, includes_fixed=False, complex_step=False, cov_type='none', cov_kwds=None, return_ssm=False, results_class=None, results_wrapper_class=None, **kwargs)\n",
      "     |      Kalman smoothing.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : array_like\n",
      "     |          Array of parameters at which to evaluate the loglikelihood\n",
      "     |          function.\n",
      "     |      transformed : bool, optional\n",
      "     |          Whether or not `params` is already transformed. Default is True.\n",
      "     |      return_ssm : bool,optional\n",
      "     |          Whether or not to return only the state space output or a full\n",
      "     |          results object. Default is to return a full results object.\n",
      "     |      cov_type : str, optional\n",
      "     |          See `MLEResults.fit` for a description of covariance matrix types\n",
      "     |          for results object. Default is None.\n",
      "     |      cov_kwds : dict or None, optional\n",
      "     |          See `MLEResults.get_robustcov_results` for a description required\n",
      "     |          keywords for alternative covariance estimators\n",
      "     |      **kwargs\n",
      "     |          Additional keyword arguments to pass to the Kalman filter. See\n",
      "     |          `KalmanFilter.filter` for more details.\n",
      "     |  \n",
      "     |  summary(self, truncate_endog_names=None)\n",
      "     |      Create a summary table describing the model.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      truncate_endog_names : int, optional\n",
      "     |          The number of characters to show for names of observed variables.\n",
      "     |          Default is 24 if there is more than one observed variable, or\n",
      "     |          an unlimited number of there is only one.\n",
      "     |  \n",
      "     |  transform_params(self, unconstrained)\n",
      "     |      Transform parameters from optimizer space to model space.\n",
      "     |      \n",
      "     |      Transform unconstrained parameters used by the optimizer to constrained\n",
      "     |      parameters used in likelihood evaluation.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      unconstrained : array_like\n",
      "     |          Array of unconstrained parameters used by the optimizer, to be\n",
      "     |          transformed.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      constrained : array_like\n",
      "     |          Array of constrained parameters which may be used in likelihood\n",
      "     |          evaluation.\n",
      "     |  \n",
      "     |  untransform_params(self, constrained)\n",
      "     |      Transform parameters from model space to optimizer space.\n",
      "     |      \n",
      "     |      Transform constrained parameters used in likelihood evaluation\n",
      "     |      to unconstrained parameters used by the optimizer.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      constrained : array_like\n",
      "     |          Array of constrained parameters used in likelihood evaluation, to\n",
      "     |          be transformed.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      unconstrained : array_like\n",
      "     |          Array of unconstrained parameters used by the optimizer.\n",
      "     |  \n",
      "     |  update(self, params, **kwargs)\n",
      "     |      Update the parameters of the model.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : array_like\n",
      "     |          Array of new parameters.\n",
      "     |      transformed : bool, optional\n",
      "     |          Whether or not `params` is already transformed. If set to False,\n",
      "     |          `transform_params` is called. Default is True.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods defined here:\n",
      "     |  \n",
      "     |  construct_endog(endog_monthly, endog_quarterly) from builtins.type\n",
      "     |      Construct a combined dataset from separate monthly and quarterly data.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      endog_monthly : array_like\n",
      "     |          Monthly dataset. If a quarterly dataset is given, then this must\n",
      "     |          be a Pandas object with a PeriodIndex or DatetimeIndex at a monthly\n",
      "     |          frequency.\n",
      "     |      endog_quarterly : array_like or None\n",
      "     |          Quarterly dataset. If not None, then this must be a Pandas object\n",
      "     |          with a PeriodIndex or DatetimeIndex at a quarterly frequency.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      endog : array_like\n",
      "     |          If both endog_monthly and endog_quarterly were given, this is a\n",
      "     |          Pandas DataFrame with a PeriodIndex at the monthly frequency, with\n",
      "     |          all of the columns from `endog_monthly` ordered first and the\n",
      "     |          columns from `endog_quarterly` ordered afterwards. Otherwise it is\n",
      "     |          simply the input `endog_monthly` dataset.\n",
      "     |      k_endog_monthly : int\n",
      "     |          The number of monthly variables (which are ordered first) in the\n",
      "     |          returned `endog` dataset.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties defined here:\n",
      "     |  \n",
      "     |  loglike_constant\n",
      "     |      Constant term in the joint log-likelihood function.\n",
      "     |      \n",
      "     |      Useful in facilitating comparisons to other packages that exclude the\n",
      "     |      constant from the log-likelihood computation.\n",
      "     |  \n",
      "     |  param_names\n",
      "     |      (list of str) List of human readable parameter names.\n",
      "     |  \n",
      "     |  start_params\n",
      "     |      (array) Starting parameters for maximum likelihood estimation.\n",
      "     |  \n",
      "     |  state_names\n",
      "     |      (list of str) List of human readable names for unobserved states.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from statsmodels.tsa.statespace.mlemodel.MLEModel:\n",
      "     |  \n",
      "     |  __getitem__(self, key)\n",
      "     |  \n",
      "     |  __setitem__(self, key, value)\n",
      "     |  \n",
      "     |  fit_constrained(self, constraints, start_params=None, **fit_kwds)\n",
      "     |      Fit the model with some parameters subject to equality constraints.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      constraints : dict\n",
      "     |          Dictionary of constraints, of the form `param_name: fixed_value`.\n",
      "     |          See the `param_names` property for valid parameter names.\n",
      "     |      start_params : array_like, optional\n",
      "     |          Initial guess of the solution for the loglikelihood maximization.\n",
      "     |          If None, the default is given by Model.start_params.\n",
      "     |      **fit_kwds : keyword arguments\n",
      "     |          fit_kwds are used in the optimization of the remaining parameters.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      results : Results instance\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> mod = sm.tsa.SARIMAX(endog, order=(1, 0, 1))\n",
      "     |      >>> res = mod.fit_constrained({'ar.L1': 0.5})\n",
      "     |  \n",
      "     |  fix_params(self, params)\n",
      "     |      Fix parameters to specific values (context manager)\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : dict\n",
      "     |          Dictionary describing the fixed parameter values, of the form\n",
      "     |          `param_name: fixed_value`. See the `param_names` property for valid\n",
      "     |          parameter names.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> mod = sm.tsa.SARIMAX(endog, order=(1, 0, 1))\n",
      "     |      >>> with mod.fix_params({'ar.L1': 0.5}):\n",
      "     |              res = mod.fit()\n",
      "     |  \n",
      "     |  handle_params(self, params, transformed=True, includes_fixed=False, return_jacobian=False)\n",
      "     |      Ensure model parameters satisfy shape and other requirements\n",
      "     |  \n",
      "     |  hessian(self, params, *args, **kwargs)\n",
      "     |      Hessian matrix of the likelihood function, evaluated at the given\n",
      "     |      parameters\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : array_like\n",
      "     |          Array of parameters at which to evaluate the hessian.\n",
      "     |      *args\n",
      "     |          Additional positional arguments to the `loglike` method.\n",
      "     |      **kwargs\n",
      "     |          Additional keyword arguments to the `loglike` method.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      hessian : ndarray\n",
      "     |          Hessian matrix evaluated at `params`\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      This is a numerical approximation.\n",
      "     |      \n",
      "     |      Both args and kwargs are necessary because the optimizer from\n",
      "     |      `fit` must call this function and only supports passing arguments via\n",
      "     |      args (for example `scipy.optimize.fmin_l_bfgs`).\n",
      "     |  \n",
      "     |  initialize_approximate_diffuse(self, variance=None)\n",
      "     |      Initialize approximate diffuse\n",
      "     |  \n",
      "     |  initialize_known(self, initial_state, initial_state_cov)\n",
      "     |      Initialize known\n",
      "     |  \n",
      "     |  initialize_statespace(self, **kwargs)\n",
      "     |      Initialize the state space representation\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      **kwargs\n",
      "     |          Additional keyword arguments to pass to the state space class\n",
      "     |          constructor.\n",
      "     |  \n",
      "     |  initialize_stationary(self)\n",
      "     |      Initialize stationary\n",
      "     |  \n",
      "     |  loglike(self, params, *args, **kwargs)\n",
      "     |      Loglikelihood evaluation\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : array_like\n",
      "     |          Array of parameters at which to evaluate the loglikelihood\n",
      "     |          function.\n",
      "     |      transformed : bool, optional\n",
      "     |          Whether or not `params` is already transformed. Default is True.\n",
      "     |      **kwargs\n",
      "     |          Additional keyword arguments to pass to the Kalman filter. See\n",
      "     |          `KalmanFilter.filter` for more details.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      update : modifies the internal state of the state space model to\n",
      "     |               reflect new params\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      [1]_ recommend maximizing the average likelihood to avoid scale issues;\n",
      "     |      this is done automatically by the base Model fit method.\n",
      "     |      \n",
      "     |      References\n",
      "     |      ----------\n",
      "     |      .. [1] Koopman, Siem Jan, Neil Shephard, and Jurgen A. Doornik. 1999.\n",
      "     |         Statistical Algorithms for Models in State Space Using SsfPack 2.2.\n",
      "     |         Econometrics Journal 2 (1): 107-60. doi:10.1111/1368-423X.00023.\n",
      "     |  \n",
      "     |  loglikeobs(self, params, transformed=True, includes_fixed=False, complex_step=False, **kwargs)\n",
      "     |      Loglikelihood evaluation\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : array_like\n",
      "     |          Array of parameters at which to evaluate the loglikelihood\n",
      "     |          function.\n",
      "     |      transformed : bool, optional\n",
      "     |          Whether or not `params` is already transformed. Default is True.\n",
      "     |      **kwargs\n",
      "     |          Additional keyword arguments to pass to the Kalman filter. See\n",
      "     |          `KalmanFilter.filter` for more details.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      update : modifies the internal state of the Model to reflect new params\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      [1]_ recommend maximizing the average likelihood to avoid scale issues;\n",
      "     |      this is done automatically by the base Model fit method.\n",
      "     |      \n",
      "     |      References\n",
      "     |      ----------\n",
      "     |      .. [1] Koopman, Siem Jan, Neil Shephard, and Jurgen A. Doornik. 1999.\n",
      "     |         Statistical Algorithms for Models in State Space Using SsfPack 2.2.\n",
      "     |         Econometrics Journal 2 (1): 107-60. doi:10.1111/1368-423X.00023.\n",
      "     |  \n",
      "     |  observed_information_matrix(self, params, transformed=True, includes_fixed=False, approx_complex_step=None, approx_centered=False, **kwargs)\n",
      "     |      Observed information matrix\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : array_like, optional\n",
      "     |          Array of parameters at which to evaluate the loglikelihood\n",
      "     |          function.\n",
      "     |      **kwargs\n",
      "     |          Additional keyword arguments to pass to the Kalman filter. See\n",
      "     |          `KalmanFilter.filter` for more details.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      This method is from Harvey (1989), which shows that the information\n",
      "     |      matrix only depends on terms from the gradient. This implementation is\n",
      "     |      partially analytic and partially numeric approximation, therefore,\n",
      "     |      because it uses the analytic formula for the information matrix, with\n",
      "     |      numerically computed elements of the gradient.\n",
      "     |      \n",
      "     |      References\n",
      "     |      ----------\n",
      "     |      Harvey, Andrew C. 1990.\n",
      "     |      Forecasting, Structural Time Series Models and the Kalman Filter.\n",
      "     |      Cambridge University Press.\n",
      "     |  \n",
      "     |  opg_information_matrix(self, params, transformed=True, includes_fixed=False, approx_complex_step=None, **kwargs)\n",
      "     |      Outer product of gradients information matrix\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : array_like, optional\n",
      "     |          Array of parameters at which to evaluate the loglikelihood\n",
      "     |          function.\n",
      "     |      **kwargs\n",
      "     |          Additional arguments to the `loglikeobs` method.\n",
      "     |      \n",
      "     |      References\n",
      "     |      ----------\n",
      "     |      Berndt, Ernst R., Bronwyn Hall, Robert Hall, and Jerry Hausman. 1974.\n",
      "     |      Estimation and Inference in Nonlinear Structural Models.\n",
      "     |      NBER Chapters. National Bureau of Economic Research, Inc.\n",
      "     |  \n",
      "     |  prepare_data(self)\n",
      "     |      Prepare data for use in the state space representation\n",
      "     |  \n",
      "     |  score(self, params, *args, **kwargs)\n",
      "     |      Compute the score function at params.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : array_like\n",
      "     |          Array of parameters at which to evaluate the score.\n",
      "     |      *args\n",
      "     |          Additional positional arguments to the `loglike` method.\n",
      "     |      **kwargs\n",
      "     |          Additional keyword arguments to the `loglike` method.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      score : ndarray\n",
      "     |          Score, evaluated at `params`.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      This is a numerical approximation, calculated using first-order complex\n",
      "     |      step differentiation on the `loglike` method.\n",
      "     |      \n",
      "     |      Both args and kwargs are necessary because the optimizer from\n",
      "     |      `fit` must call this function and only supports passing arguments via\n",
      "     |      args (for example `scipy.optimize.fmin_l_bfgs`).\n",
      "     |  \n",
      "     |  score_obs(self, params, method='approx', transformed=True, includes_fixed=False, approx_complex_step=None, approx_centered=False, **kwargs)\n",
      "     |      Compute the score per observation, evaluated at params\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : array_like\n",
      "     |          Array of parameters at which to evaluate the score.\n",
      "     |      **kwargs\n",
      "     |          Additional arguments to the `loglike` method.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      score : ndarray\n",
      "     |          Score per observation, evaluated at `params`.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      This is a numerical approximation, calculated using first-order complex\n",
      "     |      step differentiation on the `loglikeobs` method.\n",
      "     |  \n",
      "     |  set_conserve_memory(self, conserve_memory=None, **kwargs)\n",
      "     |      Set the memory conservation method\n",
      "     |      \n",
      "     |      By default, the Kalman filter computes a number of intermediate\n",
      "     |      matrices at each iteration. The memory conservation options control\n",
      "     |      which of those matrices are stored.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      conserve_memory : int, optional\n",
      "     |          Bitmask value to set the memory conservation method to. See notes\n",
      "     |          for details.\n",
      "     |      **kwargs\n",
      "     |          Keyword arguments may be used to influence the memory conservation\n",
      "     |          method by setting individual boolean flags.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      This method is rarely used. See the corresponding function in the\n",
      "     |      `KalmanFilter` class for details.\n",
      "     |  \n",
      "     |  set_filter_method(self, filter_method=None, **kwargs)\n",
      "     |      Set the filtering method\n",
      "     |      \n",
      "     |      The filtering method controls aspects of which Kalman filtering\n",
      "     |      approach will be used.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      filter_method : int, optional\n",
      "     |          Bitmask value to set the filter method to. See notes for details.\n",
      "     |      **kwargs\n",
      "     |          Keyword arguments may be used to influence the filter method by\n",
      "     |          setting individual boolean flags. See notes for details.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      This method is rarely used. See the corresponding function in the\n",
      "     |      `KalmanFilter` class for details.\n",
      "     |  \n",
      "     |  set_inversion_method(self, inversion_method=None, **kwargs)\n",
      "     |      Set the inversion method\n",
      "     |      \n",
      "     |      The Kalman filter may contain one matrix inversion: that of the\n",
      "     |      forecast error covariance matrix. The inversion method controls how and\n",
      "     |      if that inverse is performed.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      inversion_method : int, optional\n",
      "     |          Bitmask value to set the inversion method to. See notes for\n",
      "     |          details.\n",
      "     |      **kwargs\n",
      "     |          Keyword arguments may be used to influence the inversion method by\n",
      "     |          setting individual boolean flags. See notes for details.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      This method is rarely used. See the corresponding function in the\n",
      "     |      `KalmanFilter` class for details.\n",
      "     |  \n",
      "     |  set_smoother_output(self, smoother_output=None, **kwargs)\n",
      "     |      Set the smoother output\n",
      "     |      \n",
      "     |      The smoother can produce several types of results. The smoother output\n",
      "     |      variable controls which are calculated and returned.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      smoother_output : int, optional\n",
      "     |          Bitmask value to set the smoother output to. See notes for details.\n",
      "     |      **kwargs\n",
      "     |          Keyword arguments may be used to influence the smoother output by\n",
      "     |          setting individual boolean flags.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      This method is rarely used. See the corresponding function in the\n",
      "     |      `KalmanSmoother` class for details.\n",
      "     |  \n",
      "     |  set_stability_method(self, stability_method=None, **kwargs)\n",
      "     |      Set the numerical stability method\n",
      "     |      \n",
      "     |      The Kalman filter is a recursive algorithm that may in some cases\n",
      "     |      suffer issues with numerical stability. The stability method controls\n",
      "     |      what, if any, measures are taken to promote stability.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      stability_method : int, optional\n",
      "     |          Bitmask value to set the stability method to. See notes for\n",
      "     |          details.\n",
      "     |      **kwargs\n",
      "     |          Keyword arguments may be used to influence the stability method by\n",
      "     |          setting individual boolean flags. See notes for details.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      This method is rarely used. See the corresponding function in the\n",
      "     |      `KalmanFilter` class for details.\n",
      "     |  \n",
      "     |  simulation_smoother(self, simulation_output=None, **kwargs)\n",
      "     |      Retrieve a simulation smoother for the state space model.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      simulation_output : int, optional\n",
      "     |          Determines which simulation smoother output is calculated.\n",
      "     |          Default is all (including state and disturbances).\n",
      "     |      **kwargs\n",
      "     |          Additional keyword arguments, used to set the simulation output.\n",
      "     |          See `set_simulation_output` for more details.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      SimulationSmoothResults\n",
      "     |  \n",
      "     |  transform_jacobian(self, unconstrained, approx_centered=False)\n",
      "     |      Jacobian matrix for the parameter transformation function\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      unconstrained : array_like\n",
      "     |          Array of unconstrained parameters used by the optimizer.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      jacobian : ndarray\n",
      "     |          Jacobian matrix of the transformation, evaluated at `unconstrained`\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      transform_params\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      This is a numerical approximation using finite differences. Note that\n",
      "     |      in general complex step methods cannot be used because it is not\n",
      "     |      guaranteed that the `transform_params` method is a real function (e.g.\n",
      "     |      if Cholesky decomposition is used).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from statsmodels.tsa.statespace.mlemodel.MLEModel:\n",
      "     |  \n",
      "     |  from_formula(formula, data, subset=None) from builtins.type\n",
      "     |      Not implemented for state space models\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from statsmodels.tsa.statespace.mlemodel.MLEModel:\n",
      "     |  \n",
      "     |  initial_variance\n",
      "     |  \n",
      "     |  initialization\n",
      "     |  \n",
      "     |  loglikelihood_burn\n",
      "     |  \n",
      "     |  tolerance\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from statsmodels.tsa.base.tsa_model.TimeSeriesModel:\n",
      "     |  \n",
      "     |  exog_names\n",
      "     |      The names of the exogenous variables.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from statsmodels.base.model.LikelihoodModel:\n",
      "     |  \n",
      "     |  information(self, params)\n",
      "     |      Fisher information matrix of model.\n",
      "     |      \n",
      "     |      Returns -1 * Hessian of the log-likelihood evaluated at params.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : ndarray\n",
      "     |          The model parameters.\n",
      "     |  \n",
      "     |  initialize(self)\n",
      "     |      Initialize (possibly re-initialize) a Model instance.\n",
      "     |      \n",
      "     |      For example, if the the design matrix of a linear model changes then\n",
      "     |      initialized can be used to recompute values using the modified design\n",
      "     |      matrix.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from statsmodels.base.model.Model:\n",
      "     |  \n",
      "     |  predict(self, params, exog=None, *args, **kwargs)\n",
      "     |      After a model has been fit predict returns the fitted values.\n",
      "     |      \n",
      "     |      This is a placeholder intended to be overwritten by individual models.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from statsmodels.base.model.Model:\n",
      "     |  \n",
      "     |  endog_names\n",
      "     |      Names of endogenous variables.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from statsmodels.base.model.Model:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class ETSModel(statsmodels.tsa.exponential_smoothing.base.StateSpaceMLEModel)\n",
      "     |  ETSModel(endog, error='add', trend=None, damped_trend=False, seasonal=None, seasonal_periods=None, initialization_method='estimated', initial_level=None, initial_trend=None, initial_seasonal=None, bounds=None, dates=None, freq=None, missing='none')\n",
      "     |  \n",
      "     |  ETS models.\n",
      "     |  \n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  endog : array_like\n",
      "     |      The observed time-series process :math:`y`\n",
      "     |  error : str, optional\n",
      "     |      The error model. \"add\" (default) or \"mul\".\n",
      "     |  trend : str or None, optional\n",
      "     |      The trend component model. \"add\", \"mul\", or None (default).\n",
      "     |  damped_trend : bool, optional\n",
      "     |      Whether or not an included trend component is damped. Default is\n",
      "     |      False.\n",
      "     |  seasonal : str, optional\n",
      "     |      The seasonality model. \"add\", \"mul\", or None (default).\n",
      "     |  seasonal_periods : int, optional\n",
      "     |      The number of periods in a complete seasonal cycle for seasonal\n",
      "     |      (Holt-Winters) models. For example, 4 for quarterly data with an\n",
      "     |      annual cycle or 7 for daily data with a weekly cycle. Required if\n",
      "     |      `seasonal` is not None.\n",
      "     |  initialization_method : str, optional\n",
      "     |      Method for initialization of the state space model. One of:\n",
      "     |  \n",
      "     |      * 'estimated' (default)\n",
      "     |      * 'heuristic'\n",
      "     |      * 'known'\n",
      "     |  \n",
      "     |      If 'known' initialization is used, then `initial_level` must be\n",
      "     |      passed, as well as `initial_trend` and `initial_seasonal` if\n",
      "     |      applicable.\n",
      "     |      'heuristic' uses a heuristic based on the data to estimate initial\n",
      "     |      level, trend, and seasonal state. 'estimated' uses the same heuristic\n",
      "     |      as initial guesses, but then estimates the initial states as part of\n",
      "     |      the fitting process.  Default is 'estimated'.\n",
      "     |  initial_level : float, optional\n",
      "     |      The initial level component. Only used if initialization is 'known'.\n",
      "     |  initial_trend : float, optional\n",
      "     |      The initial trend component. Only used if initialization is 'known'.\n",
      "     |  initial_seasonal : array_like, optional\n",
      "     |      The initial seasonal component. An array of length `seasonal_periods`.\n",
      "     |      Only used if initialization is 'known'.\n",
      "     |  bounds : dict or None, optional\n",
      "     |      A dictionary with parameter names as keys and the respective bounds\n",
      "     |      intervals as values (lists/tuples/arrays).\n",
      "     |      The available parameter names are, depending on the model and\n",
      "     |      initialization method:\n",
      "     |  \n",
      "     |      * \"smoothing_level\"\n",
      "     |      * \"smoothing_trend\"\n",
      "     |      * \"smoothing_seasonal\"\n",
      "     |      * \"damping_trend\"\n",
      "     |      * \"initial_level\"\n",
      "     |      * \"initial_trend\"\n",
      "     |      * \"initial_seasonal.0\", ..., \"initial_seasonal.<m-1>\"\n",
      "     |  \n",
      "     |      The default option is ``None``, in which case the traditional\n",
      "     |      (nonlinear) bounds as described in [1]_ are used.\n",
      "     |  \n",
      "     |  Notes\n",
      "     |  -----\n",
      "     |  The ETS models are a family of time series models. They can be seen as a\n",
      "     |  generalization of simple exponential smoothing to time series that contain\n",
      "     |  trends and seasonalities. Additionally, they have an underlying state\n",
      "     |  space model.\n",
      "     |  \n",
      "     |  An ETS model is specified by an error type (E; additive or multiplicative),\n",
      "     |  a trend type (T; additive or multiplicative, both damped or undamped, or\n",
      "     |  none), and a seasonality type (S; additive or multiplicative or none).\n",
      "     |  The following gives a very short summary, a more thorough introduction can\n",
      "     |  be found in [1]_.\n",
      "     |  \n",
      "     |  Denote with :math:`\\circ_b` the trend operation (addition or\n",
      "     |  multiplication), with :math:`\\circ_d` the operation linking trend and\n",
      "     |  dampening factor :math:`\\phi` (multiplication if trend is additive, power\n",
      "     |  if trend is multiplicative), and with :math:`\\circ_s` the seasonality\n",
      "     |  operation (addition or multiplication). Furthermore, let :math:`\\ominus`\n",
      "     |  be the respective inverse operation (subtraction or division).\n",
      "     |  \n",
      "     |  With this, it is possible to formulate the ETS models as a forecast\n",
      "     |  equation and 3 smoothing equations. The former is used to forecast\n",
      "     |  observations, the latter are used to update the internal state.\n",
      "     |  \n",
      "     |  .. math::\n",
      "     |  \n",
      "     |      \\hat{y}_{t|t-1} &= (l_{t-1} \\circ_b (b_{t-1}\\circ_d \\phi))\n",
      "     |                         \\circ_s s_{t-m}\\\\\n",
      "     |      l_{t} &= \\alpha (y_{t} \\ominus_s s_{t-m})\n",
      "     |               + (1 - \\alpha) (l_{t-1} \\circ_b (b_{t-1} \\circ_d \\phi))\\\\\n",
      "     |      b_{t} &= \\beta/\\alpha (l_{t} \\ominus_b l_{t-1})\n",
      "     |               + (1 - \\beta/\\alpha) b_{t-1}\\\\\n",
      "     |      s_{t} &= \\gamma (y_t \\ominus_s (l_{t-1} \\circ_b (b_{t-1}\\circ_d\\phi))\n",
      "     |               + (1 - \\gamma) s_{t-m}\n",
      "     |  \n",
      "     |  The notation here follows [1]_; :math:`l_t` denotes the level at time\n",
      "     |  :math:`t`, `b_t` the trend, and `s_t` the seasonal component. :math:`m`\n",
      "     |  is the number of seasonal periods, and :math:`\\phi` a trend damping\n",
      "     |  factor. The parameters :math:`\\alpha, \\beta, \\gamma` are the smoothing\n",
      "     |  parameters, which are called ``smoothing_level``, ``smoothing_trend``, and\n",
      "     |  ``smoothing_seasonal``, respectively.\n",
      "     |  \n",
      "     |  Note that the formulation above as forecast and smoothing equation does\n",
      "     |  not distinguish different error models -- it is the same for additive and\n",
      "     |  multiplicative errors. But the different error models lead to different\n",
      "     |  likelihood models, and therefore will lead to different fit results.\n",
      "     |  \n",
      "     |  The error models specify how the true values :math:`y_t` are\n",
      "     |  updated. In the additive error model,\n",
      "     |  \n",
      "     |  .. math::\n",
      "     |  \n",
      "     |      y_t = \\hat{y}_{t|t-1} + e_t,\n",
      "     |  \n",
      "     |  in the multiplicative error model,\n",
      "     |  \n",
      "     |  .. math::\n",
      "     |  \n",
      "     |      y_t = \\hat{y}_{t|t-1}\\cdot (1 + e_t).\n",
      "     |  \n",
      "     |  Using these error models, it is possible to formulate state space\n",
      "     |  equations for the ETS models:\n",
      "     |  \n",
      "     |  .. math::\n",
      "     |  \n",
      "     |     y_t &= Y_t + \\eta \\cdot e_t\\\\\n",
      "     |     l_t &= L_t + \\alpha \\cdot (M_e \\cdot L_t + \\kappa_l) \\cdot e_t\\\\\n",
      "     |     b_t &= B_t + \\beta \\cdot (M_e \\cdot B_t + \\kappa_b) \\cdot e_t\\\\\n",
      "     |     s_t &= S_t + \\gamma \\cdot (M_e \\cdot S_t+\\kappa_s)\\cdot e_t\\\\\n",
      "     |  \n",
      "     |  with\n",
      "     |  \n",
      "     |  .. math::\n",
      "     |  \n",
      "     |     B_t &= b_{t-1} \\circ_d \\phi\\\\\n",
      "     |     L_t &= l_{t-1} \\circ_b B_t\\\\\n",
      "     |     S_t &= s_{t-m}\\\\\n",
      "     |     Y_t &= L_t \\circ_s S_t,\n",
      "     |  \n",
      "     |  and\n",
      "     |  \n",
      "     |  .. math::\n",
      "     |  \n",
      "     |     \\eta &= \\begin{cases}\n",
      "     |                 Y_t\\quad\\text{if error is multiplicative}\\\\\n",
      "     |                 1\\quad\\text{else}\n",
      "     |             \\end{cases}\\\\\n",
      "     |     M_e &= \\begin{cases}\n",
      "     |                 1\\quad\\text{if error is multiplicative}\\\\\n",
      "     |                 0\\quad\\text{else}\n",
      "     |             \\end{cases}\\\\\n",
      "     |  \n",
      "     |  and, when using the additive error model,\n",
      "     |  \n",
      "     |  .. math::\n",
      "     |  \n",
      "     |     \\kappa_l &= \\begin{cases}\n",
      "     |                 \\frac{1}{S_t}\\quad\n",
      "     |                 \\text{if seasonality is multiplicative}\\\\\n",
      "     |                 1\\quad\\text{else}\n",
      "     |             \\end{cases}\\\\\n",
      "     |     \\kappa_b &= \\begin{cases}\n",
      "     |                 \\frac{\\kappa_l}{l_{t-1}}\\quad\n",
      "     |                 \\text{if trend is multiplicative}\\\\\n",
      "     |                 \\kappa_l\\quad\\text{else}\n",
      "     |             \\end{cases}\\\\\n",
      "     |     \\kappa_s &= \\begin{cases}\n",
      "     |                 \\frac{1}{L_t}\\quad\\text{if seasonality is multiplicative}\\\\\n",
      "     |                 1\\quad\\text{else}\n",
      "     |             \\end{cases}\n",
      "     |  \n",
      "     |  When using the multiplicative error model\n",
      "     |  \n",
      "     |  .. math::\n",
      "     |  \n",
      "     |     \\kappa_l &= \\begin{cases}\n",
      "     |                 0\\quad\n",
      "     |                 \\text{if seasonality is multiplicative}\\\\\n",
      "     |                 S_t\\quad\\text{else}\n",
      "     |             \\end{cases}\\\\\n",
      "     |     \\kappa_b &= \\begin{cases}\n",
      "     |                 \\frac{\\kappa_l}{l_{t-1}}\\quad\n",
      "     |                 \\text{if trend is multiplicative}\\\\\n",
      "     |                 \\kappa_l + l_{t-1}\\quad\\text{else}\n",
      "     |             \\end{cases}\\\\\n",
      "     |     \\kappa_s &= \\begin{cases}\n",
      "     |                 0\\quad\\text{if seasonality is multiplicative}\\\\\n",
      "     |                 L_t\\quad\\text{else}\n",
      "     |             \\end{cases}\n",
      "     |  \n",
      "     |  When fitting an ETS model, the parameters :math:`\\alpha, \\beta`, \\gamma,\n",
      "     |  \\phi` and the initial states `l_{-1}, b_{-1}, s_{-1}, \\ldots, s_{-m}` are\n",
      "     |  selected as maximizers of log likelihood.\n",
      "     |  \n",
      "     |  References\n",
      "     |  ----------\n",
      "     |  .. [1] Hyndman, R.J., & Athanasopoulos, G. (2019) *Forecasting:\n",
      "     |     principles and practice*, 3rd edition, OTexts: Melbourne,\n",
      "     |     Australia. OTexts.com/fpp3. Accessed on April 19th 2020.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      ETSModel\n",
      "     |      statsmodels.tsa.exponential_smoothing.base.StateSpaceMLEModel\n",
      "     |      statsmodels.tsa.base.tsa_model.TimeSeriesModel\n",
      "     |      statsmodels.base.model.LikelihoodModel\n",
      "     |      statsmodels.base.model.Model\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, endog, error='add', trend=None, damped_trend=False, seasonal=None, seasonal_periods=None, initialization_method='estimated', initial_level=None, initial_trend=None, initial_seasonal=None, bounds=None, dates=None, freq=None, missing='none')\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  fit(self, start_params=None, maxiter=1000, full_output=True, disp=True, callback=None, return_params=False, **kwargs)\n",
      "     |      Fit an ETS model by maximizing log-likelihood.\n",
      "     |      \n",
      "     |      Log-likelihood is a function of the model parameters :math:`\\alpha,\n",
      "     |      \\beta, \\gamma, \\phi` (depending on the chosen model), and, if\n",
      "     |      `initialization_method` was set to `'estimated'` in the constructor,\n",
      "     |      also the initial states :math:`l_{-1}, b_{-1}, s_{-1}, \\ldots, s_{-m}`.\n",
      "     |      \n",
      "     |      The fit is performed using the L-BFGS algorithm.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      start_params : array_like, optional\n",
      "     |          Initial values for parameters that will be optimized. If this is\n",
      "     |          ``None``, default values will be used.\n",
      "     |          The length of this depends on the chosen model. This should contain\n",
      "     |          the parameters in the following order, skipping parameters that do\n",
      "     |          not exist in the chosen model.\n",
      "     |      \n",
      "     |          * `smoothing_level` (:math:`\\alpha`)\n",
      "     |          * `smoothing_trend` (:math:`\\beta`)\n",
      "     |          * `smoothing_seasonal` (:math:`\\gamma`)\n",
      "     |          * `damping_trend` (:math:`\\phi`)\n",
      "     |      \n",
      "     |          If ``initialization_method`` was set to ``'estimated'`` (the\n",
      "     |          default), additionally, the parameters\n",
      "     |      \n",
      "     |          * `initial_level` (:math:`l_{-1}`)\n",
      "     |          * `initial_trend` (:math:`l_{-1}`)\n",
      "     |          * `initial_seasonal.0` (:math:`s_{-1}`)\n",
      "     |          * ...\n",
      "     |          * `initial_seasonal.<m-1>` (:math:`s_{-m}`)\n",
      "     |      \n",
      "     |          also have to be specified.\n",
      "     |      maxiter : int, optional\n",
      "     |          The maximum number of iterations to perform.\n",
      "     |      full_output : bool, optional\n",
      "     |          Set to True to have all available output in the Results object's\n",
      "     |          mle_retvals attribute. The output is dependent on the solver.\n",
      "     |          See LikelihoodModelResults notes section for more information.\n",
      "     |      disp : bool, optional\n",
      "     |          Set to True to print convergence messages.\n",
      "     |      callback : callable callback(xk), optional\n",
      "     |          Called after each iteration, as callback(xk), where xk is the\n",
      "     |          current parameter vector.\n",
      "     |      return_params : bool, optional\n",
      "     |          Whether or not to return only the array of maximizing parameters.\n",
      "     |          Default is False.\n",
      "     |      **kwargs\n",
      "     |          Additional keyword arguments to pass to the optimizer.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      results : ETSResults\n",
      "     |  \n",
      "     |  hessian(self, params, approx_centered=False, approx_complex_step=True, **kwargs)\n",
      "     |      Hessian matrix of the likelihood function, evaluated at the given\n",
      "     |      parameters\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : array_like\n",
      "     |          Array of parameters at which to evaluate the hessian.\n",
      "     |      approx_centered : bool\n",
      "     |          Whether to use a centered scheme for finite difference\n",
      "     |          approximation\n",
      "     |      approx_complex_step : bool\n",
      "     |          Whether to use complex step differentiation for approximation\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      hessian : ndarray\n",
      "     |          Hessian matrix evaluated at `params`\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      This is a numerical approximation.\n",
      "     |  \n",
      "     |  loglike(self, params, **kwargs)\n",
      "     |      Log-likelihood of model.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : np.ndarray of np.float\n",
      "     |          Model parameters: (alpha, beta, gamma, phi, l[-1],\n",
      "     |          b[-1], s[-1], ..., s[-m])\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      The log-likelihood of a exponential smoothing model is [1]_:\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |      \n",
      "     |         l(\\theta, x_0|y) = - \\frac{n}{2}(\\log(2\\pi s^2) + 1)\n",
      "     |                            - \\sum\\limits_{t=1}^n \\log(k_t)\n",
      "     |      \n",
      "     |      with\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |      \n",
      "     |         s^2 = \\frac{1}{n}\\sum\\limits_{t=1}^n \\frac{(\\hat{y}_t - y_t)^2}{k_t}\n",
      "     |      \n",
      "     |      where :math:`k_t = 1` for the additive error model and :math:`k_t =\n",
      "     |      y_t` for the multiplicative error model.\n",
      "     |      \n",
      "     |      References\n",
      "     |      ----------\n",
      "     |      .. [1] J. K. Ord, A. B. Koehler R. D. and Snyder (1997). Estimation and\n",
      "     |         Prediction for a Class of Dynamic Nonlinear Statistical Models.\n",
      "     |         *Journal of the American Statistical Association*, 92(440),\n",
      "     |         1621-1629\n",
      "     |  \n",
      "     |  score(self, params, approx_centered=False, approx_complex_step=True, **kwargs)\n",
      "     |      Score vector of model.\n",
      "     |      \n",
      "     |      The gradient of logL with respect to each parameter.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : ndarray\n",
      "     |          The parameters to use when evaluating the Hessian.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      ndarray\n",
      "     |          The score vector evaluated at the parameters.\n",
      "     |  \n",
      "     |  set_bounds(self, bounds)\n",
      "     |      Set bounds for parameter estimation.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      bounds : dict or None, optional\n",
      "     |          A dictionary with parameter names as keys and the respective bounds\n",
      "     |          intervals as values (lists/tuples/arrays).\n",
      "     |          The available parameter names are in ``self.param_names``.\n",
      "     |          The default option is ``None``, in which case the traditional\n",
      "     |          (nonlinear) bounds as described in [1]_ are used.\n",
      "     |      \n",
      "     |      References\n",
      "     |      ----------\n",
      "     |      .. [1] Hyndman, R.J., & Athanasopoulos, G. (2019) *Forecasting:\n",
      "     |         principles and practice*, 3rd edition, OTexts: Melbourne,\n",
      "     |         Australia. OTexts.com/fpp3. Accessed on April 19th 2020.\n",
      "     |  \n",
      "     |  set_initialization_method(self, initialization_method, initial_level=None, initial_trend=None, initial_seasonal=None)\n",
      "     |      Sets a new initialization method for the state space model.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      initialization_method : str, optional\n",
      "     |          Method for initialization of the state space model. One of:\n",
      "     |      \n",
      "     |          * 'estimated' (default)\n",
      "     |          * 'heuristic'\n",
      "     |          * 'known'\n",
      "     |      \n",
      "     |          If 'known' initialization is used, then `initial_level` must be\n",
      "     |          passed, as well as `initial_trend` and `initial_seasonal` if\n",
      "     |          applicable.\n",
      "     |          'heuristic' uses a heuristic based on the data to estimate initial\n",
      "     |          level, trend, and seasonal state. 'estimated' uses the same\n",
      "     |          heuristic as initial guesses, but then estimates the initial states\n",
      "     |          as part of the fitting process. Default is 'estimated'.\n",
      "     |      initial_level : float, optional\n",
      "     |          The initial level component. Only used if initialization is\n",
      "     |          'known'.\n",
      "     |      initial_trend : float, optional\n",
      "     |          The initial trend component. Only used if initialization is\n",
      "     |          'known'.\n",
      "     |      initial_seasonal : array_like, optional\n",
      "     |          The initial seasonal component. An array of length\n",
      "     |          `seasonal_periods`. Only used if initialization is 'known'.\n",
      "     |  \n",
      "     |  smooth(self, params, return_raw=False)\n",
      "     |      Exponential smoothing with given parameters\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : array_like\n",
      "     |          Model parameters\n",
      "     |      return_raw : bool, optional\n",
      "     |          Whether to return only the state space results or the full results\n",
      "     |          object. Default is ``False``.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      result : ETSResultsWrapper or tuple\n",
      "     |          If ``return_raw=False``, returns a ETSResultsWrapper\n",
      "     |          object. Otherwise a tuple of arrays or pandas objects, depending on\n",
      "     |          the format of the endog data.\n",
      "     |  \n",
      "     |  update(params, *args, **kwargs)\n",
      "     |  \n",
      "     |  use_internal_loglike(self)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  prepare_data(data)\n",
      "     |      Prepare data for use in the state space representation\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties defined here:\n",
      "     |  \n",
      "     |  initial_state_names\n",
      "     |  \n",
      "     |  k_endog\n",
      "     |  \n",
      "     |  k_params\n",
      "     |  \n",
      "     |  nobs_effective\n",
      "     |  \n",
      "     |  short_name\n",
      "     |  \n",
      "     |  state_names\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from statsmodels.tsa.exponential_smoothing.base.StateSpaceMLEModel:\n",
      "     |  \n",
      "     |  clone(self, endog, exog=None, **kwargs)\n",
      "     |  \n",
      "     |  fit_constrained(self, constraints, start_params=None, **fit_kwds)\n",
      "     |      Fit the model with some parameters subject to equality constraints.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      constraints : dict\n",
      "     |          Dictionary of constraints, of the form `param_name: fixed_value`.\n",
      "     |          See the `param_names` property for valid parameter names.\n",
      "     |      start_params : array_like, optional\n",
      "     |          Initial guess of the solution for the loglikelihood maximization.\n",
      "     |          If None, the default is given by Model.start_params.\n",
      "     |      **fit_kwds : keyword arguments\n",
      "     |          fit_kwds are used in the optimization of the remaining parameters.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      results : Results instance\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> mod = sm.tsa.SARIMAX(endog, order=(1, 0, 1))\n",
      "     |      >>> res = mod.fit_constrained({'ar.L1': 0.5})\n",
      "     |  \n",
      "     |  fix_params(self, params)\n",
      "     |      Fix parameters to specific values (context manager)\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : dict\n",
      "     |          Dictionary describing the fixed parameter values, of the form\n",
      "     |          `param_name: fixed_value`. See the `param_names` property for valid\n",
      "     |          parameter names.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> mod = sm.tsa.SARIMAX(endog, order=(1, 0, 1))\n",
      "     |      >>> with mod.fix_params({'ar.L1': 0.5}):\n",
      "     |              res = mod.fit()\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from statsmodels.tsa.exponential_smoothing.base.StateSpaceMLEModel:\n",
      "     |  \n",
      "     |  from_formula(formula, data, subset=None, drop_cols=None, *args, **kwargs) from builtins.type\n",
      "     |      Not implemented for state space models\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from statsmodels.tsa.exponential_smoothing.base.StateSpaceMLEModel:\n",
      "     |  \n",
      "     |  param_names\n",
      "     |      (list of str) List of human readable parameter names (for parameters\n",
      "     |      actually included in the model).\n",
      "     |  \n",
      "     |  start_params\n",
      "     |      (array) Starting parameters for maximum likelihood estimation.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from statsmodels.tsa.base.tsa_model.TimeSeriesModel:\n",
      "     |  \n",
      "     |  exog_names\n",
      "     |      The names of the exogenous variables.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from statsmodels.base.model.LikelihoodModel:\n",
      "     |  \n",
      "     |  information(self, params)\n",
      "     |      Fisher information matrix of model.\n",
      "     |      \n",
      "     |      Returns -1 * Hessian of the log-likelihood evaluated at params.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : ndarray\n",
      "     |          The model parameters.\n",
      "     |  \n",
      "     |  initialize(self)\n",
      "     |      Initialize (possibly re-initialize) a Model instance.\n",
      "     |      \n",
      "     |      For example, if the the design matrix of a linear model changes then\n",
      "     |      initialized can be used to recompute values using the modified design\n",
      "     |      matrix.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from statsmodels.base.model.Model:\n",
      "     |  \n",
      "     |  predict(self, params, exog=None, *args, **kwargs)\n",
      "     |      After a model has been fit predict returns the fitted values.\n",
      "     |      \n",
      "     |      This is a placeholder intended to be overwritten by individual models.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from statsmodels.base.model.Model:\n",
      "     |  \n",
      "     |  endog_names\n",
      "     |      Names of endogenous variables.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from statsmodels.base.model.Model:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class ExponentialSmoothing(statsmodels.tsa.base.tsa_model.TimeSeriesModel)\n",
      "     |  ExponentialSmoothing(endog, trend=None, damped_trend=False, seasonal=None, *, seasonal_periods=None, initialization_method='estimated', initial_level=None, initial_trend=None, initial_seasonal=None, use_boxcox=False, bounds=None, dates=None, freq=None, missing='none')\n",
      "     |  \n",
      "     |  Holt Winter's Exponential Smoothing\n",
      "     |  \n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  endog : array_like\n",
      "     |      The time series to model.\n",
      "     |  trend : {\"add\", \"mul\", \"additive\", \"multiplicative\", None}, optional\n",
      "     |      Type of trend component.\n",
      "     |  damped_trend : bool, optional\n",
      "     |      Should the trend component be damped.\n",
      "     |  seasonal : {\"add\", \"mul\", \"additive\", \"multiplicative\", None}, optional\n",
      "     |      Type of seasonal component.\n",
      "     |  seasonal_periods : int, optional\n",
      "     |      The number of periods in a complete seasonal cycle, e.g., 4 for\n",
      "     |      quarterly data or 7 for daily data with a weekly cycle.\n",
      "     |  initialization_method : str, optional\n",
      "     |      Method for initialize the recursions. One of:\n",
      "     |  \n",
      "     |      * None\n",
      "     |      * 'estimated'\n",
      "     |      * 'heuristic'\n",
      "     |      * 'legacy-heuristic'\n",
      "     |      * 'known'\n",
      "     |  \n",
      "     |      None defaults to the pre-0.12 behavior where initial values\n",
      "     |      are passed as part of ``fit``. If any of the other values are\n",
      "     |      passed, then the initial values must also be set when constructing\n",
      "     |      the model. If 'known' initialization is used, then `initial_level`\n",
      "     |      must be passed, as well as `initial_trend` and `initial_seasonal` if\n",
      "     |      applicable. Default is 'estimated'. \"legacy-heuristic\" uses the same\n",
      "     |      values that were used in statsmodels 0.11 and earlier.\n",
      "     |  initial_level : float, optional\n",
      "     |      The initial level component. Required if estimation method is \"known\".\n",
      "     |      If set using either \"estimated\" or \"heuristic\" this value is used.\n",
      "     |      This allows one or more of the initial values to be set while\n",
      "     |      deferring to the heuristic for others or estimating the unset\n",
      "     |      parameters.\n",
      "     |  initial_trend : float, optional\n",
      "     |      The initial trend component. Required if estimation method is \"known\".\n",
      "     |      If set using either \"estimated\" or \"heuristic\" this value is used.\n",
      "     |      This allows one or more of the initial values to be set while\n",
      "     |      deferring to the heuristic for others or estimating the unset\n",
      "     |      parameters.\n",
      "     |  initial_seasonal : array_like, optional\n",
      "     |      The initial seasonal component. An array of length `seasonal`\n",
      "     |      or length `seasonal - 1` (in which case the last initial value\n",
      "     |      is computed to make the average effect zero). Only used if\n",
      "     |      initialization is 'known'. Required if estimation method is \"known\".\n",
      "     |      If set using either \"estimated\" or \"heuristic\" this value is used.\n",
      "     |      This allows one or more of the initial values to be set while\n",
      "     |      deferring to the heuristic for others or estimating the unset\n",
      "     |      parameters.\n",
      "     |  use_boxcox : {True, False, 'log', float}, optional\n",
      "     |      Should the Box-Cox transform be applied to the data first? If 'log'\n",
      "     |      then apply the log. If float then use the value as lambda.\n",
      "     |  bounds : dict[str, tuple[float, float]], optional\n",
      "     |      An dictionary containing bounds for the parameters in the model,\n",
      "     |      excluding the initial values if estimated. The keys of the dictionary\n",
      "     |      are the variable names, e.g., smoothing_level or initial_slope.\n",
      "     |      The initial seasonal variables are labeled initial_seasonal.<j>\n",
      "     |      for j=0,...,m-1 where m is the number of period in a full season.\n",
      "     |      Use None to indicate a non-binding constraint, e.g., (0, None)\n",
      "     |      constrains a parameter to be non-negative.\n",
      "     |  dates : array_like of datetime, optional\n",
      "     |      An array-like object of datetime objects. If a Pandas object is given\n",
      "     |      for endog, it is assumed to have a DateIndex.\n",
      "     |  freq : str, optional\n",
      "     |      The frequency of the time-series. A Pandas offset or 'B', 'D', 'W',\n",
      "     |      'M', 'A', or 'Q'. This is optional if dates are given.\n",
      "     |  missing : str\n",
      "     |      Available options are 'none', 'drop', and 'raise'. If 'none', no nan\n",
      "     |      checking is done. If 'drop', any observations with nans are dropped.\n",
      "     |      If 'raise', an error is raised. Default is 'none'.\n",
      "     |  \n",
      "     |  Notes\n",
      "     |  -----\n",
      "     |  This is a full implementation of the holt winters exponential smoothing as\n",
      "     |  per [1]_. This includes all the unstable methods as well as the stable\n",
      "     |  methods. The implementation of the library covers the functionality of the\n",
      "     |  R library as much as possible whilst still being Pythonic.\n",
      "     |  \n",
      "     |  References\n",
      "     |  ----------\n",
      "     |  .. [1] Hyndman, Rob J., and George Athanasopoulos. Forecasting: principles\n",
      "     |      and practice. OTexts, 2014.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      ExponentialSmoothing\n",
      "     |      statsmodels.tsa.base.tsa_model.TimeSeriesModel\n",
      "     |      statsmodels.base.model.LikelihoodModel\n",
      "     |      statsmodels.base.model.Model\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, endog, trend=None, damped_trend=False, seasonal=None, *, seasonal_periods=None, initialization_method='estimated', initial_level=None, initial_trend=None, initial_seasonal=None, use_boxcox=False, bounds=None, dates=None, freq=None, missing='none')\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  fit(self, smoothing_level=None, smoothing_trend=None, smoothing_seasonal=None, damping_trend=None, *, optimized=True, remove_bias=False, start_params=None, method=None, minimize_kwargs=None, use_brute=True, use_boxcox=None, use_basinhopping=None, initial_level=None, initial_trend=None)\n",
      "     |      Fit the model\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      smoothing_level : float, optional\n",
      "     |          The alpha value of the simple exponential smoothing, if the value\n",
      "     |          is set then this value will be used as the value.\n",
      "     |      smoothing_trend :  float, optional\n",
      "     |          The beta value of the Holt's trend method, if the value is\n",
      "     |          set then this value will be used as the value.\n",
      "     |      smoothing_seasonal : float, optional\n",
      "     |          The gamma value of the holt winters seasonal method, if the value\n",
      "     |          is set then this value will be used as the value.\n",
      "     |      damping_trend : float, optional\n",
      "     |          The phi value of the damped method, if the value is\n",
      "     |          set then this value will be used as the value.\n",
      "     |      optimized : bool, optional\n",
      "     |          Estimate model parameters by maximizing the log-likelihood.\n",
      "     |      remove_bias : bool, optional\n",
      "     |          Remove bias from forecast values and fitted values by enforcing\n",
      "     |          that the average residual is equal to zero.\n",
      "     |      start_params : array_like, optional\n",
      "     |          Starting values to used when optimizing the fit.  If not provided,\n",
      "     |          starting values are determined using a combination of grid search\n",
      "     |          and reasonable values based on the initial values of the data. See\n",
      "     |          the notes for the structure of the model parameters.\n",
      "     |      method : str, default \"L-BFGS-B\"\n",
      "     |          The minimizer used. Valid options are \"L-BFGS-B\" , \"TNC\",\n",
      "     |          \"SLSQP\" (default), \"Powell\", \"trust-constr\", \"basinhopping\" (also\n",
      "     |          \"bh\") and \"least_squares\" (also \"ls\"). basinhopping tries multiple\n",
      "     |          starting values in an attempt to find a global minimizer in\n",
      "     |          non-convex problems, and so is slower than the others.\n",
      "     |      minimize_kwargs : dict[str, Any]\n",
      "     |          A dictionary of keyword arguments passed to SciPy's minimize\n",
      "     |          function if method is one of \"L-BFGS-B\", \"TNC\",\n",
      "     |          \"SLSQP\", \"Powell\", or \"trust-constr\", or SciPy's basinhopping\n",
      "     |          or least_squares functions. The valid keywords are optimizer\n",
      "     |          specific. Consult SciPy's documentation for the full set of\n",
      "     |          options.\n",
      "     |      use_brute : bool, optional\n",
      "     |          Search for good starting values using a brute force (grid)\n",
      "     |          optimizer. If False, a naive set of starting values is used.\n",
      "     |      use_boxcox : {True, False, 'log', float}, optional\n",
      "     |          Should the Box-Cox transform be applied to the data first? If 'log'\n",
      "     |          then apply the log. If float then use the value as lambda.\n",
      "     |      \n",
      "     |          .. deprecated:: 0.12\n",
      "     |      \n",
      "     |             Set use_boxcox when constructing the model\n",
      "     |      \n",
      "     |      use_basinhopping : bool, optional\n",
      "     |          Deprecated. Using Basin Hopping optimizer to find optimal values.\n",
      "     |          Use ``method`` instead.\n",
      "     |      \n",
      "     |          .. deprecated:: 0.12\n",
      "     |      \n",
      "     |             Use ``method`` instead.\n",
      "     |      \n",
      "     |      initial_level : float, optional\n",
      "     |          Value to use when initializing the fitted level.\n",
      "     |      \n",
      "     |          .. deprecated:: 0.12\n",
      "     |      \n",
      "     |             Set initial_level when constructing the model\n",
      "     |      \n",
      "     |      initial_trend : float, optional\n",
      "     |          Value to use when initializing the fitted trend.\n",
      "     |      \n",
      "     |          .. deprecated:: 0.12\n",
      "     |      \n",
      "     |             Set initial_trend when constructing the model\n",
      "     |             or set initialization_method.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      HoltWintersResults\n",
      "     |          See statsmodels.tsa.holtwinters.HoltWintersResults.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      This is a full implementation of the holt winters exponential smoothing\n",
      "     |      as per [1]. This includes all the unstable methods as well as the\n",
      "     |      stable methods. The implementation of the library covers the\n",
      "     |      functionality of the R library as much as possible whilst still\n",
      "     |      being Pythonic.\n",
      "     |      \n",
      "     |      The parameters are ordered\n",
      "     |      \n",
      "     |      [alpha, beta, gamma, initial_level, initial_trend, phi]\n",
      "     |      \n",
      "     |      which are then followed by m seasonal values if the model contains\n",
      "     |      a seasonal smoother. Any parameter not relevant for the model is\n",
      "     |      omitted. For example, a model that has a level and a seasonal\n",
      "     |      component, but no trend and is not damped, would have starting\n",
      "     |      values\n",
      "     |      \n",
      "     |      [alpha, gamma, initial_level, s0, s1, ..., s<m-1>]\n",
      "     |      \n",
      "     |      where sj is the initial value for seasonal component j.\n",
      "     |      \n",
      "     |      References\n",
      "     |      ----------\n",
      "     |      [1] Hyndman, Rob J., and George Athanasopoulos. Forecasting: principles\n",
      "     |          and practice. OTexts, 2014.\n",
      "     |  \n",
      "     |  fix_params(self, values)\n",
      "     |      Temporarily fix parameters for estimation.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      values : dict\n",
      "     |          Values to fix. The key is the parameter name and the value is the\n",
      "     |          fixed value.\n",
      "     |      \n",
      "     |      Yields\n",
      "     |      ------\n",
      "     |      None\n",
      "     |          No value returned.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> from statsmodels.datasets.macrodata import load_pandas\n",
      "     |      >>> data = load_pandas()\n",
      "     |      >>> import statsmodels.tsa.api as tsa\n",
      "     |      >>> mod = tsa.ExponentialSmoothing(data.data.realcons, trend=\"add\",\n",
      "     |      ...                                initialization_method=\"estimated\")\n",
      "     |      >>> with mod.fix_params({\"smoothing_level\": 0.2}):\n",
      "     |      ...     mod.fit()\n",
      "     |  \n",
      "     |  initial_values(self, initial_level=None, initial_trend=None, force=False)\n",
      "     |      Compute initial values used in the exponential smoothing recursions.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      initial_level : {float, None}\n",
      "     |          The initial value used for the level component.\n",
      "     |      initial_trend : {float, None}\n",
      "     |          The initial value used for the trend component.\n",
      "     |      force : bool\n",
      "     |          Force the calculation even if initial values exist.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      initial_level : float\n",
      "     |          The initial value used for the level component.\n",
      "     |      initial_trend : {float, None}\n",
      "     |          The initial value used for the trend component.\n",
      "     |      initial_seasons : list\n",
      "     |          The initial values used for the seasonal components.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Convenience function the exposes the values used to initialize the\n",
      "     |      recursions. When optimizing parameters these are used as starting\n",
      "     |      values.\n",
      "     |      \n",
      "     |      Method used to compute the initial value depends on when components\n",
      "     |      are included in the model.  In a simple exponential smoothing model\n",
      "     |      without trend or a seasonal components, the initial value is set to the\n",
      "     |      first observation. When a trend is added, the trend is initialized\n",
      "     |      either using y[1]/y[0], if multiplicative, or y[1]-y[0]. When the\n",
      "     |      seasonal component is added the initialization adapts to account for\n",
      "     |      the modified structure.\n",
      "     |  \n",
      "     |  predict(self, params, start=None, end=None)\n",
      "     |      In-sample and out-of-sample prediction.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : ndarray\n",
      "     |          The fitted model parameters.\n",
      "     |      start : int, str, or datetime\n",
      "     |          Zero-indexed observation number at which to start forecasting, ie.,\n",
      "     |          the first forecast is start. Can also be a date string to\n",
      "     |          parse or a datetime type.\n",
      "     |      end : int, str, or datetime\n",
      "     |          Zero-indexed observation number at which to end forecasting, ie.,\n",
      "     |          the first forecast is start. Can also be a date string to\n",
      "     |          parse or a datetime type.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      ndarray\n",
      "     |          The predicted values.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from statsmodels.tsa.base.tsa_model.TimeSeriesModel:\n",
      "     |  \n",
      "     |  exog_names\n",
      "     |      The names of the exogenous variables.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from statsmodels.base.model.LikelihoodModel:\n",
      "     |  \n",
      "     |  hessian(self, params)\n",
      "     |      The Hessian matrix of the model.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : ndarray\n",
      "     |          The parameters to use when evaluating the Hessian.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      ndarray\n",
      "     |          The hessian evaluated at the parameters.\n",
      "     |  \n",
      "     |  information(self, params)\n",
      "     |      Fisher information matrix of model.\n",
      "     |      \n",
      "     |      Returns -1 * Hessian of the log-likelihood evaluated at params.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : ndarray\n",
      "     |          The model parameters.\n",
      "     |  \n",
      "     |  initialize(self)\n",
      "     |      Initialize (possibly re-initialize) a Model instance.\n",
      "     |      \n",
      "     |      For example, if the the design matrix of a linear model changes then\n",
      "     |      initialized can be used to recompute values using the modified design\n",
      "     |      matrix.\n",
      "     |  \n",
      "     |  loglike(self, params)\n",
      "     |      Log-likelihood of model.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : ndarray\n",
      "     |          The model parameters used to compute the log-likelihood.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Must be overridden by subclasses.\n",
      "     |  \n",
      "     |  score(self, params)\n",
      "     |      Score vector of model.\n",
      "     |      \n",
      "     |      The gradient of logL with respect to each parameter.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : ndarray\n",
      "     |          The parameters to use when evaluating the Hessian.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      ndarray\n",
      "     |          The score vector evaluated at the parameters.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from statsmodels.base.model.Model:\n",
      "     |  \n",
      "     |  from_formula(formula, data, subset=None, drop_cols=None, *args, **kwargs) from builtins.type\n",
      "     |      Create a Model from a formula and dataframe.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      formula : str or generic Formula object\n",
      "     |          The formula specifying the model.\n",
      "     |      data : array_like\n",
      "     |          The data for the model. See Notes.\n",
      "     |      subset : array_like\n",
      "     |          An array-like object of booleans, integers, or index values that\n",
      "     |          indicate the subset of df to use in the model. Assumes df is a\n",
      "     |          `pandas.DataFrame`.\n",
      "     |      drop_cols : array_like\n",
      "     |          Columns to drop from the design matrix.  Cannot be used to\n",
      "     |          drop terms involving categoricals.\n",
      "     |      *args\n",
      "     |          Additional positional argument that are passed to the model.\n",
      "     |      **kwargs\n",
      "     |          These are passed to the model with one exception. The\n",
      "     |          ``eval_env`` keyword is passed to patsy. It can be either a\n",
      "     |          :class:`patsy:patsy.EvalEnvironment` object or an integer\n",
      "     |          indicating the depth of the namespace to use. For example, the\n",
      "     |          default ``eval_env=0`` uses the calling namespace. If you wish\n",
      "     |          to use a \"clean\" environment set ``eval_env=-1``.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      model\n",
      "     |          The model instance.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      data must define __getitem__ with the keys in the formula terms\n",
      "     |      args and kwargs are passed on to the model instantiation. E.g.,\n",
      "     |      a numpy structured or rec array, a dictionary, or a pandas DataFrame.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from statsmodels.base.model.Model:\n",
      "     |  \n",
      "     |  endog_names\n",
      "     |      Names of endogenous variables.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from statsmodels.base.model.Model:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class Holt(ExponentialSmoothing)\n",
      "     |  Holt(endog, exponential=False, damped_trend=False, initialization_method=None, initial_level=None, initial_trend=None)\n",
      "     |  \n",
      "     |  Holt's Exponential Smoothing\n",
      "     |  \n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  endog : array_like\n",
      "     |      The time series to model.\n",
      "     |  exponential : bool, optional\n",
      "     |      Type of trend component.\n",
      "     |  damped_trend : bool, optional\n",
      "     |      Should the trend component be damped.\n",
      "     |  initialization_method : str, optional\n",
      "     |      Method for initialize the recursions. One of:\n",
      "     |  \n",
      "     |      * None\n",
      "     |      * 'estimated'\n",
      "     |      * 'heuristic'\n",
      "     |      * 'legacy-heuristic'\n",
      "     |      * 'known'\n",
      "     |  \n",
      "     |      None defaults to the pre-0.12 behavior where initial values\n",
      "     |      are passed as part of ``fit``. If any of the other values are\n",
      "     |      passed, then the initial values must also be set when constructing\n",
      "     |      the model. If 'known' initialization is used, then `initial_level`\n",
      "     |      must be passed, as well as `initial_trend` and `initial_seasonal` if\n",
      "     |      applicable. Default is 'estimated'. \"legacy-heuristic\" uses the same\n",
      "     |      values that were used in statsmodels 0.11 and earlier.\n",
      "     |  initial_level : float, optional\n",
      "     |      The initial level component. Required if estimation method is \"known\".\n",
      "     |      If set using either \"estimated\" or \"heuristic\" this value is used.\n",
      "     |      This allows one or more of the initial values to be set while\n",
      "     |      deferring to the heuristic for others or estimating the unset\n",
      "     |      parameters.\n",
      "     |  initial_trend : float, optional\n",
      "     |      The initial trend component. Required if estimation method is \"known\".\n",
      "     |      If set using either \"estimated\" or \"heuristic\" this value is used.\n",
      "     |      This allows one or more of the initial values to be set while\n",
      "     |      deferring to the heuristic for others or estimating the unset\n",
      "     |      parameters.\n",
      "     |  \n",
      "     |  See Also\n",
      "     |  --------\n",
      "     |  ExponentialSmoothing\n",
      "     |      Exponential smoothing with trend and seasonal components.\n",
      "     |  SimpleExpSmoothing\n",
      "     |      Basic exponential smoothing with only a level component.\n",
      "     |  \n",
      "     |  Notes\n",
      "     |  -----\n",
      "     |  This is a full implementation of the Holt's exponential smoothing as\n",
      "     |  per [1]_. `Holt` is a restricted version of :class:`ExponentialSmoothing`.\n",
      "     |  \n",
      "     |  References\n",
      "     |  ----------\n",
      "     |  .. [1] Hyndman, Rob J., and George Athanasopoulos. Forecasting: principles\n",
      "     |      and practice. OTexts, 2014.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      Holt\n",
      "     |      ExponentialSmoothing\n",
      "     |      statsmodels.tsa.base.tsa_model.TimeSeriesModel\n",
      "     |      statsmodels.base.model.LikelihoodModel\n",
      "     |      statsmodels.base.model.Model\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, endog, exponential=False, damped_trend=False, initialization_method=None, initial_level=None, initial_trend=None)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  fit(self, smoothing_level=None, smoothing_trend=None, *, damping_trend=None, optimized=True, start_params=None, initial_level=None, initial_trend=None, use_brute=True, use_boxcox=None, remove_bias=False, method=None, minimize_kwargs=None)\n",
      "     |      Fit the model\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      smoothing_level : float, optional\n",
      "     |          The alpha value of the simple exponential smoothing, if the value\n",
      "     |          is set then this value will be used as the value.\n",
      "     |      smoothing_trend :  float, optional\n",
      "     |          The beta value of the Holt's trend method, if the value is\n",
      "     |          set then this value will be used as the value.\n",
      "     |      damping_trend : float, optional\n",
      "     |          The phi value of the damped method, if the value is\n",
      "     |          set then this value will be used as the value.\n",
      "     |      optimized : bool, optional\n",
      "     |          Estimate model parameters by maximizing the log-likelihood.\n",
      "     |      start_params : ndarray, optional\n",
      "     |          Starting values to used when optimizing the fit.  If not provided,\n",
      "     |          starting values are determined using a combination of grid search\n",
      "     |          and reasonable values based on the initial values of the data.\n",
      "     |      initial_level : float, optional\n",
      "     |          Value to use when initializing the fitted level.\n",
      "     |      \n",
      "     |          .. deprecated:: 0.12\n",
      "     |      \n",
      "     |             Set initial_level when constructing the model\n",
      "     |      \n",
      "     |      initial_trend : float, optional\n",
      "     |          Value to use when initializing the fitted trend.\n",
      "     |      \n",
      "     |          .. deprecated:: 0.12\n",
      "     |      \n",
      "     |             Set initial_trend when constructing the model\n",
      "     |      \n",
      "     |      use_brute : bool, optional\n",
      "     |          Search for good starting values using a brute force (grid)\n",
      "     |          optimizer. If False, a naive set of starting values is used.\n",
      "     |      use_boxcox : {True, False, 'log', float}, optional\n",
      "     |          Should the Box-Cox transform be applied to the data first? If 'log'\n",
      "     |          then apply the log. If float then use the value as lambda.\n",
      "     |      remove_bias : bool, optional\n",
      "     |          Remove bias from forecast values and fitted values by enforcing\n",
      "     |          that the average residual is equal to zero.\n",
      "     |      method : str, default \"L-BFGS-B\"\n",
      "     |          The minimizer used. Valid options are \"L-BFGS-B\" (default), \"TNC\",\n",
      "     |          \"SLSQP\", \"Powell\", \"trust-constr\", \"basinhopping\" (also \"bh\") and\n",
      "     |          \"least_squares\" (also \"ls\"). basinhopping tries multiple starting\n",
      "     |          values in an attempt to find a global minimizer in non-convex\n",
      "     |          problems, and so is slower than the others.\n",
      "     |      minimize_kwargs : dict[str, Any]\n",
      "     |          A dictionary of keyword arguments passed to SciPy's minimize\n",
      "     |          function if method is one of \"L-BFGS-B\" (default), \"TNC\",\n",
      "     |          \"SLSQP\", \"Powell\", or \"trust-constr\", or SciPy's basinhopping\n",
      "     |          or least_squares. The valid keywords are optimizer specific.\n",
      "     |          Consult SciPy's documentation for the full set of options.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      HoltWintersResults\n",
      "     |          See statsmodels.tsa.holtwinters.HoltWintersResults.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      This is a full implementation of the Holt's exponential smoothing as\n",
      "     |      per [1].\n",
      "     |      \n",
      "     |      References\n",
      "     |      ----------\n",
      "     |      [1] Hyndman, Rob J., and George Athanasopoulos. Forecasting: principles\n",
      "     |          and practice. OTexts, 2014.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from ExponentialSmoothing:\n",
      "     |  \n",
      "     |  fix_params(self, values)\n",
      "     |      Temporarily fix parameters for estimation.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      values : dict\n",
      "     |          Values to fix. The key is the parameter name and the value is the\n",
      "     |          fixed value.\n",
      "     |      \n",
      "     |      Yields\n",
      "     |      ------\n",
      "     |      None\n",
      "     |          No value returned.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> from statsmodels.datasets.macrodata import load_pandas\n",
      "     |      >>> data = load_pandas()\n",
      "     |      >>> import statsmodels.tsa.api as tsa\n",
      "     |      >>> mod = tsa.ExponentialSmoothing(data.data.realcons, trend=\"add\",\n",
      "     |      ...                                initialization_method=\"estimated\")\n",
      "     |      >>> with mod.fix_params({\"smoothing_level\": 0.2}):\n",
      "     |      ...     mod.fit()\n",
      "     |  \n",
      "     |  initial_values(self, initial_level=None, initial_trend=None, force=False)\n",
      "     |      Compute initial values used in the exponential smoothing recursions.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      initial_level : {float, None}\n",
      "     |          The initial value used for the level component.\n",
      "     |      initial_trend : {float, None}\n",
      "     |          The initial value used for the trend component.\n",
      "     |      force : bool\n",
      "     |          Force the calculation even if initial values exist.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      initial_level : float\n",
      "     |          The initial value used for the level component.\n",
      "     |      initial_trend : {float, None}\n",
      "     |          The initial value used for the trend component.\n",
      "     |      initial_seasons : list\n",
      "     |          The initial values used for the seasonal components.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Convenience function the exposes the values used to initialize the\n",
      "     |      recursions. When optimizing parameters these are used as starting\n",
      "     |      values.\n",
      "     |      \n",
      "     |      Method used to compute the initial value depends on when components\n",
      "     |      are included in the model.  In a simple exponential smoothing model\n",
      "     |      without trend or a seasonal components, the initial value is set to the\n",
      "     |      first observation. When a trend is added, the trend is initialized\n",
      "     |      either using y[1]/y[0], if multiplicative, or y[1]-y[0]. When the\n",
      "     |      seasonal component is added the initialization adapts to account for\n",
      "     |      the modified structure.\n",
      "     |  \n",
      "     |  predict(self, params, start=None, end=None)\n",
      "     |      In-sample and out-of-sample prediction.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : ndarray\n",
      "     |          The fitted model parameters.\n",
      "     |      start : int, str, or datetime\n",
      "     |          Zero-indexed observation number at which to start forecasting, ie.,\n",
      "     |          the first forecast is start. Can also be a date string to\n",
      "     |          parse or a datetime type.\n",
      "     |      end : int, str, or datetime\n",
      "     |          Zero-indexed observation number at which to end forecasting, ie.,\n",
      "     |          the first forecast is start. Can also be a date string to\n",
      "     |          parse or a datetime type.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      ndarray\n",
      "     |          The predicted values.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from statsmodels.tsa.base.tsa_model.TimeSeriesModel:\n",
      "     |  \n",
      "     |  exog_names\n",
      "     |      The names of the exogenous variables.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from statsmodels.base.model.LikelihoodModel:\n",
      "     |  \n",
      "     |  hessian(self, params)\n",
      "     |      The Hessian matrix of the model.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : ndarray\n",
      "     |          The parameters to use when evaluating the Hessian.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      ndarray\n",
      "     |          The hessian evaluated at the parameters.\n",
      "     |  \n",
      "     |  information(self, params)\n",
      "     |      Fisher information matrix of model.\n",
      "     |      \n",
      "     |      Returns -1 * Hessian of the log-likelihood evaluated at params.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : ndarray\n",
      "     |          The model parameters.\n",
      "     |  \n",
      "     |  initialize(self)\n",
      "     |      Initialize (possibly re-initialize) a Model instance.\n",
      "     |      \n",
      "     |      For example, if the the design matrix of a linear model changes then\n",
      "     |      initialized can be used to recompute values using the modified design\n",
      "     |      matrix.\n",
      "     |  \n",
      "     |  loglike(self, params)\n",
      "     |      Log-likelihood of model.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : ndarray\n",
      "     |          The model parameters used to compute the log-likelihood.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Must be overridden by subclasses.\n",
      "     |  \n",
      "     |  score(self, params)\n",
      "     |      Score vector of model.\n",
      "     |      \n",
      "     |      The gradient of logL with respect to each parameter.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : ndarray\n",
      "     |          The parameters to use when evaluating the Hessian.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      ndarray\n",
      "     |          The score vector evaluated at the parameters.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from statsmodels.base.model.Model:\n",
      "     |  \n",
      "     |  from_formula(formula, data, subset=None, drop_cols=None, *args, **kwargs) from builtins.type\n",
      "     |      Create a Model from a formula and dataframe.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      formula : str or generic Formula object\n",
      "     |          The formula specifying the model.\n",
      "     |      data : array_like\n",
      "     |          The data for the model. See Notes.\n",
      "     |      subset : array_like\n",
      "     |          An array-like object of booleans, integers, or index values that\n",
      "     |          indicate the subset of df to use in the model. Assumes df is a\n",
      "     |          `pandas.DataFrame`.\n",
      "     |      drop_cols : array_like\n",
      "     |          Columns to drop from the design matrix.  Cannot be used to\n",
      "     |          drop terms involving categoricals.\n",
      "     |      *args\n",
      "     |          Additional positional argument that are passed to the model.\n",
      "     |      **kwargs\n",
      "     |          These are passed to the model with one exception. The\n",
      "     |          ``eval_env`` keyword is passed to patsy. It can be either a\n",
      "     |          :class:`patsy:patsy.EvalEnvironment` object or an integer\n",
      "     |          indicating the depth of the namespace to use. For example, the\n",
      "     |          default ``eval_env=0`` uses the calling namespace. If you wish\n",
      "     |          to use a \"clean\" environment set ``eval_env=-1``.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      model\n",
      "     |          The model instance.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      data must define __getitem__ with the keys in the formula terms\n",
      "     |      args and kwargs are passed on to the model instantiation. E.g.,\n",
      "     |      a numpy structured or rec array, a dictionary, or a pandas DataFrame.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from statsmodels.base.model.Model:\n",
      "     |  \n",
      "     |  endog_names\n",
      "     |      Names of endogenous variables.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from statsmodels.base.model.Model:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class MarkovAutoregression(statsmodels.tsa.regime_switching.markov_regression.MarkovRegression)\n",
      "     |  MarkovAutoregression(endog, k_regimes, order, trend='c', exog=None, exog_tvtp=None, switching_ar=True, switching_trend=True, switching_exog=False, switching_variance=False, dates=None, freq=None, missing='none')\n",
      "     |  \n",
      "     |  Markov switching regression model\n",
      "     |  \n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  endog : array_like\n",
      "     |      The endogenous variable.\n",
      "     |  k_regimes : int\n",
      "     |      The number of regimes.\n",
      "     |  order : int\n",
      "     |      The order of the autoregressive lag polynomial.\n",
      "     |  trend : {'n', 'c', 't', 'ct'}\n",
      "     |      Whether or not to include a trend. To include an constant, time trend,\n",
      "     |      or both, set `trend='c'`, `trend='t'`, or `trend='ct'`. For no trend,\n",
      "     |      set `trend='n'`. Default is a constant.\n",
      "     |  exog : array_like, optional\n",
      "     |      Array of exogenous regressors, shaped nobs x k.\n",
      "     |  exog_tvtp : array_like, optional\n",
      "     |      Array of exogenous or lagged variables to use in calculating\n",
      "     |      time-varying transition probabilities (TVTP). TVTP is only used if this\n",
      "     |      variable is provided. If an intercept is desired, a column of ones must\n",
      "     |      be explicitly included in this array.\n",
      "     |  switching_ar : bool or iterable, optional\n",
      "     |      If a boolean, sets whether or not all autoregressive coefficients are\n",
      "     |      switching across regimes. If an iterable, should be of length equal\n",
      "     |      to `order`, where each element is a boolean describing whether the\n",
      "     |      corresponding coefficient is switching. Default is True.\n",
      "     |  switching_trend : bool or iterable, optional\n",
      "     |      If a boolean, sets whether or not all trend coefficients are\n",
      "     |      switching across regimes. If an iterable, should be of length equal\n",
      "     |      to the number of trend variables, where each element is\n",
      "     |      a boolean describing whether the corresponding coefficient is\n",
      "     |      switching. Default is True.\n",
      "     |  switching_exog : bool or iterable, optional\n",
      "     |      If a boolean, sets whether or not all regression coefficients are\n",
      "     |      switching across regimes. If an iterable, should be of length equal\n",
      "     |      to the number of exogenous variables, where each element is\n",
      "     |      a boolean describing whether the corresponding coefficient is\n",
      "     |      switching. Default is True.\n",
      "     |  switching_variance : bool, optional\n",
      "     |      Whether or not there is regime-specific heteroskedasticity, i.e.\n",
      "     |      whether or not the error term has a switching variance. Default is\n",
      "     |      False.\n",
      "     |  \n",
      "     |  Notes\n",
      "     |  -----\n",
      "     |  This model is new and API stability is not guaranteed, although changes\n",
      "     |  will be made in a backwards compatible way if possible.\n",
      "     |  \n",
      "     |  The model can be written as:\n",
      "     |  \n",
      "     |  .. math::\n",
      "     |  \n",
      "     |      y_t = a_{S_t} + x_t' \\beta_{S_t} + \\phi_{1, S_t}\n",
      "     |      (y_{t-1} - a_{S_{t-1}} - x_{t-1}' \\beta_{S_{t-1}}) + \\dots +\n",
      "     |      \\phi_{p, S_t} (y_{t-p} - a_{S_{t-p}} - x_{t-p}' \\beta_{S_{t-p}}) +\n",
      "     |      \\varepsilon_t \\\\\n",
      "     |      \\varepsilon_t \\sim N(0, \\sigma_{S_t}^2)\n",
      "     |  \n",
      "     |  i.e. the model is an autoregression with where the autoregressive\n",
      "     |  coefficients, the mean of the process (possibly including trend or\n",
      "     |  regression effects) and the variance of the error term may be switching\n",
      "     |  across regimes.\n",
      "     |  \n",
      "     |  The `trend` is accommodated by prepending columns to the `exog` array. Thus\n",
      "     |  if `trend='c'`, the passed `exog` array should not already have a column of\n",
      "     |  ones.\n",
      "     |  \n",
      "     |  References\n",
      "     |  ----------\n",
      "     |  Kim, Chang-Jin, and Charles R. Nelson. 1999.\n",
      "     |  \"State-Space Models with Regime Switching:\n",
      "     |  Classical and Gibbs-Sampling Approaches with Applications\".\n",
      "     |  MIT Press Books. The MIT Press.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      MarkovAutoregression\n",
      "     |      statsmodels.tsa.regime_switching.markov_regression.MarkovRegression\n",
      "     |      statsmodels.tsa.regime_switching.markov_switching.MarkovSwitching\n",
      "     |      statsmodels.tsa.base.tsa_model.TimeSeriesModel\n",
      "     |      statsmodels.base.model.LikelihoodModel\n",
      "     |      statsmodels.base.model.Model\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, endog, k_regimes, order, trend='c', exog=None, exog_tvtp=None, switching_ar=True, switching_trend=True, switching_exog=False, switching_variance=False, dates=None, freq=None, missing='none')\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  predict_conditional(self, params)\n",
      "     |      In-sample prediction, conditional on the current and previous regime\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : array_like\n",
      "     |          Array of parameters at which to create predictions.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      predict : array_like\n",
      "     |          Array of predictions conditional on current, and possibly past,\n",
      "     |          regimes\n",
      "     |  \n",
      "     |  transform_params(self, unconstrained)\n",
      "     |      Transform unconstrained parameters used by the optimizer to constrained\n",
      "     |      parameters used in likelihood evaluation\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      unconstrained : array_like\n",
      "     |          Array of unconstrained parameters used by the optimizer, to be\n",
      "     |          transformed.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      constrained : array_like\n",
      "     |          Array of constrained parameters which may be used in likelihood\n",
      "     |          evaluation.\n",
      "     |  \n",
      "     |  untransform_params(self, constrained)\n",
      "     |      Transform constrained parameters used in likelihood evaluation\n",
      "     |      to unconstrained parameters used by the optimizer\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      constrained : array_like\n",
      "     |          Array of constrained parameters used in likelihood evaluation, to\n",
      "     |          be transformed.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      unconstrained : array_like\n",
      "     |          Array of unconstrained parameters used by the optimizer.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties defined here:\n",
      "     |  \n",
      "     |  param_names\n",
      "     |      (list of str) List of human readable parameter names (for parameters\n",
      "     |      actually included in the model).\n",
      "     |  \n",
      "     |  start_params\n",
      "     |      (array) Starting parameters for maximum likelihood estimation.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from statsmodels.tsa.regime_switching.markov_switching.MarkovSwitching:\n",
      "     |  \n",
      "     |  filter(self, params, transformed=True, cov_type=None, cov_kwds=None, return_raw=False, results_class=None, results_wrapper_class=None)\n",
      "     |      Apply the Hamilton filter\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : array_like\n",
      "     |          Array of parameters at which to perform filtering.\n",
      "     |      transformed : bool, optional\n",
      "     |          Whether or not `params` is already transformed. Default is True.\n",
      "     |      cov_type : str, optional\n",
      "     |          See `fit` for a description of covariance matrix types\n",
      "     |          for results object.\n",
      "     |      cov_kwds : dict or None, optional\n",
      "     |          See `fit` for a description of required keywords for alternative\n",
      "     |          covariance estimators\n",
      "     |      return_raw : bool,optional\n",
      "     |          Whether or not to return only the raw Hamilton filter output or a\n",
      "     |          full results object. Default is to return a full results object.\n",
      "     |      results_class : type, optional\n",
      "     |          A results class to instantiate rather than\n",
      "     |          `MarkovSwitchingResults`. Usually only used internally by\n",
      "     |          subclasses.\n",
      "     |      results_wrapper_class : type, optional\n",
      "     |          A results wrapper class to instantiate rather than\n",
      "     |          `MarkovSwitchingResults`. Usually only used internally by\n",
      "     |          subclasses.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      MarkovSwitchingResults\n",
      "     |  \n",
      "     |  fit(self, start_params=None, transformed=True, cov_type='approx', cov_kwds=None, method='bfgs', maxiter=100, full_output=1, disp=0, callback=None, return_params=False, em_iter=5, search_reps=0, search_iter=5, search_scale=1.0, **kwargs)\n",
      "     |      Fits the model by maximum likelihood via Hamilton filter.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      start_params : array_like, optional\n",
      "     |          Initial guess of the solution for the loglikelihood maximization.\n",
      "     |          If None, the default is given by Model.start_params.\n",
      "     |      transformed : bool, optional\n",
      "     |          Whether or not `start_params` is already transformed. Default is\n",
      "     |          True.\n",
      "     |      cov_type : str, optional\n",
      "     |          The type of covariance matrix estimator to use. Can be one of\n",
      "     |          'approx', 'opg', 'robust', or 'none'. Default is 'approx'.\n",
      "     |      cov_kwds : dict or None, optional\n",
      "     |          Keywords for alternative covariance estimators\n",
      "     |      method : str, optional\n",
      "     |          The `method` determines which solver from `scipy.optimize`\n",
      "     |          is used, and it can be chosen from among the following strings:\n",
      "     |      \n",
      "     |          - 'newton' for Newton-Raphson, 'nm' for Nelder-Mead\n",
      "     |          - 'bfgs' for Broyden-Fletcher-Goldfarb-Shanno (BFGS)\n",
      "     |          - 'lbfgs' for limited-memory BFGS with optional box constraints\n",
      "     |          - 'powell' for modified Powell's method\n",
      "     |          - 'cg' for conjugate gradient\n",
      "     |          - 'ncg' for Newton-conjugate gradient\n",
      "     |          - 'basinhopping' for global basin-hopping solver\n",
      "     |      \n",
      "     |          The explicit arguments in `fit` are passed to the solver,\n",
      "     |          with the exception of the basin-hopping solver. Each\n",
      "     |          solver has several optional arguments that are not the same across\n",
      "     |          solvers. See the notes section below (or scipy.optimize) for the\n",
      "     |          available arguments and for the list of explicit arguments that the\n",
      "     |          basin-hopping solver supports.\n",
      "     |      maxiter : int, optional\n",
      "     |          The maximum number of iterations to perform.\n",
      "     |      full_output : bool, optional\n",
      "     |          Set to True to have all available output in the Results object's\n",
      "     |          mle_retvals attribute. The output is dependent on the solver.\n",
      "     |          See LikelihoodModelResults notes section for more information.\n",
      "     |      disp : bool, optional\n",
      "     |          Set to True to print convergence messages.\n",
      "     |      callback : callable callback(xk), optional\n",
      "     |          Called after each iteration, as callback(xk), where xk is the\n",
      "     |          current parameter vector.\n",
      "     |      return_params : bool, optional\n",
      "     |          Whether or not to return only the array of maximizing parameters.\n",
      "     |          Default is False.\n",
      "     |      em_iter : int, optional\n",
      "     |          Number of initial EM iteration steps used to improve starting\n",
      "     |          parameters.\n",
      "     |      search_reps : int, optional\n",
      "     |          Number of randomly drawn search parameters that are drawn around\n",
      "     |          `start_params` to try and improve starting parameters. Default is\n",
      "     |          0.\n",
      "     |      search_iter : int, optional\n",
      "     |          Number of initial EM iteration steps used to improve each of the\n",
      "     |          search parameter repetitions.\n",
      "     |      search_scale : float or array, optional.\n",
      "     |          Scale of variates for random start parameter search.\n",
      "     |      **kwargs\n",
      "     |          Additional keyword arguments to pass to the optimizer.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      MarkovSwitchingResults\n",
      "     |  \n",
      "     |  hessian(self, params, transformed=True)\n",
      "     |      Hessian matrix of the likelihood function, evaluated at the given\n",
      "     |      parameters\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : array_like\n",
      "     |          Array of parameters at which to evaluate the Hessian\n",
      "     |          function.\n",
      "     |      transformed : bool, optional\n",
      "     |          Whether or not `params` is already transformed. Default is True.\n",
      "     |  \n",
      "     |  initial_probabilities(self, params, regime_transition=None)\n",
      "     |      Retrieve initial probabilities\n",
      "     |  \n",
      "     |  initialize_known(self, probabilities, tol=1e-08)\n",
      "     |      Set initialization of regime probabilities to use known values\n",
      "     |  \n",
      "     |  initialize_steady_state(self)\n",
      "     |      Set initialization of regime probabilities to be steady-state values\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Only valid if there are not time-varying transition probabilities.\n",
      "     |  \n",
      "     |  loglike(self, params, transformed=True)\n",
      "     |      Loglikelihood evaluation\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : array_like\n",
      "     |          Array of parameters at which to evaluate the loglikelihood\n",
      "     |          function.\n",
      "     |      transformed : bool, optional\n",
      "     |          Whether or not `params` is already transformed. Default is True.\n",
      "     |  \n",
      "     |  loglikeobs(self, params, transformed=True)\n",
      "     |      Loglikelihood evaluation for each period\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : array_like\n",
      "     |          Array of parameters at which to evaluate the loglikelihood\n",
      "     |          function.\n",
      "     |      transformed : bool, optional\n",
      "     |          Whether or not `params` is already transformed. Default is True.\n",
      "     |  \n",
      "     |  predict(self, params, start=None, end=None, probabilities=None, conditional=False)\n",
      "     |      In-sample prediction and out-of-sample forecasting\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : ndarray\n",
      "     |          Parameters at which to form predictions\n",
      "     |      start : int, str, or datetime, optional\n",
      "     |          Zero-indexed observation number at which to start forecasting,\n",
      "     |          i.e., the first forecast is start. Can also be a date string to\n",
      "     |          parse or a datetime type. Default is the the zeroth observation.\n",
      "     |      end : int, str, or datetime, optional\n",
      "     |          Zero-indexed observation number at which to end forecasting, i.e.,\n",
      "     |          the last forecast is end. Can also be a date string to\n",
      "     |          parse or a datetime type. However, if the dates index does not\n",
      "     |          have a fixed frequency, end must be an integer index if you\n",
      "     |          want out of sample prediction. Default is the last observation in\n",
      "     |          the sample.\n",
      "     |      probabilities : str or array_like, optional\n",
      "     |          Specifies the weighting probabilities used in constructing the\n",
      "     |          prediction as a weighted average. If a string, can be 'predicted',\n",
      "     |          'filtered', or 'smoothed'. Otherwise can be an array of\n",
      "     |          probabilities to use. Default is smoothed.\n",
      "     |      conditional : bool or int, optional\n",
      "     |          Whether or not to return predictions conditional on current or\n",
      "     |          past regimes. If False, returns a single vector of weighted\n",
      "     |          predictions. If True or 1, returns predictions conditional on the\n",
      "     |          current regime. For larger integers, returns predictions\n",
      "     |          conditional on the current regime and some number of past regimes.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      predict : ndarray\n",
      "     |          Array of out of in-sample predictions and / or out-of-sample\n",
      "     |          forecasts.\n",
      "     |  \n",
      "     |  regime_transition_matrix(self, params, exog_tvtp=None)\n",
      "     |      Construct the left-stochastic transition matrix\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      This matrix will either be shaped (k_regimes, k_regimes, 1) or if there\n",
      "     |      are time-varying transition probabilities, it will be shaped\n",
      "     |      (k_regimes, k_regimes, nobs).\n",
      "     |      \n",
      "     |      The (i,j)th element of this matrix is the probability of transitioning\n",
      "     |      from regime j to regime i; thus the previous regime is represented in a\n",
      "     |      column and the next regime is represented by a row.\n",
      "     |      \n",
      "     |      It is left-stochastic, meaning that each column sums to one (because\n",
      "     |      it is certain that from one regime (j) you will transition to *some\n",
      "     |      other regime*).\n",
      "     |  \n",
      "     |  score(self, params, transformed=True)\n",
      "     |      Compute the score function at params.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : array_like\n",
      "     |          Array of parameters at which to evaluate the score\n",
      "     |          function.\n",
      "     |      transformed : bool, optional\n",
      "     |          Whether or not `params` is already transformed. Default is True.\n",
      "     |  \n",
      "     |  score_obs(self, params, transformed=True)\n",
      "     |      Compute the score per observation, evaluated at params\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : array_like\n",
      "     |          Array of parameters at which to evaluate the score\n",
      "     |          function.\n",
      "     |      transformed : bool, optional\n",
      "     |          Whether or not `params` is already transformed. Default is True.\n",
      "     |  \n",
      "     |  smooth(self, params, transformed=True, cov_type=None, cov_kwds=None, return_raw=False, results_class=None, results_wrapper_class=None)\n",
      "     |      Apply the Kim smoother and Hamilton filter\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : array_like\n",
      "     |          Array of parameters at which to perform filtering.\n",
      "     |      transformed : bool, optional\n",
      "     |          Whether or not `params` is already transformed. Default is True.\n",
      "     |      cov_type : str, optional\n",
      "     |          See `fit` for a description of covariance matrix types\n",
      "     |          for results object.\n",
      "     |      cov_kwds : dict or None, optional\n",
      "     |          See `fit` for a description of required keywords for alternative\n",
      "     |          covariance estimators\n",
      "     |      return_raw : bool,optional\n",
      "     |          Whether or not to return only the raw Hamilton filter output or a\n",
      "     |          full results object. Default is to return a full results object.\n",
      "     |      results_class : type, optional\n",
      "     |          A results class to instantiate rather than\n",
      "     |          `MarkovSwitchingResults`. Usually only used internally by\n",
      "     |          subclasses.\n",
      "     |      results_wrapper_class : type, optional\n",
      "     |          A results wrapper class to instantiate rather than\n",
      "     |          `MarkovSwitchingResults`. Usually only used internally by\n",
      "     |          subclasses.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      MarkovSwitchingResults\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from statsmodels.tsa.regime_switching.markov_switching.MarkovSwitching:\n",
      "     |  \n",
      "     |  k_params\n",
      "     |      (int) Number of parameters in the model\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from statsmodels.tsa.base.tsa_model.TimeSeriesModel:\n",
      "     |  \n",
      "     |  exog_names\n",
      "     |      The names of the exogenous variables.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from statsmodels.base.model.LikelihoodModel:\n",
      "     |  \n",
      "     |  information(self, params)\n",
      "     |      Fisher information matrix of model.\n",
      "     |      \n",
      "     |      Returns -1 * Hessian of the log-likelihood evaluated at params.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : ndarray\n",
      "     |          The model parameters.\n",
      "     |  \n",
      "     |  initialize(self)\n",
      "     |      Initialize (possibly re-initialize) a Model instance.\n",
      "     |      \n",
      "     |      For example, if the the design matrix of a linear model changes then\n",
      "     |      initialized can be used to recompute values using the modified design\n",
      "     |      matrix.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from statsmodels.base.model.Model:\n",
      "     |  \n",
      "     |  from_formula(formula, data, subset=None, drop_cols=None, *args, **kwargs) from builtins.type\n",
      "     |      Create a Model from a formula and dataframe.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      formula : str or generic Formula object\n",
      "     |          The formula specifying the model.\n",
      "     |      data : array_like\n",
      "     |          The data for the model. See Notes.\n",
      "     |      subset : array_like\n",
      "     |          An array-like object of booleans, integers, or index values that\n",
      "     |          indicate the subset of df to use in the model. Assumes df is a\n",
      "     |          `pandas.DataFrame`.\n",
      "     |      drop_cols : array_like\n",
      "     |          Columns to drop from the design matrix.  Cannot be used to\n",
      "     |          drop terms involving categoricals.\n",
      "     |      *args\n",
      "     |          Additional positional argument that are passed to the model.\n",
      "     |      **kwargs\n",
      "     |          These are passed to the model with one exception. The\n",
      "     |          ``eval_env`` keyword is passed to patsy. It can be either a\n",
      "     |          :class:`patsy:patsy.EvalEnvironment` object or an integer\n",
      "     |          indicating the depth of the namespace to use. For example, the\n",
      "     |          default ``eval_env=0`` uses the calling namespace. If you wish\n",
      "     |          to use a \"clean\" environment set ``eval_env=-1``.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      model\n",
      "     |          The model instance.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      data must define __getitem__ with the keys in the formula terms\n",
      "     |      args and kwargs are passed on to the model instantiation. E.g.,\n",
      "     |      a numpy structured or rec array, a dictionary, or a pandas DataFrame.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from statsmodels.base.model.Model:\n",
      "     |  \n",
      "     |  endog_names\n",
      "     |      Names of endogenous variables.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from statsmodels.base.model.Model:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class MarkovRegression(statsmodels.tsa.regime_switching.markov_switching.MarkovSwitching)\n",
      "     |  MarkovRegression(endog, k_regimes, trend='c', exog=None, order=0, exog_tvtp=None, switching_trend=True, switching_exog=True, switching_variance=False, dates=None, freq=None, missing='none')\n",
      "     |  \n",
      "     |  First-order k-regime Markov switching regression model\n",
      "     |  \n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  endog : array_like\n",
      "     |      The endogenous variable.\n",
      "     |  k_regimes : int\n",
      "     |      The number of regimes.\n",
      "     |  trend : {'n', 'c', 't', 'ct'}\n",
      "     |      Whether or not to include a trend. To include an intercept, time trend,\n",
      "     |      or both, set `trend='c'`, `trend='t'`, or `trend='ct'`. For no trend,\n",
      "     |      set `trend='n'`. Default is an intercept.\n",
      "     |  exog : array_like, optional\n",
      "     |      Array of exogenous regressors, shaped nobs x k.\n",
      "     |  order : int, optional\n",
      "     |      The order of the model describes the dependence of the likelihood on\n",
      "     |      previous regimes. This depends on the model in question and should be\n",
      "     |      set appropriately by subclasses.\n",
      "     |  exog_tvtp : array_like, optional\n",
      "     |      Array of exogenous or lagged variables to use in calculating\n",
      "     |      time-varying transition probabilities (TVTP). TVTP is only used if this\n",
      "     |      variable is provided. If an intercept is desired, a column of ones must\n",
      "     |      be explicitly included in this array.\n",
      "     |  switching_trend : bool or iterable, optional\n",
      "     |      If a boolean, sets whether or not all trend coefficients are\n",
      "     |      switching across regimes. If an iterable, should be of length equal\n",
      "     |      to the number of trend variables, where each element is\n",
      "     |      a boolean describing whether the corresponding coefficient is\n",
      "     |      switching. Default is True.\n",
      "     |  switching_exog : bool or iterable, optional\n",
      "     |      If a boolean, sets whether or not all regression coefficients are\n",
      "     |      switching across regimes. If an iterable, should be of length equal\n",
      "     |      to the number of exogenous variables, where each element is\n",
      "     |      a boolean describing whether the corresponding coefficient is\n",
      "     |      switching. Default is True.\n",
      "     |  switching_variance : bool, optional\n",
      "     |      Whether or not there is regime-specific heteroskedasticity, i.e.\n",
      "     |      whether or not the error term has a switching variance. Default is\n",
      "     |      False.\n",
      "     |  \n",
      "     |  Notes\n",
      "     |  -----\n",
      "     |  This model is new and API stability is not guaranteed, although changes\n",
      "     |  will be made in a backwards compatible way if possible.\n",
      "     |  \n",
      "     |  The model can be written as:\n",
      "     |  \n",
      "     |  .. math::\n",
      "     |  \n",
      "     |      y_t = a_{S_t} + x_t' \\beta_{S_t} + \\varepsilon_t \\\\\n",
      "     |      \\varepsilon_t \\sim N(0, \\sigma_{S_t}^2)\n",
      "     |  \n",
      "     |  i.e. the model is a dynamic linear regression where the coefficients and\n",
      "     |  the variance of the error term may be switching across regimes.\n",
      "     |  \n",
      "     |  The `trend` is accommodated by prepending columns to the `exog` array. Thus\n",
      "     |  if `trend='c'`, the passed `exog` array should not already have a column of\n",
      "     |  ones.\n",
      "     |  \n",
      "     |  References\n",
      "     |  ----------\n",
      "     |  Kim, Chang-Jin, and Charles R. Nelson. 1999.\n",
      "     |  \"State-Space Models with Regime Switching:\n",
      "     |  Classical and Gibbs-Sampling Approaches with Applications\".\n",
      "     |  MIT Press Books. The MIT Press.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      MarkovRegression\n",
      "     |      statsmodels.tsa.regime_switching.markov_switching.MarkovSwitching\n",
      "     |      statsmodels.tsa.base.tsa_model.TimeSeriesModel\n",
      "     |      statsmodels.base.model.LikelihoodModel\n",
      "     |      statsmodels.base.model.Model\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, endog, k_regimes, trend='c', exog=None, order=0, exog_tvtp=None, switching_trend=True, switching_exog=True, switching_variance=False, dates=None, freq=None, missing='none')\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  predict_conditional(self, params)\n",
      "     |      In-sample prediction, conditional on the current regime\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : array_like\n",
      "     |          Array of parameters at which to perform prediction.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      predict : array_like\n",
      "     |          Array of predictions conditional on current, and possibly past,\n",
      "     |          regimes\n",
      "     |  \n",
      "     |  transform_params(self, unconstrained)\n",
      "     |      Transform unconstrained parameters used by the optimizer to constrained\n",
      "     |      parameters used in likelihood evaluation\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      unconstrained : array_like\n",
      "     |          Array of unconstrained parameters used by the optimizer, to be\n",
      "     |          transformed.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      constrained : array_like\n",
      "     |          Array of constrained parameters which may be used in likelihood\n",
      "     |          evaluation.\n",
      "     |  \n",
      "     |  untransform_params(self, constrained)\n",
      "     |      Transform constrained parameters used in likelihood evaluation\n",
      "     |      to unconstrained parameters used by the optimizer\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      constrained : array_like\n",
      "     |          Array of constrained parameters used in likelihood evaluation, to\n",
      "     |          be transformed.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      unconstrained : array_like\n",
      "     |          Array of unconstrained parameters used by the optimizer.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties defined here:\n",
      "     |  \n",
      "     |  param_names\n",
      "     |      (list of str) List of human readable parameter names (for parameters\n",
      "     |      actually included in the model).\n",
      "     |  \n",
      "     |  start_params\n",
      "     |      (array) Starting parameters for maximum likelihood estimation.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      These are not very sophisticated and / or good. We set equal transition\n",
      "     |      probabilities and interpolate regression coefficients between zero and\n",
      "     |      the OLS estimates, where the interpolation is based on the regime\n",
      "     |      number. We rely heavily on the EM algorithm to quickly find much better\n",
      "     |      starting parameters, which are then used by the typical scoring\n",
      "     |      approach.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from statsmodels.tsa.regime_switching.markov_switching.MarkovSwitching:\n",
      "     |  \n",
      "     |  filter(self, params, transformed=True, cov_type=None, cov_kwds=None, return_raw=False, results_class=None, results_wrapper_class=None)\n",
      "     |      Apply the Hamilton filter\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : array_like\n",
      "     |          Array of parameters at which to perform filtering.\n",
      "     |      transformed : bool, optional\n",
      "     |          Whether or not `params` is already transformed. Default is True.\n",
      "     |      cov_type : str, optional\n",
      "     |          See `fit` for a description of covariance matrix types\n",
      "     |          for results object.\n",
      "     |      cov_kwds : dict or None, optional\n",
      "     |          See `fit` for a description of required keywords for alternative\n",
      "     |          covariance estimators\n",
      "     |      return_raw : bool,optional\n",
      "     |          Whether or not to return only the raw Hamilton filter output or a\n",
      "     |          full results object. Default is to return a full results object.\n",
      "     |      results_class : type, optional\n",
      "     |          A results class to instantiate rather than\n",
      "     |          `MarkovSwitchingResults`. Usually only used internally by\n",
      "     |          subclasses.\n",
      "     |      results_wrapper_class : type, optional\n",
      "     |          A results wrapper class to instantiate rather than\n",
      "     |          `MarkovSwitchingResults`. Usually only used internally by\n",
      "     |          subclasses.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      MarkovSwitchingResults\n",
      "     |  \n",
      "     |  fit(self, start_params=None, transformed=True, cov_type='approx', cov_kwds=None, method='bfgs', maxiter=100, full_output=1, disp=0, callback=None, return_params=False, em_iter=5, search_reps=0, search_iter=5, search_scale=1.0, **kwargs)\n",
      "     |      Fits the model by maximum likelihood via Hamilton filter.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      start_params : array_like, optional\n",
      "     |          Initial guess of the solution for the loglikelihood maximization.\n",
      "     |          If None, the default is given by Model.start_params.\n",
      "     |      transformed : bool, optional\n",
      "     |          Whether or not `start_params` is already transformed. Default is\n",
      "     |          True.\n",
      "     |      cov_type : str, optional\n",
      "     |          The type of covariance matrix estimator to use. Can be one of\n",
      "     |          'approx', 'opg', 'robust', or 'none'. Default is 'approx'.\n",
      "     |      cov_kwds : dict or None, optional\n",
      "     |          Keywords for alternative covariance estimators\n",
      "     |      method : str, optional\n",
      "     |          The `method` determines which solver from `scipy.optimize`\n",
      "     |          is used, and it can be chosen from among the following strings:\n",
      "     |      \n",
      "     |          - 'newton' for Newton-Raphson, 'nm' for Nelder-Mead\n",
      "     |          - 'bfgs' for Broyden-Fletcher-Goldfarb-Shanno (BFGS)\n",
      "     |          - 'lbfgs' for limited-memory BFGS with optional box constraints\n",
      "     |          - 'powell' for modified Powell's method\n",
      "     |          - 'cg' for conjugate gradient\n",
      "     |          - 'ncg' for Newton-conjugate gradient\n",
      "     |          - 'basinhopping' for global basin-hopping solver\n",
      "     |      \n",
      "     |          The explicit arguments in `fit` are passed to the solver,\n",
      "     |          with the exception of the basin-hopping solver. Each\n",
      "     |          solver has several optional arguments that are not the same across\n",
      "     |          solvers. See the notes section below (or scipy.optimize) for the\n",
      "     |          available arguments and for the list of explicit arguments that the\n",
      "     |          basin-hopping solver supports.\n",
      "     |      maxiter : int, optional\n",
      "     |          The maximum number of iterations to perform.\n",
      "     |      full_output : bool, optional\n",
      "     |          Set to True to have all available output in the Results object's\n",
      "     |          mle_retvals attribute. The output is dependent on the solver.\n",
      "     |          See LikelihoodModelResults notes section for more information.\n",
      "     |      disp : bool, optional\n",
      "     |          Set to True to print convergence messages.\n",
      "     |      callback : callable callback(xk), optional\n",
      "     |          Called after each iteration, as callback(xk), where xk is the\n",
      "     |          current parameter vector.\n",
      "     |      return_params : bool, optional\n",
      "     |          Whether or not to return only the array of maximizing parameters.\n",
      "     |          Default is False.\n",
      "     |      em_iter : int, optional\n",
      "     |          Number of initial EM iteration steps used to improve starting\n",
      "     |          parameters.\n",
      "     |      search_reps : int, optional\n",
      "     |          Number of randomly drawn search parameters that are drawn around\n",
      "     |          `start_params` to try and improve starting parameters. Default is\n",
      "     |          0.\n",
      "     |      search_iter : int, optional\n",
      "     |          Number of initial EM iteration steps used to improve each of the\n",
      "     |          search parameter repetitions.\n",
      "     |      search_scale : float or array, optional.\n",
      "     |          Scale of variates for random start parameter search.\n",
      "     |      **kwargs\n",
      "     |          Additional keyword arguments to pass to the optimizer.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      MarkovSwitchingResults\n",
      "     |  \n",
      "     |  hessian(self, params, transformed=True)\n",
      "     |      Hessian matrix of the likelihood function, evaluated at the given\n",
      "     |      parameters\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : array_like\n",
      "     |          Array of parameters at which to evaluate the Hessian\n",
      "     |          function.\n",
      "     |      transformed : bool, optional\n",
      "     |          Whether or not `params` is already transformed. Default is True.\n",
      "     |  \n",
      "     |  initial_probabilities(self, params, regime_transition=None)\n",
      "     |      Retrieve initial probabilities\n",
      "     |  \n",
      "     |  initialize_known(self, probabilities, tol=1e-08)\n",
      "     |      Set initialization of regime probabilities to use known values\n",
      "     |  \n",
      "     |  initialize_steady_state(self)\n",
      "     |      Set initialization of regime probabilities to be steady-state values\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Only valid if there are not time-varying transition probabilities.\n",
      "     |  \n",
      "     |  loglike(self, params, transformed=True)\n",
      "     |      Loglikelihood evaluation\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : array_like\n",
      "     |          Array of parameters at which to evaluate the loglikelihood\n",
      "     |          function.\n",
      "     |      transformed : bool, optional\n",
      "     |          Whether or not `params` is already transformed. Default is True.\n",
      "     |  \n",
      "     |  loglikeobs(self, params, transformed=True)\n",
      "     |      Loglikelihood evaluation for each period\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : array_like\n",
      "     |          Array of parameters at which to evaluate the loglikelihood\n",
      "     |          function.\n",
      "     |      transformed : bool, optional\n",
      "     |          Whether or not `params` is already transformed. Default is True.\n",
      "     |  \n",
      "     |  predict(self, params, start=None, end=None, probabilities=None, conditional=False)\n",
      "     |      In-sample prediction and out-of-sample forecasting\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : ndarray\n",
      "     |          Parameters at which to form predictions\n",
      "     |      start : int, str, or datetime, optional\n",
      "     |          Zero-indexed observation number at which to start forecasting,\n",
      "     |          i.e., the first forecast is start. Can also be a date string to\n",
      "     |          parse or a datetime type. Default is the the zeroth observation.\n",
      "     |      end : int, str, or datetime, optional\n",
      "     |          Zero-indexed observation number at which to end forecasting, i.e.,\n",
      "     |          the last forecast is end. Can also be a date string to\n",
      "     |          parse or a datetime type. However, if the dates index does not\n",
      "     |          have a fixed frequency, end must be an integer index if you\n",
      "     |          want out of sample prediction. Default is the last observation in\n",
      "     |          the sample.\n",
      "     |      probabilities : str or array_like, optional\n",
      "     |          Specifies the weighting probabilities used in constructing the\n",
      "     |          prediction as a weighted average. If a string, can be 'predicted',\n",
      "     |          'filtered', or 'smoothed'. Otherwise can be an array of\n",
      "     |          probabilities to use. Default is smoothed.\n",
      "     |      conditional : bool or int, optional\n",
      "     |          Whether or not to return predictions conditional on current or\n",
      "     |          past regimes. If False, returns a single vector of weighted\n",
      "     |          predictions. If True or 1, returns predictions conditional on the\n",
      "     |          current regime. For larger integers, returns predictions\n",
      "     |          conditional on the current regime and some number of past regimes.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      predict : ndarray\n",
      "     |          Array of out of in-sample predictions and / or out-of-sample\n",
      "     |          forecasts.\n",
      "     |  \n",
      "     |  regime_transition_matrix(self, params, exog_tvtp=None)\n",
      "     |      Construct the left-stochastic transition matrix\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      This matrix will either be shaped (k_regimes, k_regimes, 1) or if there\n",
      "     |      are time-varying transition probabilities, it will be shaped\n",
      "     |      (k_regimes, k_regimes, nobs).\n",
      "     |      \n",
      "     |      The (i,j)th element of this matrix is the probability of transitioning\n",
      "     |      from regime j to regime i; thus the previous regime is represented in a\n",
      "     |      column and the next regime is represented by a row.\n",
      "     |      \n",
      "     |      It is left-stochastic, meaning that each column sums to one (because\n",
      "     |      it is certain that from one regime (j) you will transition to *some\n",
      "     |      other regime*).\n",
      "     |  \n",
      "     |  score(self, params, transformed=True)\n",
      "     |      Compute the score function at params.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : array_like\n",
      "     |          Array of parameters at which to evaluate the score\n",
      "     |          function.\n",
      "     |      transformed : bool, optional\n",
      "     |          Whether or not `params` is already transformed. Default is True.\n",
      "     |  \n",
      "     |  score_obs(self, params, transformed=True)\n",
      "     |      Compute the score per observation, evaluated at params\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : array_like\n",
      "     |          Array of parameters at which to evaluate the score\n",
      "     |          function.\n",
      "     |      transformed : bool, optional\n",
      "     |          Whether or not `params` is already transformed. Default is True.\n",
      "     |  \n",
      "     |  smooth(self, params, transformed=True, cov_type=None, cov_kwds=None, return_raw=False, results_class=None, results_wrapper_class=None)\n",
      "     |      Apply the Kim smoother and Hamilton filter\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : array_like\n",
      "     |          Array of parameters at which to perform filtering.\n",
      "     |      transformed : bool, optional\n",
      "     |          Whether or not `params` is already transformed. Default is True.\n",
      "     |      cov_type : str, optional\n",
      "     |          See `fit` for a description of covariance matrix types\n",
      "     |          for results object.\n",
      "     |      cov_kwds : dict or None, optional\n",
      "     |          See `fit` for a description of required keywords for alternative\n",
      "     |          covariance estimators\n",
      "     |      return_raw : bool,optional\n",
      "     |          Whether or not to return only the raw Hamilton filter output or a\n",
      "     |          full results object. Default is to return a full results object.\n",
      "     |      results_class : type, optional\n",
      "     |          A results class to instantiate rather than\n",
      "     |          `MarkovSwitchingResults`. Usually only used internally by\n",
      "     |          subclasses.\n",
      "     |      results_wrapper_class : type, optional\n",
      "     |          A results wrapper class to instantiate rather than\n",
      "     |          `MarkovSwitchingResults`. Usually only used internally by\n",
      "     |          subclasses.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      MarkovSwitchingResults\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from statsmodels.tsa.regime_switching.markov_switching.MarkovSwitching:\n",
      "     |  \n",
      "     |  k_params\n",
      "     |      (int) Number of parameters in the model\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from statsmodels.tsa.base.tsa_model.TimeSeriesModel:\n",
      "     |  \n",
      "     |  exog_names\n",
      "     |      The names of the exogenous variables.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from statsmodels.base.model.LikelihoodModel:\n",
      "     |  \n",
      "     |  information(self, params)\n",
      "     |      Fisher information matrix of model.\n",
      "     |      \n",
      "     |      Returns -1 * Hessian of the log-likelihood evaluated at params.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : ndarray\n",
      "     |          The model parameters.\n",
      "     |  \n",
      "     |  initialize(self)\n",
      "     |      Initialize (possibly re-initialize) a Model instance.\n",
      "     |      \n",
      "     |      For example, if the the design matrix of a linear model changes then\n",
      "     |      initialized can be used to recompute values using the modified design\n",
      "     |      matrix.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from statsmodels.base.model.Model:\n",
      "     |  \n",
      "     |  from_formula(formula, data, subset=None, drop_cols=None, *args, **kwargs) from builtins.type\n",
      "     |      Create a Model from a formula and dataframe.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      formula : str or generic Formula object\n",
      "     |          The formula specifying the model.\n",
      "     |      data : array_like\n",
      "     |          The data for the model. See Notes.\n",
      "     |      subset : array_like\n",
      "     |          An array-like object of booleans, integers, or index values that\n",
      "     |          indicate the subset of df to use in the model. Assumes df is a\n",
      "     |          `pandas.DataFrame`.\n",
      "     |      drop_cols : array_like\n",
      "     |          Columns to drop from the design matrix.  Cannot be used to\n",
      "     |          drop terms involving categoricals.\n",
      "     |      *args\n",
      "     |          Additional positional argument that are passed to the model.\n",
      "     |      **kwargs\n",
      "     |          These are passed to the model with one exception. The\n",
      "     |          ``eval_env`` keyword is passed to patsy. It can be either a\n",
      "     |          :class:`patsy:patsy.EvalEnvironment` object or an integer\n",
      "     |          indicating the depth of the namespace to use. For example, the\n",
      "     |          default ``eval_env=0`` uses the calling namespace. If you wish\n",
      "     |          to use a \"clean\" environment set ``eval_env=-1``.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      model\n",
      "     |          The model instance.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      data must define __getitem__ with the keys in the formula terms\n",
      "     |      args and kwargs are passed on to the model instantiation. E.g.,\n",
      "     |      a numpy structured or rec array, a dictionary, or a pandas DataFrame.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from statsmodels.base.model.Model:\n",
      "     |  \n",
      "     |  endog_names\n",
      "     |      Names of endogenous variables.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from statsmodels.base.model.Model:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class SARIMAX(statsmodels.tsa.statespace.mlemodel.MLEModel)\n",
      "     |  SARIMAX(endog, exog=None, order=(1, 0, 0), seasonal_order=(0, 0, 0, 0), trend=None, measurement_error=False, time_varying_regression=False, mle_regression=True, simple_differencing=False, enforce_stationarity=True, enforce_invertibility=True, hamilton_representation=False, concentrate_scale=False, trend_offset=1, use_exact_diffuse=False, dates=None, freq=None, missing='none', validate_specification=True, **kwargs)\n",
      "     |  \n",
      "     |  Seasonal AutoRegressive Integrated Moving Average with eXogenous regressors\n",
      "     |  model\n",
      "     |  \n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  endog : array_like\n",
      "     |      The observed time-series process :math:`y`\n",
      "     |  exog : array_like, optional\n",
      "     |      Array of exogenous regressors, shaped nobs x k.\n",
      "     |  order : iterable or iterable of iterables, optional\n",
      "     |      The (p,d,q) order of the model for the number of AR parameters,\n",
      "     |      differences, and MA parameters. `d` must be an integer\n",
      "     |      indicating the integration order of the process, while\n",
      "     |      `p` and `q` may either be an integers indicating the AR and MA\n",
      "     |      orders (so that all lags up to those orders are included) or else\n",
      "     |      iterables giving specific AR and / or MA lags to include. Default is\n",
      "     |      an AR(1) model: (1,0,0).\n",
      "     |  seasonal_order : iterable, optional\n",
      "     |      The (P,D,Q,s) order of the seasonal component of the model for the\n",
      "     |      AR parameters, differences, MA parameters, and periodicity.\n",
      "     |      `D` must be an integer indicating the integration order of the process,\n",
      "     |      while `P` and `Q` may either be an integers indicating the AR and MA\n",
      "     |      orders (so that all lags up to those orders are included) or else\n",
      "     |      iterables giving specific AR and / or MA lags to include. `s` is an\n",
      "     |      integer giving the periodicity (number of periods in season), often it\n",
      "     |      is 4 for quarterly data or 12 for monthly data. Default is no seasonal\n",
      "     |      effect.\n",
      "     |  trend : str{'n','c','t','ct'} or iterable, optional\n",
      "     |      Parameter controlling the deterministic trend polynomial :math:`A(t)`.\n",
      "     |      Can be specified as a string where 'c' indicates a constant (i.e. a\n",
      "     |      degree zero component of the trend polynomial), 't' indicates a\n",
      "     |      linear trend with time, and 'ct' is both. Can also be specified as an\n",
      "     |      iterable defining the non-zero polynomial exponents to include, in\n",
      "     |      increasing order. For example, `[1,1,0,1]` denotes\n",
      "     |      :math:`a + bt + ct^3`. Default is to not include a trend component.\n",
      "     |  measurement_error : bool, optional\n",
      "     |      Whether or not to assume the endogenous observations `endog` were\n",
      "     |      measured with error. Default is False.\n",
      "     |  time_varying_regression : bool, optional\n",
      "     |      Used when an explanatory variables, `exog`, are provided\n",
      "     |      to select whether or not coefficients on the exogenous regressors are\n",
      "     |      allowed to vary over time. Default is False.\n",
      "     |  mle_regression : bool, optional\n",
      "     |      Whether or not to use estimate the regression coefficients for the\n",
      "     |      exogenous variables as part of maximum likelihood estimation or through\n",
      "     |      the Kalman filter (i.e. recursive least squares). If\n",
      "     |      `time_varying_regression` is True, this must be set to False. Default\n",
      "     |      is True.\n",
      "     |  simple_differencing : bool, optional\n",
      "     |      Whether or not to use partially conditional maximum likelihood\n",
      "     |      estimation. If True, differencing is performed prior to estimation,\n",
      "     |      which discards the first :math:`s D + d` initial rows but results in a\n",
      "     |      smaller state-space formulation. See the Notes section for important\n",
      "     |      details about interpreting results when this option is used. If False,\n",
      "     |      the full SARIMAX model is put in state-space form so that all\n",
      "     |      datapoints can be used in estimation. Default is False.\n",
      "     |  enforce_stationarity : bool, optional\n",
      "     |      Whether or not to transform the AR parameters to enforce stationarity\n",
      "     |      in the autoregressive component of the model. Default is True.\n",
      "     |  enforce_invertibility : bool, optional\n",
      "     |      Whether or not to transform the MA parameters to enforce invertibility\n",
      "     |      in the moving average component of the model. Default is True.\n",
      "     |  hamilton_representation : bool, optional\n",
      "     |      Whether or not to use the Hamilton representation of an ARMA process\n",
      "     |      (if True) or the Harvey representation (if False). Default is False.\n",
      "     |  concentrate_scale : bool, optional\n",
      "     |      Whether or not to concentrate the scale (variance of the error term)\n",
      "     |      out of the likelihood. This reduces the number of parameters estimated\n",
      "     |      by maximum likelihood by one, but standard errors will then not\n",
      "     |      be available for the scale parameter.\n",
      "     |  trend_offset : int, optional\n",
      "     |      The offset at which to start time trend values. Default is 1, so that\n",
      "     |      if `trend='t'` the trend is equal to 1, 2, ..., nobs. Typically is only\n",
      "     |      set when the model created by extending a previous dataset.\n",
      "     |  use_exact_diffuse : bool, optional\n",
      "     |      Whether or not to use exact diffuse initialization for non-stationary\n",
      "     |      states. Default is False (in which case approximate diffuse\n",
      "     |      initialization is used).\n",
      "     |  **kwargs\n",
      "     |      Keyword arguments may be used to provide default values for state space\n",
      "     |      matrices or for Kalman filtering options. See `Representation`, and\n",
      "     |      `KalmanFilter` for more details.\n",
      "     |  \n",
      "     |  Attributes\n",
      "     |  ----------\n",
      "     |  measurement_error : bool\n",
      "     |      Whether or not to assume the endogenous\n",
      "     |      observations `endog` were measured with error.\n",
      "     |  state_error : bool\n",
      "     |      Whether or not the transition equation has an error component.\n",
      "     |  mle_regression : bool\n",
      "     |      Whether or not the regression coefficients for\n",
      "     |      the exogenous variables were estimated via maximum\n",
      "     |      likelihood estimation.\n",
      "     |  state_regression : bool\n",
      "     |      Whether or not the regression coefficients for\n",
      "     |      the exogenous variables are included as elements\n",
      "     |      of the state space and estimated via the Kalman\n",
      "     |      filter.\n",
      "     |  time_varying_regression : bool\n",
      "     |      Whether or not coefficients on the exogenous\n",
      "     |      regressors are allowed to vary over time.\n",
      "     |  simple_differencing : bool\n",
      "     |      Whether or not to use partially conditional maximum likelihood\n",
      "     |      estimation.\n",
      "     |  enforce_stationarity : bool\n",
      "     |      Whether or not to transform the AR parameters\n",
      "     |      to enforce stationarity in the autoregressive\n",
      "     |      component of the model.\n",
      "     |  enforce_invertibility : bool\n",
      "     |      Whether or not to transform the MA parameters\n",
      "     |      to enforce invertibility in the moving average\n",
      "     |      component of the model.\n",
      "     |  hamilton_representation : bool\n",
      "     |      Whether or not to use the Hamilton representation of an ARMA process.\n",
      "     |  trend : str{'n','c','t','ct'} or iterable\n",
      "     |      Parameter controlling the deterministic\n",
      "     |      trend polynomial :math:`A(t)`. See the class\n",
      "     |      parameter documentation for more information.\n",
      "     |  polynomial_ar : ndarray\n",
      "     |      Array containing autoregressive lag polynomial lags, ordered from\n",
      "     |      lowest degree to highest. The polynomial begins with lag 0.\n",
      "     |      Initialized with ones, unless a coefficient is constrained to be\n",
      "     |      zero (in which case it is zero).\n",
      "     |  polynomial_ma : ndarray\n",
      "     |      Array containing moving average lag polynomial lags, ordered from\n",
      "     |      lowest degree to highest. Initialized with ones, unless a coefficient\n",
      "     |      is constrained to be zero (in which case it is zero).\n",
      "     |  polynomial_seasonal_ar : ndarray\n",
      "     |      Array containing seasonal moving average lag\n",
      "     |      polynomial lags, ordered from lowest degree\n",
      "     |      to highest. Initialized with ones, unless a\n",
      "     |      coefficient is constrained to be zero (in which\n",
      "     |      case it is zero).\n",
      "     |  polynomial_seasonal_ma : ndarray\n",
      "     |      Array containing seasonal moving average lag\n",
      "     |      polynomial lags, ordered from lowest degree\n",
      "     |      to highest. Initialized with ones, unless a\n",
      "     |      coefficient is constrained to be zero (in which\n",
      "     |      case it is zero).\n",
      "     |  polynomial_trend : ndarray\n",
      "     |      Array containing trend polynomial coefficients,\n",
      "     |      ordered from lowest degree to highest. Initialized\n",
      "     |      with ones, unless a coefficient is constrained to be\n",
      "     |      zero (in which case it is zero).\n",
      "     |  k_ar : int\n",
      "     |      Highest autoregressive order in the model, zero-indexed.\n",
      "     |  k_ar_params : int\n",
      "     |      Number of autoregressive parameters to be estimated.\n",
      "     |  k_diff : int\n",
      "     |      Order of integration.\n",
      "     |  k_ma : int\n",
      "     |      Highest moving average order in the model, zero-indexed.\n",
      "     |  k_ma_params : int\n",
      "     |      Number of moving average parameters to be estimated.\n",
      "     |  seasonal_periods : int\n",
      "     |      Number of periods in a season.\n",
      "     |  k_seasonal_ar : int\n",
      "     |      Highest seasonal autoregressive order in the model, zero-indexed.\n",
      "     |  k_seasonal_ar_params : int\n",
      "     |      Number of seasonal autoregressive parameters to be estimated.\n",
      "     |  k_seasonal_diff : int\n",
      "     |      Order of seasonal integration.\n",
      "     |  k_seasonal_ma : int\n",
      "     |      Highest seasonal moving average order in the model, zero-indexed.\n",
      "     |  k_seasonal_ma_params : int\n",
      "     |      Number of seasonal moving average parameters to be estimated.\n",
      "     |  k_trend : int\n",
      "     |      Order of the trend polynomial plus one (i.e. the constant polynomial\n",
      "     |      would have `k_trend=1`).\n",
      "     |  k_exog : int\n",
      "     |      Number of exogenous regressors.\n",
      "     |  \n",
      "     |  Notes\n",
      "     |  -----\n",
      "     |  The SARIMA model is specified :math:`(p, d, q) \\times (P, D, Q)_s`.\n",
      "     |  \n",
      "     |  .. math::\n",
      "     |  \n",
      "     |      \\phi_p (L) \\tilde \\phi_P (L^s) \\Delta^d \\Delta_s^D y_t = A(t) +\n",
      "     |          \\theta_q (L) \\tilde \\theta_Q (L^s) \\zeta_t\n",
      "     |  \n",
      "     |  In terms of a univariate structural model, this can be represented as\n",
      "     |  \n",
      "     |  .. math::\n",
      "     |  \n",
      "     |      y_t & = u_t + \\eta_t \\\\\n",
      "     |      \\phi_p (L) \\tilde \\phi_P (L^s) \\Delta^d \\Delta_s^D u_t & = A(t) +\n",
      "     |          \\theta_q (L) \\tilde \\theta_Q (L^s) \\zeta_t\n",
      "     |  \n",
      "     |  where :math:`\\eta_t` is only applicable in the case of measurement error\n",
      "     |  (although it is also used in the case of a pure regression model, i.e. if\n",
      "     |  p=q=0).\n",
      "     |  \n",
      "     |  In terms of this model, regression with SARIMA errors can be represented\n",
      "     |  easily as\n",
      "     |  \n",
      "     |  .. math::\n",
      "     |  \n",
      "     |      y_t & = \\beta_t x_t + u_t \\\\\n",
      "     |      \\phi_p (L) \\tilde \\phi_P (L^s) \\Delta^d \\Delta_s^D u_t & = A(t) +\n",
      "     |          \\theta_q (L) \\tilde \\theta_Q (L^s) \\zeta_t\n",
      "     |  \n",
      "     |  this model is the one used when exogenous regressors are provided.\n",
      "     |  \n",
      "     |  Note that the reduced form lag polynomials will be written as:\n",
      "     |  \n",
      "     |  .. math::\n",
      "     |  \n",
      "     |      \\Phi (L) \\equiv \\phi_p (L) \\tilde \\phi_P (L^s) \\\\\n",
      "     |      \\Theta (L) \\equiv \\theta_q (L) \\tilde \\theta_Q (L^s)\n",
      "     |  \n",
      "     |  If `mle_regression` is True, regression coefficients are treated as\n",
      "     |  additional parameters to be estimated via maximum likelihood. Otherwise\n",
      "     |  they are included as part of the state with a diffuse initialization.\n",
      "     |  In this case, however, with approximate diffuse initialization, results\n",
      "     |  can be sensitive to the initial variance.\n",
      "     |  \n",
      "     |  This class allows two different underlying representations of ARMA models\n",
      "     |  as state space models: that of Hamilton and that of Harvey. Both are\n",
      "     |  equivalent in the sense that they are analytical representations of the\n",
      "     |  ARMA model, but the state vectors of each have different meanings. For\n",
      "     |  this reason, maximum likelihood does not result in identical parameter\n",
      "     |  estimates and even the same set of parameters will result in different\n",
      "     |  loglikelihoods.\n",
      "     |  \n",
      "     |  The Harvey representation is convenient because it allows integrating\n",
      "     |  differencing into the state vector to allow using all observations for\n",
      "     |  estimation.\n",
      "     |  \n",
      "     |  In this implementation of differenced models, the Hamilton representation\n",
      "     |  is not able to accommodate differencing in the state vector, so\n",
      "     |  `simple_differencing` (which performs differencing prior to estimation so\n",
      "     |  that the first d + sD observations are lost) must be used.\n",
      "     |  \n",
      "     |  Many other packages use the Hamilton representation, so that tests against\n",
      "     |  Stata and R require using it along with simple differencing (as Stata\n",
      "     |  does).\n",
      "     |  \n",
      "     |  If `filter_concentrated = True` is used, then the scale of the model is\n",
      "     |  concentrated out of the likelihood. A benefit of this is that there the\n",
      "     |  dimension of the parameter vector is reduced so that numerical maximization\n",
      "     |  of the log-likelihood function may be faster and more stable. If this\n",
      "     |  option in a model with measurement error, it is important to note that the\n",
      "     |  estimated measurement error parameter will be relative to the scale, and\n",
      "     |  is named \"snr.measurement_error\" instead of \"var.measurement_error\". To\n",
      "     |  compute the variance of the measurement error in this case one would\n",
      "     |  multiply `snr.measurement_error` parameter by the scale.\n",
      "     |  \n",
      "     |  If `simple_differencing = True` is used, then the `endog` and `exog` data\n",
      "     |  are differenced prior to putting the model in state-space form. This has\n",
      "     |  the same effect as if the user differenced the data prior to constructing\n",
      "     |  the model, which has implications for using the results:\n",
      "     |  \n",
      "     |  - Forecasts and predictions will be about the *differenced* data, not about\n",
      "     |    the original data. (while if `simple_differencing = False` is used, then\n",
      "     |    forecasts and predictions will be about the original data).\n",
      "     |  - If the original data has an Int64Index, a new RangeIndex will be created\n",
      "     |    for the differenced data that starts from one, and forecasts and\n",
      "     |    predictions will use this new index.\n",
      "     |  \n",
      "     |  Detailed information about state space models can be found in [1]_. Some\n",
      "     |  specific references are:\n",
      "     |  \n",
      "     |  - Chapter 3.4 describes ARMA and ARIMA models in state space form (using\n",
      "     |    the Harvey representation), and gives references for basic seasonal\n",
      "     |    models and models with a multiplicative form (for example the airline\n",
      "     |    model). It also shows a state space model for a full ARIMA process (this\n",
      "     |    is what is done here if `simple_differencing=False`).\n",
      "     |  - Chapter 3.6 describes estimating regression effects via the Kalman filter\n",
      "     |    (this is performed if `mle_regression` is False), regression with\n",
      "     |    time-varying coefficients, and regression with ARMA errors (recall from\n",
      "     |    above that if regression effects are present, the model estimated by this\n",
      "     |    class is regression with SARIMA errors).\n",
      "     |  - Chapter 8.4 describes the application of an ARMA model to an example\n",
      "     |    dataset. A replication of this section is available in an example\n",
      "     |    IPython notebook in the documentation.\n",
      "     |  \n",
      "     |  References\n",
      "     |  ----------\n",
      "     |  .. [1] Durbin, James, and Siem Jan Koopman. 2012.\n",
      "     |     Time Series Analysis by State Space Methods: Second Edition.\n",
      "     |     Oxford University Press.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      SARIMAX\n",
      "     |      statsmodels.tsa.statespace.mlemodel.MLEModel\n",
      "     |      statsmodels.tsa.base.tsa_model.TimeSeriesModel\n",
      "     |      statsmodels.base.model.LikelihoodModel\n",
      "     |      statsmodels.base.model.Model\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, endog, exog=None, order=(1, 0, 0), seasonal_order=(0, 0, 0, 0), trend=None, measurement_error=False, time_varying_regression=False, mle_regression=True, simple_differencing=False, enforce_stationarity=True, enforce_invertibility=True, hamilton_representation=False, concentrate_scale=False, trend_offset=1, use_exact_diffuse=False, dates=None, freq=None, missing='none', validate_specification=True, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  clone(self, endog, exog=None, **kwargs)\n",
      "     |      Clone state space model with new data and optionally new specification\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      endog : array_like\n",
      "     |          The observed time-series process :math:`y`\n",
      "     |      k_states : int\n",
      "     |          The dimension of the unobserved state process.\n",
      "     |      exog : array_like, optional\n",
      "     |          Array of exogenous regressors, shaped nobs x k. Default is no\n",
      "     |          exogenous regressors.\n",
      "     |      kwargs\n",
      "     |          Keyword arguments to pass to the new model class to change the\n",
      "     |          model specification.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      model : MLEModel subclass\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      This method must be implemented\n",
      "     |  \n",
      "     |  initialize(self)\n",
      "     |      Initialize the SARIMAX model.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      These initialization steps must occur following the parent class\n",
      "     |      __init__ function calls.\n",
      "     |  \n",
      "     |  initialize_default(self, approximate_diffuse_variance=None)\n",
      "     |      Initialize default\n",
      "     |  \n",
      "     |  prepare_data(self)\n",
      "     |      Prepare data for use in the state space representation\n",
      "     |  \n",
      "     |  transform_params(self, unconstrained)\n",
      "     |      Transform unconstrained parameters used by the optimizer to constrained\n",
      "     |      parameters used in likelihood evaluation.\n",
      "     |      \n",
      "     |      Used primarily to enforce stationarity of the autoregressive lag\n",
      "     |      polynomial, invertibility of the moving average lag polynomial, and\n",
      "     |      positive variance parameters.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      unconstrained : array_like\n",
      "     |          Unconstrained parameters used by the optimizer.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      constrained : array_like\n",
      "     |          Constrained parameters used in likelihood evaluation.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      If the lag polynomial has non-consecutive powers (so that the\n",
      "     |      coefficient is zero on some element of the polynomial), then the\n",
      "     |      constraint function is not onto the entire space of invertible\n",
      "     |      polynomials, although it only excludes a very small portion very close\n",
      "     |      to the invertibility boundary.\n",
      "     |  \n",
      "     |  untransform_params(self, constrained)\n",
      "     |      Transform constrained parameters used in likelihood evaluation\n",
      "     |      to unconstrained parameters used by the optimizer\n",
      "     |      \n",
      "     |      Used primarily to reverse enforcement of stationarity of the\n",
      "     |      autoregressive lag polynomial and invertibility of the moving average\n",
      "     |      lag polynomial.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      constrained : array_like\n",
      "     |          Constrained parameters used in likelihood evaluation.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      constrained : array_like\n",
      "     |          Unconstrained parameters used by the optimizer.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      If the lag polynomial has non-consecutive powers (so that the\n",
      "     |      coefficient is zero on some element of the polynomial), then the\n",
      "     |      constraint function is not onto the entire space of invertible\n",
      "     |      polynomials, although it only excludes a very small portion very close\n",
      "     |      to the invertibility boundary.\n",
      "     |  \n",
      "     |  update(self, params, transformed=True, includes_fixed=False, complex_step=False)\n",
      "     |      Update the parameters of the model\n",
      "     |      \n",
      "     |      Updates the representation matrices to fill in the new parameter\n",
      "     |      values.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : array_like\n",
      "     |          Array of new parameters.\n",
      "     |      transformed : bool, optional\n",
      "     |          Whether or not `params` is already transformed. If set to False,\n",
      "     |          `transform_params` is called. Default is True..\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      params : array_like\n",
      "     |          Array of parameters.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties defined here:\n",
      "     |  \n",
      "     |  endog_names\n",
      "     |      Names of endogenous variables\n",
      "     |  \n",
      "     |  initial_design\n",
      "     |      Initial design matrix\n",
      "     |  \n",
      "     |  initial_selection\n",
      "     |      Initial selection matrix\n",
      "     |  \n",
      "     |  initial_state_intercept\n",
      "     |      Initial state intercept vector\n",
      "     |  \n",
      "     |  initial_transition\n",
      "     |      Initial transition matrix\n",
      "     |  \n",
      "     |  model_latex_names\n",
      "     |      The latex names of all possible model parameters.\n",
      "     |  \n",
      "     |  model_names\n",
      "     |      The plain text names of all possible model parameters.\n",
      "     |  \n",
      "     |  model_orders\n",
      "     |      The orders of each of the polynomials in the model.\n",
      "     |  \n",
      "     |  param_names\n",
      "     |      List of human readable parameter names (for parameters actually\n",
      "     |      included in the model).\n",
      "     |  \n",
      "     |  param_terms\n",
      "     |      List of parameters actually included in the model, in sorted order.\n",
      "     |      \n",
      "     |      TODO Make this an dict with slice or indices as the values.\n",
      "     |  \n",
      "     |  start_params\n",
      "     |      Starting parameters for maximum likelihood estimation\n",
      "     |  \n",
      "     |  state_names\n",
      "     |      (list of str) List of human readable names for unobserved states.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  params_complete = ['trend', 'exog', 'ar', 'ma', 'seasonal_ar', 'season...\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from statsmodels.tsa.statespace.mlemodel.MLEModel:\n",
      "     |  \n",
      "     |  __getitem__(self, key)\n",
      "     |  \n",
      "     |  __setitem__(self, key, value)\n",
      "     |  \n",
      "     |  filter(self, params, transformed=True, includes_fixed=False, complex_step=False, cov_type=None, cov_kwds=None, return_ssm=False, results_class=None, results_wrapper_class=None, low_memory=False, **kwargs)\n",
      "     |      Kalman filtering\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : array_like\n",
      "     |          Array of parameters at which to evaluate the loglikelihood\n",
      "     |          function.\n",
      "     |      transformed : bool, optional\n",
      "     |          Whether or not `params` is already transformed. Default is True.\n",
      "     |      return_ssm : bool,optional\n",
      "     |          Whether or not to return only the state space output or a full\n",
      "     |          results object. Default is to return a full results object.\n",
      "     |      cov_type : str, optional\n",
      "     |          See `MLEResults.fit` for a description of covariance matrix types\n",
      "     |          for results object.\n",
      "     |      cov_kwds : dict or None, optional\n",
      "     |          See `MLEResults.get_robustcov_results` for a description required\n",
      "     |          keywords for alternative covariance estimators\n",
      "     |      low_memory : bool, optional\n",
      "     |          If set to True, techniques are applied to substantially reduce\n",
      "     |          memory usage. If used, some features of the results object will\n",
      "     |          not be available (including in-sample prediction), although\n",
      "     |          out-of-sample forecasting is possible. Default is False.\n",
      "     |      **kwargs\n",
      "     |          Additional keyword arguments to pass to the Kalman filter. See\n",
      "     |          `KalmanFilter.filter` for more details.\n",
      "     |  \n",
      "     |  fit(self, start_params=None, transformed=True, includes_fixed=False, cov_type=None, cov_kwds=None, method='lbfgs', maxiter=50, full_output=1, disp=5, callback=None, return_params=False, optim_score=None, optim_complex_step=None, optim_hessian=None, flags=None, low_memory=False, **kwargs)\n",
      "     |      Fits the model by maximum likelihood via Kalman filter.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      start_params : array_like, optional\n",
      "     |          Initial guess of the solution for the loglikelihood maximization.\n",
      "     |          If None, the default is given by Model.start_params.\n",
      "     |      transformed : bool, optional\n",
      "     |          Whether or not `start_params` is already transformed. Default is\n",
      "     |          True.\n",
      "     |      includes_fixed : bool, optional\n",
      "     |          If parameters were previously fixed with the `fix_params` method,\n",
      "     |          this argument describes whether or not `start_params` also includes\n",
      "     |          the fixed parameters, in addition to the free parameters. Default\n",
      "     |          is False.\n",
      "     |      cov_type : str, optional\n",
      "     |          The `cov_type` keyword governs the method for calculating the\n",
      "     |          covariance matrix of parameter estimates. Can be one of:\n",
      "     |      \n",
      "     |          - 'opg' for the outer product of gradient estimator\n",
      "     |          - 'oim' for the observed information matrix estimator, calculated\n",
      "     |            using the method of Harvey (1989)\n",
      "     |          - 'approx' for the observed information matrix estimator,\n",
      "     |            calculated using a numerical approximation of the Hessian matrix.\n",
      "     |          - 'robust' for an approximate (quasi-maximum likelihood) covariance\n",
      "     |            matrix that may be valid even in the presence of some\n",
      "     |            misspecifications. Intermediate calculations use the 'oim'\n",
      "     |            method.\n",
      "     |          - 'robust_approx' is the same as 'robust' except that the\n",
      "     |            intermediate calculations use the 'approx' method.\n",
      "     |          - 'none' for no covariance matrix calculation.\n",
      "     |      \n",
      "     |          Default is 'opg' unless memory conservation is used to avoid\n",
      "     |          computing the loglikelihood values for each observation, in which\n",
      "     |          case the default is 'approx'.\n",
      "     |      cov_kwds : dict or None, optional\n",
      "     |          A dictionary of arguments affecting covariance matrix computation.\n",
      "     |      \n",
      "     |          **opg, oim, approx, robust, robust_approx**\n",
      "     |      \n",
      "     |          - 'approx_complex_step' : bool, optional - If True, numerical\n",
      "     |            approximations are computed using complex-step methods. If False,\n",
      "     |            numerical approximations are computed using finite difference\n",
      "     |            methods. Default is True.\n",
      "     |          - 'approx_centered' : bool, optional - If True, numerical\n",
      "     |            approximations computed using finite difference methods use a\n",
      "     |            centered approximation. Default is False.\n",
      "     |      method : str, optional\n",
      "     |          The `method` determines which solver from `scipy.optimize`\n",
      "     |          is used, and it can be chosen from among the following strings:\n",
      "     |      \n",
      "     |          - 'newton' for Newton-Raphson\n",
      "     |          - 'nm' for Nelder-Mead\n",
      "     |          - 'bfgs' for Broyden-Fletcher-Goldfarb-Shanno (BFGS)\n",
      "     |          - 'lbfgs' for limited-memory BFGS with optional box constraints\n",
      "     |          - 'powell' for modified Powell's method\n",
      "     |          - 'cg' for conjugate gradient\n",
      "     |          - 'ncg' for Newton-conjugate gradient\n",
      "     |          - 'basinhopping' for global basin-hopping solver\n",
      "     |      \n",
      "     |          The explicit arguments in `fit` are passed to the solver,\n",
      "     |          with the exception of the basin-hopping solver. Each\n",
      "     |          solver has several optional arguments that are not the same across\n",
      "     |          solvers. See the notes section below (or scipy.optimize) for the\n",
      "     |          available arguments and for the list of explicit arguments that the\n",
      "     |          basin-hopping solver supports.\n",
      "     |      maxiter : int, optional\n",
      "     |          The maximum number of iterations to perform.\n",
      "     |      full_output : bool, optional\n",
      "     |          Set to True to have all available output in the Results object's\n",
      "     |          mle_retvals attribute. The output is dependent on the solver.\n",
      "     |          See LikelihoodModelResults notes section for more information.\n",
      "     |      disp : bool, optional\n",
      "     |          Set to True to print convergence messages.\n",
      "     |      callback : callable callback(xk), optional\n",
      "     |          Called after each iteration, as callback(xk), where xk is the\n",
      "     |          current parameter vector.\n",
      "     |      return_params : bool, optional\n",
      "     |          Whether or not to return only the array of maximizing parameters.\n",
      "     |          Default is False.\n",
      "     |      optim_score : {'harvey', 'approx'} or None, optional\n",
      "     |          The method by which the score vector is calculated. 'harvey' uses\n",
      "     |          the method from Harvey (1989), 'approx' uses either finite\n",
      "     |          difference or complex step differentiation depending upon the\n",
      "     |          value of `optim_complex_step`, and None uses the built-in gradient\n",
      "     |          approximation of the optimizer. Default is None. This keyword is\n",
      "     |          only relevant if the optimization method uses the score.\n",
      "     |      optim_complex_step : bool, optional\n",
      "     |          Whether or not to use complex step differentiation when\n",
      "     |          approximating the score; if False, finite difference approximation\n",
      "     |          is used. Default is True. This keyword is only relevant if\n",
      "     |          `optim_score` is set to 'harvey' or 'approx'.\n",
      "     |      optim_hessian : {'opg','oim','approx'}, optional\n",
      "     |          The method by which the Hessian is numerically approximated. 'opg'\n",
      "     |          uses outer product of gradients, 'oim' uses the information\n",
      "     |          matrix formula from Harvey (1989), and 'approx' uses numerical\n",
      "     |          approximation. This keyword is only relevant if the\n",
      "     |          optimization method uses the Hessian matrix.\n",
      "     |      low_memory : bool, optional\n",
      "     |          If set to True, techniques are applied to substantially reduce\n",
      "     |          memory usage. If used, some features of the results object will\n",
      "     |          not be available (including smoothed results and in-sample\n",
      "     |          prediction), although out-of-sample forecasting is possible.\n",
      "     |          Default is False.\n",
      "     |      **kwargs\n",
      "     |          Additional keyword arguments to pass to the optimizer.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      results\n",
      "     |          Results object holding results from fitting a state space model.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      statsmodels.base.model.LikelihoodModel.fit\n",
      "     |      statsmodels.tsa.statespace.mlemodel.MLEResults\n",
      "     |      statsmodels.tsa.statespace.structural.UnobservedComponentsResults\n",
      "     |  \n",
      "     |  fit_constrained(self, constraints, start_params=None, **fit_kwds)\n",
      "     |      Fit the model with some parameters subject to equality constraints.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      constraints : dict\n",
      "     |          Dictionary of constraints, of the form `param_name: fixed_value`.\n",
      "     |          See the `param_names` property for valid parameter names.\n",
      "     |      start_params : array_like, optional\n",
      "     |          Initial guess of the solution for the loglikelihood maximization.\n",
      "     |          If None, the default is given by Model.start_params.\n",
      "     |      **fit_kwds : keyword arguments\n",
      "     |          fit_kwds are used in the optimization of the remaining parameters.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      results : Results instance\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> mod = sm.tsa.SARIMAX(endog, order=(1, 0, 1))\n",
      "     |      >>> res = mod.fit_constrained({'ar.L1': 0.5})\n",
      "     |  \n",
      "     |  fix_params(self, params)\n",
      "     |      Fix parameters to specific values (context manager)\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : dict\n",
      "     |          Dictionary describing the fixed parameter values, of the form\n",
      "     |          `param_name: fixed_value`. See the `param_names` property for valid\n",
      "     |          parameter names.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> mod = sm.tsa.SARIMAX(endog, order=(1, 0, 1))\n",
      "     |      >>> with mod.fix_params({'ar.L1': 0.5}):\n",
      "     |              res = mod.fit()\n",
      "     |  \n",
      "     |  handle_params(self, params, transformed=True, includes_fixed=False, return_jacobian=False)\n",
      "     |      Ensure model parameters satisfy shape and other requirements\n",
      "     |  \n",
      "     |  hessian(self, params, *args, **kwargs)\n",
      "     |      Hessian matrix of the likelihood function, evaluated at the given\n",
      "     |      parameters\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : array_like\n",
      "     |          Array of parameters at which to evaluate the hessian.\n",
      "     |      *args\n",
      "     |          Additional positional arguments to the `loglike` method.\n",
      "     |      **kwargs\n",
      "     |          Additional keyword arguments to the `loglike` method.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      hessian : ndarray\n",
      "     |          Hessian matrix evaluated at `params`\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      This is a numerical approximation.\n",
      "     |      \n",
      "     |      Both args and kwargs are necessary because the optimizer from\n",
      "     |      `fit` must call this function and only supports passing arguments via\n",
      "     |      args (for example `scipy.optimize.fmin_l_bfgs`).\n",
      "     |  \n",
      "     |  impulse_responses(self, params, steps=1, impulse=0, orthogonalized=False, cumulative=False, anchor=None, exog=None, extend_model=None, extend_kwargs=None, transformed=True, includes_fixed=False, **kwargs)\n",
      "     |      Impulse response function\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : array_like\n",
      "     |          Array of model parameters.\n",
      "     |      steps : int, optional\n",
      "     |          The number of steps for which impulse responses are calculated.\n",
      "     |          Default is 1. Note that for time-invariant models, the initial\n",
      "     |          impulse is not counted as a step, so if `steps=1`, the output will\n",
      "     |          have 2 entries.\n",
      "     |      impulse : int, str or array_like\n",
      "     |          If an integer, the state innovation to pulse; must be between 0\n",
      "     |          and `k_posdef-1`. If a str, it indicates which column of df\n",
      "     |          the unit (1) impulse is given.\n",
      "     |          Alternatively, a custom impulse vector may be provided; must be\n",
      "     |          shaped `k_posdef x 1`.\n",
      "     |      orthogonalized : bool, optional\n",
      "     |          Whether or not to perform impulse using orthogonalized innovations.\n",
      "     |          Note that this will also affect custum `impulse` vectors. Default\n",
      "     |          is False.\n",
      "     |      cumulative : bool, optional\n",
      "     |          Whether or not to return cumulative impulse responses. Default is\n",
      "     |          False.\n",
      "     |      anchor : int, str, or datetime, optional\n",
      "     |          Time point within the sample for the state innovation impulse. Type\n",
      "     |          depends on the index of the given `endog` in the model. Two special\n",
      "     |          cases are the strings 'start' and 'end', which refer to setting the\n",
      "     |          impulse at the first and last points of the sample, respectively.\n",
      "     |          Integer values can run from 0 to `nobs - 1`, or can be negative to\n",
      "     |          apply negative indexing. Finally, if a date/time index was provided\n",
      "     |          to the model, then this argument can be a date string to parse or a\n",
      "     |          datetime type. Default is 'start'.\n",
      "     |      exog : array_like, optional\n",
      "     |          New observations of exogenous regressors for our-of-sample periods,\n",
      "     |          if applicable.\n",
      "     |      transformed : bool, optional\n",
      "     |          Whether or not `params` is already transformed. Default is\n",
      "     |          True.\n",
      "     |      includes_fixed : bool, optional\n",
      "     |          If parameters were previously fixed with the `fix_params` method,\n",
      "     |          this argument describes whether or not `params` also includes\n",
      "     |          the fixed parameters, in addition to the free parameters. Default\n",
      "     |          is False.\n",
      "     |      **kwargs\n",
      "     |          If the model has time-varying design or transition matrices and the\n",
      "     |          combination of `anchor` and `steps` implies creating impulse\n",
      "     |          responses for the out-of-sample period, then these matrices must\n",
      "     |          have updated values provided for the out-of-sample steps. For\n",
      "     |          example, if `design` is a time-varying component, `nobs` is 10,\n",
      "     |          `anchor=1`, and `steps` is 15, a (`k_endog` x `k_states` x 7)\n",
      "     |          matrix must be provided with the new design matrix values.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      impulse_responses : ndarray\n",
      "     |          Responses for each endogenous variable due to the impulse\n",
      "     |          given by the `impulse` argument. For a time-invariant model, the\n",
      "     |          impulse responses are given for `steps + 1` elements (this gives\n",
      "     |          the \"initial impulse\" followed by `steps` responses for the\n",
      "     |          important cases of VAR and SARIMAX models), while for time-varying\n",
      "     |          models the impulse responses are only given for `steps` elements\n",
      "     |          (to avoid having to unexpectedly provide updated time-varying\n",
      "     |          matrices).\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      simulate\n",
      "     |          Simulate a time series according to the given state space model,\n",
      "     |          optionally with specified series for the innovations.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Intercepts in the measurement and state equation are ignored when\n",
      "     |      calculating impulse responses.\n",
      "     |      \n",
      "     |      TODO: add an option to allow changing the ordering for the\n",
      "     |            orthogonalized option. Will require permuting matrices when\n",
      "     |            constructing the extended model.\n",
      "     |  \n",
      "     |  initialize_approximate_diffuse(self, variance=None)\n",
      "     |      Initialize approximate diffuse\n",
      "     |  \n",
      "     |  initialize_known(self, initial_state, initial_state_cov)\n",
      "     |      Initialize known\n",
      "     |  \n",
      "     |  initialize_statespace(self, **kwargs)\n",
      "     |      Initialize the state space representation\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      **kwargs\n",
      "     |          Additional keyword arguments to pass to the state space class\n",
      "     |          constructor.\n",
      "     |  \n",
      "     |  initialize_stationary(self)\n",
      "     |      Initialize stationary\n",
      "     |  \n",
      "     |  loglike(self, params, *args, **kwargs)\n",
      "     |      Loglikelihood evaluation\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : array_like\n",
      "     |          Array of parameters at which to evaluate the loglikelihood\n",
      "     |          function.\n",
      "     |      transformed : bool, optional\n",
      "     |          Whether or not `params` is already transformed. Default is True.\n",
      "     |      **kwargs\n",
      "     |          Additional keyword arguments to pass to the Kalman filter. See\n",
      "     |          `KalmanFilter.filter` for more details.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      update : modifies the internal state of the state space model to\n",
      "     |               reflect new params\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      [1]_ recommend maximizing the average likelihood to avoid scale issues;\n",
      "     |      this is done automatically by the base Model fit method.\n",
      "     |      \n",
      "     |      References\n",
      "     |      ----------\n",
      "     |      .. [1] Koopman, Siem Jan, Neil Shephard, and Jurgen A. Doornik. 1999.\n",
      "     |         Statistical Algorithms for Models in State Space Using SsfPack 2.2.\n",
      "     |         Econometrics Journal 2 (1): 107-60. doi:10.1111/1368-423X.00023.\n",
      "     |  \n",
      "     |  loglikeobs(self, params, transformed=True, includes_fixed=False, complex_step=False, **kwargs)\n",
      "     |      Loglikelihood evaluation\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : array_like\n",
      "     |          Array of parameters at which to evaluate the loglikelihood\n",
      "     |          function.\n",
      "     |      transformed : bool, optional\n",
      "     |          Whether or not `params` is already transformed. Default is True.\n",
      "     |      **kwargs\n",
      "     |          Additional keyword arguments to pass to the Kalman filter. See\n",
      "     |          `KalmanFilter.filter` for more details.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      update : modifies the internal state of the Model to reflect new params\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      [1]_ recommend maximizing the average likelihood to avoid scale issues;\n",
      "     |      this is done automatically by the base Model fit method.\n",
      "     |      \n",
      "     |      References\n",
      "     |      ----------\n",
      "     |      .. [1] Koopman, Siem Jan, Neil Shephard, and Jurgen A. Doornik. 1999.\n",
      "     |         Statistical Algorithms for Models in State Space Using SsfPack 2.2.\n",
      "     |         Econometrics Journal 2 (1): 107-60. doi:10.1111/1368-423X.00023.\n",
      "     |  \n",
      "     |  observed_information_matrix(self, params, transformed=True, includes_fixed=False, approx_complex_step=None, approx_centered=False, **kwargs)\n",
      "     |      Observed information matrix\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : array_like, optional\n",
      "     |          Array of parameters at which to evaluate the loglikelihood\n",
      "     |          function.\n",
      "     |      **kwargs\n",
      "     |          Additional keyword arguments to pass to the Kalman filter. See\n",
      "     |          `KalmanFilter.filter` for more details.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      This method is from Harvey (1989), which shows that the information\n",
      "     |      matrix only depends on terms from the gradient. This implementation is\n",
      "     |      partially analytic and partially numeric approximation, therefore,\n",
      "     |      because it uses the analytic formula for the information matrix, with\n",
      "     |      numerically computed elements of the gradient.\n",
      "     |      \n",
      "     |      References\n",
      "     |      ----------\n",
      "     |      Harvey, Andrew C. 1990.\n",
      "     |      Forecasting, Structural Time Series Models and the Kalman Filter.\n",
      "     |      Cambridge University Press.\n",
      "     |  \n",
      "     |  opg_information_matrix(self, params, transformed=True, includes_fixed=False, approx_complex_step=None, **kwargs)\n",
      "     |      Outer product of gradients information matrix\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : array_like, optional\n",
      "     |          Array of parameters at which to evaluate the loglikelihood\n",
      "     |          function.\n",
      "     |      **kwargs\n",
      "     |          Additional arguments to the `loglikeobs` method.\n",
      "     |      \n",
      "     |      References\n",
      "     |      ----------\n",
      "     |      Berndt, Ernst R., Bronwyn Hall, Robert Hall, and Jerry Hausman. 1974.\n",
      "     |      Estimation and Inference in Nonlinear Structural Models.\n",
      "     |      NBER Chapters. National Bureau of Economic Research, Inc.\n",
      "     |  \n",
      "     |  score(self, params, *args, **kwargs)\n",
      "     |      Compute the score function at params.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : array_like\n",
      "     |          Array of parameters at which to evaluate the score.\n",
      "     |      *args\n",
      "     |          Additional positional arguments to the `loglike` method.\n",
      "     |      **kwargs\n",
      "     |          Additional keyword arguments to the `loglike` method.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      score : ndarray\n",
      "     |          Score, evaluated at `params`.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      This is a numerical approximation, calculated using first-order complex\n",
      "     |      step differentiation on the `loglike` method.\n",
      "     |      \n",
      "     |      Both args and kwargs are necessary because the optimizer from\n",
      "     |      `fit` must call this function and only supports passing arguments via\n",
      "     |      args (for example `scipy.optimize.fmin_l_bfgs`).\n",
      "     |  \n",
      "     |  score_obs(self, params, method='approx', transformed=True, includes_fixed=False, approx_complex_step=None, approx_centered=False, **kwargs)\n",
      "     |      Compute the score per observation, evaluated at params\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : array_like\n",
      "     |          Array of parameters at which to evaluate the score.\n",
      "     |      **kwargs\n",
      "     |          Additional arguments to the `loglike` method.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      score : ndarray\n",
      "     |          Score per observation, evaluated at `params`.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      This is a numerical approximation, calculated using first-order complex\n",
      "     |      step differentiation on the `loglikeobs` method.\n",
      "     |  \n",
      "     |  set_conserve_memory(self, conserve_memory=None, **kwargs)\n",
      "     |      Set the memory conservation method\n",
      "     |      \n",
      "     |      By default, the Kalman filter computes a number of intermediate\n",
      "     |      matrices at each iteration. The memory conservation options control\n",
      "     |      which of those matrices are stored.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      conserve_memory : int, optional\n",
      "     |          Bitmask value to set the memory conservation method to. See notes\n",
      "     |          for details.\n",
      "     |      **kwargs\n",
      "     |          Keyword arguments may be used to influence the memory conservation\n",
      "     |          method by setting individual boolean flags.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      This method is rarely used. See the corresponding function in the\n",
      "     |      `KalmanFilter` class for details.\n",
      "     |  \n",
      "     |  set_filter_method(self, filter_method=None, **kwargs)\n",
      "     |      Set the filtering method\n",
      "     |      \n",
      "     |      The filtering method controls aspects of which Kalman filtering\n",
      "     |      approach will be used.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      filter_method : int, optional\n",
      "     |          Bitmask value to set the filter method to. See notes for details.\n",
      "     |      **kwargs\n",
      "     |          Keyword arguments may be used to influence the filter method by\n",
      "     |          setting individual boolean flags. See notes for details.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      This method is rarely used. See the corresponding function in the\n",
      "     |      `KalmanFilter` class for details.\n",
      "     |  \n",
      "     |  set_inversion_method(self, inversion_method=None, **kwargs)\n",
      "     |      Set the inversion method\n",
      "     |      \n",
      "     |      The Kalman filter may contain one matrix inversion: that of the\n",
      "     |      forecast error covariance matrix. The inversion method controls how and\n",
      "     |      if that inverse is performed.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      inversion_method : int, optional\n",
      "     |          Bitmask value to set the inversion method to. See notes for\n",
      "     |          details.\n",
      "     |      **kwargs\n",
      "     |          Keyword arguments may be used to influence the inversion method by\n",
      "     |          setting individual boolean flags. See notes for details.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      This method is rarely used. See the corresponding function in the\n",
      "     |      `KalmanFilter` class for details.\n",
      "     |  \n",
      "     |  set_smoother_output(self, smoother_output=None, **kwargs)\n",
      "     |      Set the smoother output\n",
      "     |      \n",
      "     |      The smoother can produce several types of results. The smoother output\n",
      "     |      variable controls which are calculated and returned.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      smoother_output : int, optional\n",
      "     |          Bitmask value to set the smoother output to. See notes for details.\n",
      "     |      **kwargs\n",
      "     |          Keyword arguments may be used to influence the smoother output by\n",
      "     |          setting individual boolean flags.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      This method is rarely used. See the corresponding function in the\n",
      "     |      `KalmanSmoother` class for details.\n",
      "     |  \n",
      "     |  set_stability_method(self, stability_method=None, **kwargs)\n",
      "     |      Set the numerical stability method\n",
      "     |      \n",
      "     |      The Kalman filter is a recursive algorithm that may in some cases\n",
      "     |      suffer issues with numerical stability. The stability method controls\n",
      "     |      what, if any, measures are taken to promote stability.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      stability_method : int, optional\n",
      "     |          Bitmask value to set the stability method to. See notes for\n",
      "     |          details.\n",
      "     |      **kwargs\n",
      "     |          Keyword arguments may be used to influence the stability method by\n",
      "     |          setting individual boolean flags. See notes for details.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      This method is rarely used. See the corresponding function in the\n",
      "     |      `KalmanFilter` class for details.\n",
      "     |  \n",
      "     |  simulate(self, params, nsimulations, measurement_shocks=None, state_shocks=None, initial_state=None, anchor=None, repetitions=None, exog=None, extend_model=None, extend_kwargs=None, transformed=True, includes_fixed=False, **kwargs)\n",
      "     |      Simulate a new time series following the state space model\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : array_like\n",
      "     |          Array of parameters to use in constructing the state space\n",
      "     |          representation to use when simulating.\n",
      "     |      nsimulations : int\n",
      "     |          The number of observations to simulate. If the model is\n",
      "     |          time-invariant this can be any number. If the model is\n",
      "     |          time-varying, then this number must be less than or equal to the\n",
      "     |          number of observations.\n",
      "     |      measurement_shocks : array_like, optional\n",
      "     |          If specified, these are the shocks to the measurement equation,\n",
      "     |          :math:`\\varepsilon_t`. If unspecified, these are automatically\n",
      "     |          generated using a pseudo-random number generator. If specified,\n",
      "     |          must be shaped `nsimulations` x `k_endog`, where `k_endog` is the\n",
      "     |          same as in the state space model.\n",
      "     |      state_shocks : array_like, optional\n",
      "     |          If specified, these are the shocks to the state equation,\n",
      "     |          :math:`\\eta_t`. If unspecified, these are automatically\n",
      "     |          generated using a pseudo-random number generator. If specified,\n",
      "     |          must be shaped `nsimulations` x `k_posdef` where `k_posdef` is the\n",
      "     |          same as in the state space model.\n",
      "     |      initial_state : array_like, optional\n",
      "     |          If specified, this is the initial state vector to use in\n",
      "     |          simulation, which should be shaped (`k_states` x 1), where\n",
      "     |          `k_states` is the same as in the state space model. If unspecified,\n",
      "     |          but the model has been initialized, then that initialization is\n",
      "     |          used. This must be specified if `anchor` is anything other than\n",
      "     |          \"start\" or 0 (or else you can use the `simulate` method on a\n",
      "     |          results object rather than on the model object).\n",
      "     |      anchor : int, str, or datetime, optional\n",
      "     |          First period for simulation. The simulation will be conditional on\n",
      "     |          all existing datapoints prior to the `anchor`.  Type depends on the\n",
      "     |          index of the given `endog` in the model. Two special cases are the\n",
      "     |          strings 'start' and 'end'. `start` refers to beginning the\n",
      "     |          simulation at the first period of the sample, and `end` refers to\n",
      "     |          beginning the simulation at the first period after the sample.\n",
      "     |          Integer values can run from 0 to `nobs`, or can be negative to\n",
      "     |          apply negative indexing. Finally, if a date/time index was provided\n",
      "     |          to the model, then this argument can be a date string to parse or a\n",
      "     |          datetime type. Default is 'start'.\n",
      "     |      repetitions : int, optional\n",
      "     |          Number of simulated paths to generate. Default is 1 simulated path.\n",
      "     |      exog : array_like, optional\n",
      "     |          New observations of exogenous regressors, if applicable.\n",
      "     |      transformed : bool, optional\n",
      "     |          Whether or not `params` is already transformed. Default is\n",
      "     |          True.\n",
      "     |      includes_fixed : bool, optional\n",
      "     |          If parameters were previously fixed with the `fix_params` method,\n",
      "     |          this argument describes whether or not `params` also includes\n",
      "     |          the fixed parameters, in addition to the free parameters. Default\n",
      "     |          is False.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      simulated_obs : ndarray\n",
      "     |          An array of simulated observations. If `repetitions=None`, then it\n",
      "     |          will be shaped (nsimulations x k_endog) or (nsimulations,) if\n",
      "     |          `k_endog=1`. Otherwise it will be shaped\n",
      "     |          (nsimulations x k_endog x repetitions). If the model was given\n",
      "     |          Pandas input then the output will be a Pandas object. If\n",
      "     |          `k_endog > 1` and `repetitions` is not None, then the output will\n",
      "     |          be a Pandas DataFrame that has a MultiIndex for the columns, with\n",
      "     |          the first level containing the names of the `endog` variables and\n",
      "     |          the second level containing the repetition number.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      impulse_responses\n",
      "     |          Impulse response functions\n",
      "     |  \n",
      "     |  simulation_smoother(self, simulation_output=None, **kwargs)\n",
      "     |      Retrieve a simulation smoother for the state space model.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      simulation_output : int, optional\n",
      "     |          Determines which simulation smoother output is calculated.\n",
      "     |          Default is all (including state and disturbances).\n",
      "     |      **kwargs\n",
      "     |          Additional keyword arguments, used to set the simulation output.\n",
      "     |          See `set_simulation_output` for more details.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      SimulationSmoothResults\n",
      "     |  \n",
      "     |  smooth(self, params, transformed=True, includes_fixed=False, complex_step=False, cov_type=None, cov_kwds=None, return_ssm=False, results_class=None, results_wrapper_class=None, **kwargs)\n",
      "     |      Kalman smoothing\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : array_like\n",
      "     |          Array of parameters at which to evaluate the loglikelihood\n",
      "     |          function.\n",
      "     |      transformed : bool, optional\n",
      "     |          Whether or not `params` is already transformed. Default is True.\n",
      "     |      return_ssm : bool,optional\n",
      "     |          Whether or not to return only the state space output or a full\n",
      "     |          results object. Default is to return a full results object.\n",
      "     |      cov_type : str, optional\n",
      "     |          See `MLEResults.fit` for a description of covariance matrix types\n",
      "     |          for results object.\n",
      "     |      cov_kwds : dict or None, optional\n",
      "     |          See `MLEResults.get_robustcov_results` for a description required\n",
      "     |          keywords for alternative covariance estimators\n",
      "     |      **kwargs\n",
      "     |          Additional keyword arguments to pass to the Kalman filter. See\n",
      "     |          `KalmanFilter.filter` for more details.\n",
      "     |  \n",
      "     |  transform_jacobian(self, unconstrained, approx_centered=False)\n",
      "     |      Jacobian matrix for the parameter transformation function\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      unconstrained : array_like\n",
      "     |          Array of unconstrained parameters used by the optimizer.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      jacobian : ndarray\n",
      "     |          Jacobian matrix of the transformation, evaluated at `unconstrained`\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      transform_params\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      This is a numerical approximation using finite differences. Note that\n",
      "     |      in general complex step methods cannot be used because it is not\n",
      "     |      guaranteed that the `transform_params` method is a real function (e.g.\n",
      "     |      if Cholesky decomposition is used).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from statsmodels.tsa.statespace.mlemodel.MLEModel:\n",
      "     |  \n",
      "     |  from_formula(formula, data, subset=None) from builtins.type\n",
      "     |      Not implemented for state space models\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from statsmodels.tsa.statespace.mlemodel.MLEModel:\n",
      "     |  \n",
      "     |  initial_variance\n",
      "     |  \n",
      "     |  initialization\n",
      "     |  \n",
      "     |  loglikelihood_burn\n",
      "     |  \n",
      "     |  tolerance\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from statsmodels.tsa.base.tsa_model.TimeSeriesModel:\n",
      "     |  \n",
      "     |  exog_names\n",
      "     |      The names of the exogenous variables.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from statsmodels.base.model.LikelihoodModel:\n",
      "     |  \n",
      "     |  information(self, params)\n",
      "     |      Fisher information matrix of model.\n",
      "     |      \n",
      "     |      Returns -1 * Hessian of the log-likelihood evaluated at params.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : ndarray\n",
      "     |          The model parameters.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from statsmodels.base.model.Model:\n",
      "     |  \n",
      "     |  predict(self, params, exog=None, *args, **kwargs)\n",
      "     |      After a model has been fit predict returns the fitted values.\n",
      "     |      \n",
      "     |      This is a placeholder intended to be overwritten by individual models.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from statsmodels.base.model.Model:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class STL(builtins.object)\n",
      "     |  STL(endog, period=None, seasonal=7, trend=None, low_pass=None,\n",
      "     |      seasonal_deg=0, trend_deg=0, low_pass_deg=0, robust=False,\n",
      "     |      seasonal_jump=1, trend_jump=1, low_pass_jump=1)\n",
      "     |  \n",
      "     |  Season-Trend decomposition using LOESS.\n",
      "     |  \n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  endog : array_like\n",
      "     |      Data to be decomposed. Must be squeezable to 1-d.\n",
      "     |  period : {int, None}, optional\n",
      "     |      Periodicity of the sequence. If None and endog is a pandas Series or\n",
      "     |      DataFrame, attempts to determine from endog. If endog is a ndarray,\n",
      "     |      period must be provided.\n",
      "     |  seasonal : int, optional\n",
      "     |      Length of the seasonal smoother. Must be an odd integer, and should\n",
      "     |      normally be >= 7 (default).\n",
      "     |  trend : {int, None}, optional\n",
      "     |      Length of the trend smoother. Must be an odd integer. If not provided\n",
      "     |      uses the smallest odd integer greater than\n",
      "     |      1.5 * period / (1 - 1.5 / seasonal), following the suggestion in\n",
      "     |      the original implementation.\n",
      "     |  low_pass : {int, None}, optional\n",
      "     |      Length of the low-pass filter. Must be an odd integer >=3. If not\n",
      "     |      provided, uses the smallest odd integer > period.\n",
      "     |  seasonal_deg : int, optional\n",
      "     |      Degree of seasonal LOESS. 0 (constant) or 1 (constant and trend).\n",
      "     |  trend_deg : int, optional\n",
      "     |      Degree of trend LOESS. 0 (constant) or 1 (constant and trend).\n",
      "     |  low_pass_deg : int, optional\n",
      "     |      Degree of low pass LOESS. 0 (constant) or 1 (constant and trend).\n",
      "     |  robust : bool, optional\n",
      "     |      Flag indicating whether to use a weighted version that is robust to\n",
      "     |      some forms of outliers.\n",
      "     |  seasonal_jump : int, optional\n",
      "     |      Positive integer determining the linear interpolation step. If larger\n",
      "     |      than 1, the LOESS is used every seasonal_jump points and linear\n",
      "     |      interpolation is between fitted points. Higher values reduce\n",
      "     |      estimation time.\n",
      "     |  trend_jump : int, optional\n",
      "     |      Positive integer determining the linear interpolation step. If larger\n",
      "     |      than 1, the LOESS is used every trend_jump points and values between\n",
      "     |      the two are linearly interpolated. Higher values reduce estimation\n",
      "     |      time.\n",
      "     |  low_pass_jump : int, optional\n",
      "     |      Positive integer determining the linear interpolation step. If larger\n",
      "     |      than 1, the LOESS is used every low_pass_jump points and values between\n",
      "     |      the two are linearly interpolated. Higher values reduce estimation\n",
      "     |      time.\n",
      "     |  \n",
      "     |  See Also\n",
      "     |  --------\n",
      "     |  statsmodels.tsa.seasonal.DecomposeResult\n",
      "     |  statsmodels.tsa.seasonal.seasonal_decompose\n",
      "     |  \n",
      "     |  Notes\n",
      "     |  -----\n",
      "     |  Derived from the NETLIB fortran written by [1]_.  The original code\n",
      "     |  contains a bug that appears in the determination of the median that is\n",
      "     |  used in the robust weighting. This version matches the fixed version that\n",
      "     |  uses a correct partitioned sort to determine the median.\n",
      "     |  \n",
      "     |  References\n",
      "     |  ----------\n",
      "     |  .. [1] R. B. Cleveland, W. S. Cleveland, J.E. McRae, and I. Terpenning\n",
      "     |      (1990) STL: A Seasonal-Trend Decomposition Procedure Based on LOESS.\n",
      "     |      Journal of Official Statistics, 6, 3-73.\n",
      "     |  \n",
      "     |  Examples\n",
      "     |  --------\n",
      "     |  The original example uses STL to decompose CO2 data into level, season and a\n",
      "     |  residual.\n",
      "     |  \n",
      "     |  Start by aggregating to monthly, and filling any missing values\n",
      "     |  \n",
      "     |  >>> from statsmodels.datasets import co2\n",
      "     |  >>> import matplotlib.pyplot as plt\n",
      "     |  >>> from pandas.plotting import register_matplotlib_converters\n",
      "     |  >>> register_matplotlib_converters()\n",
      "     |  >>> data = co2.load(True).data\n",
      "     |  >>> data = data.resample('M').mean().ffill()\n",
      "     |  \n",
      "     |  The period (12) is automatically detected from the data's frequency ('M').\n",
      "     |  \n",
      "     |  >>> from statsmodels.tsa.seasonal import STL\n",
      "     |  >>> res = STL(data).fit()\n",
      "     |  >>> res.plot()\n",
      "     |  >>> plt.show()\n",
      "     |  \n",
      "     |  .. plot:: plots/stl_plot.py\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __reduce__(...)\n",
      "     |      Helper for pickle.\n",
      "     |  \n",
      "     |  fit(...)\n",
      "     |      fit(inner_iter=None, outer_iter=None)\n",
      "     |      \n",
      "     |      Estimate season, trend and residuals components.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      inner_iter : {int, None}, optional\n",
      "     |          Number of iterations to perform in the inner loop. If not provided\n",
      "     |          uses 2 if ``robust`` is True, or 5 if not.\n",
      "     |      outer_iter : {int, None}, optional\n",
      "     |          Number of iterations to perform in the outer loop. If not provided\n",
      "     |          uses 15 if ``robust`` is True, or 0 if not.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      DecomposeResult\n",
      "     |          Estimation results.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  config\n",
      "     |      The parameters used in the model.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      dict[str, Union[int, bool]]\n",
      "     |          The values used in the STL decomposition.\n",
      "     |  \n",
      "     |  period\n",
      "     |      The period length of the time series\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __pyx_vtable__ = <capsule object NULL>\n",
      "    \n",
      "    class STLForecast(builtins.object)\n",
      "     |  STLForecast(endog, model, *, model_kwargs=None, period=None, seasonal=7, trend=None, low_pass=None, seasonal_deg=1, trend_deg=1, low_pass_deg=1, robust=False, seasonal_jump=1, trend_jump=1, low_pass_jump=1)\n",
      "     |  \n",
      "     |  Model-based forecasting using STL to remove seasonality\n",
      "     |  \n",
      "     |  Forecasts are produced by first subtracting the seasonality\n",
      "     |  estimated using STL, then forecasting the deseasonalized\n",
      "     |  data using a time-series model, for example, ARIMA.\n",
      "     |  \n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  endog : array_like\n",
      "     |      Data to be decomposed. Must be squeezable to 1-d.\n",
      "     |  model : Model\n",
      "     |      The model used to forecast endog after the seasonality has been removed using STL\n",
      "     |  model_kwargs : Dict[str, Any]\n",
      "     |      Any additional arguments needed to initialized the model using the residuals produced by subtracting the seasonality.\n",
      "     |  period : {int, None}, optional\n",
      "     |      Periodicity of the sequence. If None and endog is a pandas Series or\n",
      "     |      DataFrame, attempts to determine from endog. If endog is a ndarray,\n",
      "     |      period must be provided.\n",
      "     |  seasonal : int, optional\n",
      "     |      Length of the seasonal smoother. Must be an odd integer, and should\n",
      "     |      normally be >= 7 (default).\n",
      "     |  trend : {int, None}, optional\n",
      "     |      Length of the trend smoother. Must be an odd integer. If not provided\n",
      "     |      uses the smallest odd integer greater than\n",
      "     |      1.5 * period / (1 - 1.5 / seasonal), following the suggestion in\n",
      "     |      the original implementation.\n",
      "     |  low_pass : {int, None}, optional\n",
      "     |      Length of the low-pass filter. Must be an odd integer >=3. If not\n",
      "     |      provided, uses the smallest odd integer > period.\n",
      "     |  seasonal_deg : int, optional\n",
      "     |      Degree of seasonal LOESS. 0 (constant) or 1 (constant and trend).\n",
      "     |  trend_deg : int, optional\n",
      "     |      Degree of trend LOESS. 0 (constant) or 1 (constant and trend).\n",
      "     |  low_pass_deg : int, optional\n",
      "     |      Degree of low pass LOESS. 0 (constant) or 1 (constant and trend).\n",
      "     |  robust : bool, optional\n",
      "     |      Flag indicating whether to use a weighted version that is robust to\n",
      "     |      some forms of outliers.\n",
      "     |  seasonal_jump : int, optional\n",
      "     |      Positive integer determining the linear interpolation step. If larger\n",
      "     |      than 1, the LOESS is used every seasonal_jump points and linear\n",
      "     |      interpolation is between fitted points. Higher values reduce\n",
      "     |      estimation time.\n",
      "     |  trend_jump : int, optional\n",
      "     |      Positive integer determining the linear interpolation step. If larger\n",
      "     |      than 1, the LOESS is used every trend_jump points and values between\n",
      "     |      the two are linearly interpolated. Higher values reduce estimation\n",
      "     |      time.\n",
      "     |  low_pass_jump : int, optional\n",
      "     |      Positive integer determining the linear interpolation step. If larger\n",
      "     |      than 1, the LOESS is used every low_pass_jump points and values between\n",
      "     |      the two are linearly interpolated. Higher values reduce estimation\n",
      "     |      time.\n",
      "     |  \n",
      "     |  See Also\n",
      "     |  --------\n",
      "     |  statsmodels.tsa.arima.model.ARIMA\n",
      "     |      ARIMA modeling.\n",
      "     |  statsmodels.tsa.ar_model.AutoReg\n",
      "     |      Autoregressive modeling supporting complex deterministics.\n",
      "     |  statsmodels.tsa.exponential_smoothing.ets.ETSModel\n",
      "     |      Additive and multiplicative exponential smoothing with trend.\n",
      "     |  statsmodels.tsa.statespace.exponential_smoothing.ExponentialSmoothing\n",
      "     |      Additive exponential smoothing with trend.\n",
      "     |  \n",
      "     |  Notes\n",
      "     |  -----\n",
      "     |  If :math:`\\hat{S}_t` is the seasonal component, then the deseasonalize\n",
      "     |  series is constructed as\n",
      "     |  \n",
      "     |  .. math::\n",
      "     |  \n",
      "     |      Y_t - \\hat{S}_t\n",
      "     |  \n",
      "     |  The trend component is not removed, and so the time series model should\n",
      "     |  be capable of adequately fitting and forecasting the trend if present. The\n",
      "     |  out-of-sample forecasts of the seasonal component are produced as\n",
      "     |  \n",
      "     |  .. math::\n",
      "     |  \n",
      "     |      \\hat{S}_{T + h} = \\hat{S}_{T - k}\n",
      "     |  \n",
      "     |  where :math:`k = m - h + m \\lfloor (h-1)/m \\rfloor` tracks the period\n",
      "     |  offset in the full cycle of 1, 2, ..., m where m is the period length.\n",
      "     |  \n",
      "     |  This class is mostly a convenience wrapper around ``STL`` and a\n",
      "     |  user-specified model. The model is assumed to follow the standard\n",
      "     |  statsmodels pattern:\n",
      "     |  \n",
      "     |  * ``fit`` is used to estimate parameters and returns a results instance,\n",
      "     |    ``results``.\n",
      "     |  * ``results`` must exposes a method ``forecast(steps, **kwargs)`` that\n",
      "     |    produces out-of-sample forecasts.\n",
      "     |  * ``results`` may also exposes a method ``get_prediction`` that produces\n",
      "     |    both in- and out-of-sample predictions.\n",
      "     |  \n",
      "     |  Examples\n",
      "     |  --------\n",
      "     |  >>> import numpy as np\n",
      "     |  >>> import pandas as pd\n",
      "     |  >>> from statsmodels.tsa.api import STLForecast\n",
      "     |  >>> from statsmodels.tsa.arima.model import ARIMA\n",
      "     |  >>> from statsmodels.datasets import macrodata\n",
      "     |  >>> ds = macrodata.load_pandas()\n",
      "     |  >>> data = np.log(ds.data.m1)\n",
      "     |  >>> base_date = f\"{int(ds.data.year[0])}-{3*int(ds.data.quarter[0])+1}-1\"\n",
      "     |  >>> data.index = pd.date_range(base_date, periods=data.shape[0], freq=\"QS\")\n",
      "     |  \n",
      "     |  Generate forecasts from an ARIMA\n",
      "     |  \n",
      "     |  >>> stlf = STLForecast(data, ARIMA, model_kwargs={\"order\": (2, 1, 0)})\n",
      "     |  >>> res = stlf.fit()\n",
      "     |  >>> forecasts = res.forecast(12)\n",
      "     |  \n",
      "     |  Generate forecasts from an Exponential Smoothing model with trend\n",
      "     |  >>> from statsmodels.tsa.statespace import exponential_smoothing\n",
      "     |  >>> ES = exponential_smoothing.ExponentialSmoothing\n",
      "     |  >>> config = {\"trend\": True}\n",
      "     |  >>> stlf = STLForecast(data, ES, model_kwargs=config)\n",
      "     |  >>> res = stlf.fit()\n",
      "     |  >>> forecasts = res.forecast(12)\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, endog, model, *, model_kwargs=None, period=None, seasonal=7, trend=None, low_pass=None, seasonal_deg=1, trend_deg=1, low_pass_deg=1, robust=False, seasonal_jump=1, trend_jump=1, low_pass_jump=1)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  fit(self, *, inner_iter=None, outer_iter=None, fit_kwargs=None)\n",
      "     |      Estimate STL and forecasting model parameters.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      inner_iter : {int, None}, optional\n",
      "     |          Number of iterations to perform in the inner loop. If not provided\n",
      "     |          uses 2 if ``robust`` is True, or 5 if not.\n",
      "     |      outer_iter : {int, None}, optional\n",
      "     |          Number of iterations to perform in the outer loop. If not provided\n",
      "     |          uses 15 if ``robust`` is True, or 0 if not.\n",
      "     |      fit_kwargs : Dict[str, Any]\n",
      "     |          Any additional keyword arguments to pass to ``model``'s ``fit``\n",
      "     |          method when estimating the model on the decomposed residuals.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      STLForecastResults\n",
      "     |          Results with forecasting methods.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class SVAR(statsmodels.tsa.base.tsa_model.TimeSeriesModel)\n",
      "     |  SVAR(endog, svar_type, dates=None, freq=None, A=None, B=None, missing='none')\n",
      "     |  \n",
      "     |  Fit VAR and then estimate structural components of A and B, defined:\n",
      "     |  \n",
      "     |  .. math:: Ay_t = A_1 y_{t-1} + \\ldots + A_p y_{t-p} + B\\var(\\epsilon_t)\n",
      "     |  \n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  endog : array_like\n",
      "     |      1-d endogenous response variable. The independent variable.\n",
      "     |  dates : array_like\n",
      "     |      must match number of rows of endog\n",
      "     |  svar_type : str\n",
      "     |      \"A\" - estimate structural parameters of A matrix, B assumed = I\n",
      "     |      \"B\" - estimate structural parameters of B matrix, A assumed = I\n",
      "     |      \"AB\" - estimate structural parameters indicated in both A and B matrix\n",
      "     |  A : array_like\n",
      "     |      neqs x neqs with unknown parameters marked with 'E' for estimate\n",
      "     |  B : array_like\n",
      "     |      neqs x neqs with unknown parameters marked with 'E' for estimate\n",
      "     |  \n",
      "     |  References\n",
      "     |  ----------\n",
      "     |  Hamilton (1994) Time Series Analysis\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      SVAR\n",
      "     |      statsmodels.tsa.base.tsa_model.TimeSeriesModel\n",
      "     |      statsmodels.base.model.LikelihoodModel\n",
      "     |      statsmodels.base.model.Model\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, endog, svar_type, dates=None, freq=None, A=None, B=None, missing='none')\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  check_order(self, J)\n",
      "     |  \n",
      "     |  check_rank(self, J)\n",
      "     |  \n",
      "     |  fit(self, A_guess=None, B_guess=None, maxlags=None, method='ols', ic=None, trend='c', verbose=False, s_method='mle', solver='bfgs', override=False, maxiter=500, maxfun=500)\n",
      "     |      Fit the SVAR model and solve for structural parameters\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      A_guess : array_like, optional\n",
      "     |          A vector of starting values for all parameters to be estimated\n",
      "     |          in A.\n",
      "     |      B_guess : array_like, optional\n",
      "     |          A vector of starting values for all parameters to be estimated\n",
      "     |          in B.\n",
      "     |      maxlags : int\n",
      "     |          Maximum number of lags to check for order selection, defaults to\n",
      "     |          12 * (nobs/100.)**(1./4), see select_order function\n",
      "     |      method : {'ols'}\n",
      "     |          Estimation method to use\n",
      "     |      ic : {'aic', 'fpe', 'hqic', 'bic', None}\n",
      "     |          Information criterion to use for VAR order selection.\n",
      "     |          aic : Akaike\n",
      "     |          fpe : Final prediction error\n",
      "     |          hqic : Hannan-Quinn\n",
      "     |          bic : Bayesian a.k.a. Schwarz\n",
      "     |      verbose : bool, default False\n",
      "     |          Print order selection output to the screen\n",
      "     |      trend, str {\"c\", \"ct\", \"ctt\", \"n\"}\n",
      "     |          \"c\" - add constant\n",
      "     |          \"ct\" - constant and trend\n",
      "     |          \"ctt\" - constant, linear and quadratic trend\n",
      "     |          \"n\" - co constant, no trend\n",
      "     |          Note that these are prepended to the columns of the dataset.\n",
      "     |      s_method : {'mle'}\n",
      "     |          Estimation method for structural parameters\n",
      "     |      solver : {'nm', 'newton', 'bfgs', 'cg', 'ncg', 'powell'}\n",
      "     |          Solution method\n",
      "     |          See statsmodels.base for details\n",
      "     |      override : bool, default False\n",
      "     |          If True, returns estimates of A and B without checking\n",
      "     |          order or rank condition\n",
      "     |      maxiter : int, default 500\n",
      "     |          Number of iterations to perform in solution method\n",
      "     |      maxfun : int\n",
      "     |          Number of function evaluations to perform\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Ltkepohl pp. 146-153\n",
      "     |      Hamilton pp. 324-336\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      est : SVARResults\n",
      "     |  \n",
      "     |  hessian(self, AB_mask)\n",
      "     |      Returns numerical hessian.\n",
      "     |  \n",
      "     |  loglike(self, params)\n",
      "     |      Loglikelihood for SVAR model\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      This method assumes that the autoregressive parameters are\n",
      "     |      first estimated, then likelihood with structural parameters\n",
      "     |      is estimated\n",
      "     |  \n",
      "     |  score(self, AB_mask)\n",
      "     |      Return the gradient of the loglike at AB_mask.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      AB_mask : unknown values of A and B matrix concatenated\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Return numerical gradient\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  y\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from statsmodels.tsa.base.tsa_model.TimeSeriesModel:\n",
      "     |  \n",
      "     |  exog_names\n",
      "     |      The names of the exogenous variables.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from statsmodels.base.model.LikelihoodModel:\n",
      "     |  \n",
      "     |  information(self, params)\n",
      "     |      Fisher information matrix of model.\n",
      "     |      \n",
      "     |      Returns -1 * Hessian of the log-likelihood evaluated at params.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : ndarray\n",
      "     |          The model parameters.\n",
      "     |  \n",
      "     |  initialize(self)\n",
      "     |      Initialize (possibly re-initialize) a Model instance.\n",
      "     |      \n",
      "     |      For example, if the the design matrix of a linear model changes then\n",
      "     |      initialized can be used to recompute values using the modified design\n",
      "     |      matrix.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from statsmodels.base.model.Model:\n",
      "     |  \n",
      "     |  predict(self, params, exog=None, *args, **kwargs)\n",
      "     |      After a model has been fit predict returns the fitted values.\n",
      "     |      \n",
      "     |      This is a placeholder intended to be overwritten by individual models.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from statsmodels.base.model.Model:\n",
      "     |  \n",
      "     |  from_formula(formula, data, subset=None, drop_cols=None, *args, **kwargs) from builtins.type\n",
      "     |      Create a Model from a formula and dataframe.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      formula : str or generic Formula object\n",
      "     |          The formula specifying the model.\n",
      "     |      data : array_like\n",
      "     |          The data for the model. See Notes.\n",
      "     |      subset : array_like\n",
      "     |          An array-like object of booleans, integers, or index values that\n",
      "     |          indicate the subset of df to use in the model. Assumes df is a\n",
      "     |          `pandas.DataFrame`.\n",
      "     |      drop_cols : array_like\n",
      "     |          Columns to drop from the design matrix.  Cannot be used to\n",
      "     |          drop terms involving categoricals.\n",
      "     |      *args\n",
      "     |          Additional positional argument that are passed to the model.\n",
      "     |      **kwargs\n",
      "     |          These are passed to the model with one exception. The\n",
      "     |          ``eval_env`` keyword is passed to patsy. It can be either a\n",
      "     |          :class:`patsy:patsy.EvalEnvironment` object or an integer\n",
      "     |          indicating the depth of the namespace to use. For example, the\n",
      "     |          default ``eval_env=0`` uses the calling namespace. If you wish\n",
      "     |          to use a \"clean\" environment set ``eval_env=-1``.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      model\n",
      "     |          The model instance.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      data must define __getitem__ with the keys in the formula terms\n",
      "     |      args and kwargs are passed on to the model instantiation. E.g.,\n",
      "     |      a numpy structured or rec array, a dictionary, or a pandas DataFrame.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from statsmodels.base.model.Model:\n",
      "     |  \n",
      "     |  endog_names\n",
      "     |      Names of endogenous variables.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from statsmodels.base.model.Model:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class SimpleExpSmoothing(ExponentialSmoothing)\n",
      "     |  SimpleExpSmoothing(endog, initialization_method=None, initial_level=None)\n",
      "     |  \n",
      "     |  Simple Exponential Smoothing\n",
      "     |  \n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  endog : array_like\n",
      "     |      The time series to model.\n",
      "     |  initialization_method : str, optional\n",
      "     |      Method for initialize the recursions. One of:\n",
      "     |  \n",
      "     |      * None\n",
      "     |      * 'estimated'\n",
      "     |      * 'heuristic'\n",
      "     |      * 'legacy-heuristic'\n",
      "     |      * 'known'\n",
      "     |  \n",
      "     |      None defaults to the pre-0.12 behavior where initial values\n",
      "     |      are passed as part of ``fit``. If any of the other values are\n",
      "     |      passed, then the initial values must also be set when constructing\n",
      "     |      the model. If 'known' initialization is used, then `initial_level`\n",
      "     |      must be passed, as well as `initial_trend` and `initial_seasonal` if\n",
      "     |      applicable. Default is 'estimated'. \"legacy-heuristic\" uses the same\n",
      "     |      values that were used in statsmodels 0.11 and earlier.\n",
      "     |  initial_level : float, optional\n",
      "     |      The initial level component. Required if estimation method is \"known\".\n",
      "     |      If set using either \"estimated\" or \"heuristic\" this value is used.\n",
      "     |      This allows one or more of the initial values to be set while\n",
      "     |      deferring to the heuristic for others or estimating the unset\n",
      "     |      parameters.\n",
      "     |  \n",
      "     |  See Also\n",
      "     |  --------\n",
      "     |  ExponentialSmoothing\n",
      "     |      Exponential smoothing with trend and seasonal components.\n",
      "     |  Holt\n",
      "     |      Exponential smoothing with a trend component.\n",
      "     |  \n",
      "     |  Notes\n",
      "     |  -----\n",
      "     |  This is a full implementation of the simple exponential smoothing as\n",
      "     |  per [1]_.  `SimpleExpSmoothing` is a restricted version of\n",
      "     |  :class:`ExponentialSmoothing`.\n",
      "     |  \n",
      "     |  References\n",
      "     |  ----------\n",
      "     |  .. [1] Hyndman, Rob J., and George Athanasopoulos. Forecasting: principles\n",
      "     |      and practice. OTexts, 2014.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      SimpleExpSmoothing\n",
      "     |      ExponentialSmoothing\n",
      "     |      statsmodels.tsa.base.tsa_model.TimeSeriesModel\n",
      "     |      statsmodels.base.model.LikelihoodModel\n",
      "     |      statsmodels.base.model.Model\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, endog, initialization_method=None, initial_level=None)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  fit(self, smoothing_level=None, *, optimized=True, start_params=None, initial_level=None, use_brute=True, use_boxcox=None, remove_bias=False, method=None, minimize_kwargs=None)\n",
      "     |      Fit the model\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      smoothing_level : float, optional\n",
      "     |          The smoothing_level value of the simple exponential smoothing, if\n",
      "     |          the value is set then this value will be used as the value.\n",
      "     |      optimized : bool, optional\n",
      "     |          Estimate model parameters by maximizing the log-likelihood.\n",
      "     |      start_params : ndarray, optional\n",
      "     |          Starting values to used when optimizing the fit.  If not provided,\n",
      "     |          starting values are determined using a combination of grid search\n",
      "     |          and reasonable values based on the initial values of the data.\n",
      "     |      initial_level : float, optional\n",
      "     |          Value to use when initializing the fitted level.\n",
      "     |      use_brute : bool, optional\n",
      "     |          Search for good starting values using a brute force (grid)\n",
      "     |          optimizer. If False, a naive set of starting values is used.\n",
      "     |      use_boxcox : {True, False, 'log', float}, optional\n",
      "     |          Should the Box-Cox transform be applied to the data first? If 'log'\n",
      "     |          then apply the log. If float then use the value as lambda.\n",
      "     |      remove_bias : bool, optional\n",
      "     |          Remove bias from forecast values and fitted values by enforcing\n",
      "     |          that the average residual is equal to zero.\n",
      "     |      method : str, default \"L-BFGS-B\"\n",
      "     |          The minimizer used. Valid options are \"L-BFGS-B\" (default), \"TNC\",\n",
      "     |          \"SLSQP\", \"Powell\", \"trust-constr\", \"basinhopping\" (also \"bh\") and\n",
      "     |          \"least_squares\" (also \"ls\"). basinhopping tries multiple starting\n",
      "     |          values in an attempt to find a global minimizer in non-convex\n",
      "     |          problems, and so is slower than the others.\n",
      "     |      minimize_kwargs : dict[str, Any]\n",
      "     |          A dictionary of keyword arguments passed to SciPy's minimize\n",
      "     |          function if method is one of \"L-BFGS-B\" (default), \"TNC\",\n",
      "     |          \"SLSQP\", \"Powell\", or \"trust-constr\", or SciPy's basinhopping\n",
      "     |          or least_squares. The valid keywords are optimizer specific.\n",
      "     |          Consult SciPy's documentation for the full set of options.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      HoltWintersResults\n",
      "     |          See statsmodels.tsa.holtwinters.HoltWintersResults.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      This is a full implementation of the simple exponential smoothing as\n",
      "     |      per [1].\n",
      "     |      \n",
      "     |      References\n",
      "     |      ----------\n",
      "     |      [1] Hyndman, Rob J., and George Athanasopoulos. Forecasting: principles\n",
      "     |          and practice. OTexts, 2014.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from ExponentialSmoothing:\n",
      "     |  \n",
      "     |  fix_params(self, values)\n",
      "     |      Temporarily fix parameters for estimation.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      values : dict\n",
      "     |          Values to fix. The key is the parameter name and the value is the\n",
      "     |          fixed value.\n",
      "     |      \n",
      "     |      Yields\n",
      "     |      ------\n",
      "     |      None\n",
      "     |          No value returned.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> from statsmodels.datasets.macrodata import load_pandas\n",
      "     |      >>> data = load_pandas()\n",
      "     |      >>> import statsmodels.tsa.api as tsa\n",
      "     |      >>> mod = tsa.ExponentialSmoothing(data.data.realcons, trend=\"add\",\n",
      "     |      ...                                initialization_method=\"estimated\")\n",
      "     |      >>> with mod.fix_params({\"smoothing_level\": 0.2}):\n",
      "     |      ...     mod.fit()\n",
      "     |  \n",
      "     |  initial_values(self, initial_level=None, initial_trend=None, force=False)\n",
      "     |      Compute initial values used in the exponential smoothing recursions.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      initial_level : {float, None}\n",
      "     |          The initial value used for the level component.\n",
      "     |      initial_trend : {float, None}\n",
      "     |          The initial value used for the trend component.\n",
      "     |      force : bool\n",
      "     |          Force the calculation even if initial values exist.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      initial_level : float\n",
      "     |          The initial value used for the level component.\n",
      "     |      initial_trend : {float, None}\n",
      "     |          The initial value used for the trend component.\n",
      "     |      initial_seasons : list\n",
      "     |          The initial values used for the seasonal components.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Convenience function the exposes the values used to initialize the\n",
      "     |      recursions. When optimizing parameters these are used as starting\n",
      "     |      values.\n",
      "     |      \n",
      "     |      Method used to compute the initial value depends on when components\n",
      "     |      are included in the model.  In a simple exponential smoothing model\n",
      "     |      without trend or a seasonal components, the initial value is set to the\n",
      "     |      first observation. When a trend is added, the trend is initialized\n",
      "     |      either using y[1]/y[0], if multiplicative, or y[1]-y[0]. When the\n",
      "     |      seasonal component is added the initialization adapts to account for\n",
      "     |      the modified structure.\n",
      "     |  \n",
      "     |  predict(self, params, start=None, end=None)\n",
      "     |      In-sample and out-of-sample prediction.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : ndarray\n",
      "     |          The fitted model parameters.\n",
      "     |      start : int, str, or datetime\n",
      "     |          Zero-indexed observation number at which to start forecasting, ie.,\n",
      "     |          the first forecast is start. Can also be a date string to\n",
      "     |          parse or a datetime type.\n",
      "     |      end : int, str, or datetime\n",
      "     |          Zero-indexed observation number at which to end forecasting, ie.,\n",
      "     |          the first forecast is start. Can also be a date string to\n",
      "     |          parse or a datetime type.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      ndarray\n",
      "     |          The predicted values.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from statsmodels.tsa.base.tsa_model.TimeSeriesModel:\n",
      "     |  \n",
      "     |  exog_names\n",
      "     |      The names of the exogenous variables.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from statsmodels.base.model.LikelihoodModel:\n",
      "     |  \n",
      "     |  hessian(self, params)\n",
      "     |      The Hessian matrix of the model.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : ndarray\n",
      "     |          The parameters to use when evaluating the Hessian.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      ndarray\n",
      "     |          The hessian evaluated at the parameters.\n",
      "     |  \n",
      "     |  information(self, params)\n",
      "     |      Fisher information matrix of model.\n",
      "     |      \n",
      "     |      Returns -1 * Hessian of the log-likelihood evaluated at params.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : ndarray\n",
      "     |          The model parameters.\n",
      "     |  \n",
      "     |  initialize(self)\n",
      "     |      Initialize (possibly re-initialize) a Model instance.\n",
      "     |      \n",
      "     |      For example, if the the design matrix of a linear model changes then\n",
      "     |      initialized can be used to recompute values using the modified design\n",
      "     |      matrix.\n",
      "     |  \n",
      "     |  loglike(self, params)\n",
      "     |      Log-likelihood of model.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : ndarray\n",
      "     |          The model parameters used to compute the log-likelihood.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Must be overridden by subclasses.\n",
      "     |  \n",
      "     |  score(self, params)\n",
      "     |      Score vector of model.\n",
      "     |      \n",
      "     |      The gradient of logL with respect to each parameter.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : ndarray\n",
      "     |          The parameters to use when evaluating the Hessian.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      ndarray\n",
      "     |          The score vector evaluated at the parameters.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from statsmodels.base.model.Model:\n",
      "     |  \n",
      "     |  from_formula(formula, data, subset=None, drop_cols=None, *args, **kwargs) from builtins.type\n",
      "     |      Create a Model from a formula and dataframe.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      formula : str or generic Formula object\n",
      "     |          The formula specifying the model.\n",
      "     |      data : array_like\n",
      "     |          The data for the model. See Notes.\n",
      "     |      subset : array_like\n",
      "     |          An array-like object of booleans, integers, or index values that\n",
      "     |          indicate the subset of df to use in the model. Assumes df is a\n",
      "     |          `pandas.DataFrame`.\n",
      "     |      drop_cols : array_like\n",
      "     |          Columns to drop from the design matrix.  Cannot be used to\n",
      "     |          drop terms involving categoricals.\n",
      "     |      *args\n",
      "     |          Additional positional argument that are passed to the model.\n",
      "     |      **kwargs\n",
      "     |          These are passed to the model with one exception. The\n",
      "     |          ``eval_env`` keyword is passed to patsy. It can be either a\n",
      "     |          :class:`patsy:patsy.EvalEnvironment` object or an integer\n",
      "     |          indicating the depth of the namespace to use. For example, the\n",
      "     |          default ``eval_env=0`` uses the calling namespace. If you wish\n",
      "     |          to use a \"clean\" environment set ``eval_env=-1``.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      model\n",
      "     |          The model instance.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      data must define __getitem__ with the keys in the formula terms\n",
      "     |      args and kwargs are passed on to the model instantiation. E.g.,\n",
      "     |      a numpy structured or rec array, a dictionary, or a pandas DataFrame.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from statsmodels.base.model.Model:\n",
      "     |  \n",
      "     |  endog_names\n",
      "     |      Names of endogenous variables.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from statsmodels.base.model.Model:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class UECM(ARDL)\n",
      "     |  UECM(endog: 'Union[Sequence[float], pd.Series, _ArrayLike2D]', lags: 'Union[None, int]', exog: 'Optional[_ArrayLike2D]' = None, order: '_UECMOrder' = 0, trend: \"Literal[('n', 'c', 'ct', 'ctt')]\" = 'c', *, fixed: 'Optional[_ArrayLike2D]' = None, causal: 'bool' = False, seasonal: 'bool' = False, deterministic: 'Optional[DeterministicProcess]' = None, hold_back: 'Optional[int]' = None, period: 'Optional[int]' = None, missing: \"Literal[('none', 'drop', 'raise')]\" = 'none') -> 'None'\n",
      "     |  \n",
      "     |  Unconstrained Error Correlation Model(UECM)\n",
      "     |  \n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  endog : array_like\n",
      "     |      A 1-d endogenous response variable. The dependent variable.\n",
      "     |  lags : {int, list[int]}\n",
      "     |      The number of lags of the endogenous variable to include in the\n",
      "     |      model. Must be at least 1.\n",
      "     |  exog : array_like\n",
      "     |      Exogenous variables to include in the model. Either a DataFrame or\n",
      "     |      an 2-d array-like structure that can be converted to a NumPy array.\n",
      "     |  order : {int, sequence[int], dict}\n",
      "     |      If int, uses lags 0, 1, ..., order  for all exog variables. If a\n",
      "     |      dict, applies the lags series by series. If ``exog`` is anything\n",
      "     |      other than a DataFrame, the keys are the column index of exog\n",
      "     |      (e.g., 0, 1, ...). If a DataFrame, keys are column names.\n",
      "     |  fixed : array_like\n",
      "     |      Additional fixed regressors that are not lagged.\n",
      "     |  causal : bool, optional\n",
      "     |      Whether to include lag 0 of exog variables.  If True, only includes\n",
      "     |      lags 1, 2, ...\n",
      "     |  trend : {'n', 'c', 't', 'ct'}, optional\n",
      "     |      The trend to include in the model:\n",
      "     |  \n",
      "     |      * 'n' - No trend.\n",
      "     |      * 'c' - Constant only.\n",
      "     |      * 't' - Time trend only.\n",
      "     |      * 'ct' - Constant and time trend.\n",
      "     |  \n",
      "     |      The default is 'c'.\n",
      "     |  \n",
      "     |  seasonal : bool, optional\n",
      "     |      Flag indicating whether to include seasonal dummies in the model. If\n",
      "     |      seasonal is True and trend includes 'c', then the first period\n",
      "     |      is excluded from the seasonal terms.\n",
      "     |  deterministic : DeterministicProcess, optional\n",
      "     |      A deterministic process.  If provided, trend and seasonal are ignored.\n",
      "     |      A warning is raised if trend is not \"n\" and seasonal is not False.\n",
      "     |  hold_back : {None, int}, optional\n",
      "     |      Initial observations to exclude from the estimation sample.  If None,\n",
      "     |      then hold_back is equal to the maximum lag in the model.  Set to a\n",
      "     |      non-zero value to produce comparable models with different lag\n",
      "     |      length.  For example, to compare the fit of a model with lags=3 and\n",
      "     |      lags=1, set hold_back=3 which ensures that both models are estimated\n",
      "     |      using observations 3,...,nobs. hold_back must be >= the maximum lag in\n",
      "     |      the model.\n",
      "     |  period : {None, int}, optional\n",
      "     |      The period of the data. Only used if seasonal is True. This parameter\n",
      "     |      can be omitted if using a pandas object for endog that contains a\n",
      "     |      recognized frequency.\n",
      "     |  missing : {\"none\", \"drop\", \"raise\"}, optional\n",
      "     |      Available options are 'none', 'drop', and 'raise'. If 'none', no nan\n",
      "     |      checking is done. If 'drop', any observations with nans are dropped.\n",
      "     |      If 'raise', an error is raised. Default is 'none'.\n",
      "     |  \n",
      "     |  Notes\n",
      "     |  -----\n",
      "     |  The full specification of an UECM is\n",
      "     |  \n",
      "     |  .. math ::\n",
      "     |  \n",
      "     |     \\Delta Y_t = \\delta_0 + \\delta_1 t + \\delta_2 t^2\n",
      "     |           + \\sum_{i=1}^{s-1} \\gamma_i I_{[(\\mod(t,s) + 1) = i]}\n",
      "     |           + \\lambda_0 Y_{t-1} + \\lambda_1 X_{1,t-1} + \\ldots\n",
      "     |           + \\lambda_{k} X_{k,t-1}\n",
      "     |           + \\sum_{j=1}^{p-1} \\phi_j \\Delta Y_{t-j}\n",
      "     |           + \\sum_{l=1}^k \\sum_{m=0}^{o_l-1} \\beta_{l,m} \\Delta X_{l, t-m}\n",
      "     |           + Z_t \\lambda\n",
      "     |           + \\epsilon_t\n",
      "     |  \n",
      "     |  where :math:`\\delta_\\bullet` capture trends, :math:`\\gamma_\\bullet`\n",
      "     |  capture seasonal shifts, s is the period of the seasonality, p is the\n",
      "     |  lag length of the endogenous variable, k is the number of exogenous\n",
      "     |  variables :math:`X_{l}`, :math:`o_l` is included the lag length of\n",
      "     |  :math:`X_{l}`, :math:`Z_t` are ``r`` included fixed regressors and\n",
      "     |  :math:`\\epsilon_t` is a white noise shock. If ``causal`` is ``True``,\n",
      "     |  then the 0-th lag of the exogenous variables is not included and the\n",
      "     |  sum starts at ``m=1``.\n",
      "     |  \n",
      "     |  See Also\n",
      "     |  --------\n",
      "     |  statsmodels.tsa.ardl.ARDL\n",
      "     |      Autoregressive distributed lag model estimation\n",
      "     |  statsmodels.tsa.ar_model.AutoReg\n",
      "     |      Autoregressive model estimation with optional exogenous regressors\n",
      "     |  statsmodels.tsa.statespace.sarimax.SARIMAX\n",
      "     |      Seasonal ARIMA model estimation with optional exogenous regressors\n",
      "     |  statsmodels.tsa.arima.model.ARIMA\n",
      "     |      ARIMA model estimation\n",
      "     |  \n",
      "     |  Examples\n",
      "     |  --------\n",
      "     |  >>> from statsmodels.tsa.api import UECM\n",
      "     |  >>> from statsmodels.datasets import danish_data\n",
      "     |  >>> data = danish_data.load_pandas().data\n",
      "     |  >>> lrm = data.lrm\n",
      "     |  >>> exog = data[[\"lry\", \"ibo\", \"ide\"]]\n",
      "     |  \n",
      "     |  A basic model where all variables have 3 lags included\n",
      "     |  \n",
      "     |  >>> UECM(data.lrm, 3, data[[\"lry\", \"ibo\", \"ide\"]], 3)\n",
      "     |  \n",
      "     |  A dictionary can be used to pass custom lag orders\n",
      "     |  \n",
      "     |  >>> UECM(data.lrm, [1, 3], exog, {\"lry\": 1, \"ibo\": 3, \"ide\": 2})\n",
      "     |  \n",
      "     |  Setting causal removes the 0-th lag from the exogenous variables\n",
      "     |  \n",
      "     |  >>> exog_lags = {\"lry\": 1, \"ibo\": 3, \"ide\": 2}\n",
      "     |  >>> UECM(data.lrm, 3, exog, exog_lags, causal=True)\n",
      "     |  \n",
      "     |  When using NumPy arrays, the dictionary keys are the column index.\n",
      "     |  \n",
      "     |  >>> import numpy as np\n",
      "     |  >>> lrma = np.asarray(lrm)\n",
      "     |  >>> exoga = np.asarray(exog)\n",
      "     |  >>> UECM(lrma, 3, exoga, {0: 1, 1: 3, 2: 2})\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      UECM\n",
      "     |      ARDL\n",
      "     |      statsmodels.tsa.ar_model.AutoReg\n",
      "     |      statsmodels.tsa.base.tsa_model.TimeSeriesModel\n",
      "     |      statsmodels.base.model.LikelihoodModel\n",
      "     |      statsmodels.base.model.Model\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, endog: 'Union[Sequence[float], pd.Series, _ArrayLike2D]', lags: 'Union[None, int]', exog: 'Optional[_ArrayLike2D]' = None, order: '_UECMOrder' = 0, trend: \"Literal[('n', 'c', 'ct', 'ctt')]\" = 'c', *, fixed: 'Optional[_ArrayLike2D]' = None, causal: 'bool' = False, seasonal: 'bool' = False, deterministic: 'Optional[DeterministicProcess]' = None, hold_back: 'Optional[int]' = None, period: 'Optional[int]' = None, missing: \"Literal[('none', 'drop', 'raise')]\" = 'none') -> 'None'\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  fit(self, *, cov_type: 'str' = 'nonrobust', cov_kwds: 'Dict[str, Any]' = None, use_t: 'bool' = True) -> 'UECMResults'\n",
      "     |      Estimate the model parameters.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      cov_type : str\n",
      "     |          The covariance estimator to use. The most common choices are listed\n",
      "     |          below.  Supports all covariance estimators that are available\n",
      "     |          in ``OLS.fit``.\n",
      "     |      \n",
      "     |          * 'nonrobust' - The class OLS covariance estimator that assumes\n",
      "     |            homoskedasticity.\n",
      "     |          * 'HC0', 'HC1', 'HC2', 'HC3' - Variants of White's\n",
      "     |            (or Eiker-Huber-White) covariance estimator. `HC0` is the\n",
      "     |            standard implementation.  The other make corrections to improve\n",
      "     |            the finite sample performance of the heteroskedasticity robust\n",
      "     |            covariance estimator.\n",
      "     |          * 'HAC' - Heteroskedasticity-autocorrelation robust covariance\n",
      "     |            estimation. Supports cov_kwds.\n",
      "     |      \n",
      "     |            - `maxlags` integer (required) : number of lags to use.\n",
      "     |            - `kernel` callable or str (optional) : kernel\n",
      "     |                currently available kernels are ['bartlett', 'uniform'],\n",
      "     |                default is Bartlett.\n",
      "     |            - `use_correction` bool (optional) : If true, use small sample\n",
      "     |                correction.\n",
      "     |      cov_kwds : dict, optional\n",
      "     |          A dictionary of keyword arguments to pass to the covariance\n",
      "     |          estimator. `nonrobust` and `HC#` do not support cov_kwds.\n",
      "     |      use_t : bool, optional\n",
      "     |          A flag indicating that inference should use the Student's t\n",
      "     |          distribution that accounts for model degree of freedom.  If False,\n",
      "     |          uses the normal distribution. If None, defers the choice to\n",
      "     |          the cov_type. It also removes degree of freedom corrections from\n",
      "     |          the covariance estimator when cov_type is 'nonrobust'.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      UECMResults\n",
      "     |          Estimation results.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      statsmodels.tsa.ardl.ARDL\n",
      "     |          Autoregressive distributed lag model estimation\n",
      "     |      statsmodels.tsa.ar_model.AutoReg\n",
      "     |          Ordinary Least Squares estimation.\n",
      "     |      statsmodels.regression.linear_model.OLS\n",
      "     |          Ordinary Least Squares estimation.\n",
      "     |      statsmodels.regression.linear_model.RegressionResults\n",
      "     |          See ``get_robustcov_results`` for a detailed list of available covariance estimators and options.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Use ``OLS`` to estimate model parameters and to estimate parameter\n",
      "     |      covariance.\n",
      "     |  \n",
      "     |  predict(self, params: 'Union[np.ndarray, pd.DataFrame]', start: 'Union[None, int, str, dt.datetime, pd.Timestamp]' = None, end: 'Union[None, int, str, dt.datetime, pd.Timestamp]' = None, dynamic: 'bool' = False, exog: 'Union[None, np.ndarray, pd.DataFrame]' = None, exog_oos: 'Union[None, np.ndarray, pd.DataFrame]' = None, fixed: 'Union[None, np.ndarray, pd.DataFrame]' = None, fixed_oos: 'Union[None, np.ndarray, pd.DataFrame]' = None) -> 'np.ndarray'\n",
      "     |      In-sample prediction and out-of-sample forecasting.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : array_like\n",
      "     |          The fitted model parameters.\n",
      "     |      start : int, str, or datetime, optional\n",
      "     |          Zero-indexed observation number at which to start forecasting,\n",
      "     |          i.e., the first forecast is start. Can also be a date string to\n",
      "     |          parse or a datetime type. Default is the the zeroth observation.\n",
      "     |      end : int, str, or datetime, optional\n",
      "     |          Zero-indexed observation number at which to end forecasting, i.e.,\n",
      "     |          the last forecast is end. Can also be a date string to\n",
      "     |          parse or a datetime type. However, if the dates index does not\n",
      "     |          have a fixed frequency, end must be an integer index if you\n",
      "     |          want out-of-sample prediction. Default is the last observation in\n",
      "     |          the sample. Unlike standard python slices, end is inclusive so\n",
      "     |          that all the predictions [start, start+1, ..., end-1, end] are\n",
      "     |          returned.\n",
      "     |      dynamic : {bool, int, str, datetime, Timestamp}, optional\n",
      "     |          Integer offset relative to `start` at which to begin dynamic\n",
      "     |          prediction. Prior to this observation, true endogenous values\n",
      "     |          will be used for prediction; starting with this observation and\n",
      "     |          continuing through the end of prediction, forecasted endogenous\n",
      "     |          values will be used instead. Datetime-like objects are not\n",
      "     |          interpreted as offsets. They are instead used to find the index\n",
      "     |          location of `dynamic` which is then used to to compute the offset.\n",
      "     |      exog : array_like\n",
      "     |          A replacement exogenous array.  Must have the same shape as the\n",
      "     |          exogenous data array used when the model was created.\n",
      "     |      exog_oos : array_like\n",
      "     |          An array containing out-of-sample values of the exogenous\n",
      "     |          variables. Must have the same number of columns as the exog\n",
      "     |          used when the model was created, and at least as many rows as\n",
      "     |          the number of out-of-sample forecasts.\n",
      "     |      fixed : array_like\n",
      "     |          A replacement fixed array.  Must have the same shape as the\n",
      "     |          fixed data array used when the model was created.\n",
      "     |      fixed_oos : array_like\n",
      "     |          An array containing out-of-sample values of the fixed variables.\n",
      "     |          Must have the same number of columns as the fixed used when the\n",
      "     |          model was created, and at least as many rows as the number of\n",
      "     |          out-of-sample forecasts.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      predictions : {ndarray, Series}\n",
      "     |          Array of out of in-sample predictions and / or out-of-sample\n",
      "     |          forecasts.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods defined here:\n",
      "     |  \n",
      "     |  from_ardl(ardl: 'ARDL', missing: \"Literal[('none', 'drop', 'raise')]\" = 'none') from builtins.type\n",
      "     |      Construct a UECM from an ARDL model\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      ardl : ARDL\n",
      "     |          The ARDL model instance\n",
      "     |      missing : {\"none\", \"drop\", \"raise\"}, default \"none\"\n",
      "     |          How to treat missing observations.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      UECM\n",
      "     |          The UECM model instance\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      The lag requirements for a UECM are stricter than for an ARDL.\n",
      "     |      Any variable that is included in the UECM must have a lag length\n",
      "     |      of at least 1. Additionally, the included lags must be contiguous\n",
      "     |      starting at 0 if non-causal or 1 if causal.\n",
      "     |  \n",
      "     |  from_formula(formula: 'str', data: 'pd.DataFrame', lags: 'Union[None, int, Sequence[int]]' = 0, order: '_ARDLOrder' = 0, trend: \"Literal[('n', 'c', 'ct', 'ctt')]\" = 'n', *, causal: 'bool' = False, seasonal: 'bool' = False, deterministic: 'Optional[DeterministicProcess]' = None, hold_back: 'Optional[int]' = None, period: 'Optional[int]' = None, missing: \"Literal[('none', 'raise')]\" = 'none') -> 'UECM' from builtins.type\n",
      "     |      Construct an UECM from a formula\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      formula : str\n",
      "     |          Formula with form dependent ~ independent | fixed. See Examples\n",
      "     |          below.\n",
      "     |      data : DataFrame\n",
      "     |          DataFrame containing the variables in the formula.\n",
      "     |      lags : int\n",
      "     |          The number of lags of the endogenous variable to include in the model.\n",
      "     |          Must be at least 1.\n",
      "     |      order : int, dict\n",
      "     |          If int, uses lags 0, 1, ..., order  for all exog variables. If a dict,\n",
      "     |          applies the lags series by series. If ``exog`` is anything other than a\n",
      "     |          DataFrame, the keys are the column index of exog (e.g., 0, 1, ...). If\n",
      "     |          a DataFrame, keys are column names.\n",
      "     |      causal : bool, optional\n",
      "     |          Whether to include lag 0 of exog variables.  If True, only\n",
      "     |          includes lags 1, 2, ...\n",
      "     |      trend : {'n', 'c', 't', 'ct'}, optional\n",
      "     |          The trend to include in the model:\n",
      "     |      \n",
      "     |          * 'n' - No trend.\n",
      "     |          * 'c' - Constant only.\n",
      "     |          * 't' - Time trend only.\n",
      "     |          * 'ct' - Constant and time trend.\n",
      "     |      \n",
      "     |          The default is 'c'.\n",
      "     |      seasonal : bool, optional\n",
      "     |          Flag indicating whether to include seasonal dummies in the model.\n",
      "     |          If seasonal is True and trend includes 'c', then the first period\n",
      "     |          is excluded from the seasonal terms.\n",
      "     |      deterministic : DeterministicProcess, optional\n",
      "     |          A deterministic process.  If provided, trend and seasonal are\n",
      "     |          ignored. A warning is raised if trend is not \"n\" and seasonal\n",
      "     |          is not False.\n",
      "     |      hold_back : {None, int}, optional\n",
      "     |          Initial observations to exclude from the estimation sample.  If\n",
      "     |          None, then hold_back is equal to the maximum lag in the model.\n",
      "     |          Set to a non-zero value to produce comparable models with\n",
      "     |          different lag length.  For example, to compare the fit of a model\n",
      "     |          with lags=3 and lags=1, set hold_back=3 which ensures that both\n",
      "     |          models are estimated using observations 3,...,nobs. hold_back\n",
      "     |          must be >= the maximum lag in the model.\n",
      "     |      period : {None, int}, optional\n",
      "     |          The period of the data. Only used if seasonal is True. This\n",
      "     |          parameter can be omitted if using a pandas object for endog\n",
      "     |          that contains a recognized frequency.\n",
      "     |      missing : {\"none\", \"drop\", \"raise\"}, optional\n",
      "     |          Available options are 'none', 'drop', and 'raise'. If 'none', no\n",
      "     |          nan checking is done. If 'drop', any observations with nans are\n",
      "     |          dropped. If 'raise', an error is raised. Default is 'none'.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      UECM\n",
      "     |          The UECM model instance\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      A simple UECM using the Danish data\n",
      "     |      \n",
      "     |      >>> from statsmodels.datasets.danish_data import load\n",
      "     |      >>> from statsmodels.tsa.api import UECM\n",
      "     |      >>> data = load().data\n",
      "     |      >>> mod = UECM.from_formula(\"lrm ~ ibo\", data, 2, 2)\n",
      "     |      \n",
      "     |      Fixed regressors can be specified using a |\n",
      "     |      \n",
      "     |      >>> mod = UECM.from_formula(\"lrm ~ ibo | ide\", data, 2, 2)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from ARDL:\n",
      "     |  \n",
      "     |  ar_lags\n",
      "     |      The autoregressive lags included in the model\n",
      "     |  \n",
      "     |  ardl_order\n",
      "     |      The order of the ARDL(p,q)\n",
      "     |  \n",
      "     |  causal\n",
      "     |      Flag indicating that the ARDL is causal\n",
      "     |  \n",
      "     |  dl_lags\n",
      "     |      The lags of exogenous variables included in the model\n",
      "     |  \n",
      "     |  fixed\n",
      "     |      The fixed data used to construct the model\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from statsmodels.tsa.ar_model.AutoReg:\n",
      "     |  \n",
      "     |  hessian(self, params)\n",
      "     |      The Hessian matrix of the model.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : ndarray\n",
      "     |          The parameters to use when evaluating the Hessian.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      ndarray\n",
      "     |          The hessian evaluated at the parameters.\n",
      "     |  \n",
      "     |  information(self, params)\n",
      "     |      Fisher information matrix of model.\n",
      "     |      \n",
      "     |      Returns -1 * Hessian of the log-likelihood evaluated at params.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : ndarray\n",
      "     |          The model parameters.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      ndarray\n",
      "     |          The information matrix.\n",
      "     |  \n",
      "     |  initialize(self)\n",
      "     |      Initialize the model (no-op).\n",
      "     |  \n",
      "     |  loglike(self, params)\n",
      "     |      Log-likelihood of model.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : ndarray\n",
      "     |          The model parameters used to compute the log-likelihood.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      float\n",
      "     |          The log-likelihood value.\n",
      "     |  \n",
      "     |  score(self, params)\n",
      "     |      Score vector of model.\n",
      "     |      \n",
      "     |      The gradient of logL with respect to each parameter.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : ndarray\n",
      "     |          The parameters to use when evaluating the Hessian.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      ndarray\n",
      "     |          The score vector evaluated at the parameters.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from statsmodels.tsa.ar_model.AutoReg:\n",
      "     |  \n",
      "     |  deterministic\n",
      "     |      The deterministic used to construct the model\n",
      "     |  \n",
      "     |  df_model\n",
      "     |      The model degrees of freedom.\n",
      "     |  \n",
      "     |  exog_names\n",
      "     |      Names of exogenous variables included in model\n",
      "     |  \n",
      "     |  hold_back\n",
      "     |      The number of initial obs. excluded from the estimation sample.\n",
      "     |  \n",
      "     |  period\n",
      "     |      The period of the seasonal component.\n",
      "     |  \n",
      "     |  seasonal\n",
      "     |      Flag indicating that the model contains a seasonal component.\n",
      "     |  \n",
      "     |  trend\n",
      "     |      The trend used in the model.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from statsmodels.base.model.Model:\n",
      "     |  \n",
      "     |  endog_names\n",
      "     |      Names of endogenous variables.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from statsmodels.base.model.Model:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class UnobservedComponents(statsmodels.tsa.statespace.mlemodel.MLEModel)\n",
      "     |  UnobservedComponents(endog, level=False, trend=False, seasonal=None, freq_seasonal=None, cycle=False, autoregressive=None, exog=None, irregular=False, stochastic_level=False, stochastic_trend=False, stochastic_seasonal=True, stochastic_freq_seasonal=None, stochastic_cycle=False, damped_cycle=False, cycle_period_bounds=None, mle_regression=True, use_exact_diffuse=False, **kwargs)\n",
      "     |  \n",
      "     |  Univariate unobserved components time series model\n",
      "     |  \n",
      "     |  These are also known as structural time series models, and decompose a\n",
      "     |  (univariate) time series into trend, seasonal, cyclical, and irregular\n",
      "     |  components.\n",
      "     |  \n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  \n",
      "     |  endog : array_like\n",
      "     |      The observed time-series process :math:`y`\n",
      "     |  level : {bool, str}, optional\n",
      "     |      Whether or not to include a level component. Default is False. Can also\n",
      "     |      be a string specification of the level / trend component; see Notes\n",
      "     |      for available model specification strings.\n",
      "     |  trend : bool, optional\n",
      "     |      Whether or not to include a trend component. Default is False. If True,\n",
      "     |      `level` must also be True.\n",
      "     |  seasonal : {int, None}, optional\n",
      "     |      The period of the seasonal component, if any. Default is None.\n",
      "     |  freq_seasonal : {list[dict], None}, optional.\n",
      "     |      Whether (and how) to model seasonal component(s) with trig. functions.\n",
      "     |      If specified, there is one dictionary for each frequency-domain\n",
      "     |      seasonal component.  Each dictionary must have the key, value pair for\n",
      "     |      'period' -- integer and may have a key, value pair for\n",
      "     |      'harmonics' -- integer. If 'harmonics' is not specified in any of the\n",
      "     |      dictionaries, it defaults to the floor of period/2.\n",
      "     |  cycle : bool, optional\n",
      "     |      Whether or not to include a cycle component. Default is False.\n",
      "     |  autoregressive : {int, None}, optional\n",
      "     |      The order of the autoregressive component. Default is None.\n",
      "     |  exog : {array_like, None}, optional\n",
      "     |      Exogenous variables.\n",
      "     |  irregular : bool, optional\n",
      "     |      Whether or not to include an irregular component. Default is False.\n",
      "     |  stochastic_level : bool, optional\n",
      "     |      Whether or not any level component is stochastic. Default is False.\n",
      "     |  stochastic_trend : bool, optional\n",
      "     |      Whether or not any trend component is stochastic. Default is False.\n",
      "     |  stochastic_seasonal : bool, optional\n",
      "     |      Whether or not any seasonal component is stochastic. Default is True.\n",
      "     |  stochastic_freq_seasonal : list[bool], optional\n",
      "     |      Whether or not each seasonal component(s) is (are) stochastic.  Default\n",
      "     |      is True for each component.  The list should be of the same length as\n",
      "     |      freq_seasonal.\n",
      "     |  stochastic_cycle : bool, optional\n",
      "     |      Whether or not any cycle component is stochastic. Default is False.\n",
      "     |  damped_cycle : bool, optional\n",
      "     |      Whether or not the cycle component is damped. Default is False.\n",
      "     |  cycle_period_bounds : tuple, optional\n",
      "     |      A tuple with lower and upper allowed bounds for the period of the\n",
      "     |      cycle. If not provided, the following default bounds are used:\n",
      "     |      (1) if no date / time information is provided, the frequency is\n",
      "     |      constrained to be between zero and :math:`\\pi`, so the period is\n",
      "     |      constrained to be in [0.5, infinity].\n",
      "     |      (2) If the date / time information is provided, the default bounds\n",
      "     |      allow the cyclical component to be between 1.5 and 12 years; depending\n",
      "     |      on the frequency of the endogenous variable, this will imply different\n",
      "     |      specific bounds.\n",
      "     |  mle_regression : bool, optional\n",
      "     |      Whether or not to estimate regression coefficients by maximum likelihood\n",
      "     |      as one of hyperparameters. Default is True.\n",
      "     |      If False, the regression coefficients are estimated by recursive OLS,\n",
      "     |      included in the state vector.\n",
      "     |  use_exact_diffuse : bool, optional\n",
      "     |      Whether or not to use exact diffuse initialization for non-stationary\n",
      "     |      states. Default is False (in which case approximate diffuse\n",
      "     |      initialization is used).\n",
      "     |  \n",
      "     |  See Also\n",
      "     |  --------\n",
      "     |  statsmodels.tsa.statespace.structural.UnobservedComponentsResults\n",
      "     |  statsmodels.tsa.statespace.mlemodel.MLEModel\n",
      "     |  \n",
      "     |  Notes\n",
      "     |  -----\n",
      "     |  \n",
      "     |  These models take the general form (see [1]_ Chapter 3.2 for all details)\n",
      "     |  \n",
      "     |  .. math::\n",
      "     |  \n",
      "     |      y_t = \\mu_t + \\gamma_t + c_t + \\varepsilon_t\n",
      "     |  \n",
      "     |  where :math:`y_t` refers to the observation vector at time :math:`t`,\n",
      "     |  :math:`\\mu_t` refers to the trend component, :math:`\\gamma_t` refers to the\n",
      "     |  seasonal component, :math:`c_t` refers to the cycle, and\n",
      "     |  :math:`\\varepsilon_t` is the irregular. The modeling details of these\n",
      "     |  components are given below.\n",
      "     |  \n",
      "     |  **Trend**\n",
      "     |  \n",
      "     |  The trend component is a dynamic extension of a regression model that\n",
      "     |  includes an intercept and linear time-trend. It can be written:\n",
      "     |  \n",
      "     |  .. math::\n",
      "     |  \n",
      "     |      \\mu_t = \\mu_{t-1} + \\beta_{t-1} + \\eta_{t-1} \\\\\n",
      "     |      \\beta_t = \\beta_{t-1} + \\zeta_{t-1}\n",
      "     |  \n",
      "     |  where the level is a generalization of the intercept term that can\n",
      "     |  dynamically vary across time, and the trend is a generalization of the\n",
      "     |  time-trend such that the slope can dynamically vary across time.\n",
      "     |  \n",
      "     |  Here :math:`\\eta_t \\sim N(0, \\sigma_\\eta^2)` and\n",
      "     |  :math:`\\zeta_t \\sim N(0, \\sigma_\\zeta^2)`.\n",
      "     |  \n",
      "     |  For both elements (level and trend), we can consider models in which:\n",
      "     |  \n",
      "     |  - The element is included vs excluded (if the trend is included, there must\n",
      "     |    also be a level included).\n",
      "     |  - The element is deterministic vs stochastic (i.e. whether or not the\n",
      "     |    variance on the error term is confined to be zero or not)\n",
      "     |  \n",
      "     |  The only additional parameters to be estimated via MLE are the variances of\n",
      "     |  any included stochastic components.\n",
      "     |  \n",
      "     |  The level/trend components can be specified using the boolean keyword\n",
      "     |  arguments `level`, `stochastic_level`, `trend`, etc., or all at once as a\n",
      "     |  string argument to `level`. The following table shows the available\n",
      "     |  model specifications:\n",
      "     |  \n",
      "     |  +----------------------------------+--------------------------------------+--------------------+--------------------------------------------------+\n",
      "     |  | Model name                       | Full string syntax                   | Abbreviated syntax | Model                                            |\n",
      "     |  +==================================+======================================+====================+==================================================+\n",
      "     |  | No trend                         | `'irregular'`                        | `'ntrend'`         | .. math:: y_t = \\varepsilon_t                    |\n",
      "     |  +----------------------------------+--------------------------------------+--------------------+--------------------------------------------------+\n",
      "     |  | Fixed intercept                  | `'fixed intercept'`                  |                    | .. math:: y_t = \\mu                              |\n",
      "     |  +----------------------------------+--------------------------------------+--------------------+--------------------------------------------------+\n",
      "     |  | Deterministic constant           | `'deterministic constant'`           | `'dconstant'`      | .. math:: y_t = \\mu + \\varepsilon_t              |\n",
      "     |  +----------------------------------+--------------------------------------+--------------------+--------------------------------------------------+\n",
      "     |  | Local level                      | `'local level'`                      | `'llevel'`         | .. math:: y_t &= \\mu_t + \\varepsilon_t \\\\        |\n",
      "     |  |                                  |                                      |                    |     \\mu_t &= \\mu_{t-1} + \\eta_t                  |\n",
      "     |  +----------------------------------+--------------------------------------+--------------------+--------------------------------------------------+\n",
      "     |  | Random walk                      | `'random walk'`                      | `'rwalk'`          | .. math:: y_t &= \\mu_t \\\\                        |\n",
      "     |  |                                  |                                      |                    |     \\mu_t &= \\mu_{t-1} + \\eta_t                  |\n",
      "     |  +----------------------------------+--------------------------------------+--------------------+--------------------------------------------------+\n",
      "     |  | Fixed slope                      | `'fixed slope'`                      |                    | .. math:: y_t &= \\mu_t \\\\                        |\n",
      "     |  |                                  |                                      |                    |     \\mu_t &= \\mu_{t-1} + \\beta                   |\n",
      "     |  +----------------------------------+--------------------------------------+--------------------+--------------------------------------------------+\n",
      "     |  | Deterministic trend              | `'deterministic trend'`              | `'dtrend'`         | .. math:: y_t &= \\mu_t + \\varepsilon_t \\\\        |\n",
      "     |  |                                  |                                      |                    |     \\mu_t &= \\mu_{t-1} + \\beta                   |\n",
      "     |  +----------------------------------+--------------------------------------+--------------------+--------------------------------------------------+\n",
      "     |  | Local linear deterministic trend | `'local linear deterministic trend'` | `'lldtrend'`       | .. math:: y_t &= \\mu_t + \\varepsilon_t \\\\        |\n",
      "     |  |                                  |                                      |                    |     \\mu_t &= \\mu_{t-1} + \\beta + \\eta_t          |\n",
      "     |  +----------------------------------+--------------------------------------+--------------------+--------------------------------------------------+\n",
      "     |  | Random walk with drift           | `'random walk with drift'`           | `'rwdrift'`        | .. math:: y_t &= \\mu_t \\\\                        |\n",
      "     |  |                                  |                                      |                    |     \\mu_t &= \\mu_{t-1} + \\beta + \\eta_t          |\n",
      "     |  +----------------------------------+--------------------------------------+--------------------+--------------------------------------------------+\n",
      "     |  | Local linear trend               | `'local linear trend'`               | `'lltrend'`        | .. math:: y_t &= \\mu_t + \\varepsilon_t \\\\        |\n",
      "     |  |                                  |                                      |                    |     \\mu_t &= \\mu_{t-1} + \\beta_{t-1} + \\eta_t \\\\ |\n",
      "     |  |                                  |                                      |                    |     \\beta_t &= \\beta_{t-1} + \\zeta_t             |\n",
      "     |  +----------------------------------+--------------------------------------+--------------------+--------------------------------------------------+\n",
      "     |  | Smooth trend                     | `'smooth trend'`                     | `'strend'`         | .. math:: y_t &= \\mu_t + \\varepsilon_t \\\\        |\n",
      "     |  |                                  |                                      |                    |     \\mu_t &= \\mu_{t-1} + \\beta_{t-1} \\\\          |\n",
      "     |  |                                  |                                      |                    |     \\beta_t &= \\beta_{t-1} + \\zeta_t             |\n",
      "     |  +----------------------------------+--------------------------------------+--------------------+--------------------------------------------------+\n",
      "     |  | Random trend                     | `'random trend'`                     | `'rtrend'`         | .. math:: y_t &= \\mu_t \\\\                        |\n",
      "     |  |                                  |                                      |                    |     \\mu_t &= \\mu_{t-1} + \\beta_{t-1} \\\\          |\n",
      "     |  |                                  |                                      |                    |     \\beta_t &= \\beta_{t-1} + \\zeta_t             |\n",
      "     |  +----------------------------------+--------------------------------------+--------------------+--------------------------------------------------+\n",
      "     |  \n",
      "     |  Following the fitting of the model, the unobserved level and trend\n",
      "     |  component time series are available in the results class in the\n",
      "     |  `level` and `trend` attributes, respectively.\n",
      "     |  \n",
      "     |  **Seasonal (Time-domain)**\n",
      "     |  \n",
      "     |  The seasonal component is modeled as:\n",
      "     |  \n",
      "     |  .. math::\n",
      "     |  \n",
      "     |      \\gamma_t = - \\sum_{j=1}^{s-1} \\gamma_{t+1-j} + \\omega_t \\\\\n",
      "     |      \\omega_t \\sim N(0, \\sigma_\\omega^2)\n",
      "     |  \n",
      "     |  The periodicity (number of seasons) is s, and the defining character is\n",
      "     |  that (without the error term), the seasonal components sum to zero across\n",
      "     |  one complete cycle. The inclusion of an error term allows the seasonal\n",
      "     |  effects to vary over time (if this is not desired, :math:`\\sigma_\\omega^2`\n",
      "     |  can be set to zero using the `stochastic_seasonal=False` keyword argument).\n",
      "     |  \n",
      "     |  This component results in one parameter to be selected via maximum\n",
      "     |  likelihood: :math:`\\sigma_\\omega^2`, and one parameter to be chosen, the\n",
      "     |  number of seasons `s`.\n",
      "     |  \n",
      "     |  Following the fitting of the model, the unobserved seasonal component\n",
      "     |  time series is available in the results class in the `seasonal`\n",
      "     |  attribute.\n",
      "     |  \n",
      "     |  **Frequency-domain Seasonal**\n",
      "     |  \n",
      "     |  Each frequency-domain seasonal component is modeled as:\n",
      "     |  \n",
      "     |  .. math::\n",
      "     |  \n",
      "     |      \\gamma_t & =  \\sum_{j=1}^h \\gamma_{j, t} \\\\\n",
      "     |      \\gamma_{j, t+1} & = \\gamma_{j, t}\\cos(\\lambda_j)\n",
      "     |                      + \\gamma^{*}_{j, t}\\sin(\\lambda_j) + \\omega_{j,t} \\\\\n",
      "     |      \\gamma^{*}_{j, t+1} & = -\\gamma^{(1)}_{j, t}\\sin(\\lambda_j)\n",
      "     |                          + \\gamma^{*}_{j, t}\\cos(\\lambda_j)\n",
      "     |                          + \\omega^{*}_{j, t}, \\\\\n",
      "     |      \\omega^{*}_{j, t}, \\omega_{j, t} & \\sim N(0, \\sigma_{\\omega^2}) \\\\\n",
      "     |      \\lambda_j & = \\frac{2 \\pi j}{s}\n",
      "     |  \n",
      "     |  where j ranges from 1 to h.\n",
      "     |  \n",
      "     |  The periodicity (number of \"seasons\" in a \"year\") is s and the number of\n",
      "     |  harmonics is h.  Note that h is configurable to be less than s/2, but\n",
      "     |  s/2 harmonics is sufficient to fully model all seasonal variations of\n",
      "     |  periodicity s.  Like the time domain seasonal term (cf. Seasonal section,\n",
      "     |  above), the inclusion of the error terms allows for the seasonal effects to\n",
      "     |  vary over time.  The argument stochastic_freq_seasonal can be used to set\n",
      "     |  one or more of the seasonal components of this type to be non-random,\n",
      "     |  meaning they will not vary over time.\n",
      "     |  \n",
      "     |  This component results in one parameter to be fitted using maximum\n",
      "     |  likelihood: :math:`\\sigma_{\\omega^2}`, and up to two parameters to be\n",
      "     |  chosen, the number of seasons s and optionally the number of harmonics\n",
      "     |  h, with :math:`1 \\leq h \\leq \\lfloor s/2 \\rfloor`.\n",
      "     |  \n",
      "     |  After fitting the model, each unobserved seasonal component modeled in the\n",
      "     |  frequency domain is available in the results class in the `freq_seasonal`\n",
      "     |  attribute.\n",
      "     |  \n",
      "     |  **Cycle**\n",
      "     |  \n",
      "     |  The cyclical component is intended to capture cyclical effects at time\n",
      "     |  frames much longer than captured by the seasonal component. For example,\n",
      "     |  in economics the cyclical term is often intended to capture the business\n",
      "     |  cycle, and is then expected to have a period between \"1.5 and 12 years\"\n",
      "     |  (see Durbin and Koopman).\n",
      "     |  \n",
      "     |  .. math::\n",
      "     |  \n",
      "     |      c_{t+1} & = \\rho_c (\\tilde c_t \\cos \\lambda_c t\n",
      "     |              + \\tilde c_t^* \\sin \\lambda_c) +\n",
      "     |              \\tilde \\omega_t \\\\\n",
      "     |      c_{t+1}^* & = \\rho_c (- \\tilde c_t \\sin \\lambda_c  t +\n",
      "     |              \\tilde c_t^* \\cos \\lambda_c) +\n",
      "     |              \\tilde \\omega_t^* \\\\\n",
      "     |  \n",
      "     |  where :math:`\\omega_t, \\tilde \\omega_t iid N(0, \\sigma_{\\tilde \\omega}^2)`\n",
      "     |  \n",
      "     |  The parameter :math:`\\lambda_c` (the frequency of the cycle) is an\n",
      "     |  additional parameter to be estimated by MLE.\n",
      "     |  \n",
      "     |  If the cyclical effect is stochastic (`stochastic_cycle=True`), then there\n",
      "     |  is another parameter to estimate (the variance of the error term - note\n",
      "     |  that both of the error terms here share the same variance, but are assumed\n",
      "     |  to have independent draws).\n",
      "     |  \n",
      "     |  If the cycle is damped (`damped_cycle=True`), then there is a third\n",
      "     |  parameter to estimate, :math:`\\rho_c`.\n",
      "     |  \n",
      "     |  In order to achieve cycles with the appropriate frequencies, bounds are\n",
      "     |  imposed on the parameter :math:`\\lambda_c` in estimation. These can be\n",
      "     |  controlled via the keyword argument `cycle_period_bounds`, which, if\n",
      "     |  specified, must be a tuple of bounds on the **period** `(lower, upper)`.\n",
      "     |  The bounds on the frequency are then calculated from those bounds.\n",
      "     |  \n",
      "     |  The default bounds, if none are provided, are selected in the following\n",
      "     |  way:\n",
      "     |  \n",
      "     |  1. If no date / time information is provided, the frequency is\n",
      "     |     constrained to be between zero and :math:`\\pi`, so the period is\n",
      "     |     constrained to be in :math:`[0.5, \\infty]`.\n",
      "     |  2. If the date / time information is provided, the default bounds\n",
      "     |     allow the cyclical component to be between 1.5 and 12 years; depending\n",
      "     |     on the frequency of the endogenous variable, this will imply different\n",
      "     |     specific bounds.\n",
      "     |  \n",
      "     |  Following the fitting of the model, the unobserved cyclical component\n",
      "     |  time series is available in the results class in the `cycle`\n",
      "     |  attribute.\n",
      "     |  \n",
      "     |  **Irregular**\n",
      "     |  \n",
      "     |  The irregular components are independent and identically distributed (iid):\n",
      "     |  \n",
      "     |  .. math::\n",
      "     |  \n",
      "     |      \\varepsilon_t \\sim N(0, \\sigma_\\varepsilon^2)\n",
      "     |  \n",
      "     |  **Autoregressive Irregular**\n",
      "     |  \n",
      "     |  An autoregressive component (often used as a replacement for the white\n",
      "     |  noise irregular term) can be specified as:\n",
      "     |  \n",
      "     |  .. math::\n",
      "     |  \n",
      "     |      \\varepsilon_t = \\rho(L) \\varepsilon_{t-1} + \\epsilon_t \\\\\n",
      "     |      \\epsilon_t \\sim N(0, \\sigma_\\epsilon^2)\n",
      "     |  \n",
      "     |  In this case, the AR order is specified via the `autoregressive` keyword,\n",
      "     |  and the autoregressive coefficients are estimated.\n",
      "     |  \n",
      "     |  Following the fitting of the model, the unobserved autoregressive component\n",
      "     |  time series is available in the results class in the `autoregressive`\n",
      "     |  attribute.\n",
      "     |  \n",
      "     |  **Regression effects**\n",
      "     |  \n",
      "     |  Exogenous regressors can be pass to the `exog` argument. The regression\n",
      "     |  coefficients will be estimated by maximum likelihood unless\n",
      "     |  `mle_regression=False`, in which case the regression coefficients will be\n",
      "     |  included in the state vector where they are essentially estimated via\n",
      "     |  recursive OLS.\n",
      "     |  \n",
      "     |  If the regression_coefficients are included in the state vector, the\n",
      "     |  recursive estimates are available in the results class in the\n",
      "     |  `regression_coefficients` attribute.\n",
      "     |  \n",
      "     |  References\n",
      "     |  ----------\n",
      "     |  .. [1] Durbin, James, and Siem Jan Koopman. 2012.\n",
      "     |     Time Series Analysis by State Space Methods: Second Edition.\n",
      "     |     Oxford University Press.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      UnobservedComponents\n",
      "     |      statsmodels.tsa.statespace.mlemodel.MLEModel\n",
      "     |      statsmodels.tsa.base.tsa_model.TimeSeriesModel\n",
      "     |      statsmodels.base.model.LikelihoodModel\n",
      "     |      statsmodels.base.model.Model\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, endog, level=False, trend=False, seasonal=None, freq_seasonal=None, cycle=False, autoregressive=None, exog=None, irregular=False, stochastic_level=False, stochastic_trend=False, stochastic_seasonal=True, stochastic_freq_seasonal=None, stochastic_cycle=False, damped_cycle=False, cycle_period_bounds=None, mle_regression=True, use_exact_diffuse=False, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  clone(self, endog, exog=None, **kwargs)\n",
      "     |      Clone state space model with new data and optionally new specification\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      endog : array_like\n",
      "     |          The observed time-series process :math:`y`\n",
      "     |      k_states : int\n",
      "     |          The dimension of the unobserved state process.\n",
      "     |      exog : array_like, optional\n",
      "     |          Array of exogenous regressors, shaped nobs x k. Default is no\n",
      "     |          exogenous regressors.\n",
      "     |      kwargs\n",
      "     |          Keyword arguments to pass to the new model class to change the\n",
      "     |          model specification.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      model : MLEModel subclass\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      This method must be implemented\n",
      "     |  \n",
      "     |  initialize_default(self, approximate_diffuse_variance=None)\n",
      "     |  \n",
      "     |  setup(self)\n",
      "     |      Setup the structural time series representation\n",
      "     |  \n",
      "     |  transform_params(self, unconstrained)\n",
      "     |      Transform unconstrained parameters used by the optimizer to constrained\n",
      "     |      parameters used in likelihood evaluation\n",
      "     |  \n",
      "     |  untransform_params(self, constrained)\n",
      "     |      Reverse the transformation\n",
      "     |  \n",
      "     |  update(self, params, transformed=True, includes_fixed=False, complex_step=False)\n",
      "     |      Update the parameters of the model\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : array_like\n",
      "     |          Array of new parameters.\n",
      "     |      transformed : bool, optional\n",
      "     |          Whether or not `params` is already transformed. If set to False,\n",
      "     |          `transform_params` is called. Default is True.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      params : array_like\n",
      "     |          Array of parameters.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Since Model is a base class, this method should be overridden by\n",
      "     |      subclasses to perform actual updating steps.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties defined here:\n",
      "     |  \n",
      "     |  param_names\n",
      "     |      (list of str) List of human readable parameter names (for parameters\n",
      "     |      actually included in the model).\n",
      "     |  \n",
      "     |  start_params\n",
      "     |      (array) Starting parameters for maximum likelihood estimation.\n",
      "     |  \n",
      "     |  state_names\n",
      "     |      (list of str) List of human readable names for unobserved states.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from statsmodels.tsa.statespace.mlemodel.MLEModel:\n",
      "     |  \n",
      "     |  __getitem__(self, key)\n",
      "     |  \n",
      "     |  __setitem__(self, key, value)\n",
      "     |  \n",
      "     |  filter(self, params, transformed=True, includes_fixed=False, complex_step=False, cov_type=None, cov_kwds=None, return_ssm=False, results_class=None, results_wrapper_class=None, low_memory=False, **kwargs)\n",
      "     |      Kalman filtering\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : array_like\n",
      "     |          Array of parameters at which to evaluate the loglikelihood\n",
      "     |          function.\n",
      "     |      transformed : bool, optional\n",
      "     |          Whether or not `params` is already transformed. Default is True.\n",
      "     |      return_ssm : bool,optional\n",
      "     |          Whether or not to return only the state space output or a full\n",
      "     |          results object. Default is to return a full results object.\n",
      "     |      cov_type : str, optional\n",
      "     |          See `MLEResults.fit` for a description of covariance matrix types\n",
      "     |          for results object.\n",
      "     |      cov_kwds : dict or None, optional\n",
      "     |          See `MLEResults.get_robustcov_results` for a description required\n",
      "     |          keywords for alternative covariance estimators\n",
      "     |      low_memory : bool, optional\n",
      "     |          If set to True, techniques are applied to substantially reduce\n",
      "     |          memory usage. If used, some features of the results object will\n",
      "     |          not be available (including in-sample prediction), although\n",
      "     |          out-of-sample forecasting is possible. Default is False.\n",
      "     |      **kwargs\n",
      "     |          Additional keyword arguments to pass to the Kalman filter. See\n",
      "     |          `KalmanFilter.filter` for more details.\n",
      "     |  \n",
      "     |  fit(self, start_params=None, transformed=True, includes_fixed=False, cov_type=None, cov_kwds=None, method='lbfgs', maxiter=50, full_output=1, disp=5, callback=None, return_params=False, optim_score=None, optim_complex_step=None, optim_hessian=None, flags=None, low_memory=False, **kwargs)\n",
      "     |      Fits the model by maximum likelihood via Kalman filter.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      start_params : array_like, optional\n",
      "     |          Initial guess of the solution for the loglikelihood maximization.\n",
      "     |          If None, the default is given by Model.start_params.\n",
      "     |      transformed : bool, optional\n",
      "     |          Whether or not `start_params` is already transformed. Default is\n",
      "     |          True.\n",
      "     |      includes_fixed : bool, optional\n",
      "     |          If parameters were previously fixed with the `fix_params` method,\n",
      "     |          this argument describes whether or not `start_params` also includes\n",
      "     |          the fixed parameters, in addition to the free parameters. Default\n",
      "     |          is False.\n",
      "     |      cov_type : str, optional\n",
      "     |          The `cov_type` keyword governs the method for calculating the\n",
      "     |          covariance matrix of parameter estimates. Can be one of:\n",
      "     |      \n",
      "     |          - 'opg' for the outer product of gradient estimator\n",
      "     |          - 'oim' for the observed information matrix estimator, calculated\n",
      "     |            using the method of Harvey (1989)\n",
      "     |          - 'approx' for the observed information matrix estimator,\n",
      "     |            calculated using a numerical approximation of the Hessian matrix.\n",
      "     |          - 'robust' for an approximate (quasi-maximum likelihood) covariance\n",
      "     |            matrix that may be valid even in the presence of some\n",
      "     |            misspecifications. Intermediate calculations use the 'oim'\n",
      "     |            method.\n",
      "     |          - 'robust_approx' is the same as 'robust' except that the\n",
      "     |            intermediate calculations use the 'approx' method.\n",
      "     |          - 'none' for no covariance matrix calculation.\n",
      "     |      \n",
      "     |          Default is 'opg' unless memory conservation is used to avoid\n",
      "     |          computing the loglikelihood values for each observation, in which\n",
      "     |          case the default is 'approx'.\n",
      "     |      cov_kwds : dict or None, optional\n",
      "     |          A dictionary of arguments affecting covariance matrix computation.\n",
      "     |      \n",
      "     |          **opg, oim, approx, robust, robust_approx**\n",
      "     |      \n",
      "     |          - 'approx_complex_step' : bool, optional - If True, numerical\n",
      "     |            approximations are computed using complex-step methods. If False,\n",
      "     |            numerical approximations are computed using finite difference\n",
      "     |            methods. Default is True.\n",
      "     |          - 'approx_centered' : bool, optional - If True, numerical\n",
      "     |            approximations computed using finite difference methods use a\n",
      "     |            centered approximation. Default is False.\n",
      "     |      method : str, optional\n",
      "     |          The `method` determines which solver from `scipy.optimize`\n",
      "     |          is used, and it can be chosen from among the following strings:\n",
      "     |      \n",
      "     |          - 'newton' for Newton-Raphson\n",
      "     |          - 'nm' for Nelder-Mead\n",
      "     |          - 'bfgs' for Broyden-Fletcher-Goldfarb-Shanno (BFGS)\n",
      "     |          - 'lbfgs' for limited-memory BFGS with optional box constraints\n",
      "     |          - 'powell' for modified Powell's method\n",
      "     |          - 'cg' for conjugate gradient\n",
      "     |          - 'ncg' for Newton-conjugate gradient\n",
      "     |          - 'basinhopping' for global basin-hopping solver\n",
      "     |      \n",
      "     |          The explicit arguments in `fit` are passed to the solver,\n",
      "     |          with the exception of the basin-hopping solver. Each\n",
      "     |          solver has several optional arguments that are not the same across\n",
      "     |          solvers. See the notes section below (or scipy.optimize) for the\n",
      "     |          available arguments and for the list of explicit arguments that the\n",
      "     |          basin-hopping solver supports.\n",
      "     |      maxiter : int, optional\n",
      "     |          The maximum number of iterations to perform.\n",
      "     |      full_output : bool, optional\n",
      "     |          Set to True to have all available output in the Results object's\n",
      "     |          mle_retvals attribute. The output is dependent on the solver.\n",
      "     |          See LikelihoodModelResults notes section for more information.\n",
      "     |      disp : bool, optional\n",
      "     |          Set to True to print convergence messages.\n",
      "     |      callback : callable callback(xk), optional\n",
      "     |          Called after each iteration, as callback(xk), where xk is the\n",
      "     |          current parameter vector.\n",
      "     |      return_params : bool, optional\n",
      "     |          Whether or not to return only the array of maximizing parameters.\n",
      "     |          Default is False.\n",
      "     |      optim_score : {'harvey', 'approx'} or None, optional\n",
      "     |          The method by which the score vector is calculated. 'harvey' uses\n",
      "     |          the method from Harvey (1989), 'approx' uses either finite\n",
      "     |          difference or complex step differentiation depending upon the\n",
      "     |          value of `optim_complex_step`, and None uses the built-in gradient\n",
      "     |          approximation of the optimizer. Default is None. This keyword is\n",
      "     |          only relevant if the optimization method uses the score.\n",
      "     |      optim_complex_step : bool, optional\n",
      "     |          Whether or not to use complex step differentiation when\n",
      "     |          approximating the score; if False, finite difference approximation\n",
      "     |          is used. Default is True. This keyword is only relevant if\n",
      "     |          `optim_score` is set to 'harvey' or 'approx'.\n",
      "     |      optim_hessian : {'opg','oim','approx'}, optional\n",
      "     |          The method by which the Hessian is numerically approximated. 'opg'\n",
      "     |          uses outer product of gradients, 'oim' uses the information\n",
      "     |          matrix formula from Harvey (1989), and 'approx' uses numerical\n",
      "     |          approximation. This keyword is only relevant if the\n",
      "     |          optimization method uses the Hessian matrix.\n",
      "     |      low_memory : bool, optional\n",
      "     |          If set to True, techniques are applied to substantially reduce\n",
      "     |          memory usage. If used, some features of the results object will\n",
      "     |          not be available (including smoothed results and in-sample\n",
      "     |          prediction), although out-of-sample forecasting is possible.\n",
      "     |          Default is False.\n",
      "     |      **kwargs\n",
      "     |          Additional keyword arguments to pass to the optimizer.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      results\n",
      "     |          Results object holding results from fitting a state space model.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      statsmodels.base.model.LikelihoodModel.fit\n",
      "     |      statsmodels.tsa.statespace.mlemodel.MLEResults\n",
      "     |      statsmodels.tsa.statespace.structural.UnobservedComponentsResults\n",
      "     |  \n",
      "     |  fit_constrained(self, constraints, start_params=None, **fit_kwds)\n",
      "     |      Fit the model with some parameters subject to equality constraints.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      constraints : dict\n",
      "     |          Dictionary of constraints, of the form `param_name: fixed_value`.\n",
      "     |          See the `param_names` property for valid parameter names.\n",
      "     |      start_params : array_like, optional\n",
      "     |          Initial guess of the solution for the loglikelihood maximization.\n",
      "     |          If None, the default is given by Model.start_params.\n",
      "     |      **fit_kwds : keyword arguments\n",
      "     |          fit_kwds are used in the optimization of the remaining parameters.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      results : Results instance\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> mod = sm.tsa.SARIMAX(endog, order=(1, 0, 1))\n",
      "     |      >>> res = mod.fit_constrained({'ar.L1': 0.5})\n",
      "     |  \n",
      "     |  fix_params(self, params)\n",
      "     |      Fix parameters to specific values (context manager)\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : dict\n",
      "     |          Dictionary describing the fixed parameter values, of the form\n",
      "     |          `param_name: fixed_value`. See the `param_names` property for valid\n",
      "     |          parameter names.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> mod = sm.tsa.SARIMAX(endog, order=(1, 0, 1))\n",
      "     |      >>> with mod.fix_params({'ar.L1': 0.5}):\n",
      "     |              res = mod.fit()\n",
      "     |  \n",
      "     |  handle_params(self, params, transformed=True, includes_fixed=False, return_jacobian=False)\n",
      "     |      Ensure model parameters satisfy shape and other requirements\n",
      "     |  \n",
      "     |  hessian(self, params, *args, **kwargs)\n",
      "     |      Hessian matrix of the likelihood function, evaluated at the given\n",
      "     |      parameters\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : array_like\n",
      "     |          Array of parameters at which to evaluate the hessian.\n",
      "     |      *args\n",
      "     |          Additional positional arguments to the `loglike` method.\n",
      "     |      **kwargs\n",
      "     |          Additional keyword arguments to the `loglike` method.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      hessian : ndarray\n",
      "     |          Hessian matrix evaluated at `params`\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      This is a numerical approximation.\n",
      "     |      \n",
      "     |      Both args and kwargs are necessary because the optimizer from\n",
      "     |      `fit` must call this function and only supports passing arguments via\n",
      "     |      args (for example `scipy.optimize.fmin_l_bfgs`).\n",
      "     |  \n",
      "     |  impulse_responses(self, params, steps=1, impulse=0, orthogonalized=False, cumulative=False, anchor=None, exog=None, extend_model=None, extend_kwargs=None, transformed=True, includes_fixed=False, **kwargs)\n",
      "     |      Impulse response function\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : array_like\n",
      "     |          Array of model parameters.\n",
      "     |      steps : int, optional\n",
      "     |          The number of steps for which impulse responses are calculated.\n",
      "     |          Default is 1. Note that for time-invariant models, the initial\n",
      "     |          impulse is not counted as a step, so if `steps=1`, the output will\n",
      "     |          have 2 entries.\n",
      "     |      impulse : int, str or array_like\n",
      "     |          If an integer, the state innovation to pulse; must be between 0\n",
      "     |          and `k_posdef-1`. If a str, it indicates which column of df\n",
      "     |          the unit (1) impulse is given.\n",
      "     |          Alternatively, a custom impulse vector may be provided; must be\n",
      "     |          shaped `k_posdef x 1`.\n",
      "     |      orthogonalized : bool, optional\n",
      "     |          Whether or not to perform impulse using orthogonalized innovations.\n",
      "     |          Note that this will also affect custum `impulse` vectors. Default\n",
      "     |          is False.\n",
      "     |      cumulative : bool, optional\n",
      "     |          Whether or not to return cumulative impulse responses. Default is\n",
      "     |          False.\n",
      "     |      anchor : int, str, or datetime, optional\n",
      "     |          Time point within the sample for the state innovation impulse. Type\n",
      "     |          depends on the index of the given `endog` in the model. Two special\n",
      "     |          cases are the strings 'start' and 'end', which refer to setting the\n",
      "     |          impulse at the first and last points of the sample, respectively.\n",
      "     |          Integer values can run from 0 to `nobs - 1`, or can be negative to\n",
      "     |          apply negative indexing. Finally, if a date/time index was provided\n",
      "     |          to the model, then this argument can be a date string to parse or a\n",
      "     |          datetime type. Default is 'start'.\n",
      "     |      exog : array_like, optional\n",
      "     |          New observations of exogenous regressors for our-of-sample periods,\n",
      "     |          if applicable.\n",
      "     |      transformed : bool, optional\n",
      "     |          Whether or not `params` is already transformed. Default is\n",
      "     |          True.\n",
      "     |      includes_fixed : bool, optional\n",
      "     |          If parameters were previously fixed with the `fix_params` method,\n",
      "     |          this argument describes whether or not `params` also includes\n",
      "     |          the fixed parameters, in addition to the free parameters. Default\n",
      "     |          is False.\n",
      "     |      **kwargs\n",
      "     |          If the model has time-varying design or transition matrices and the\n",
      "     |          combination of `anchor` and `steps` implies creating impulse\n",
      "     |          responses for the out-of-sample period, then these matrices must\n",
      "     |          have updated values provided for the out-of-sample steps. For\n",
      "     |          example, if `design` is a time-varying component, `nobs` is 10,\n",
      "     |          `anchor=1`, and `steps` is 15, a (`k_endog` x `k_states` x 7)\n",
      "     |          matrix must be provided with the new design matrix values.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      impulse_responses : ndarray\n",
      "     |          Responses for each endogenous variable due to the impulse\n",
      "     |          given by the `impulse` argument. For a time-invariant model, the\n",
      "     |          impulse responses are given for `steps + 1` elements (this gives\n",
      "     |          the \"initial impulse\" followed by `steps` responses for the\n",
      "     |          important cases of VAR and SARIMAX models), while for time-varying\n",
      "     |          models the impulse responses are only given for `steps` elements\n",
      "     |          (to avoid having to unexpectedly provide updated time-varying\n",
      "     |          matrices).\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      simulate\n",
      "     |          Simulate a time series according to the given state space model,\n",
      "     |          optionally with specified series for the innovations.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Intercepts in the measurement and state equation are ignored when\n",
      "     |      calculating impulse responses.\n",
      "     |      \n",
      "     |      TODO: add an option to allow changing the ordering for the\n",
      "     |            orthogonalized option. Will require permuting matrices when\n",
      "     |            constructing the extended model.\n",
      "     |  \n",
      "     |  initialize_approximate_diffuse(self, variance=None)\n",
      "     |      Initialize approximate diffuse\n",
      "     |  \n",
      "     |  initialize_known(self, initial_state, initial_state_cov)\n",
      "     |      Initialize known\n",
      "     |  \n",
      "     |  initialize_statespace(self, **kwargs)\n",
      "     |      Initialize the state space representation\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      **kwargs\n",
      "     |          Additional keyword arguments to pass to the state space class\n",
      "     |          constructor.\n",
      "     |  \n",
      "     |  initialize_stationary(self)\n",
      "     |      Initialize stationary\n",
      "     |  \n",
      "     |  loglike(self, params, *args, **kwargs)\n",
      "     |      Loglikelihood evaluation\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : array_like\n",
      "     |          Array of parameters at which to evaluate the loglikelihood\n",
      "     |          function.\n",
      "     |      transformed : bool, optional\n",
      "     |          Whether or not `params` is already transformed. Default is True.\n",
      "     |      **kwargs\n",
      "     |          Additional keyword arguments to pass to the Kalman filter. See\n",
      "     |          `KalmanFilter.filter` for more details.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      update : modifies the internal state of the state space model to\n",
      "     |               reflect new params\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      [1]_ recommend maximizing the average likelihood to avoid scale issues;\n",
      "     |      this is done automatically by the base Model fit method.\n",
      "     |      \n",
      "     |      References\n",
      "     |      ----------\n",
      "     |      .. [1] Koopman, Siem Jan, Neil Shephard, and Jurgen A. Doornik. 1999.\n",
      "     |         Statistical Algorithms for Models in State Space Using SsfPack 2.2.\n",
      "     |         Econometrics Journal 2 (1): 107-60. doi:10.1111/1368-423X.00023.\n",
      "     |  \n",
      "     |  loglikeobs(self, params, transformed=True, includes_fixed=False, complex_step=False, **kwargs)\n",
      "     |      Loglikelihood evaluation\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : array_like\n",
      "     |          Array of parameters at which to evaluate the loglikelihood\n",
      "     |          function.\n",
      "     |      transformed : bool, optional\n",
      "     |          Whether or not `params` is already transformed. Default is True.\n",
      "     |      **kwargs\n",
      "     |          Additional keyword arguments to pass to the Kalman filter. See\n",
      "     |          `KalmanFilter.filter` for more details.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      update : modifies the internal state of the Model to reflect new params\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      [1]_ recommend maximizing the average likelihood to avoid scale issues;\n",
      "     |      this is done automatically by the base Model fit method.\n",
      "     |      \n",
      "     |      References\n",
      "     |      ----------\n",
      "     |      .. [1] Koopman, Siem Jan, Neil Shephard, and Jurgen A. Doornik. 1999.\n",
      "     |         Statistical Algorithms for Models in State Space Using SsfPack 2.2.\n",
      "     |         Econometrics Journal 2 (1): 107-60. doi:10.1111/1368-423X.00023.\n",
      "     |  \n",
      "     |  observed_information_matrix(self, params, transformed=True, includes_fixed=False, approx_complex_step=None, approx_centered=False, **kwargs)\n",
      "     |      Observed information matrix\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : array_like, optional\n",
      "     |          Array of parameters at which to evaluate the loglikelihood\n",
      "     |          function.\n",
      "     |      **kwargs\n",
      "     |          Additional keyword arguments to pass to the Kalman filter. See\n",
      "     |          `KalmanFilter.filter` for more details.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      This method is from Harvey (1989), which shows that the information\n",
      "     |      matrix only depends on terms from the gradient. This implementation is\n",
      "     |      partially analytic and partially numeric approximation, therefore,\n",
      "     |      because it uses the analytic formula for the information matrix, with\n",
      "     |      numerically computed elements of the gradient.\n",
      "     |      \n",
      "     |      References\n",
      "     |      ----------\n",
      "     |      Harvey, Andrew C. 1990.\n",
      "     |      Forecasting, Structural Time Series Models and the Kalman Filter.\n",
      "     |      Cambridge University Press.\n",
      "     |  \n",
      "     |  opg_information_matrix(self, params, transformed=True, includes_fixed=False, approx_complex_step=None, **kwargs)\n",
      "     |      Outer product of gradients information matrix\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : array_like, optional\n",
      "     |          Array of parameters at which to evaluate the loglikelihood\n",
      "     |          function.\n",
      "     |      **kwargs\n",
      "     |          Additional arguments to the `loglikeobs` method.\n",
      "     |      \n",
      "     |      References\n",
      "     |      ----------\n",
      "     |      Berndt, Ernst R., Bronwyn Hall, Robert Hall, and Jerry Hausman. 1974.\n",
      "     |      Estimation and Inference in Nonlinear Structural Models.\n",
      "     |      NBER Chapters. National Bureau of Economic Research, Inc.\n",
      "     |  \n",
      "     |  prepare_data(self)\n",
      "     |      Prepare data for use in the state space representation\n",
      "     |  \n",
      "     |  score(self, params, *args, **kwargs)\n",
      "     |      Compute the score function at params.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : array_like\n",
      "     |          Array of parameters at which to evaluate the score.\n",
      "     |      *args\n",
      "     |          Additional positional arguments to the `loglike` method.\n",
      "     |      **kwargs\n",
      "     |          Additional keyword arguments to the `loglike` method.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      score : ndarray\n",
      "     |          Score, evaluated at `params`.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      This is a numerical approximation, calculated using first-order complex\n",
      "     |      step differentiation on the `loglike` method.\n",
      "     |      \n",
      "     |      Both args and kwargs are necessary because the optimizer from\n",
      "     |      `fit` must call this function and only supports passing arguments via\n",
      "     |      args (for example `scipy.optimize.fmin_l_bfgs`).\n",
      "     |  \n",
      "     |  score_obs(self, params, method='approx', transformed=True, includes_fixed=False, approx_complex_step=None, approx_centered=False, **kwargs)\n",
      "     |      Compute the score per observation, evaluated at params\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : array_like\n",
      "     |          Array of parameters at which to evaluate the score.\n",
      "     |      **kwargs\n",
      "     |          Additional arguments to the `loglike` method.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      score : ndarray\n",
      "     |          Score per observation, evaluated at `params`.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      This is a numerical approximation, calculated using first-order complex\n",
      "     |      step differentiation on the `loglikeobs` method.\n",
      "     |  \n",
      "     |  set_conserve_memory(self, conserve_memory=None, **kwargs)\n",
      "     |      Set the memory conservation method\n",
      "     |      \n",
      "     |      By default, the Kalman filter computes a number of intermediate\n",
      "     |      matrices at each iteration. The memory conservation options control\n",
      "     |      which of those matrices are stored.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      conserve_memory : int, optional\n",
      "     |          Bitmask value to set the memory conservation method to. See notes\n",
      "     |          for details.\n",
      "     |      **kwargs\n",
      "     |          Keyword arguments may be used to influence the memory conservation\n",
      "     |          method by setting individual boolean flags.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      This method is rarely used. See the corresponding function in the\n",
      "     |      `KalmanFilter` class for details.\n",
      "     |  \n",
      "     |  set_filter_method(self, filter_method=None, **kwargs)\n",
      "     |      Set the filtering method\n",
      "     |      \n",
      "     |      The filtering method controls aspects of which Kalman filtering\n",
      "     |      approach will be used.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      filter_method : int, optional\n",
      "     |          Bitmask value to set the filter method to. See notes for details.\n",
      "     |      **kwargs\n",
      "     |          Keyword arguments may be used to influence the filter method by\n",
      "     |          setting individual boolean flags. See notes for details.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      This method is rarely used. See the corresponding function in the\n",
      "     |      `KalmanFilter` class for details.\n",
      "     |  \n",
      "     |  set_inversion_method(self, inversion_method=None, **kwargs)\n",
      "     |      Set the inversion method\n",
      "     |      \n",
      "     |      The Kalman filter may contain one matrix inversion: that of the\n",
      "     |      forecast error covariance matrix. The inversion method controls how and\n",
      "     |      if that inverse is performed.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      inversion_method : int, optional\n",
      "     |          Bitmask value to set the inversion method to. See notes for\n",
      "     |          details.\n",
      "     |      **kwargs\n",
      "     |          Keyword arguments may be used to influence the inversion method by\n",
      "     |          setting individual boolean flags. See notes for details.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      This method is rarely used. See the corresponding function in the\n",
      "     |      `KalmanFilter` class for details.\n",
      "     |  \n",
      "     |  set_smoother_output(self, smoother_output=None, **kwargs)\n",
      "     |      Set the smoother output\n",
      "     |      \n",
      "     |      The smoother can produce several types of results. The smoother output\n",
      "     |      variable controls which are calculated and returned.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      smoother_output : int, optional\n",
      "     |          Bitmask value to set the smoother output to. See notes for details.\n",
      "     |      **kwargs\n",
      "     |          Keyword arguments may be used to influence the smoother output by\n",
      "     |          setting individual boolean flags.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      This method is rarely used. See the corresponding function in the\n",
      "     |      `KalmanSmoother` class for details.\n",
      "     |  \n",
      "     |  set_stability_method(self, stability_method=None, **kwargs)\n",
      "     |      Set the numerical stability method\n",
      "     |      \n",
      "     |      The Kalman filter is a recursive algorithm that may in some cases\n",
      "     |      suffer issues with numerical stability. The stability method controls\n",
      "     |      what, if any, measures are taken to promote stability.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      stability_method : int, optional\n",
      "     |          Bitmask value to set the stability method to. See notes for\n",
      "     |          details.\n",
      "     |      **kwargs\n",
      "     |          Keyword arguments may be used to influence the stability method by\n",
      "     |          setting individual boolean flags. See notes for details.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      This method is rarely used. See the corresponding function in the\n",
      "     |      `KalmanFilter` class for details.\n",
      "     |  \n",
      "     |  simulate(self, params, nsimulations, measurement_shocks=None, state_shocks=None, initial_state=None, anchor=None, repetitions=None, exog=None, extend_model=None, extend_kwargs=None, transformed=True, includes_fixed=False, **kwargs)\n",
      "     |      Simulate a new time series following the state space model\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : array_like\n",
      "     |          Array of parameters to use in constructing the state space\n",
      "     |          representation to use when simulating.\n",
      "     |      nsimulations : int\n",
      "     |          The number of observations to simulate. If the model is\n",
      "     |          time-invariant this can be any number. If the model is\n",
      "     |          time-varying, then this number must be less than or equal to the\n",
      "     |          number of observations.\n",
      "     |      measurement_shocks : array_like, optional\n",
      "     |          If specified, these are the shocks to the measurement equation,\n",
      "     |          :math:`\\varepsilon_t`. If unspecified, these are automatically\n",
      "     |          generated using a pseudo-random number generator. If specified,\n",
      "     |          must be shaped `nsimulations` x `k_endog`, where `k_endog` is the\n",
      "     |          same as in the state space model.\n",
      "     |      state_shocks : array_like, optional\n",
      "     |          If specified, these are the shocks to the state equation,\n",
      "     |          :math:`\\eta_t`. If unspecified, these are automatically\n",
      "     |          generated using a pseudo-random number generator. If specified,\n",
      "     |          must be shaped `nsimulations` x `k_posdef` where `k_posdef` is the\n",
      "     |          same as in the state space model.\n",
      "     |      initial_state : array_like, optional\n",
      "     |          If specified, this is the initial state vector to use in\n",
      "     |          simulation, which should be shaped (`k_states` x 1), where\n",
      "     |          `k_states` is the same as in the state space model. If unspecified,\n",
      "     |          but the model has been initialized, then that initialization is\n",
      "     |          used. This must be specified if `anchor` is anything other than\n",
      "     |          \"start\" or 0 (or else you can use the `simulate` method on a\n",
      "     |          results object rather than on the model object).\n",
      "     |      anchor : int, str, or datetime, optional\n",
      "     |          First period for simulation. The simulation will be conditional on\n",
      "     |          all existing datapoints prior to the `anchor`.  Type depends on the\n",
      "     |          index of the given `endog` in the model. Two special cases are the\n",
      "     |          strings 'start' and 'end'. `start` refers to beginning the\n",
      "     |          simulation at the first period of the sample, and `end` refers to\n",
      "     |          beginning the simulation at the first period after the sample.\n",
      "     |          Integer values can run from 0 to `nobs`, or can be negative to\n",
      "     |          apply negative indexing. Finally, if a date/time index was provided\n",
      "     |          to the model, then this argument can be a date string to parse or a\n",
      "     |          datetime type. Default is 'start'.\n",
      "     |      repetitions : int, optional\n",
      "     |          Number of simulated paths to generate. Default is 1 simulated path.\n",
      "     |      exog : array_like, optional\n",
      "     |          New observations of exogenous regressors, if applicable.\n",
      "     |      transformed : bool, optional\n",
      "     |          Whether or not `params` is already transformed. Default is\n",
      "     |          True.\n",
      "     |      includes_fixed : bool, optional\n",
      "     |          If parameters were previously fixed with the `fix_params` method,\n",
      "     |          this argument describes whether or not `params` also includes\n",
      "     |          the fixed parameters, in addition to the free parameters. Default\n",
      "     |          is False.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      simulated_obs : ndarray\n",
      "     |          An array of simulated observations. If `repetitions=None`, then it\n",
      "     |          will be shaped (nsimulations x k_endog) or (nsimulations,) if\n",
      "     |          `k_endog=1`. Otherwise it will be shaped\n",
      "     |          (nsimulations x k_endog x repetitions). If the model was given\n",
      "     |          Pandas input then the output will be a Pandas object. If\n",
      "     |          `k_endog > 1` and `repetitions` is not None, then the output will\n",
      "     |          be a Pandas DataFrame that has a MultiIndex for the columns, with\n",
      "     |          the first level containing the names of the `endog` variables and\n",
      "     |          the second level containing the repetition number.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      impulse_responses\n",
      "     |          Impulse response functions\n",
      "     |  \n",
      "     |  simulation_smoother(self, simulation_output=None, **kwargs)\n",
      "     |      Retrieve a simulation smoother for the state space model.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      simulation_output : int, optional\n",
      "     |          Determines which simulation smoother output is calculated.\n",
      "     |          Default is all (including state and disturbances).\n",
      "     |      **kwargs\n",
      "     |          Additional keyword arguments, used to set the simulation output.\n",
      "     |          See `set_simulation_output` for more details.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      SimulationSmoothResults\n",
      "     |  \n",
      "     |  smooth(self, params, transformed=True, includes_fixed=False, complex_step=False, cov_type=None, cov_kwds=None, return_ssm=False, results_class=None, results_wrapper_class=None, **kwargs)\n",
      "     |      Kalman smoothing\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : array_like\n",
      "     |          Array of parameters at which to evaluate the loglikelihood\n",
      "     |          function.\n",
      "     |      transformed : bool, optional\n",
      "     |          Whether or not `params` is already transformed. Default is True.\n",
      "     |      return_ssm : bool,optional\n",
      "     |          Whether or not to return only the state space output or a full\n",
      "     |          results object. Default is to return a full results object.\n",
      "     |      cov_type : str, optional\n",
      "     |          See `MLEResults.fit` for a description of covariance matrix types\n",
      "     |          for results object.\n",
      "     |      cov_kwds : dict or None, optional\n",
      "     |          See `MLEResults.get_robustcov_results` for a description required\n",
      "     |          keywords for alternative covariance estimators\n",
      "     |      **kwargs\n",
      "     |          Additional keyword arguments to pass to the Kalman filter. See\n",
      "     |          `KalmanFilter.filter` for more details.\n",
      "     |  \n",
      "     |  transform_jacobian(self, unconstrained, approx_centered=False)\n",
      "     |      Jacobian matrix for the parameter transformation function\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      unconstrained : array_like\n",
      "     |          Array of unconstrained parameters used by the optimizer.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      jacobian : ndarray\n",
      "     |          Jacobian matrix of the transformation, evaluated at `unconstrained`\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      transform_params\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      This is a numerical approximation using finite differences. Note that\n",
      "     |      in general complex step methods cannot be used because it is not\n",
      "     |      guaranteed that the `transform_params` method is a real function (e.g.\n",
      "     |      if Cholesky decomposition is used).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from statsmodels.tsa.statespace.mlemodel.MLEModel:\n",
      "     |  \n",
      "     |  from_formula(formula, data, subset=None) from builtins.type\n",
      "     |      Not implemented for state space models\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from statsmodels.tsa.statespace.mlemodel.MLEModel:\n",
      "     |  \n",
      "     |  initial_variance\n",
      "     |  \n",
      "     |  initialization\n",
      "     |  \n",
      "     |  loglikelihood_burn\n",
      "     |  \n",
      "     |  tolerance\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from statsmodels.tsa.base.tsa_model.TimeSeriesModel:\n",
      "     |  \n",
      "     |  exog_names\n",
      "     |      The names of the exogenous variables.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from statsmodels.base.model.LikelihoodModel:\n",
      "     |  \n",
      "     |  information(self, params)\n",
      "     |      Fisher information matrix of model.\n",
      "     |      \n",
      "     |      Returns -1 * Hessian of the log-likelihood evaluated at params.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : ndarray\n",
      "     |          The model parameters.\n",
      "     |  \n",
      "     |  initialize(self)\n",
      "     |      Initialize (possibly re-initialize) a Model instance.\n",
      "     |      \n",
      "     |      For example, if the the design matrix of a linear model changes then\n",
      "     |      initialized can be used to recompute values using the modified design\n",
      "     |      matrix.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from statsmodels.base.model.Model:\n",
      "     |  \n",
      "     |  predict(self, params, exog=None, *args, **kwargs)\n",
      "     |      After a model has been fit predict returns the fitted values.\n",
      "     |      \n",
      "     |      This is a placeholder intended to be overwritten by individual models.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from statsmodels.base.model.Model:\n",
      "     |  \n",
      "     |  endog_names\n",
      "     |      Names of endogenous variables.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from statsmodels.base.model.Model:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class VAR(statsmodels.tsa.base.tsa_model.TimeSeriesModel)\n",
      "     |  VAR(endog, exog=None, dates=None, freq=None, missing='none')\n",
      "     |  \n",
      "     |  Fit VAR(p) process and do lag order selection\n",
      "     |  \n",
      "     |  .. math:: y_t = A_1 y_{t-1} + \\ldots + A_p y_{t-p} + u_t\n",
      "     |  \n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  endog : array_like\n",
      "     |      2-d endogenous response variable. The independent variable.\n",
      "     |  exog : array_like\n",
      "     |      2-d exogenous variable.\n",
      "     |  dates : array_like\n",
      "     |      must match number of rows of endog\n",
      "     |  \n",
      "     |  References\n",
      "     |  ----------\n",
      "     |  Ltkepohl (2005) New Introduction to Multiple Time Series Analysis\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      VAR\n",
      "     |      statsmodels.tsa.base.tsa_model.TimeSeriesModel\n",
      "     |      statsmodels.base.model.LikelihoodModel\n",
      "     |      statsmodels.base.model.Model\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, endog, exog=None, dates=None, freq=None, missing='none')\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  fit(self, maxlags: 'int | None' = None, method='ols', ic=None, trend='c', verbose=False)\n",
      "     |      Fit the VAR model\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      maxlags : {int, None}, default None\n",
      "     |          Maximum number of lags to check for order selection, defaults to\n",
      "     |          12 * (nobs/100.)**(1./4), see select_order function\n",
      "     |      method : {'ols'}\n",
      "     |          Estimation method to use\n",
      "     |      ic : {'aic', 'fpe', 'hqic', 'bic', None}\n",
      "     |          Information criterion to use for VAR order selection.\n",
      "     |          aic : Akaike\n",
      "     |          fpe : Final prediction error\n",
      "     |          hqic : Hannan-Quinn\n",
      "     |          bic : Bayesian a.k.a. Schwarz\n",
      "     |      verbose : bool, default False\n",
      "     |          Print order selection output to the screen\n",
      "     |      trend : str {\"c\", \"ct\", \"ctt\", \"n\"}\n",
      "     |          \"c\" - add constant\n",
      "     |          \"ct\" - constant and trend\n",
      "     |          \"ctt\" - constant, linear and quadratic trend\n",
      "     |          \"n\" - co constant, no trend\n",
      "     |          Note that these are prepended to the columns of the dataset.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      VARResults\n",
      "     |          Estimation results\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      See Ltkepohl pp. 146-153 for implementation details.\n",
      "     |  \n",
      "     |  predict(self, params, start=None, end=None, lags=1, trend='c')\n",
      "     |      Returns in-sample predictions or forecasts\n",
      "     |  \n",
      "     |  select_order(self, maxlags=None, trend='c')\n",
      "     |      Compute lag order selections based on each of the available information\n",
      "     |      criteria\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      maxlags : int\n",
      "     |          if None, defaults to 12 * (nobs/100.)**(1./4)\n",
      "     |      trend : str {\"n\", \"c\", \"ct\", \"ctt\"}\n",
      "     |          * \"n\" - no deterministic terms\n",
      "     |          * \"c\" - constant term\n",
      "     |          * \"ct\" - constant and linear term\n",
      "     |          * \"ctt\" - constant, linear, and quadratic term\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      selections : LagOrderResults\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods defined here:\n",
      "     |  \n",
      "     |  from_formula(formula, data, subset=None, drop_cols=None, *args, **kwargs) from builtins.type\n",
      "     |      Not implemented. Formulas are not supported for VAR models.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  y\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from statsmodels.tsa.base.tsa_model.TimeSeriesModel:\n",
      "     |  \n",
      "     |  exog_names\n",
      "     |      The names of the exogenous variables.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from statsmodels.base.model.LikelihoodModel:\n",
      "     |  \n",
      "     |  hessian(self, params)\n",
      "     |      The Hessian matrix of the model.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : ndarray\n",
      "     |          The parameters to use when evaluating the Hessian.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      ndarray\n",
      "     |          The hessian evaluated at the parameters.\n",
      "     |  \n",
      "     |  information(self, params)\n",
      "     |      Fisher information matrix of model.\n",
      "     |      \n",
      "     |      Returns -1 * Hessian of the log-likelihood evaluated at params.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : ndarray\n",
      "     |          The model parameters.\n",
      "     |  \n",
      "     |  initialize(self)\n",
      "     |      Initialize (possibly re-initialize) a Model instance.\n",
      "     |      \n",
      "     |      For example, if the the design matrix of a linear model changes then\n",
      "     |      initialized can be used to recompute values using the modified design\n",
      "     |      matrix.\n",
      "     |  \n",
      "     |  loglike(self, params)\n",
      "     |      Log-likelihood of model.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : ndarray\n",
      "     |          The model parameters used to compute the log-likelihood.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Must be overridden by subclasses.\n",
      "     |  \n",
      "     |  score(self, params)\n",
      "     |      Score vector of model.\n",
      "     |      \n",
      "     |      The gradient of logL with respect to each parameter.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : ndarray\n",
      "     |          The parameters to use when evaluating the Hessian.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      ndarray\n",
      "     |          The score vector evaluated at the parameters.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from statsmodels.base.model.Model:\n",
      "     |  \n",
      "     |  endog_names\n",
      "     |      Names of endogenous variables.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from statsmodels.base.model.Model:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class VARMAX(statsmodels.tsa.statespace.mlemodel.MLEModel)\n",
      "     |  VARMAX(endog, exog=None, order=(1, 0), trend='c', error_cov_type='unstructured', measurement_error=False, enforce_stationarity=True, enforce_invertibility=True, trend_offset=1, **kwargs)\n",
      "     |  \n",
      "     |  Vector Autoregressive Moving Average with eXogenous regressors model\n",
      "     |  \n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  endog : array_like\n",
      "     |      The observed time-series process :math:`y`, , shaped nobs x k_endog.\n",
      "     |  exog : array_like, optional\n",
      "     |      Array of exogenous regressors, shaped nobs x k.\n",
      "     |  order : iterable\n",
      "     |      The (p,q) order of the model for the number of AR and MA parameters to\n",
      "     |      use.\n",
      "     |  trend : str{'n','c','t','ct'} or iterable, optional\n",
      "     |      Parameter controlling the deterministic trend polynomial :math:`A(t)`.\n",
      "     |      Can be specified as a string where 'c' indicates a constant (i.e. a\n",
      "     |      degree zero component of the trend polynomial), 't' indicates a\n",
      "     |      linear trend with time, and 'ct' is both. Can also be specified as an\n",
      "     |      iterable defining the non-zero polynomial exponents to include, in\n",
      "     |      increasing order. For example, `[1,1,0,1]` denotes\n",
      "     |      :math:`a + bt + ct^3`. Default is a constant trend component.\n",
      "     |  error_cov_type : {'diagonal', 'unstructured'}, optional\n",
      "     |      The structure of the covariance matrix of the error term, where\n",
      "     |      \"unstructured\" puts no restrictions on the matrix and \"diagonal\"\n",
      "     |      requires it to be a diagonal matrix (uncorrelated errors). Default is\n",
      "     |      \"unstructured\".\n",
      "     |  measurement_error : bool, optional\n",
      "     |      Whether or not to assume the endogenous observations `endog` were\n",
      "     |      measured with error. Default is False.\n",
      "     |  enforce_stationarity : bool, optional\n",
      "     |      Whether or not to transform the AR parameters to enforce stationarity\n",
      "     |      in the autoregressive component of the model. Default is True.\n",
      "     |  enforce_invertibility : bool, optional\n",
      "     |      Whether or not to transform the MA parameters to enforce invertibility\n",
      "     |      in the moving average component of the model. Default is True.\n",
      "     |  trend_offset : int, optional\n",
      "     |      The offset at which to start time trend values. Default is 1, so that\n",
      "     |      if `trend='t'` the trend is equal to 1, 2, ..., nobs. Typically is only\n",
      "     |      set when the model created by extending a previous dataset.\n",
      "     |  **kwargs\n",
      "     |      Keyword arguments may be used to provide default values for state space\n",
      "     |      matrices or for Kalman filtering options. See `Representation`, and\n",
      "     |      `KalmanFilter` for more details.\n",
      "     |  \n",
      "     |  Attributes\n",
      "     |  ----------\n",
      "     |  order : iterable\n",
      "     |      The (p,q) order of the model for the number of AR and MA parameters to\n",
      "     |      use.\n",
      "     |  trend : str{'n','c','t','ct'} or iterable\n",
      "     |      Parameter controlling the deterministic trend polynomial :math:`A(t)`.\n",
      "     |      Can be specified as a string where 'c' indicates a constant (i.e. a\n",
      "     |      degree zero component of the trend polynomial), 't' indicates a\n",
      "     |      linear trend with time, and 'ct' is both. Can also be specified as an\n",
      "     |      iterable defining the non-zero polynomial exponents to include, in\n",
      "     |      increasing order. For example, `[1,1,0,1]` denotes\n",
      "     |      :math:`a + bt + ct^3`.\n",
      "     |  error_cov_type : {'diagonal', 'unstructured'}, optional\n",
      "     |      The structure of the covariance matrix of the error term, where\n",
      "     |      \"unstructured\" puts no restrictions on the matrix and \"diagonal\"\n",
      "     |      requires it to be a diagonal matrix (uncorrelated errors). Default is\n",
      "     |      \"unstructured\".\n",
      "     |  measurement_error : bool, optional\n",
      "     |      Whether or not to assume the endogenous observations `endog` were\n",
      "     |      measured with error. Default is False.\n",
      "     |  enforce_stationarity : bool, optional\n",
      "     |      Whether or not to transform the AR parameters to enforce stationarity\n",
      "     |      in the autoregressive component of the model. Default is True.\n",
      "     |  enforce_invertibility : bool, optional\n",
      "     |      Whether or not to transform the MA parameters to enforce invertibility\n",
      "     |      in the moving average component of the model. Default is True.\n",
      "     |  \n",
      "     |  Notes\n",
      "     |  -----\n",
      "     |  Generically, the VARMAX model is specified (see for example chapter 18 of\n",
      "     |  [1]_):\n",
      "     |  \n",
      "     |  .. math::\n",
      "     |  \n",
      "     |      y_t = A(t) + A_1 y_{t-1} + \\dots + A_p y_{t-p} + B x_t + \\epsilon_t +\n",
      "     |      M_1 \\epsilon_{t-1} + \\dots M_q \\epsilon_{t-q}\n",
      "     |  \n",
      "     |  where :math:`\\epsilon_t \\sim N(0, \\Omega)`, and where :math:`y_t` is a\n",
      "     |  `k_endog x 1` vector. Additionally, this model allows considering the case\n",
      "     |  where the variables are measured with error.\n",
      "     |  \n",
      "     |  Note that in the full VARMA(p,q) case there is a fundamental identification\n",
      "     |  problem in that the coefficient matrices :math:`\\{A_i, M_j\\}` are not\n",
      "     |  generally unique, meaning that for a given time series process there may\n",
      "     |  be multiple sets of matrices that equivalently represent it. See Chapter 12\n",
      "     |  of [1]_ for more information. Although this class can be used to estimate\n",
      "     |  VARMA(p,q) models, a warning is issued to remind users that no steps have\n",
      "     |  been taken to ensure identification in this case.\n",
      "     |  \n",
      "     |  References\n",
      "     |  ----------\n",
      "     |  .. [1] Ltkepohl, Helmut. 2007.\n",
      "     |     New Introduction to Multiple Time Series Analysis.\n",
      "     |     Berlin: Springer.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      VARMAX\n",
      "     |      statsmodels.tsa.statespace.mlemodel.MLEModel\n",
      "     |      statsmodels.tsa.base.tsa_model.TimeSeriesModel\n",
      "     |      statsmodels.base.model.LikelihoodModel\n",
      "     |      statsmodels.base.model.Model\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, endog, exog=None, order=(1, 0), trend='c', error_cov_type='unstructured', measurement_error=False, enforce_stationarity=True, enforce_invertibility=True, trend_offset=1, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  clone(self, endog, exog=None, **kwargs)\n",
      "     |      Clone state space model with new data and optionally new specification\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      endog : array_like\n",
      "     |          The observed time-series process :math:`y`\n",
      "     |      k_states : int\n",
      "     |          The dimension of the unobserved state process.\n",
      "     |      exog : array_like, optional\n",
      "     |          Array of exogenous regressors, shaped nobs x k. Default is no\n",
      "     |          exogenous regressors.\n",
      "     |      kwargs\n",
      "     |          Keyword arguments to pass to the new model class to change the\n",
      "     |          model specification.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      model : MLEModel subclass\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      This method must be implemented\n",
      "     |  \n",
      "     |  simulate(self, params, nsimulations, measurement_shocks=None, state_shocks=None, initial_state=None, anchor=None, repetitions=None, exog=None, extend_model=None, extend_kwargs=None, transformed=True, includes_fixed=False, **kwargs)\n",
      "     |      Simulate a new time series following the state space model\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : array_like\n",
      "     |          Array of parameters to use in constructing the state space\n",
      "     |          representation to use when simulating.\n",
      "     |      nsimulations : int\n",
      "     |          The number of observations to simulate. If the model is\n",
      "     |          time-invariant this can be any number. If the model is\n",
      "     |          time-varying, then this number must be less than or equal to the\n",
      "     |          number of observations.\n",
      "     |      measurement_shocks : array_like, optional\n",
      "     |          If specified, these are the shocks to the measurement equation,\n",
      "     |          :math:`\\varepsilon_t`. If unspecified, these are automatically\n",
      "     |          generated using a pseudo-random number generator. If specified,\n",
      "     |          must be shaped `nsimulations` x `k_endog`, where `k_endog` is the\n",
      "     |          same as in the state space model.\n",
      "     |      state_shocks : array_like, optional\n",
      "     |          If specified, these are the shocks to the state equation,\n",
      "     |          :math:`\\eta_t`. If unspecified, these are automatically\n",
      "     |          generated using a pseudo-random number generator. If specified,\n",
      "     |          must be shaped `nsimulations` x `k_posdef` where `k_posdef` is the\n",
      "     |          same as in the state space model.\n",
      "     |      initial_state : array_like, optional\n",
      "     |          If specified, this is the initial state vector to use in\n",
      "     |          simulation, which should be shaped (`k_states` x 1), where\n",
      "     |          `k_states` is the same as in the state space model. If unspecified,\n",
      "     |          but the model has been initialized, then that initialization is\n",
      "     |          used. This must be specified if `anchor` is anything other than\n",
      "     |          \"start\" or 0 (or else you can use the `simulate` method on a\n",
      "     |          results object rather than on the model object).\n",
      "     |      anchor : int, str, or datetime, optional\n",
      "     |          First period for simulation. The simulation will be conditional on\n",
      "     |          all existing datapoints prior to the `anchor`.  Type depends on the\n",
      "     |          index of the given `endog` in the model. Two special cases are the\n",
      "     |          strings 'start' and 'end'. `start` refers to beginning the\n",
      "     |          simulation at the first period of the sample, and `end` refers to\n",
      "     |          beginning the simulation at the first period after the sample.\n",
      "     |          Integer values can run from 0 to `nobs`, or can be negative to\n",
      "     |          apply negative indexing. Finally, if a date/time index was provided\n",
      "     |          to the model, then this argument can be a date string to parse or a\n",
      "     |          datetime type. Default is 'start'.\n",
      "     |      repetitions : int, optional\n",
      "     |          Number of simulated paths to generate. Default is 1 simulated path.\n",
      "     |      exog : array_like, optional\n",
      "     |          New observations of exogenous regressors, if applicable.\n",
      "     |      transformed : bool, optional\n",
      "     |          Whether or not `params` is already transformed. Default is\n",
      "     |          True.\n",
      "     |      includes_fixed : bool, optional\n",
      "     |          If parameters were previously fixed with the `fix_params` method,\n",
      "     |          this argument describes whether or not `params` also includes\n",
      "     |          the fixed parameters, in addition to the free parameters. Default\n",
      "     |          is False.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      simulated_obs : ndarray\n",
      "     |          An array of simulated observations. If `repetitions=None`, then it\n",
      "     |          will be shaped (nsimulations x k_endog) or (nsimulations,) if\n",
      "     |          `k_endog=1`. Otherwise it will be shaped\n",
      "     |          (nsimulations x k_endog x repetitions). If the model was given\n",
      "     |          Pandas input then the output will be a Pandas object. If\n",
      "     |          `k_endog > 1` and `repetitions` is not None, then the output will\n",
      "     |          be a Pandas DataFrame that has a MultiIndex for the columns, with\n",
      "     |          the first level containing the names of the `endog` variables and\n",
      "     |          the second level containing the repetition number.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      impulse_responses\n",
      "     |          Impulse response functions\n",
      "     |  \n",
      "     |  transform_params(self, unconstrained)\n",
      "     |      Transform unconstrained parameters used by the optimizer to constrained\n",
      "     |      parameters used in likelihood evaluation\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      unconstrained : array_like\n",
      "     |          Array of unconstrained parameters used by the optimizer, to be\n",
      "     |          transformed.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      constrained : array_like\n",
      "     |          Array of constrained parameters which may be used in likelihood\n",
      "     |          evaluation.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Constrains the factor transition to be stationary and variances to be\n",
      "     |      positive.\n",
      "     |  \n",
      "     |  untransform_params(self, constrained)\n",
      "     |      Transform constrained parameters used in likelihood evaluation\n",
      "     |      to unconstrained parameters used by the optimizer.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      constrained : array_like\n",
      "     |          Array of constrained parameters used in likelihood evaluation, to\n",
      "     |          be transformed.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      unconstrained : array_like\n",
      "     |          Array of unconstrained parameters used by the optimizer.\n",
      "     |  \n",
      "     |  update(self, params, transformed=True, includes_fixed=False, complex_step=False)\n",
      "     |      Update the parameters of the model\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : array_like\n",
      "     |          Array of new parameters.\n",
      "     |      transformed : bool, optional\n",
      "     |          Whether or not `params` is already transformed. If set to False,\n",
      "     |          `transform_params` is called. Default is True.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      params : array_like\n",
      "     |          Array of parameters.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Since Model is a base class, this method should be overridden by\n",
      "     |      subclasses to perform actual updating steps.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties defined here:\n",
      "     |  \n",
      "     |  param_names\n",
      "     |      (list of str) List of human readable parameter names (for parameters\n",
      "     |      actually included in the model).\n",
      "     |  \n",
      "     |  start_params\n",
      "     |      (array) Starting parameters for maximum likelihood estimation.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from statsmodels.tsa.statespace.mlemodel.MLEModel:\n",
      "     |  \n",
      "     |  __getitem__(self, key)\n",
      "     |  \n",
      "     |  __setitem__(self, key, value)\n",
      "     |  \n",
      "     |  filter(self, params, transformed=True, includes_fixed=False, complex_step=False, cov_type=None, cov_kwds=None, return_ssm=False, results_class=None, results_wrapper_class=None, low_memory=False, **kwargs)\n",
      "     |      Kalman filtering\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : array_like\n",
      "     |          Array of parameters at which to evaluate the loglikelihood\n",
      "     |          function.\n",
      "     |      transformed : bool, optional\n",
      "     |          Whether or not `params` is already transformed. Default is True.\n",
      "     |      return_ssm : bool,optional\n",
      "     |          Whether or not to return only the state space output or a full\n",
      "     |          results object. Default is to return a full results object.\n",
      "     |      cov_type : str, optional\n",
      "     |          See `MLEResults.fit` for a description of covariance matrix types\n",
      "     |          for results object.\n",
      "     |      cov_kwds : dict or None, optional\n",
      "     |          See `MLEResults.get_robustcov_results` for a description required\n",
      "     |          keywords for alternative covariance estimators\n",
      "     |      low_memory : bool, optional\n",
      "     |          If set to True, techniques are applied to substantially reduce\n",
      "     |          memory usage. If used, some features of the results object will\n",
      "     |          not be available (including in-sample prediction), although\n",
      "     |          out-of-sample forecasting is possible. Default is False.\n",
      "     |      **kwargs\n",
      "     |          Additional keyword arguments to pass to the Kalman filter. See\n",
      "     |          `KalmanFilter.filter` for more details.\n",
      "     |  \n",
      "     |  fit(self, start_params=None, transformed=True, includes_fixed=False, cov_type=None, cov_kwds=None, method='lbfgs', maxiter=50, full_output=1, disp=5, callback=None, return_params=False, optim_score=None, optim_complex_step=None, optim_hessian=None, flags=None, low_memory=False, **kwargs)\n",
      "     |      Fits the model by maximum likelihood via Kalman filter.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      start_params : array_like, optional\n",
      "     |          Initial guess of the solution for the loglikelihood maximization.\n",
      "     |          If None, the default is given by Model.start_params.\n",
      "     |      transformed : bool, optional\n",
      "     |          Whether or not `start_params` is already transformed. Default is\n",
      "     |          True.\n",
      "     |      includes_fixed : bool, optional\n",
      "     |          If parameters were previously fixed with the `fix_params` method,\n",
      "     |          this argument describes whether or not `start_params` also includes\n",
      "     |          the fixed parameters, in addition to the free parameters. Default\n",
      "     |          is False.\n",
      "     |      cov_type : str, optional\n",
      "     |          The `cov_type` keyword governs the method for calculating the\n",
      "     |          covariance matrix of parameter estimates. Can be one of:\n",
      "     |      \n",
      "     |          - 'opg' for the outer product of gradient estimator\n",
      "     |          - 'oim' for the observed information matrix estimator, calculated\n",
      "     |            using the method of Harvey (1989)\n",
      "     |          - 'approx' for the observed information matrix estimator,\n",
      "     |            calculated using a numerical approximation of the Hessian matrix.\n",
      "     |          - 'robust' for an approximate (quasi-maximum likelihood) covariance\n",
      "     |            matrix that may be valid even in the presence of some\n",
      "     |            misspecifications. Intermediate calculations use the 'oim'\n",
      "     |            method.\n",
      "     |          - 'robust_approx' is the same as 'robust' except that the\n",
      "     |            intermediate calculations use the 'approx' method.\n",
      "     |          - 'none' for no covariance matrix calculation.\n",
      "     |      \n",
      "     |          Default is 'opg' unless memory conservation is used to avoid\n",
      "     |          computing the loglikelihood values for each observation, in which\n",
      "     |          case the default is 'approx'.\n",
      "     |      cov_kwds : dict or None, optional\n",
      "     |          A dictionary of arguments affecting covariance matrix computation.\n",
      "     |      \n",
      "     |          **opg, oim, approx, robust, robust_approx**\n",
      "     |      \n",
      "     |          - 'approx_complex_step' : bool, optional - If True, numerical\n",
      "     |            approximations are computed using complex-step methods. If False,\n",
      "     |            numerical approximations are computed using finite difference\n",
      "     |            methods. Default is True.\n",
      "     |          - 'approx_centered' : bool, optional - If True, numerical\n",
      "     |            approximations computed using finite difference methods use a\n",
      "     |            centered approximation. Default is False.\n",
      "     |      method : str, optional\n",
      "     |          The `method` determines which solver from `scipy.optimize`\n",
      "     |          is used, and it can be chosen from among the following strings:\n",
      "     |      \n",
      "     |          - 'newton' for Newton-Raphson\n",
      "     |          - 'nm' for Nelder-Mead\n",
      "     |          - 'bfgs' for Broyden-Fletcher-Goldfarb-Shanno (BFGS)\n",
      "     |          - 'lbfgs' for limited-memory BFGS with optional box constraints\n",
      "     |          - 'powell' for modified Powell's method\n",
      "     |          - 'cg' for conjugate gradient\n",
      "     |          - 'ncg' for Newton-conjugate gradient\n",
      "     |          - 'basinhopping' for global basin-hopping solver\n",
      "     |      \n",
      "     |          The explicit arguments in `fit` are passed to the solver,\n",
      "     |          with the exception of the basin-hopping solver. Each\n",
      "     |          solver has several optional arguments that are not the same across\n",
      "     |          solvers. See the notes section below (or scipy.optimize) for the\n",
      "     |          available arguments and for the list of explicit arguments that the\n",
      "     |          basin-hopping solver supports.\n",
      "     |      maxiter : int, optional\n",
      "     |          The maximum number of iterations to perform.\n",
      "     |      full_output : bool, optional\n",
      "     |          Set to True to have all available output in the Results object's\n",
      "     |          mle_retvals attribute. The output is dependent on the solver.\n",
      "     |          See LikelihoodModelResults notes section for more information.\n",
      "     |      disp : bool, optional\n",
      "     |          Set to True to print convergence messages.\n",
      "     |      callback : callable callback(xk), optional\n",
      "     |          Called after each iteration, as callback(xk), where xk is the\n",
      "     |          current parameter vector.\n",
      "     |      return_params : bool, optional\n",
      "     |          Whether or not to return only the array of maximizing parameters.\n",
      "     |          Default is False.\n",
      "     |      optim_score : {'harvey', 'approx'} or None, optional\n",
      "     |          The method by which the score vector is calculated. 'harvey' uses\n",
      "     |          the method from Harvey (1989), 'approx' uses either finite\n",
      "     |          difference or complex step differentiation depending upon the\n",
      "     |          value of `optim_complex_step`, and None uses the built-in gradient\n",
      "     |          approximation of the optimizer. Default is None. This keyword is\n",
      "     |          only relevant if the optimization method uses the score.\n",
      "     |      optim_complex_step : bool, optional\n",
      "     |          Whether or not to use complex step differentiation when\n",
      "     |          approximating the score; if False, finite difference approximation\n",
      "     |          is used. Default is True. This keyword is only relevant if\n",
      "     |          `optim_score` is set to 'harvey' or 'approx'.\n",
      "     |      optim_hessian : {'opg','oim','approx'}, optional\n",
      "     |          The method by which the Hessian is numerically approximated. 'opg'\n",
      "     |          uses outer product of gradients, 'oim' uses the information\n",
      "     |          matrix formula from Harvey (1989), and 'approx' uses numerical\n",
      "     |          approximation. This keyword is only relevant if the\n",
      "     |          optimization method uses the Hessian matrix.\n",
      "     |      low_memory : bool, optional\n",
      "     |          If set to True, techniques are applied to substantially reduce\n",
      "     |          memory usage. If used, some features of the results object will\n",
      "     |          not be available (including smoothed results and in-sample\n",
      "     |          prediction), although out-of-sample forecasting is possible.\n",
      "     |          Default is False.\n",
      "     |      **kwargs\n",
      "     |          Additional keyword arguments to pass to the optimizer.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      results\n",
      "     |          Results object holding results from fitting a state space model.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      statsmodels.base.model.LikelihoodModel.fit\n",
      "     |      statsmodels.tsa.statespace.mlemodel.MLEResults\n",
      "     |      statsmodels.tsa.statespace.structural.UnobservedComponentsResults\n",
      "     |  \n",
      "     |  fit_constrained(self, constraints, start_params=None, **fit_kwds)\n",
      "     |      Fit the model with some parameters subject to equality constraints.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      constraints : dict\n",
      "     |          Dictionary of constraints, of the form `param_name: fixed_value`.\n",
      "     |          See the `param_names` property for valid parameter names.\n",
      "     |      start_params : array_like, optional\n",
      "     |          Initial guess of the solution for the loglikelihood maximization.\n",
      "     |          If None, the default is given by Model.start_params.\n",
      "     |      **fit_kwds : keyword arguments\n",
      "     |          fit_kwds are used in the optimization of the remaining parameters.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      results : Results instance\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> mod = sm.tsa.SARIMAX(endog, order=(1, 0, 1))\n",
      "     |      >>> res = mod.fit_constrained({'ar.L1': 0.5})\n",
      "     |  \n",
      "     |  fix_params(self, params)\n",
      "     |      Fix parameters to specific values (context manager)\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : dict\n",
      "     |          Dictionary describing the fixed parameter values, of the form\n",
      "     |          `param_name: fixed_value`. See the `param_names` property for valid\n",
      "     |          parameter names.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> mod = sm.tsa.SARIMAX(endog, order=(1, 0, 1))\n",
      "     |      >>> with mod.fix_params({'ar.L1': 0.5}):\n",
      "     |              res = mod.fit()\n",
      "     |  \n",
      "     |  handle_params(self, params, transformed=True, includes_fixed=False, return_jacobian=False)\n",
      "     |      Ensure model parameters satisfy shape and other requirements\n",
      "     |  \n",
      "     |  hessian(self, params, *args, **kwargs)\n",
      "     |      Hessian matrix of the likelihood function, evaluated at the given\n",
      "     |      parameters\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : array_like\n",
      "     |          Array of parameters at which to evaluate the hessian.\n",
      "     |      *args\n",
      "     |          Additional positional arguments to the `loglike` method.\n",
      "     |      **kwargs\n",
      "     |          Additional keyword arguments to the `loglike` method.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      hessian : ndarray\n",
      "     |          Hessian matrix evaluated at `params`\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      This is a numerical approximation.\n",
      "     |      \n",
      "     |      Both args and kwargs are necessary because the optimizer from\n",
      "     |      `fit` must call this function and only supports passing arguments via\n",
      "     |      args (for example `scipy.optimize.fmin_l_bfgs`).\n",
      "     |  \n",
      "     |  impulse_responses(self, params, steps=1, impulse=0, orthogonalized=False, cumulative=False, anchor=None, exog=None, extend_model=None, extend_kwargs=None, transformed=True, includes_fixed=False, **kwargs)\n",
      "     |      Impulse response function\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : array_like\n",
      "     |          Array of model parameters.\n",
      "     |      steps : int, optional\n",
      "     |          The number of steps for which impulse responses are calculated.\n",
      "     |          Default is 1. Note that for time-invariant models, the initial\n",
      "     |          impulse is not counted as a step, so if `steps=1`, the output will\n",
      "     |          have 2 entries.\n",
      "     |      impulse : int, str or array_like\n",
      "     |          If an integer, the state innovation to pulse; must be between 0\n",
      "     |          and `k_posdef-1`. If a str, it indicates which column of df\n",
      "     |          the unit (1) impulse is given.\n",
      "     |          Alternatively, a custom impulse vector may be provided; must be\n",
      "     |          shaped `k_posdef x 1`.\n",
      "     |      orthogonalized : bool, optional\n",
      "     |          Whether or not to perform impulse using orthogonalized innovations.\n",
      "     |          Note that this will also affect custum `impulse` vectors. Default\n",
      "     |          is False.\n",
      "     |      cumulative : bool, optional\n",
      "     |          Whether or not to return cumulative impulse responses. Default is\n",
      "     |          False.\n",
      "     |      anchor : int, str, or datetime, optional\n",
      "     |          Time point within the sample for the state innovation impulse. Type\n",
      "     |          depends on the index of the given `endog` in the model. Two special\n",
      "     |          cases are the strings 'start' and 'end', which refer to setting the\n",
      "     |          impulse at the first and last points of the sample, respectively.\n",
      "     |          Integer values can run from 0 to `nobs - 1`, or can be negative to\n",
      "     |          apply negative indexing. Finally, if a date/time index was provided\n",
      "     |          to the model, then this argument can be a date string to parse or a\n",
      "     |          datetime type. Default is 'start'.\n",
      "     |      exog : array_like, optional\n",
      "     |          New observations of exogenous regressors for our-of-sample periods,\n",
      "     |          if applicable.\n",
      "     |      transformed : bool, optional\n",
      "     |          Whether or not `params` is already transformed. Default is\n",
      "     |          True.\n",
      "     |      includes_fixed : bool, optional\n",
      "     |          If parameters were previously fixed with the `fix_params` method,\n",
      "     |          this argument describes whether or not `params` also includes\n",
      "     |          the fixed parameters, in addition to the free parameters. Default\n",
      "     |          is False.\n",
      "     |      **kwargs\n",
      "     |          If the model has time-varying design or transition matrices and the\n",
      "     |          combination of `anchor` and `steps` implies creating impulse\n",
      "     |          responses for the out-of-sample period, then these matrices must\n",
      "     |          have updated values provided for the out-of-sample steps. For\n",
      "     |          example, if `design` is a time-varying component, `nobs` is 10,\n",
      "     |          `anchor=1`, and `steps` is 15, a (`k_endog` x `k_states` x 7)\n",
      "     |          matrix must be provided with the new design matrix values.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      impulse_responses : ndarray\n",
      "     |          Responses for each endogenous variable due to the impulse\n",
      "     |          given by the `impulse` argument. For a time-invariant model, the\n",
      "     |          impulse responses are given for `steps + 1` elements (this gives\n",
      "     |          the \"initial impulse\" followed by `steps` responses for the\n",
      "     |          important cases of VAR and SARIMAX models), while for time-varying\n",
      "     |          models the impulse responses are only given for `steps` elements\n",
      "     |          (to avoid having to unexpectedly provide updated time-varying\n",
      "     |          matrices).\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      simulate\n",
      "     |          Simulate a time series according to the given state space model,\n",
      "     |          optionally with specified series for the innovations.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Intercepts in the measurement and state equation are ignored when\n",
      "     |      calculating impulse responses.\n",
      "     |      \n",
      "     |      TODO: add an option to allow changing the ordering for the\n",
      "     |            orthogonalized option. Will require permuting matrices when\n",
      "     |            constructing the extended model.\n",
      "     |  \n",
      "     |  initialize_approximate_diffuse(self, variance=None)\n",
      "     |      Initialize approximate diffuse\n",
      "     |  \n",
      "     |  initialize_known(self, initial_state, initial_state_cov)\n",
      "     |      Initialize known\n",
      "     |  \n",
      "     |  initialize_statespace(self, **kwargs)\n",
      "     |      Initialize the state space representation\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      **kwargs\n",
      "     |          Additional keyword arguments to pass to the state space class\n",
      "     |          constructor.\n",
      "     |  \n",
      "     |  initialize_stationary(self)\n",
      "     |      Initialize stationary\n",
      "     |  \n",
      "     |  loglike(self, params, *args, **kwargs)\n",
      "     |      Loglikelihood evaluation\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : array_like\n",
      "     |          Array of parameters at which to evaluate the loglikelihood\n",
      "     |          function.\n",
      "     |      transformed : bool, optional\n",
      "     |          Whether or not `params` is already transformed. Default is True.\n",
      "     |      **kwargs\n",
      "     |          Additional keyword arguments to pass to the Kalman filter. See\n",
      "     |          `KalmanFilter.filter` for more details.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      update : modifies the internal state of the state space model to\n",
      "     |               reflect new params\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      [1]_ recommend maximizing the average likelihood to avoid scale issues;\n",
      "     |      this is done automatically by the base Model fit method.\n",
      "     |      \n",
      "     |      References\n",
      "     |      ----------\n",
      "     |      .. [1] Koopman, Siem Jan, Neil Shephard, and Jurgen A. Doornik. 1999.\n",
      "     |         Statistical Algorithms for Models in State Space Using SsfPack 2.2.\n",
      "     |         Econometrics Journal 2 (1): 107-60. doi:10.1111/1368-423X.00023.\n",
      "     |  \n",
      "     |  loglikeobs(self, params, transformed=True, includes_fixed=False, complex_step=False, **kwargs)\n",
      "     |      Loglikelihood evaluation\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : array_like\n",
      "     |          Array of parameters at which to evaluate the loglikelihood\n",
      "     |          function.\n",
      "     |      transformed : bool, optional\n",
      "     |          Whether or not `params` is already transformed. Default is True.\n",
      "     |      **kwargs\n",
      "     |          Additional keyword arguments to pass to the Kalman filter. See\n",
      "     |          `KalmanFilter.filter` for more details.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      update : modifies the internal state of the Model to reflect new params\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      [1]_ recommend maximizing the average likelihood to avoid scale issues;\n",
      "     |      this is done automatically by the base Model fit method.\n",
      "     |      \n",
      "     |      References\n",
      "     |      ----------\n",
      "     |      .. [1] Koopman, Siem Jan, Neil Shephard, and Jurgen A. Doornik. 1999.\n",
      "     |         Statistical Algorithms for Models in State Space Using SsfPack 2.2.\n",
      "     |         Econometrics Journal 2 (1): 107-60. doi:10.1111/1368-423X.00023.\n",
      "     |  \n",
      "     |  observed_information_matrix(self, params, transformed=True, includes_fixed=False, approx_complex_step=None, approx_centered=False, **kwargs)\n",
      "     |      Observed information matrix\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : array_like, optional\n",
      "     |          Array of parameters at which to evaluate the loglikelihood\n",
      "     |          function.\n",
      "     |      **kwargs\n",
      "     |          Additional keyword arguments to pass to the Kalman filter. See\n",
      "     |          `KalmanFilter.filter` for more details.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      This method is from Harvey (1989), which shows that the information\n",
      "     |      matrix only depends on terms from the gradient. This implementation is\n",
      "     |      partially analytic and partially numeric approximation, therefore,\n",
      "     |      because it uses the analytic formula for the information matrix, with\n",
      "     |      numerically computed elements of the gradient.\n",
      "     |      \n",
      "     |      References\n",
      "     |      ----------\n",
      "     |      Harvey, Andrew C. 1990.\n",
      "     |      Forecasting, Structural Time Series Models and the Kalman Filter.\n",
      "     |      Cambridge University Press.\n",
      "     |  \n",
      "     |  opg_information_matrix(self, params, transformed=True, includes_fixed=False, approx_complex_step=None, **kwargs)\n",
      "     |      Outer product of gradients information matrix\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : array_like, optional\n",
      "     |          Array of parameters at which to evaluate the loglikelihood\n",
      "     |          function.\n",
      "     |      **kwargs\n",
      "     |          Additional arguments to the `loglikeobs` method.\n",
      "     |      \n",
      "     |      References\n",
      "     |      ----------\n",
      "     |      Berndt, Ernst R., Bronwyn Hall, Robert Hall, and Jerry Hausman. 1974.\n",
      "     |      Estimation and Inference in Nonlinear Structural Models.\n",
      "     |      NBER Chapters. National Bureau of Economic Research, Inc.\n",
      "     |  \n",
      "     |  prepare_data(self)\n",
      "     |      Prepare data for use in the state space representation\n",
      "     |  \n",
      "     |  score(self, params, *args, **kwargs)\n",
      "     |      Compute the score function at params.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : array_like\n",
      "     |          Array of parameters at which to evaluate the score.\n",
      "     |      *args\n",
      "     |          Additional positional arguments to the `loglike` method.\n",
      "     |      **kwargs\n",
      "     |          Additional keyword arguments to the `loglike` method.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      score : ndarray\n",
      "     |          Score, evaluated at `params`.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      This is a numerical approximation, calculated using first-order complex\n",
      "     |      step differentiation on the `loglike` method.\n",
      "     |      \n",
      "     |      Both args and kwargs are necessary because the optimizer from\n",
      "     |      `fit` must call this function and only supports passing arguments via\n",
      "     |      args (for example `scipy.optimize.fmin_l_bfgs`).\n",
      "     |  \n",
      "     |  score_obs(self, params, method='approx', transformed=True, includes_fixed=False, approx_complex_step=None, approx_centered=False, **kwargs)\n",
      "     |      Compute the score per observation, evaluated at params\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : array_like\n",
      "     |          Array of parameters at which to evaluate the score.\n",
      "     |      **kwargs\n",
      "     |          Additional arguments to the `loglike` method.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      score : ndarray\n",
      "     |          Score per observation, evaluated at `params`.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      This is a numerical approximation, calculated using first-order complex\n",
      "     |      step differentiation on the `loglikeobs` method.\n",
      "     |  \n",
      "     |  set_conserve_memory(self, conserve_memory=None, **kwargs)\n",
      "     |      Set the memory conservation method\n",
      "     |      \n",
      "     |      By default, the Kalman filter computes a number of intermediate\n",
      "     |      matrices at each iteration. The memory conservation options control\n",
      "     |      which of those matrices are stored.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      conserve_memory : int, optional\n",
      "     |          Bitmask value to set the memory conservation method to. See notes\n",
      "     |          for details.\n",
      "     |      **kwargs\n",
      "     |          Keyword arguments may be used to influence the memory conservation\n",
      "     |          method by setting individual boolean flags.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      This method is rarely used. See the corresponding function in the\n",
      "     |      `KalmanFilter` class for details.\n",
      "     |  \n",
      "     |  set_filter_method(self, filter_method=None, **kwargs)\n",
      "     |      Set the filtering method\n",
      "     |      \n",
      "     |      The filtering method controls aspects of which Kalman filtering\n",
      "     |      approach will be used.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      filter_method : int, optional\n",
      "     |          Bitmask value to set the filter method to. See notes for details.\n",
      "     |      **kwargs\n",
      "     |          Keyword arguments may be used to influence the filter method by\n",
      "     |          setting individual boolean flags. See notes for details.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      This method is rarely used. See the corresponding function in the\n",
      "     |      `KalmanFilter` class for details.\n",
      "     |  \n",
      "     |  set_inversion_method(self, inversion_method=None, **kwargs)\n",
      "     |      Set the inversion method\n",
      "     |      \n",
      "     |      The Kalman filter may contain one matrix inversion: that of the\n",
      "     |      forecast error covariance matrix. The inversion method controls how and\n",
      "     |      if that inverse is performed.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      inversion_method : int, optional\n",
      "     |          Bitmask value to set the inversion method to. See notes for\n",
      "     |          details.\n",
      "     |      **kwargs\n",
      "     |          Keyword arguments may be used to influence the inversion method by\n",
      "     |          setting individual boolean flags. See notes for details.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      This method is rarely used. See the corresponding function in the\n",
      "     |      `KalmanFilter` class for details.\n",
      "     |  \n",
      "     |  set_smoother_output(self, smoother_output=None, **kwargs)\n",
      "     |      Set the smoother output\n",
      "     |      \n",
      "     |      The smoother can produce several types of results. The smoother output\n",
      "     |      variable controls which are calculated and returned.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      smoother_output : int, optional\n",
      "     |          Bitmask value to set the smoother output to. See notes for details.\n",
      "     |      **kwargs\n",
      "     |          Keyword arguments may be used to influence the smoother output by\n",
      "     |          setting individual boolean flags.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      This method is rarely used. See the corresponding function in the\n",
      "     |      `KalmanSmoother` class for details.\n",
      "     |  \n",
      "     |  set_stability_method(self, stability_method=None, **kwargs)\n",
      "     |      Set the numerical stability method\n",
      "     |      \n",
      "     |      The Kalman filter is a recursive algorithm that may in some cases\n",
      "     |      suffer issues with numerical stability. The stability method controls\n",
      "     |      what, if any, measures are taken to promote stability.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      stability_method : int, optional\n",
      "     |          Bitmask value to set the stability method to. See notes for\n",
      "     |          details.\n",
      "     |      **kwargs\n",
      "     |          Keyword arguments may be used to influence the stability method by\n",
      "     |          setting individual boolean flags. See notes for details.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      This method is rarely used. See the corresponding function in the\n",
      "     |      `KalmanFilter` class for details.\n",
      "     |  \n",
      "     |  simulation_smoother(self, simulation_output=None, **kwargs)\n",
      "     |      Retrieve a simulation smoother for the state space model.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      simulation_output : int, optional\n",
      "     |          Determines which simulation smoother output is calculated.\n",
      "     |          Default is all (including state and disturbances).\n",
      "     |      **kwargs\n",
      "     |          Additional keyword arguments, used to set the simulation output.\n",
      "     |          See `set_simulation_output` for more details.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      SimulationSmoothResults\n",
      "     |  \n",
      "     |  smooth(self, params, transformed=True, includes_fixed=False, complex_step=False, cov_type=None, cov_kwds=None, return_ssm=False, results_class=None, results_wrapper_class=None, **kwargs)\n",
      "     |      Kalman smoothing\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : array_like\n",
      "     |          Array of parameters at which to evaluate the loglikelihood\n",
      "     |          function.\n",
      "     |      transformed : bool, optional\n",
      "     |          Whether or not `params` is already transformed. Default is True.\n",
      "     |      return_ssm : bool,optional\n",
      "     |          Whether or not to return only the state space output or a full\n",
      "     |          results object. Default is to return a full results object.\n",
      "     |      cov_type : str, optional\n",
      "     |          See `MLEResults.fit` for a description of covariance matrix types\n",
      "     |          for results object.\n",
      "     |      cov_kwds : dict or None, optional\n",
      "     |          See `MLEResults.get_robustcov_results` for a description required\n",
      "     |          keywords for alternative covariance estimators\n",
      "     |      **kwargs\n",
      "     |          Additional keyword arguments to pass to the Kalman filter. See\n",
      "     |          `KalmanFilter.filter` for more details.\n",
      "     |  \n",
      "     |  transform_jacobian(self, unconstrained, approx_centered=False)\n",
      "     |      Jacobian matrix for the parameter transformation function\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      unconstrained : array_like\n",
      "     |          Array of unconstrained parameters used by the optimizer.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      jacobian : ndarray\n",
      "     |          Jacobian matrix of the transformation, evaluated at `unconstrained`\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      transform_params\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      This is a numerical approximation using finite differences. Note that\n",
      "     |      in general complex step methods cannot be used because it is not\n",
      "     |      guaranteed that the `transform_params` method is a real function (e.g.\n",
      "     |      if Cholesky decomposition is used).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from statsmodels.tsa.statespace.mlemodel.MLEModel:\n",
      "     |  \n",
      "     |  from_formula(formula, data, subset=None) from builtins.type\n",
      "     |      Not implemented for state space models\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from statsmodels.tsa.statespace.mlemodel.MLEModel:\n",
      "     |  \n",
      "     |  state_names\n",
      "     |      (list of str) List of human readable names for unobserved states.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from statsmodels.tsa.statespace.mlemodel.MLEModel:\n",
      "     |  \n",
      "     |  initial_variance\n",
      "     |  \n",
      "     |  initialization\n",
      "     |  \n",
      "     |  loglikelihood_burn\n",
      "     |  \n",
      "     |  tolerance\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from statsmodels.tsa.base.tsa_model.TimeSeriesModel:\n",
      "     |  \n",
      "     |  exog_names\n",
      "     |      The names of the exogenous variables.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from statsmodels.base.model.LikelihoodModel:\n",
      "     |  \n",
      "     |  information(self, params)\n",
      "     |      Fisher information matrix of model.\n",
      "     |      \n",
      "     |      Returns -1 * Hessian of the log-likelihood evaluated at params.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : ndarray\n",
      "     |          The model parameters.\n",
      "     |  \n",
      "     |  initialize(self)\n",
      "     |      Initialize (possibly re-initialize) a Model instance.\n",
      "     |      \n",
      "     |      For example, if the the design matrix of a linear model changes then\n",
      "     |      initialized can be used to recompute values using the modified design\n",
      "     |      matrix.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from statsmodels.base.model.Model:\n",
      "     |  \n",
      "     |  predict(self, params, exog=None, *args, **kwargs)\n",
      "     |      After a model has been fit predict returns the fitted values.\n",
      "     |      \n",
      "     |      This is a placeholder intended to be overwritten by individual models.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from statsmodels.base.model.Model:\n",
      "     |  \n",
      "     |  endog_names\n",
      "     |      Names of endogenous variables.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from statsmodels.base.model.Model:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class VECM(statsmodels.tsa.base.tsa_model.TimeSeriesModel)\n",
      "     |  VECM(endog, exog=None, exog_coint=None, dates=None, freq=None, missing='none', k_ar_diff=1, coint_rank=1, deterministic='n', seasons=0, first_season=0)\n",
      "     |  \n",
      "     |  Class representing a Vector Error Correction Model (VECM).\n",
      "     |  \n",
      "     |  A VECM(:math:`k_{ar}-1`) has the following form\n",
      "     |  \n",
      "     |  .. math:: \\Delta y_t = \\Pi y_{t-1} + \\Gamma_1 \\Delta y_{t-1} + \\ldots + \\Gamma_{k_{ar}-1} \\Delta y_{t-k_{ar}+1} + u_t\n",
      "     |  \n",
      "     |  where\n",
      "     |  \n",
      "     |  .. math:: \\Pi = \\alpha \\beta'\n",
      "     |  \n",
      "     |  as described in chapter 7 of [1]_.\n",
      "     |  \n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  endog : array_like (nobs_tot x neqs)\n",
      "     |      2-d endogenous response variable.\n",
      "     |  exog : ndarray (nobs_tot x neqs) or None\n",
      "     |      Deterministic terms outside the cointegration relation.\n",
      "     |  exog_coint : ndarray (nobs_tot x neqs) or None\n",
      "     |      Deterministic terms inside the cointegration relation.\n",
      "     |  dates : array_like of datetime, optional\n",
      "     |      See :class:`statsmodels.tsa.base.tsa_model.TimeSeriesModel` for more\n",
      "     |      information.\n",
      "     |  freq : str, optional\n",
      "     |      See :class:`statsmodels.tsa.base.tsa_model.TimeSeriesModel` for more\n",
      "     |      information.\n",
      "     |  missing : str, optional\n",
      "     |      See :class:`statsmodels.base.model.Model` for more information.\n",
      "     |  k_ar_diff : int\n",
      "     |      Number of lagged differences in the model. Equals :math:`k_{ar} - 1` in\n",
      "     |      the formula above.\n",
      "     |  coint_rank : int\n",
      "     |      Cointegration rank, equals the rank of the matrix :math:`\\Pi` and the\n",
      "     |      number of columns of :math:`\\alpha` and :math:`\\beta`.\n",
      "     |  deterministic : str {``\"n\"``, ``\"co\"``, ``\"ci\"``, ``\"lo\"``, ``\"li\"``}\n",
      "     |      * ``\"n\"`` - no deterministic terms\n",
      "     |      * ``\"co\"`` - constant outside the cointegration relation\n",
      "     |      * ``\"ci\"`` - constant within the cointegration relation\n",
      "     |      * ``\"lo\"`` - linear trend outside the cointegration relation\n",
      "     |      * ``\"li\"`` - linear trend within the cointegration relation\n",
      "     |  \n",
      "     |      Combinations of these are possible (e.g. ``\"cili\"`` or ``\"colo\"`` for\n",
      "     |      linear trend with intercept). When using a constant term you have to\n",
      "     |      choose whether you want to restrict it to the cointegration relation\n",
      "     |      (i.e. ``\"ci\"``) or leave it unrestricted (i.e. ``\"co\"``). Do not use\n",
      "     |      both ``\"ci\"`` and ``\"co\"``. The same applies for ``\"li\"`` and ``\"lo\"``\n",
      "     |      when using a linear term. See the Notes-section for more information.\n",
      "     |  seasons : int, default: 0\n",
      "     |      Number of periods in a seasonal cycle. 0 means no seasons.\n",
      "     |  first_season : int, default: 0\n",
      "     |      Season of the first observation.\n",
      "     |  \n",
      "     |  Notes\n",
      "     |  -----\n",
      "     |  A VECM(:math:`k_{ar} - 1`) with deterministic terms has the form\n",
      "     |  \n",
      "     |  .. math::\n",
      "     |  \n",
      "     |     \\Delta y_t = \\alpha \\begin{pmatrix}\\beta' & \\eta'\\end{pmatrix} \\begin{pmatrix}y_{t-1}\\\\D^{co}_{t-1}\\end{pmatrix} + \\Gamma_1 \\Delta y_{t-1} + \\dots + \\Gamma_{k_{ar}-1} \\Delta y_{t-k_{ar}+1} + C D_t + u_t.\n",
      "     |  \n",
      "     |  In :math:`D^{co}_{t-1}` we have the deterministic terms which are inside\n",
      "     |  the cointegration relation (or restricted to the cointegration relation).\n",
      "     |  :math:`\\eta` is the corresponding estimator. To pass a deterministic term\n",
      "     |  inside the cointegration relation, we can use the `exog_coint` argument.\n",
      "     |  For the two special cases of an intercept and a linear trend there exists\n",
      "     |  a simpler way to declare these terms: we can pass ``\"ci\"`` and ``\"li\"``\n",
      "     |  respectively to the `deterministic` argument. So for an intercept inside\n",
      "     |  the cointegration relation we can either pass ``\"ci\"`` as `deterministic`\n",
      "     |  or `np.ones(len(data))` as `exog_coint` if `data` is passed as the\n",
      "     |  `endog` argument. This ensures that :math:`D_{t-1}^{co} = 1` for all\n",
      "     |  :math:`t`.\n",
      "     |  \n",
      "     |  We can also use deterministic terms outside the cointegration relation.\n",
      "     |  These are defined in :math:`D_t` in the formula above with the\n",
      "     |  corresponding estimators in the matrix :math:`C`. We specify such terms by\n",
      "     |  passing them to the `exog` argument. For an intercept and/or linear trend\n",
      "     |  we again have the possibility to use `deterministic` alternatively. For\n",
      "     |  an intercept we pass ``\"co\"`` and for a linear trend we pass ``\"lo\"`` where\n",
      "     |  the `o` stands for `outside`.\n",
      "     |  \n",
      "     |  The following table shows the five cases considered in [2]_. The last\n",
      "     |  column indicates which string to pass to the `deterministic` argument for\n",
      "     |  each of these cases.\n",
      "     |  \n",
      "     |  ====  ===============================  ===================================  =============\n",
      "     |  Case  Intercept                        Slope of the linear trend            `deterministic`\n",
      "     |  ====  ===============================  ===================================  =============\n",
      "     |  I     0                                0                                    ``\"n\"``\n",
      "     |  II    :math:`- \\alpha \\beta^T \\mu`     0                                    ``\"ci\"``\n",
      "     |  III   :math:`\\neq 0`                   0                                    ``\"co\"``\n",
      "     |  IV    :math:`\\neq 0`                   :math:`- \\alpha \\beta^T \\gamma`      ``\"coli\"``\n",
      "     |  V     :math:`\\neq 0`                   :math:`\\neq 0`                       ``\"colo\"``\n",
      "     |  ====  ===============================  ===================================  =============\n",
      "     |  \n",
      "     |  References\n",
      "     |  ----------\n",
      "     |  .. [1] Ltkepohl, H. 2005. *New Introduction to Multiple Time Series Analysis*. Springer.\n",
      "     |  \n",
      "     |  .. [2] Johansen, S. 1995. *Likelihood-Based Inference in Cointegrated *\n",
      "     |         *Vector Autoregressive Models*. Oxford University Press.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      VECM\n",
      "     |      statsmodels.tsa.base.tsa_model.TimeSeriesModel\n",
      "     |      statsmodels.base.model.LikelihoodModel\n",
      "     |      statsmodels.base.model.Model\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, endog, exog=None, exog_coint=None, dates=None, freq=None, missing='none', k_ar_diff=1, coint_rank=1, deterministic='n', seasons=0, first_season=0)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  fit(self, method='ml')\n",
      "     |      Estimates the parameters of a VECM.\n",
      "     |      \n",
      "     |      The estimation procedure is described on pp. 269-304 in [1]_.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      method : str {\"ml\"}, default: \"ml\"\n",
      "     |          Estimation method to use. \"ml\" stands for Maximum Likelihood.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      est : :class:`VECMResults`\n",
      "     |      \n",
      "     |      References\n",
      "     |      ----------\n",
      "     |      .. [1] Ltkepohl, H. 2005. *New Introduction to Multiple Time Series Analysis*. Springer.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from statsmodels.tsa.base.tsa_model.TimeSeriesModel:\n",
      "     |  \n",
      "     |  exog_names\n",
      "     |      The names of the exogenous variables.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from statsmodels.base.model.LikelihoodModel:\n",
      "     |  \n",
      "     |  hessian(self, params)\n",
      "     |      The Hessian matrix of the model.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : ndarray\n",
      "     |          The parameters to use when evaluating the Hessian.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      ndarray\n",
      "     |          The hessian evaluated at the parameters.\n",
      "     |  \n",
      "     |  information(self, params)\n",
      "     |      Fisher information matrix of model.\n",
      "     |      \n",
      "     |      Returns -1 * Hessian of the log-likelihood evaluated at params.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : ndarray\n",
      "     |          The model parameters.\n",
      "     |  \n",
      "     |  initialize(self)\n",
      "     |      Initialize (possibly re-initialize) a Model instance.\n",
      "     |      \n",
      "     |      For example, if the the design matrix of a linear model changes then\n",
      "     |      initialized can be used to recompute values using the modified design\n",
      "     |      matrix.\n",
      "     |  \n",
      "     |  loglike(self, params)\n",
      "     |      Log-likelihood of model.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : ndarray\n",
      "     |          The model parameters used to compute the log-likelihood.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Must be overridden by subclasses.\n",
      "     |  \n",
      "     |  score(self, params)\n",
      "     |      Score vector of model.\n",
      "     |      \n",
      "     |      The gradient of logL with respect to each parameter.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : ndarray\n",
      "     |          The parameters to use when evaluating the Hessian.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      ndarray\n",
      "     |          The score vector evaluated at the parameters.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from statsmodels.base.model.Model:\n",
      "     |  \n",
      "     |  predict(self, params, exog=None, *args, **kwargs)\n",
      "     |      After a model has been fit predict returns the fitted values.\n",
      "     |      \n",
      "     |      This is a placeholder intended to be overwritten by individual models.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from statsmodels.base.model.Model:\n",
      "     |  \n",
      "     |  from_formula(formula, data, subset=None, drop_cols=None, *args, **kwargs) from builtins.type\n",
      "     |      Create a Model from a formula and dataframe.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      formula : str or generic Formula object\n",
      "     |          The formula specifying the model.\n",
      "     |      data : array_like\n",
      "     |          The data for the model. See Notes.\n",
      "     |      subset : array_like\n",
      "     |          An array-like object of booleans, integers, or index values that\n",
      "     |          indicate the subset of df to use in the model. Assumes df is a\n",
      "     |          `pandas.DataFrame`.\n",
      "     |      drop_cols : array_like\n",
      "     |          Columns to drop from the design matrix.  Cannot be used to\n",
      "     |          drop terms involving categoricals.\n",
      "     |      *args\n",
      "     |          Additional positional argument that are passed to the model.\n",
      "     |      **kwargs\n",
      "     |          These are passed to the model with one exception. The\n",
      "     |          ``eval_env`` keyword is passed to patsy. It can be either a\n",
      "     |          :class:`patsy:patsy.EvalEnvironment` object or an integer\n",
      "     |          indicating the depth of the namespace to use. For example, the\n",
      "     |          default ``eval_env=0`` uses the calling namespace. If you wish\n",
      "     |          to use a \"clean\" environment set ``eval_env=-1``.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      model\n",
      "     |          The model instance.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      data must define __getitem__ with the keys in the formula terms\n",
      "     |      args and kwargs are passed on to the model instantiation. E.g.,\n",
      "     |      a numpy structured or rec array, a dictionary, or a pandas DataFrame.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from statsmodels.base.model.Model:\n",
      "     |  \n",
      "     |  endog_names\n",
      "     |      Names of endogenous variables.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from statsmodels.base.model.Model:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "\n",
      "FUNCTIONS\n",
      "    acf(x, adjusted=False, nlags=None, qstat=False, fft=True, alpha=None, bartlett_confint=True, missing='none')\n",
      "        Calculate the autocorrelation function.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        x : array_like\n",
      "           The time series data.\n",
      "        adjusted : bool, default False\n",
      "           If True, then denominators for autocovariance are n-k, otherwise n.\n",
      "        nlags : int, optional\n",
      "            Number of lags to return autocorrelation for. If not provided,\n",
      "            uses min(10 * np.log10(nobs), nobs - 1). The returned value\n",
      "            includes lag 0 (ie., 1) so size of the acf vector is (nlags + 1,).\n",
      "        qstat : bool, default False\n",
      "            If True, returns the Ljung-Box q statistic for each autocorrelation\n",
      "            coefficient.  See q_stat for more information.\n",
      "        fft : bool, default True\n",
      "            If True, computes the ACF via FFT.\n",
      "        alpha : scalar, default None\n",
      "            If a number is given, the confidence intervals for the given level are\n",
      "            returned. For instance if alpha=.05, 95 % confidence intervals are\n",
      "            returned where the standard deviation is computed according to\n",
      "            Bartlett\"s formula.\n",
      "        bartlett_confint : bool, default True\n",
      "            Confidence intervals for ACF values are generally placed at 2\n",
      "            standard errors around r_k. The formula used for standard error\n",
      "            depends upon the situation. If the autocorrelations are being used\n",
      "            to test for randomness of residuals as part of the ARIMA routine,\n",
      "            the standard errors are determined assuming the residuals are white\n",
      "            noise. The approximate formula for any lag is that standard error\n",
      "            of each r_k = 1/sqrt(N). See section 9.4 of [2] for more details on\n",
      "            the 1/sqrt(N) result. For more elementary discussion, see section 5.3.2\n",
      "            in [3].\n",
      "            For the ACF of raw data, the standard error at a lag k is\n",
      "            found as if the right model was an MA(k-1). This allows the possible\n",
      "            interpretation that if all autocorrelations past a certain lag are\n",
      "            within the limits, the model might be an MA of order defined by the\n",
      "            last significant autocorrelation. In this case, a moving average\n",
      "            model is assumed for the data and the standard errors for the\n",
      "            confidence intervals should be generated using Bartlett's formula.\n",
      "            For more details on Bartlett formula result, see section 7.2 in [2].\n",
      "        missing : str, default \"none\"\n",
      "            A string in [\"none\", \"raise\", \"conservative\", \"drop\"] specifying how\n",
      "            the NaNs are to be treated. \"none\" performs no checks. \"raise\" raises\n",
      "            an exception if NaN values are found. \"drop\" removes the missing\n",
      "            observations and then estimates the autocovariances treating the\n",
      "            non-missing as contiguous. \"conservative\" computes the autocovariance\n",
      "            using nan-ops so that nans are removed when computing the mean\n",
      "            and cross-products that are used to estimate the autocovariance.\n",
      "            When using \"conservative\", n is set to the number of non-missing\n",
      "            observations.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        acf : ndarray\n",
      "            The autocorrelation function for lags 0, 1, ..., nlags. Shape\n",
      "            (nlags+1,).\n",
      "        confint : ndarray, optional\n",
      "            Confidence intervals for the ACF at lags 0, 1, ..., nlags. Shape\n",
      "            (nlags + 1, 2). Returned if alpha is not None.\n",
      "        qstat : ndarray, optional\n",
      "            The Ljung-Box Q-Statistic for lags 1, 2, ..., nlags (excludes lag\n",
      "            zero). Returned if q_stat is True.\n",
      "        pvalues : ndarray, optional\n",
      "            The p-values associated with the Q-statistics for lags 1, 2, ...,\n",
      "            nlags (excludes lag zero). Returned if q_stat is True.\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        The acf at lag 0 (ie., 1) is returned.\n",
      "        \n",
      "        For very long time series it is recommended to use fft convolution instead.\n",
      "        When fft is False uses a simple, direct estimator of the autocovariances\n",
      "        that only computes the first nlag + 1 values. This can be much faster when\n",
      "        the time series is long and only a small number of autocovariances are\n",
      "        needed.\n",
      "        \n",
      "        If adjusted is true, the denominator for the autocovariance is adjusted\n",
      "        for the loss of data.\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        .. [1] Parzen, E., 1963. On spectral analysis with missing observations\n",
      "           and amplitude modulation. Sankhya: The Indian Journal of\n",
      "           Statistics, Series A, pp.383-392.\n",
      "        .. [2] Brockwell and Davis, 1987. Time Series Theory and Methods\n",
      "        .. [3] Brockwell and Davis, 2010. Introduction to Time Series and\n",
      "           Forecasting, 2nd edition.\n",
      "    \n",
      "    acovf(x, adjusted=False, demean=True, fft=True, missing='none', nlag=None)\n",
      "        Estimate autocovariances.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        x : array_like\n",
      "            Time series data. Must be 1d.\n",
      "        adjusted : bool, default False\n",
      "            If True, then denominators is n-k, otherwise n.\n",
      "        demean : bool, default True\n",
      "            If True, then subtract the mean x from each element of x.\n",
      "        fft : bool, default True\n",
      "            If True, use FFT convolution.  This method should be preferred\n",
      "            for long time series.\n",
      "        missing : str, default \"none\"\n",
      "            A string in [\"none\", \"raise\", \"conservative\", \"drop\"] specifying how\n",
      "            the NaNs are to be treated. \"none\" performs no checks. \"raise\" raises\n",
      "            an exception if NaN values are found. \"drop\" removes the missing\n",
      "            observations and then estimates the autocovariances treating the\n",
      "            non-missing as contiguous. \"conservative\" computes the autocovariance\n",
      "            using nan-ops so that nans are removed when computing the mean\n",
      "            and cross-products that are used to estimate the autocovariance.\n",
      "            When using \"conservative\", n is set to the number of non-missing\n",
      "            observations.\n",
      "        nlag : {int, None}, default None\n",
      "            Limit the number of autocovariances returned.  Size of returned\n",
      "            array is nlag + 1.  Setting nlag when fft is False uses a simple,\n",
      "            direct estimator of the autocovariances that only computes the first\n",
      "            nlag + 1 values. This can be much faster when the time series is long\n",
      "            and only a small number of autocovariances are needed.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        ndarray\n",
      "            The estimated autocovariances.\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        .. [1] Parzen, E., 1963. On spectral analysis with missing observations\n",
      "               and amplitude modulation. Sankhya: The Indian Journal of\n",
      "               Statistics, Series A, pp.383-392.\n",
      "    \n",
      "    add_lag(x, col=None, lags=1, drop=False, insert=True)\n",
      "        Returns an array with lags included given an array.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        x : array_like\n",
      "            An array or NumPy ndarray subclass. Can be either a 1d or 2d array with\n",
      "            observations in columns.\n",
      "        col : int or None\n",
      "            `col` can be an int of the zero-based column index. If it's a\n",
      "            1d array `col` can be None.\n",
      "        lags : int\n",
      "            The number of lags desired.\n",
      "        drop : bool\n",
      "            Whether to keep the contemporaneous variable for the data.\n",
      "        insert : bool or int\n",
      "            If True, inserts the lagged values after `col`. If False, appends\n",
      "            the data. If int inserts the lags at int.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        array : ndarray\n",
      "            Array with lags\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        \n",
      "        >>> import statsmodels.api as sm\n",
      "        >>> data = sm.datasets.macrodata.load()\n",
      "        >>> data = data.data[['year','quarter','realgdp','cpi']]\n",
      "        >>> data = sm.tsa.add_lag(data, 'realgdp', lags=2)\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        Trims the array both forward and backward, so that the array returned\n",
      "        so that the length of the returned array is len(`X`) - lags. The lags are\n",
      "        returned in increasing order, ie., t-1,t-2,...,t-lags\n",
      "    \n",
      "    add_trend(x, trend='c', prepend=False, has_constant='skip')\n",
      "        Add a trend and/or constant to an array.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        x : array_like\n",
      "            Original array of data.\n",
      "        trend : str {'n', 'c', 't', 'ct', 'ctt'}\n",
      "            The trend to add.\n",
      "        \n",
      "            * 'n' add no trend.\n",
      "            * 'c' add constant only.\n",
      "            * 't' add trend only.\n",
      "            * 'ct' add constant and linear trend.\n",
      "            * 'ctt' add constant and linear and quadratic trend.\n",
      "        prepend : bool\n",
      "            If True, prepends the new data to the columns of X.\n",
      "        has_constant : str {'raise', 'add', 'skip'}\n",
      "            Controls what happens when trend is 'c' and a constant column already\n",
      "            exists in x. 'raise' will raise an error. 'add' will add a column of\n",
      "            1s. 'skip' will return the data without change. 'skip' is the default.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        array_like\n",
      "            The original data with the additional trend columns.  If x is a\n",
      "            pandas Series or DataFrame, then the trend column names are 'const',\n",
      "            'trend' and 'trend_squared'.\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        statsmodels.tools.tools.add_constant\n",
      "            Add a constant column to an array.\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        Returns columns as ['ctt','ct','c'] whenever applicable. There is currently\n",
      "        no checking for an existing trend.\n",
      "    \n",
      "    adfuller(x, maxlag: 'int | None' = None, regression='c', autolag='AIC', store=False, regresults=False)\n",
      "        Augmented Dickey-Fuller unit root test.\n",
      "        \n",
      "        The Augmented Dickey-Fuller test can be used to test for a unit root in a\n",
      "        univariate process in the presence of serial correlation.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        x : array_like, 1d\n",
      "            The data series to test.\n",
      "        maxlag : {None, int}\n",
      "            Maximum lag which is included in test, default value of\n",
      "            12*(nobs/100)^{1/4} is used when ``None``.\n",
      "        regression : {\"c\",\"ct\",\"ctt\",\"n\"}\n",
      "            Constant and trend order to include in regression.\n",
      "        \n",
      "            * \"c\" : constant only (default).\n",
      "            * \"ct\" : constant and trend.\n",
      "            * \"ctt\" : constant, and linear and quadratic trend.\n",
      "            * \"n\" : no constant, no trend.\n",
      "        \n",
      "        autolag : {\"AIC\", \"BIC\", \"t-stat\", None}\n",
      "            Method to use when automatically determining the lag length among the\n",
      "            values 0, 1, ..., maxlag.\n",
      "        \n",
      "            * If \"AIC\" (default) or \"BIC\", then the number of lags is chosen\n",
      "              to minimize the corresponding information criterion.\n",
      "            * \"t-stat\" based choice of maxlag.  Starts with maxlag and drops a\n",
      "              lag until the t-statistic on the last lag length is significant\n",
      "              using a 5%-sized test.\n",
      "            * If None, then the number of included lags is set to maxlag.\n",
      "        store : bool\n",
      "            If True, then a result instance is returned additionally to\n",
      "            the adf statistic. Default is False.\n",
      "        regresults : bool, optional\n",
      "            If True, the full regression results are returned. Default is False.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        adf : float\n",
      "            The test statistic.\n",
      "        pvalue : float\n",
      "            MacKinnon's approximate p-value based on MacKinnon (1994, 2010).\n",
      "        usedlag : int\n",
      "            The number of lags used.\n",
      "        nobs : int\n",
      "            The number of observations used for the ADF regression and calculation\n",
      "            of the critical values.\n",
      "        critical values : dict\n",
      "            Critical values for the test statistic at the 1 %, 5 %, and 10 %\n",
      "            levels. Based on MacKinnon (2010).\n",
      "        icbest : float\n",
      "            The maximized information criterion if autolag is not None.\n",
      "        resstore : ResultStore, optional\n",
      "            A dummy class with results attached as attributes.\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        The null hypothesis of the Augmented Dickey-Fuller is that there is a unit\n",
      "        root, with the alternative that there is no unit root. If the pvalue is\n",
      "        above a critical size, then we cannot reject that there is a unit root.\n",
      "        \n",
      "        The p-values are obtained through regression surface approximation from\n",
      "        MacKinnon 1994, but using the updated 2010 tables. If the p-value is close\n",
      "        to significant, then the critical values should be used to judge whether\n",
      "        to reject the null.\n",
      "        \n",
      "        The autolag option and maxlag for it are described in Greene.\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        .. [1] W. Green.  \"Econometric Analysis,\" 5th ed., Pearson, 2003.\n",
      "        \n",
      "        .. [2] Hamilton, J.D.  \"Time Series Analysis\".  Princeton, 1994.\n",
      "        \n",
      "        .. [3] MacKinnon, J.G. 1994.  \"Approximate asymptotic distribution functions for\n",
      "            unit-root and cointegration tests.  `Journal of Business and Economic\n",
      "            Statistics` 12, 167-76.\n",
      "        \n",
      "        .. [4] MacKinnon, J.G. 2010. \"Critical Values for Cointegration Tests.\"  Queen\"s\n",
      "            University, Dept of Economics, Working Papers.  Available at\n",
      "            http://ideas.repec.org/p/qed/wpaper/1227.html\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        See example notebook\n",
      "    \n",
      "    ardl_select_order(endog: 'Union[Sequence[float], pd.Series, _ArrayLike2D]', maxlag: 'int', exog: '_ArrayLike2D', maxorder: 'Union[int, Dict[Hashable, int]]', trend: \"Literal[('n', 'c', 'ct', 'ctt')]\" = 'c', *, fixed: 'Optional[_ArrayLike2D]' = None, causal: 'bool' = False, ic: \"Literal[('aic', 'bic')]\" = 'bic', glob: 'bool' = False, seasonal: 'bool' = False, deterministic: 'Optional[DeterministicProcess]' = None, hold_back: 'Optional[int]' = None, period: 'Optional[int]' = None, missing: \"Literal[('none', 'raise')]\" = 'none') -> 'ARDLOrderSelectionResults'\n",
      "        ARDL order selection\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        endog : array_like\n",
      "            A 1-d endogenous response variable. The dependent variable.\n",
      "        maxlag : int\n",
      "            The maximum lag to consider for the endogenous variable.\n",
      "        exog : array_like\n",
      "            Exogenous variables to include in the model. Either a DataFrame or\n",
      "            an 2-d array-like structure that can be converted to a NumPy array.\n",
      "        maxorder : {int, dict}\n",
      "            If int, sets a common max lag length for all exog variables. If\n",
      "            a dict, then sets individual lag length. They keys are column names\n",
      "            if exog is a DataFrame or column indices otherwise.\n",
      "        trend : {'n', 'c', 't', 'ct'}, optional\n",
      "            The trend to include in the model:\n",
      "        \n",
      "            * 'n' - No trend.\n",
      "            * 'c' - Constant only.\n",
      "            * 't' - Time trend only.\n",
      "            * 'ct' - Constant and time trend.\n",
      "        \n",
      "            The default is 'c'.\n",
      "        fixed : array_like\n",
      "            Additional fixed regressors that are not lagged.\n",
      "        causal : bool, optional\n",
      "            Whether to include lag 0 of exog variables.  If True, only includes\n",
      "            lags 1, 2, ...\n",
      "        ic : {\"aic\", \"bic\", \"hqic\"}\n",
      "            The information criterion to use in model selection.\n",
      "        glob : bool\n",
      "            Whether to consider all possible submodels of the largest model\n",
      "            or only if smaller order lags must be included if larger order\n",
      "            lags are.  If ``True``, the number of model considered is of the\n",
      "            order 2**(maxlag + k * maxorder) assuming maxorder is an int. This\n",
      "            can be very large unless k and maxorder are bot relatively small.\n",
      "            If False, the number of model considered is of the order\n",
      "            maxlag*maxorder**k which may also be substantial when k and maxorder\n",
      "            are large.\n",
      "        seasonal : bool, optional\n",
      "            Flag indicating whether to include seasonal dummies in the model. If\n",
      "            seasonal is True and trend includes 'c', then the first period\n",
      "            is excluded from the seasonal terms.\n",
      "        deterministic : DeterministicProcess, optional\n",
      "            A deterministic process.  If provided, trend and seasonal are ignored.\n",
      "            A warning is raised if trend is not \"n\" and seasonal is not False.\n",
      "        hold_back : {None, int}, optional\n",
      "            Initial observations to exclude from the estimation sample.  If None,\n",
      "            then hold_back is equal to the maximum lag in the model.  Set to a\n",
      "            non-zero value to produce comparable models with different lag\n",
      "            length.  For example, to compare the fit of a model with lags=3 and\n",
      "            lags=1, set hold_back=3 which ensures that both models are estimated\n",
      "            using observations 3,...,nobs. hold_back must be >= the maximum lag in\n",
      "            the model.\n",
      "        period : {None, int}, optional\n",
      "            The period of the data. Only used if seasonal is True. This parameter\n",
      "            can be omitted if using a pandas object for endog that contains a\n",
      "            recognized frequency.\n",
      "        missing : {\"none\", \"drop\", \"raise\"}, optional\n",
      "            Available options are 'none', 'drop', and 'raise'. If 'none', no nan\n",
      "            checking is done. If 'drop', any observations with nans are dropped.\n",
      "            If 'raise', an error is raised. Default is 'none'.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        ARDLSelectionResults\n",
      "            A results holder containing the selected model and the complete set\n",
      "            of information criteria for all models fit.\n",
      "    \n",
      "    arma_generate_sample(ar, ma, nsample, scale=1, distrvs=None, axis=0, burnin=0)\n",
      "        Simulate data from an ARMA.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        ar : array_like\n",
      "            The coefficient for autoregressive lag polynomial, including zero lag.\n",
      "        ma : array_like\n",
      "            The coefficient for moving-average lag polynomial, including zero lag.\n",
      "        nsample : int or tuple of ints\n",
      "            If nsample is an integer, then this creates a 1d timeseries of\n",
      "            length size. If nsample is a tuple, creates a len(nsample)\n",
      "            dimensional time series where time is indexed along the input\n",
      "            variable ``axis``. All series are unless ``distrvs`` generates\n",
      "            dependent data.\n",
      "        scale : float\n",
      "            The standard deviation of noise.\n",
      "        distrvs : function, random number generator\n",
      "            A function that generates the random numbers, and takes ``size``\n",
      "            as argument. The default is np.random.standard_normal.\n",
      "        axis : int\n",
      "            See nsample for details.\n",
      "        burnin : int\n",
      "            Number of observation at the beginning of the sample to drop.\n",
      "            Used to reduce dependence on initial values.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        ndarray\n",
      "            Random sample(s) from an ARMA process.\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        As mentioned above, both the AR and MA components should include the\n",
      "        coefficient on the zero-lag. This is typically 1. Further, due to the\n",
      "        conventions used in signal processing used in signal.lfilter vs.\n",
      "        conventions in statistics for ARMA processes, the AR parameters should\n",
      "        have the opposite sign of what you might expect. See the examples below.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> import numpy as np\n",
      "        >>> np.random.seed(12345)\n",
      "        >>> arparams = np.array([.75, -.25])\n",
      "        >>> maparams = np.array([.65, .35])\n",
      "        >>> ar = np.r_[1, -arparams] # add zero-lag and negate\n",
      "        >>> ma = np.r_[1, maparams] # add zero-lag\n",
      "        >>> y = sm.tsa.arma_generate_sample(ar, ma, 250)\n",
      "        >>> model = sm.tsa.ARIMA(y, (2, 0, 2), trend='n').fit(disp=0)\n",
      "        >>> model.params\n",
      "        array([ 0.79044189, -0.23140636,  0.70072904,  0.40608028])\n",
      "    \n",
      "    arma_order_select_ic(y, max_ar=4, max_ma=2, ic='bic', trend='c', model_kw=None, fit_kw=None)\n",
      "        Compute information criteria for many ARMA models.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        y : array_like\n",
      "            Array of time-series data.\n",
      "        max_ar : int\n",
      "            Maximum number of AR lags to use. Default 4.\n",
      "        max_ma : int\n",
      "            Maximum number of MA lags to use. Default 2.\n",
      "        ic : str, list\n",
      "            Information criteria to report. Either a single string or a list\n",
      "            of different criteria is possible.\n",
      "        trend : str\n",
      "            The trend to use when fitting the ARMA models.\n",
      "        model_kw : dict\n",
      "            Keyword arguments to be passed to the ``ARMA`` model.\n",
      "        fit_kw : dict\n",
      "            Keyword arguments to be passed to ``ARMA.fit``.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        Bunch\n",
      "            Dict-like object with attribute access. Each ic is an attribute with a\n",
      "            DataFrame for the results. The AR order used is the row index. The ma\n",
      "            order used is the column index. The minimum orders are available as\n",
      "            ``ic_min_order``.\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        This method can be used to tentatively identify the order of an ARMA\n",
      "        process, provided that the time series is stationary and invertible. This\n",
      "        function computes the full exact MLE estimate of each model and can be,\n",
      "        therefore a little slow. An implementation using approximate estimates\n",
      "        will be provided in the future. In the meantime, consider passing\n",
      "        {method : \"css\"} to fit_kw.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        \n",
      "        >>> from statsmodels.tsa.arima_process import arma_generate_sample\n",
      "        >>> import statsmodels.api as sm\n",
      "        >>> import numpy as np\n",
      "        \n",
      "        >>> arparams = np.array([.75, -.25])\n",
      "        >>> maparams = np.array([.65, .35])\n",
      "        >>> arparams = np.r_[1, -arparams]\n",
      "        >>> maparam = np.r_[1, maparams]\n",
      "        >>> nobs = 250\n",
      "        >>> np.random.seed(2014)\n",
      "        >>> y = arma_generate_sample(arparams, maparams, nobs)\n",
      "        >>> res = sm.tsa.arma_order_select_ic(y, ic=[\"aic\", \"bic\"], trend=\"n\")\n",
      "        >>> res.aic_min_order\n",
      "        >>> res.bic_min_order\n",
      "    \n",
      "    bds(x, max_dim=2, epsilon=None, distance=1.5)\n",
      "        BDS Test Statistic for Independence of a Time Series\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        x : ndarray\n",
      "            Observations of time series for which bds statistics is calculated.\n",
      "        max_dim : int\n",
      "            The maximum embedding dimension.\n",
      "        epsilon : {float, None}, optional\n",
      "            The threshold distance to use in calculating the correlation sum.\n",
      "        distance : float, optional\n",
      "            Specifies the distance multiplier to use when computing the test\n",
      "            statistic if epsilon is omitted.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        bds_stat : float\n",
      "            The BDS statistic.\n",
      "        pvalue : float\n",
      "            The p-values associated with the BDS statistic.\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        The null hypothesis of the test statistic is for an independent and\n",
      "        identically distributed (i.i.d.) time series, and an unspecified\n",
      "        alternative hypothesis.\n",
      "        \n",
      "        This test is often used as a residual diagnostic.\n",
      "        \n",
      "        The calculation involves matrices of size (nobs, nobs), so this test\n",
      "        will not work with very long datasets.\n",
      "        \n",
      "        Implementation conditions on the first m-1 initial values, which are\n",
      "        required to calculate the m-histories:\n",
      "        x_t^m = (x_t, x_{t-1}, ... x_{t-(m-1)})\n",
      "    \n",
      "    breakvar_heteroskedasticity_test(resid, subset_length=0.3333333333333333, alternative='two-sided', use_f=True)\n",
      "        Test for heteroskedasticity of residuals\n",
      "        \n",
      "        Tests whether the sum-of-squares in the first subset of the sample is\n",
      "        significantly different than the sum-of-squares in the last subset\n",
      "        of the sample. Analogous to a Goldfeld-Quandt test. The null hypothesis\n",
      "        is of no heteroskedasticity.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        resid : array_like\n",
      "            Residuals of a time series model.\n",
      "            The shape is 1d (nobs,) or 2d (nobs, nvars).\n",
      "        subset_length : {int, float}\n",
      "            Length of the subsets to test (h in Notes below).\n",
      "            If a float in 0 < subset_length < 1, it is interpreted as fraction.\n",
      "            Default is 1/3.\n",
      "        alternative : str, 'increasing', 'decreasing' or 'two-sided'\n",
      "            This specifies the alternative for the p-value calculation. Default\n",
      "            is two-sided.\n",
      "        use_f : bool, optional\n",
      "            Whether or not to compare against the asymptotic distribution\n",
      "            (chi-squared) or the approximate small-sample distribution (F).\n",
      "            Default is True (i.e. default is to compare against an F\n",
      "            distribution).\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        test_statistic : {float, ndarray}\n",
      "            Test statistic(s) H(h).\n",
      "        p_value : {float, ndarray}\n",
      "            p-value(s) of test statistic(s).\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        The null hypothesis is of no heteroskedasticity. That means different\n",
      "        things depending on which alternative is selected:\n",
      "        \n",
      "        - Increasing: Null hypothesis is that the variance is not increasing\n",
      "            throughout the sample; that the sum-of-squares in the later\n",
      "            subsample is *not* greater than the sum-of-squares in the earlier\n",
      "            subsample.\n",
      "        - Decreasing: Null hypothesis is that the variance is not decreasing\n",
      "            throughout the sample; that the sum-of-squares in the earlier\n",
      "            subsample is *not* greater than the sum-of-squares in the later\n",
      "            subsample.\n",
      "        - Two-sided: Null hypothesis is that the variance is not changing\n",
      "            throughout the sample. Both that the sum-of-squares in the earlier\n",
      "            subsample is not greater than the sum-of-squares in the later\n",
      "            subsample *and* that the sum-of-squares in the later subsample is\n",
      "            not greater than the sum-of-squares in the earlier subsample.\n",
      "        \n",
      "        For :math:`h = [T/3]`, the test statistic is:\n",
      "        \n",
      "        .. math::\n",
      "        \n",
      "            H(h) = \\sum_{t=T-h+1}^T  \\tilde v_t^2\n",
      "            \\Bigg / \\sum_{t=1}^{h} \\tilde v_t^2\n",
      "        \n",
      "        This statistic can be tested against an :math:`F(h,h)` distribution.\n",
      "        Alternatively, :math:`h H(h)` is asymptotically distributed according\n",
      "        to :math:`\\chi_h^2`; this second test can be applied by passing\n",
      "        `use_f=False` as an argument.\n",
      "        \n",
      "        See section 5.4 of [1]_ for the above formula and discussion, as well\n",
      "        as additional details.\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        .. [1] Harvey, Andrew C. 1990. *Forecasting, Structural Time Series*\n",
      "                *Models and the Kalman Filter.* Cambridge University Press.\n",
      "    \n",
      "    ccf(x, y, adjusted=True, fft=True)\n",
      "        The cross-correlation function.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        x, y : array_like\n",
      "            The time series data to use in the calculation.\n",
      "        adjusted : bool\n",
      "            If True, then denominators for cross-correlation is n-k, otherwise n.\n",
      "        fft : bool, default True\n",
      "            If True, use FFT convolution.  This method should be preferred\n",
      "            for long time series.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        ndarray\n",
      "            The cross-correlation function of x and y.\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        If adjusted is true, the denominator for the autocovariance is adjusted.\n",
      "    \n",
      "    ccovf(x, y, adjusted=True, demean=True, fft=True)\n",
      "        Calculate the crosscovariance between two series.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        x, y : array_like\n",
      "           The time series data to use in the calculation.\n",
      "        adjusted : bool, optional\n",
      "           If True, then denominators for crosscovariance is n-k, otherwise n.\n",
      "        demean : bool, optional\n",
      "            Flag indicating whether to demean x and y.\n",
      "        fft : bool, default True\n",
      "            If True, use FFT convolution.  This method should be preferred\n",
      "            for long time series.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        ndarray\n",
      "            The estimated crosscovariance function.\n",
      "    \n",
      "    coint(y0, y1, trend='c', method='aeg', maxlag=None, autolag: 'str | None' = 'aic', return_results=None)\n",
      "        Test for no-cointegration of a univariate equation.\n",
      "        \n",
      "        The null hypothesis is no cointegration. Variables in y0 and y1 are\n",
      "        assumed to be integrated of order 1, I(1).\n",
      "        \n",
      "        This uses the augmented Engle-Granger two-step cointegration test.\n",
      "        Constant or trend is included in 1st stage regression, i.e. in\n",
      "        cointegrating equation.\n",
      "        \n",
      "        **Warning:** The autolag default has changed compared to statsmodels 0.8.\n",
      "        In 0.8 autolag was always None, no the keyword is used and defaults to\n",
      "        \"aic\". Use `autolag=None` to avoid the lag search.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        y0 : array_like\n",
      "            The first element in cointegrated system. Must be 1-d.\n",
      "        y1 : array_like\n",
      "            The remaining elements in cointegrated system.\n",
      "        trend : str {\"c\", \"ct\"}\n",
      "            The trend term included in regression for cointegrating equation.\n",
      "        \n",
      "            * \"c\" : constant.\n",
      "            * \"ct\" : constant and linear trend.\n",
      "            * also available quadratic trend \"ctt\", and no constant \"n\".\n",
      "        \n",
      "        method : {\"aeg\"}\n",
      "            Only \"aeg\" (augmented Engle-Granger) is available.\n",
      "        maxlag : None or int\n",
      "            Argument for `adfuller`, largest or given number of lags.\n",
      "        autolag : str\n",
      "            Argument for `adfuller`, lag selection criterion.\n",
      "        \n",
      "            * If None, then maxlag lags are used without lag search.\n",
      "            * If \"AIC\" (default) or \"BIC\", then the number of lags is chosen\n",
      "              to minimize the corresponding information criterion.\n",
      "            * \"t-stat\" based choice of maxlag.  Starts with maxlag and drops a\n",
      "              lag until the t-statistic on the last lag length is significant\n",
      "              using a 5%-sized test.\n",
      "        return_results : bool\n",
      "            For future compatibility, currently only tuple available.\n",
      "            If True, then a results instance is returned. Otherwise, a tuple\n",
      "            with the test outcome is returned. Set `return_results=False` to\n",
      "            avoid future changes in return.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        coint_t : float\n",
      "            The t-statistic of unit-root test on residuals.\n",
      "        pvalue : float\n",
      "            MacKinnon\"s approximate, asymptotic p-value based on MacKinnon (1994).\n",
      "        crit_value : dict\n",
      "            Critical values for the test statistic at the 1 %, 5 %, and 10 %\n",
      "            levels based on regression curve. This depends on the number of\n",
      "            observations.\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        The Null hypothesis is that there is no cointegration, the alternative\n",
      "        hypothesis is that there is cointegrating relationship. If the pvalue is\n",
      "        small, below a critical size, then we can reject the hypothesis that there\n",
      "        is no cointegrating relationship.\n",
      "        \n",
      "        P-values and critical values are obtained through regression surface\n",
      "        approximation from MacKinnon 1994 and 2010.\n",
      "        \n",
      "        If the two series are almost perfectly collinear, then computing the\n",
      "        test is numerically unstable. However, the two series will be cointegrated\n",
      "        under the maintained assumption that they are integrated. In this case\n",
      "        the t-statistic will be set to -inf and the pvalue to zero.\n",
      "        \n",
      "        TODO: We could handle gaps in data by dropping rows with nans in the\n",
      "        Auxiliary regressions. Not implemented yet, currently assumes no nans\n",
      "        and no gaps in time series.\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        .. [1] MacKinnon, J.G. 1994  \"Approximate Asymptotic Distribution Functions\n",
      "           for Unit-Root and Cointegration Tests.\" Journal of Business & Economics\n",
      "           Statistics, 12.2, 167-76.\n",
      "        .. [2] MacKinnon, J.G. 2010.  \"Critical Values for Cointegration Tests.\"\n",
      "           Queen\"s University, Dept of Economics Working Papers 1227.\n",
      "           http://ideas.repec.org/p/qed/wpaper/1227.html\n",
      "    \n",
      "    detrend(x, order=1, axis=0)\n",
      "        Detrend an array with a trend of given order along axis 0 or 1.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        x : array_like, 1d or 2d\n",
      "            Data, if 2d, then each row or column is independently detrended with\n",
      "            the same trendorder, but independent trend estimates.\n",
      "        order : int\n",
      "            The polynomial order of the trend, zero is constant, one is\n",
      "            linear trend, two is quadratic trend.\n",
      "        axis : int\n",
      "            Axis can be either 0, observations by rows, or 1, observations by\n",
      "            columns.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        ndarray\n",
      "            The detrended series is the residual of the linear regression of the\n",
      "            data on the trend of given order.\n",
      "    \n",
      "    kpss(x, regression: \"Literal[('c', 'ct')]\" = 'c', nlags: \"Literal[('auto', 'legacy')] | int\" = 'auto', store: 'bool' = False) -> 'Tuple[float, float, int, dict[str, float]]'\n",
      "        Kwiatkowski-Phillips-Schmidt-Shin test for stationarity.\n",
      "        \n",
      "        Computes the Kwiatkowski-Phillips-Schmidt-Shin (KPSS) test for the null\n",
      "        hypothesis that x is level or trend stationary.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        x : array_like, 1d\n",
      "            The data series to test.\n",
      "        regression : str{\"c\", \"ct\"}\n",
      "            The null hypothesis for the KPSS test.\n",
      "        \n",
      "            * \"c\" : The data is stationary around a constant (default).\n",
      "            * \"ct\" : The data is stationary around a trend.\n",
      "        nlags : {str, int}, optional\n",
      "            Indicates the number of lags to be used. If \"auto\" (default), lags\n",
      "            is calculated using the data-dependent method of Hobijn et al. (1998).\n",
      "            See also Andrews (1991), Newey & West (1994), and Schwert (1989). If\n",
      "            set to \"legacy\",  uses int(12 * (n / 100)**(1 / 4)) , as outlined in\n",
      "            Schwert (1989).\n",
      "        store : bool\n",
      "            If True, then a result instance is returned additionally to\n",
      "            the KPSS statistic (default is False).\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        kpss_stat : float\n",
      "            The KPSS test statistic.\n",
      "        p_value : float\n",
      "            The p-value of the test. The p-value is interpolated from\n",
      "            Table 1 in Kwiatkowski et al. (1992), and a boundary point\n",
      "            is returned if the test statistic is outside the table of\n",
      "            critical values, that is, if the p-value is outside the\n",
      "            interval (0.01, 0.1).\n",
      "        lags : int\n",
      "            The truncation lag parameter.\n",
      "        crit : dict\n",
      "            The critical values at 10%, 5%, 2.5% and 1%. Based on\n",
      "            Kwiatkowski et al. (1992).\n",
      "        resstore : (optional) instance of ResultStore\n",
      "            An instance of a dummy class with results attached as attributes.\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        To estimate sigma^2 the Newey-West estimator is used. If lags is \"legacy\",\n",
      "        the truncation lag parameter is set to int(12 * (n / 100) ** (1 / 4)),\n",
      "        as outlined in Schwert (1989). The p-values are interpolated from\n",
      "        Table 1 of Kwiatkowski et al. (1992). If the computed statistic is\n",
      "        outside the table of critical values, then a warning message is\n",
      "        generated.\n",
      "        \n",
      "        Missing values are not handled.\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        .. [1] Andrews, D.W.K. (1991). Heteroskedasticity and autocorrelation\n",
      "           consistent covariance matrix estimation. Econometrica, 59: 817-858.\n",
      "        \n",
      "        .. [2] Hobijn, B., Frances, B.H., & Ooms, M. (2004). Generalizations of the\n",
      "           KPSS-test for stationarity. Statistica Neerlandica, 52: 483-502.\n",
      "        \n",
      "        .. [3] Kwiatkowski, D., Phillips, P.C.B., Schmidt, P., & Shin, Y. (1992).\n",
      "           Testing the null hypothesis of stationarity against the alternative of a\n",
      "           unit root. Journal of Econometrics, 54: 159-178.\n",
      "        \n",
      "        .. [4] Newey, W.K., & West, K.D. (1994). Automatic lag selection in\n",
      "           covariance matrix estimation. Review of Economic Studies, 61: 631-653.\n",
      "        \n",
      "        .. [5] Schwert, G. W. (1989). Tests for unit roots: A Monte Carlo\n",
      "           investigation. Journal of Business and Economic Statistics, 7 (2):\n",
      "           147-159.\n",
      "    \n",
      "    lagmat(x, maxlag: 'int', trim: \"Literal[('forward', 'backward', 'both', 'none')]\" = 'forward', original: \"Literal[('ex', 'sep', 'in')]\" = 'ex', use_pandas: 'bool' = False)\n",
      "        Create 2d array of lags.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        x : array_like\n",
      "            Data; if 2d, observation in rows and variables in columns.\n",
      "        maxlag : int\n",
      "            All lags from zero to maxlag are included.\n",
      "        trim : {'forward', 'backward', 'both', 'none', None}\n",
      "            The trimming method to use.\n",
      "        \n",
      "            * 'forward' : trim invalid observations in front.\n",
      "            * 'backward' : trim invalid initial observations.\n",
      "            * 'both' : trim invalid observations on both sides.\n",
      "            * 'none', None : no trimming of observations.\n",
      "        original : {'ex','sep','in'}\n",
      "            How the original is treated.\n",
      "        \n",
      "            * 'ex' : drops the original array returning only the lagged values.\n",
      "            * 'in' : returns the original array and the lagged values as a single\n",
      "              array.\n",
      "            * 'sep' : returns a tuple (original array, lagged values). The original\n",
      "                      array is truncated to have the same number of rows as\n",
      "                      the returned lagmat.\n",
      "        use_pandas : bool\n",
      "            If true, returns a DataFrame when the input is a pandas\n",
      "            Series or DataFrame.  If false, return numpy ndarrays.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        lagmat : ndarray\n",
      "            The array with lagged observations.\n",
      "        y : ndarray, optional\n",
      "            Only returned if original == 'sep'.\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        When using a pandas DataFrame or Series with use_pandas=True, trim can only\n",
      "        be 'forward' or 'both' since it is not possible to consistently extend\n",
      "        index values.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> from statsmodels.tsa.tsatools import lagmat\n",
      "        >>> import numpy as np\n",
      "        >>> X = np.arange(1,7).reshape(-1,2)\n",
      "        >>> lagmat(X, maxlag=2, trim=\"forward\", original='in')\n",
      "        array([[ 1.,  2.,  0.,  0.,  0.,  0.],\n",
      "           [ 3.,  4.,  1.,  2.,  0.,  0.],\n",
      "           [ 5.,  6.,  3.,  4.,  1.,  2.]])\n",
      "        \n",
      "        >>> lagmat(X, maxlag=2, trim=\"backward\", original='in')\n",
      "        array([[ 5.,  6.,  3.,  4.,  1.,  2.],\n",
      "           [ 0.,  0.,  5.,  6.,  3.,  4.],\n",
      "           [ 0.,  0.,  0.,  0.,  5.,  6.]])\n",
      "        \n",
      "        >>> lagmat(X, maxlag=2, trim=\"both\", original='in')\n",
      "        array([[ 5.,  6.,  3.,  4.,  1.,  2.]])\n",
      "        \n",
      "        >>> lagmat(X, maxlag=2, trim=\"none\", original='in')\n",
      "        array([[ 1.,  2.,  0.,  0.,  0.,  0.],\n",
      "           [ 3.,  4.,  1.,  2.,  0.,  0.],\n",
      "           [ 5.,  6.,  3.,  4.,  1.,  2.],\n",
      "           [ 0.,  0.,  5.,  6.,  3.,  4.],\n",
      "           [ 0.,  0.,  0.,  0.,  5.,  6.]])\n",
      "    \n",
      "    lagmat2ds(x, maxlag0, maxlagex=None, dropex=0, trim='forward', use_pandas=False)\n",
      "        Generate lagmatrix for 2d array, columns arranged by variables.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        x : array_like\n",
      "            Data, 2d. Observations in rows and variables in columns.\n",
      "        maxlag0 : int\n",
      "            The first variable all lags from zero to maxlag are included.\n",
      "        maxlagex : {None, int}\n",
      "            The max lag for all other variables all lags from zero to maxlag are\n",
      "            included.\n",
      "        dropex : int\n",
      "            Exclude first dropex lags from other variables. For all variables,\n",
      "            except the first, lags from dropex to maxlagex are included.\n",
      "        trim : str\n",
      "            The trimming method to use.\n",
      "        \n",
      "            * 'forward' : trim invalid observations in front.\n",
      "            * 'backward' : trim invalid initial observations.\n",
      "            * 'both' : trim invalid observations on both sides.\n",
      "            * 'none' : no trimming of observations.\n",
      "        use_pandas : bool\n",
      "            If true, returns a DataFrame when the input is a pandas\n",
      "            Series or DataFrame.  If false, return numpy ndarrays.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        ndarray\n",
      "            The array with lagged observations, columns ordered by variable.\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        Inefficient implementation for unequal lags, implemented for convenience.\n",
      "    \n",
      "    pacf(x, nlags=None, method='ywadjusted', alpha=None)\n",
      "        Partial autocorrelation estimate.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        x : array_like\n",
      "            Observations of time series for which pacf is calculated.\n",
      "        nlags : int, optional\n",
      "            Number of lags to return autocorrelation for. If not provided,\n",
      "            uses min(10 * np.log10(nobs), nobs // 2 - 1). The returned value\n",
      "            includes lag 0 (ie., 1) so size of the pacf vector is (nlags + 1,).\n",
      "        method : str, default \"ywunbiased\"\n",
      "            Specifies which method for the calculations to use.\n",
      "        \n",
      "            - \"yw\" or \"ywadjusted\" : Yule-Walker with sample-size adjustment in\n",
      "              denominator for acovf. Default.\n",
      "            - \"ywm\" or \"ywmle\" : Yule-Walker without adjustment.\n",
      "            - \"ols\" : regression of time series on lags of it and on constant.\n",
      "            - \"ols-inefficient\" : regression of time series on lags using a single\n",
      "              common sample to estimate all pacf coefficients.\n",
      "            - \"ols-adjusted\" : regression of time series on lags with a bias\n",
      "              adjustment.\n",
      "            - \"ld\" or \"ldadjusted\" : Levinson-Durbin recursion with bias\n",
      "              correction.\n",
      "            - \"ldb\" or \"ldbiased\" : Levinson-Durbin recursion without bias\n",
      "              correction.\n",
      "        \n",
      "        alpha : float, optional\n",
      "            If a number is given, the confidence intervals for the given level are\n",
      "            returned. For instance if alpha=.05, 95 % confidence intervals are\n",
      "            returned where the standard deviation is computed according to\n",
      "            1/sqrt(len(x)).\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        pacf : ndarray\n",
      "            The partial autocorrelations for lags 0, 1, ..., nlags. Shape\n",
      "            (nlags+1,).\n",
      "        confint : ndarray, optional\n",
      "            Confidence intervals for the PACF at lags 0, 1, ..., nlags. Shape\n",
      "            (nlags + 1, 2). Returned if alpha is not None.\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        statsmodels.tsa.stattools.acf\n",
      "            Estimate the autocorrelation function.\n",
      "        statsmodels.tsa.stattools.pacf\n",
      "            Partial autocorrelation estimation.\n",
      "        statsmodels.tsa.stattools.pacf_yw\n",
      "             Partial autocorrelation estimation using Yule-Walker.\n",
      "        statsmodels.tsa.stattools.pacf_ols\n",
      "            Partial autocorrelation estimation using OLS.\n",
      "        statsmodels.tsa.stattools.pacf_burg\n",
      "            Partial autocorrelation estimation using Burg\"s method.\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        Based on simulation evidence across a range of low-order ARMA models,\n",
      "        the best methods based on root MSE are Yule-Walker (MLW), Levinson-Durbin\n",
      "        (MLE) and Burg, respectively. The estimators with the lowest bias included\n",
      "        included these three in addition to OLS and OLS-adjusted.\n",
      "        \n",
      "        Yule-Walker (adjusted) and Levinson-Durbin (adjusted) performed\n",
      "        consistently worse than the other options.\n",
      "    \n",
      "    pacf_ols(x, nlags=None, efficient=True, adjusted=False)\n",
      "        Calculate partial autocorrelations via OLS.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        x : array_like\n",
      "            Observations of time series for which pacf is calculated.\n",
      "        nlags : int, optional\n",
      "            Number of lags to return autocorrelation for. If not provided,\n",
      "            uses min(10 * np.log10(nobs), nobs - 1).\n",
      "        efficient : bool, optional\n",
      "            If true, uses the maximum number of available observations to compute\n",
      "            each partial autocorrelation. If not, uses the same number of\n",
      "            observations to compute all pacf values.\n",
      "        adjusted : bool, optional\n",
      "            Adjust each partial autocorrelation by n / (n - lag).\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        ndarray\n",
      "            The partial autocorrelations, (maxlag,) array corresponding to lags\n",
      "            0, 1, ..., maxlag.\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        statsmodels.tsa.stattools.pacf\n",
      "            Partial autocorrelation estimation.\n",
      "        statsmodels.tsa.stattools.pacf_yw\n",
      "             Partial autocorrelation estimation using Yule-Walker.\n",
      "        statsmodels.tsa.stattools.pacf_burg\n",
      "            Partial autocorrelation estimation using Burg\"s method.\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        This solves a separate OLS estimation for each desired lag using method in\n",
      "        [1]_. Setting efficient to True has two effects. First, it uses\n",
      "        `nobs - lag` observations of estimate each pacf.  Second, it re-estimates\n",
      "        the mean in each regression. If efficient is False, then the data are first\n",
      "        demeaned, and then `nobs - maxlag` observations are used to estimate each\n",
      "        partial autocorrelation.\n",
      "        \n",
      "        The inefficient estimator appears to have better finite sample properties.\n",
      "        This option should only be used in time series that are covariance\n",
      "        stationary.\n",
      "        \n",
      "        OLS estimation of the pacf does not guarantee that all pacf values are\n",
      "        between -1 and 1.\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        .. [1] Box, G. E., Jenkins, G. M., Reinsel, G. C., & Ljung, G. M. (2015).\n",
      "           Time series analysis: forecasting and control. John Wiley & Sons, p. 66\n",
      "    \n",
      "    pacf_yw(x, nlags=None, method='adjusted')\n",
      "        Partial autocorrelation estimated with non-recursive yule_walker.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        x : array_like\n",
      "            The observations of time series for which pacf is calculated.\n",
      "        nlags : int, optional\n",
      "            Number of lags to return autocorrelation for. If not provided,\n",
      "            uses min(10 * np.log10(nobs), nobs - 1).\n",
      "        method : {\"adjusted\", \"mle\"}, default \"adjusted\"\n",
      "            The method for the autocovariance calculations in yule walker.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        ndarray\n",
      "            The partial autocorrelations, maxlag+1 elements.\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        statsmodels.tsa.stattools.pacf\n",
      "            Partial autocorrelation estimation.\n",
      "        statsmodels.tsa.stattools.pacf_ols\n",
      "            Partial autocorrelation estimation using OLS.\n",
      "        statsmodels.tsa.stattools.pacf_burg\n",
      "            Partial autocorrelation estimation using Burg\"s method.\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        This solves yule_walker for each desired lag and contains\n",
      "        currently duplicate calculations.\n",
      "    \n",
      "    q_stat(x, nobs)\n",
      "        Compute Ljung-Box Q Statistic.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        x : array_like\n",
      "            Array of autocorrelation coefficients.  Can be obtained from acf.\n",
      "        nobs : int, optional\n",
      "            Number of observations in the entire sample (ie., not just the length\n",
      "            of the autocorrelation function results.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        q-stat : ndarray\n",
      "            Ljung-Box Q-statistic for autocorrelation parameters.\n",
      "        p-value : ndarray\n",
      "            P-value of the Q statistic.\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        Designed to be used with acf.\n",
      "    \n",
      "    range_unit_root_test(x, store=False)\n",
      "        Range unit-root test for stationarity.\n",
      "        \n",
      "        Computes the Range Unit-Root (RUR) test for the null\n",
      "        hypothesis that x is stationary.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        x : array_like, 1d\n",
      "            The data series to test.\n",
      "        store : bool\n",
      "            If True, then a result instance is returned additionally to\n",
      "            the RUR statistic (default is False).\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        rur_stat : float\n",
      "            The RUR test statistic.\n",
      "        p_value : float\n",
      "            The p-value of the test. The p-value is interpolated from\n",
      "            Table 1 in Aparicio et al. (2006), and a boundary point\n",
      "            is returned if the test statistic is outside the table of\n",
      "            critical values, that is, if the p-value is outside the\n",
      "            interval (0.01, 0.1).\n",
      "        crit : dict\n",
      "            The critical values at 10%, 5%, 2.5% and 1%. Based on\n",
      "            Aparicio et al. (2006).\n",
      "        resstore : (optional) instance of ResultStore\n",
      "            An instance of a dummy class with results attached as attributes.\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        The p-values are interpolated from\n",
      "        Table 1 of Aparicio et al. (2006). If the computed statistic is\n",
      "        outside the table of critical values, then a warning message is\n",
      "        generated.\n",
      "        \n",
      "        Missing values are not handled.\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        .. [1] Aparicio, F., Escribano A., Sipols, A.E. (2006). Range Unit-Root (RUR)\n",
      "            tests: robust against nonlinearities, error distributions, structural breaks\n",
      "            and outliers. Journal of Time Series Analysis, 27 (4): 545-576.\n",
      "    \n",
      "    seasonal_decompose(x, model='additive', filt=None, period=None, two_sided=True, extrapolate_trend=0)\n",
      "        Seasonal decomposition using moving averages.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        x : array_like\n",
      "            Time series. If 2d, individual series are in columns. x must contain 2\n",
      "            complete cycles.\n",
      "        model : {\"additive\", \"multiplicative\"}, optional\n",
      "            Type of seasonal component. Abbreviations are accepted.\n",
      "        filt : array_like, optional\n",
      "            The filter coefficients for filtering out the seasonal component.\n",
      "            The concrete moving average method used in filtering is determined by\n",
      "            two_sided.\n",
      "        period : int, optional\n",
      "            Period of the series. Must be used if x is not a pandas object or if\n",
      "            the index of x does not have  a frequency. Overrides default\n",
      "            periodicity of x if x is a pandas object with a timeseries index.\n",
      "        two_sided : bool, optional\n",
      "            The moving average method used in filtering.\n",
      "            If True (default), a centered moving average is computed using the\n",
      "            filt. If False, the filter coefficients are for past values only.\n",
      "        extrapolate_trend : int or 'freq', optional\n",
      "            If set to > 0, the trend resulting from the convolution is\n",
      "            linear least-squares extrapolated on both ends (or the single one\n",
      "            if two_sided is False) considering this many (+1) closest points.\n",
      "            If set to 'freq', use `freq` closest points. Setting this parameter\n",
      "            results in no NaN values in trend or resid components.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        DecomposeResult\n",
      "            A object with seasonal, trend, and resid attributes.\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        statsmodels.tsa.filters.bk_filter.bkfilter\n",
      "            Baxter-King filter.\n",
      "        statsmodels.tsa.filters.cf_filter.cffilter\n",
      "            Christiano-Fitzgerald asymmetric, random walk filter.\n",
      "        statsmodels.tsa.filters.hp_filter.hpfilter\n",
      "            Hodrick-Prescott filter.\n",
      "        statsmodels.tsa.filters.convolution_filter\n",
      "            Linear filtering via convolution.\n",
      "        statsmodels.tsa.seasonal.STL\n",
      "            Season-Trend decomposition using LOESS.\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        This is a naive decomposition. More sophisticated methods should\n",
      "        be preferred.\n",
      "        \n",
      "        The additive model is Y[t] = T[t] + S[t] + e[t]\n",
      "        \n",
      "        The multiplicative model is Y[t] = T[t] * S[t] * e[t]\n",
      "        \n",
      "        The results are obtained by first estimating the trend by applying\n",
      "        a convolution filter to the data. The trend is then removed from the\n",
      "        series and the average of this de-trended series for each period is\n",
      "        the returned seasonal component.\n",
      "    \n",
      "    x13_arima_analysis(endog, maxorder=(2, 1), maxdiff=(2, 1), diff=None, exog=None, log=None, outlier=True, trading=False, forecast_periods=None, retspec=False, speconly=False, start=None, freq=None, print_stdout=False, x12path=None, prefer_x13=True)\n",
      "        Perform x13-arima analysis for monthly or quarterly data.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        endog : array_like, pandas.Series\n",
      "            The series to model. It is best to use a pandas object with a\n",
      "            DatetimeIndex or PeriodIndex. However, you can pass an array-like\n",
      "            object. If your object does not have a dates index then ``start`` and\n",
      "            ``freq`` are not optional.\n",
      "        maxorder : tuple\n",
      "            The maximum order of the regular and seasonal ARMA polynomials to\n",
      "            examine during the model identification. The order for the regular\n",
      "            polynomial must be greater than zero and no larger than 4. The\n",
      "            order for the seasonal polynomial may be 1 or 2.\n",
      "        maxdiff : tuple\n",
      "            The maximum orders for regular and seasonal differencing in the\n",
      "            automatic differencing procedure. Acceptable inputs for regular\n",
      "            differencing are 1 and 2. The maximum order for seasonal differencing\n",
      "            is 1. If ``diff`` is specified then ``maxdiff`` should be None.\n",
      "            Otherwise, ``diff`` will be ignored. See also ``diff``.\n",
      "        diff : tuple\n",
      "            Fixes the orders of differencing for the regular and seasonal\n",
      "            differencing. Regular differencing may be 0, 1, or 2. Seasonal\n",
      "            differencing may be 0 or 1. ``maxdiff`` must be None, otherwise\n",
      "            ``diff`` is ignored.\n",
      "        exog : array_like\n",
      "            Exogenous variables.\n",
      "        log : bool or None\n",
      "            If None, it is automatically determined whether to log the series or\n",
      "            not. If False, logs are not taken. If True, logs are taken.\n",
      "        outlier : bool\n",
      "            Whether or not outliers are tested for and corrected, if detected.\n",
      "        trading : bool\n",
      "            Whether or not trading day effects are tested for.\n",
      "        forecast_periods : int\n",
      "            Number of forecasts produced. The default is None.\n",
      "        retspec : bool\n",
      "            Whether to return the created specification file. Can be useful for\n",
      "            debugging.\n",
      "        speconly : bool\n",
      "            Whether to create the specification file and then return it without\n",
      "            performing the analysis. Can be useful for debugging.\n",
      "        start : str, datetime\n",
      "            Must be given if ``endog`` does not have date information in its index.\n",
      "            Anything accepted by pandas.DatetimeIndex for the start value.\n",
      "        freq : str\n",
      "            Must be givein if ``endog`` does not have date information in its\n",
      "            index. Anything accepted by pandas.DatetimeIndex for the freq value.\n",
      "        print_stdout : bool\n",
      "            The stdout from X12/X13 is suppressed. To print it out, set this\n",
      "            to True. Default is False.\n",
      "        x12path : str or None\n",
      "            The path to x12 or x13 binary. If None, the program will attempt\n",
      "            to find x13as or x12a on the PATH or by looking at X13PATH or\n",
      "            X12PATH depending on the value of prefer_x13.\n",
      "        prefer_x13 : bool\n",
      "            If True, will look for x13as first and will fallback to the X13PATH\n",
      "            environmental variable. If False, will look for x12a first and will\n",
      "            fallback to the X12PATH environmental variable. If x12path points\n",
      "            to the path for the X12/X13 binary, it does nothing.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        Bunch\n",
      "            A bunch object containing the listed attributes.\n",
      "        \n",
      "            - results : str\n",
      "              The full output from the X12/X13 run.\n",
      "            - seasadj : pandas.Series\n",
      "              The final seasonally adjusted ``endog``.\n",
      "            - trend : pandas.Series\n",
      "              The trend-cycle component of ``endog``.\n",
      "            - irregular : pandas.Series\n",
      "              The final irregular component of ``endog``.\n",
      "            - stdout : str\n",
      "              The captured stdout produced by x12/x13.\n",
      "            - spec : str, optional\n",
      "              Returned if ``retspec`` is True. The only thing returned if\n",
      "              ``speconly`` is True.\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        This works by creating a specification file, writing it to a temporary\n",
      "        directory, invoking X12/X13 in a subprocess, and reading the output\n",
      "        directory, invoking exog12/X13 in a subprocess, and reading the output\n",
      "        back in.\n",
      "    \n",
      "    x13_arima_select_order(endog, maxorder=(2, 1), maxdiff=(2, 1), diff=None, exog=None, log=None, outlier=True, trading=False, forecast_periods=None, start=None, freq=None, print_stdout=False, x12path=None, prefer_x13=True)\n",
      "        Perform automatic seasonal ARIMA order identification using x12/x13 ARIMA.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        endog : array_like, pandas.Series\n",
      "            The series to model. It is best to use a pandas object with a\n",
      "            DatetimeIndex or PeriodIndex. However, you can pass an array-like\n",
      "            object. If your object does not have a dates index then ``start`` and\n",
      "            ``freq`` are not optional.\n",
      "        maxorder : tuple\n",
      "            The maximum order of the regular and seasonal ARMA polynomials to\n",
      "            examine during the model identification. The order for the regular\n",
      "            polynomial must be greater than zero and no larger than 4. The\n",
      "            order for the seasonal polynomial may be 1 or 2.\n",
      "        maxdiff : tuple\n",
      "            The maximum orders for regular and seasonal differencing in the\n",
      "            automatic differencing procedure. Acceptable inputs for regular\n",
      "            differencing are 1 and 2. The maximum order for seasonal differencing\n",
      "            is 1. If ``diff`` is specified then ``maxdiff`` should be None.\n",
      "            Otherwise, ``diff`` will be ignored. See also ``diff``.\n",
      "        diff : tuple\n",
      "            Fixes the orders of differencing for the regular and seasonal\n",
      "            differencing. Regular differencing may be 0, 1, or 2. Seasonal\n",
      "            differencing may be 0 or 1. ``maxdiff`` must be None, otherwise\n",
      "            ``diff`` is ignored.\n",
      "        exog : array_like\n",
      "            Exogenous variables.\n",
      "        log : bool or None\n",
      "            If None, it is automatically determined whether to log the series or\n",
      "            not. If False, logs are not taken. If True, logs are taken.\n",
      "        outlier : bool\n",
      "            Whether or not outliers are tested for and corrected, if detected.\n",
      "        trading : bool\n",
      "            Whether or not trading day effects are tested for.\n",
      "        forecast_periods : int\n",
      "            Number of forecasts produced. The default is None.\n",
      "        start : str, datetime\n",
      "            Must be given if ``endog`` does not have date information in its index.\n",
      "            Anything accepted by pandas.DatetimeIndex for the start value.\n",
      "        freq : str\n",
      "            Must be givein if ``endog`` does not have date information in its\n",
      "            index. Anything accepted by pandas.DatetimeIndex for the freq value.\n",
      "        print_stdout : bool\n",
      "            The stdout from X12/X13 is suppressed. To print it out, set this\n",
      "            to True. Default is False.\n",
      "        x12path : str or None\n",
      "            The path to x12 or x13 binary. If None, the program will attempt\n",
      "            to find x13as or x12a on the PATH or by looking at X13PATH or X12PATH\n",
      "            depending on the value of prefer_x13.\n",
      "        prefer_x13 : bool\n",
      "            If True, will look for x13as first and will fallback to the X13PATH\n",
      "            environmental variable. If False, will look for x12a first and will\n",
      "            fallback to the X12PATH environmental variable. If x12path points\n",
      "            to the path for the X12/X13 binary, it does nothing.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        Bunch\n",
      "            A bunch object containing the listed attributes.\n",
      "        \n",
      "            - order : tuple\n",
      "              The regular order.\n",
      "            - sorder : tuple\n",
      "              The seasonal order.\n",
      "            - include_mean : bool\n",
      "              Whether to include a mean or not.\n",
      "            - results : str\n",
      "              The full results from the X12/X13 analysis.\n",
      "            - stdout : str\n",
      "              The captured stdout from the X12/X13 analysis.\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        This works by creating a specification file, writing it to a temporary\n",
      "        directory, invoking X12/X13 in a subprocess, and reading the output back\n",
      "        in.\n",
      "\n",
      "DATA\n",
      "    __all__ = ['AR', 'ARDL', 'ARIMA', 'ArmaProcess', 'AutoReg', 'DynamicFa...\n",
      "    zivot_andrews = <statsmodels.tsa.stattools.ZivotAndrewsUnitRoot object...\n",
      "\n",
      "FILE\n",
      "    d:\\anaconda3\\envs\\quant38\\lib\\site-packages\\statsmodels\\tsa\\api.py\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(tsa)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multiple linear-regression models expressed the variable of interest as a linear combination of predictors or input variables. Univariate time series models relate the value of the time series at the point in time of interest to a linear combination of lagged values of the series and possibly past disturbance terms.\n",
    "While exponential smoothing models are based on a description of the trend and seasonality in the data, ARIMA models aim to describe the autocorrelations in the data. ARIMA(p, d, q) models require stationarity and leverage two building blocks:\n",
    "- Autoregressive (AR) terms consisting of p-lagged values of the time series\n",
    "- Moving average (MA) terms that contain q-lagged disturbances\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chapter 8 introduces the ARIMA building blocks, simple autoregressive (AR) and moving average (MA) models, and explains how to combine them in autoregressive moving-average (ARMA) models that may account for series integration as ARIMA models or include exogenous variables as AR(I)MAX models. \n",
    "\n",
    "Furthermore, we will illustrate how to include seasonal AR and MA terms to extend the toolbox to also include SARMAX models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ARMA vs ARIMA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ARMA model of the undifferenced series produces the same result as the ARIMA model of the differenced series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-15T20:41:37.790993Z",
     "start_time": "2021-04-15T20:41:32.888997Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'statsmodels.tsa.api' has no attribute 'ARMA'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[1;32mIn [22]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model1 \u001b[38;5;241m=\u001b[39m \u001b[43msm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtsa\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mARMA\u001b[49m(endog\u001b[38;5;241m=\u001b[39mnasdaq_log_diff, order\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m2\u001b[39m))\u001b[38;5;241m.\u001b[39mfit()\n\u001b[0;32m      2\u001b[0m model2 \u001b[38;5;241m=\u001b[39m sm\u001b[38;5;241m.\u001b[39mtsa\u001b[38;5;241m.\u001b[39mARIMA(endog\u001b[38;5;241m=\u001b[39mnasdaq_log, order\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m))\u001b[38;5;241m.\u001b[39mfit()\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'statsmodels.tsa.api' has no attribute 'ARMA'"
     ]
    }
   ],
   "source": [
    "model1 = tsa.ARMA(endog=nasdaq_log_diff, order=(2,2)).fit()\n",
    "model2 = tsa.ARIMA(endog=nasdaq_log, order=(2,1,2)).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-15T20:41:37.800459Z",
     "start_time": "2021-04-15T20:41:37.792628Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "('Lengths must match to compare', (6,), (5,))",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [17]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msort_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodel2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msort_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\n",
      "File \u001b[1;32mD:\\anaconda3\\envs\\quant38\\lib\\site-packages\\pandas\\core\\ops\\common.py:70\u001b[0m, in \u001b[0;36m_unpack_zerodim_and_defer.<locals>.new_method\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m     66\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[0;32m     68\u001b[0m other \u001b[38;5;241m=\u001b[39m item_from_zerodim(other)\n\u001b[1;32m---> 70\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\anaconda3\\envs\\quant38\\lib\\site-packages\\pandas\\core\\arraylike.py:40\u001b[0m, in \u001b[0;36mOpsMixin.__eq__\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;129m@unpack_zerodim_and_defer\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__eq__\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__eq__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[1;32m---> 40\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cmp_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meq\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\anaconda3\\envs\\quant38\\lib\\site-packages\\pandas\\core\\series.py:5623\u001b[0m, in \u001b[0;36mSeries._cmp_method\u001b[1;34m(self, other, op)\u001b[0m\n\u001b[0;32m   5620\u001b[0m rvalues \u001b[38;5;241m=\u001b[39m extract_array(other, extract_numpy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, extract_range\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m   5622\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m np\u001b[38;5;241m.\u001b[39merrstate(\u001b[38;5;28mall\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m-> 5623\u001b[0m     res_values \u001b[38;5;241m=\u001b[39m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcomparison_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   5625\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_construct_result(res_values, name\u001b[38;5;241m=\u001b[39mres_name)\n",
      "File \u001b[1;32mD:\\anaconda3\\envs\\quant38\\lib\\site-packages\\pandas\\core\\ops\\array_ops.py:260\u001b[0m, in \u001b[0;36mcomparison_op\u001b[1;34m(left, right, op)\u001b[0m\n\u001b[0;32m    255\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(rvalues, (np\u001b[38;5;241m.\u001b[39mndarray, ABCExtensionArray)):\n\u001b[0;32m    256\u001b[0m     \u001b[38;5;66;03m# TODO: make this treatment consistent across ops and classes.\u001b[39;00m\n\u001b[0;32m    257\u001b[0m     \u001b[38;5;66;03m#  We are not catching all listlikes here (e.g. frozenset, tuple)\u001b[39;00m\n\u001b[0;32m    258\u001b[0m     \u001b[38;5;66;03m#  The ambiguous case is object-dtype.  See GH#27803\u001b[39;00m\n\u001b[0;32m    259\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(lvalues) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(rvalues):\n\u001b[1;32m--> 260\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    261\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLengths must match to compare\u001b[39m\u001b[38;5;124m\"\u001b[39m, lvalues\u001b[38;5;241m.\u001b[39mshape, rvalues\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m    262\u001b[0m         )\n\u001b[0;32m    264\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m should_extension_dispatch(lvalues, rvalues) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m    265\u001b[0m     (\u001b[38;5;28misinstance\u001b[39m(rvalues, (Timedelta, BaseOffset, Timestamp)) \u001b[38;5;129;01mor\u001b[39;00m right \u001b[38;5;129;01mis\u001b[39;00m NaT)\n\u001b[0;32m    266\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_object_dtype(lvalues\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[0;32m    267\u001b[0m ):\n\u001b[0;32m    268\u001b[0m     \u001b[38;5;66;03m# Call the method on lvalues\u001b[39;00m\n\u001b[0;32m    269\u001b[0m     res_values \u001b[38;5;241m=\u001b[39m op(lvalues, rvalues)\n",
      "\u001b[1;31mValueError\u001b[0m: ('Lengths must match to compare', (6,), (5,))"
     ]
    }
   ],
   "source": [
    "model1.params.sort_index() == model2.params.sort_index().values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seasonal differencing vs SARIMAX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seasonal differencing has same effect as using SARIMAX w seasonal order (0,1,0,12)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-15T20:41:38.259732Z",
     "start_time": "2021-04-15T20:41:37.801777Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\envs\\quant38\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:471: ValueWarning: No frequency information was provided, so inferred frequency MS will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "D:\\anaconda3\\envs\\quant38\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:471: ValueWarning: No frequency information was provided, so inferred frequency MS will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "D:\\anaconda3\\envs\\quant38\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:471: ValueWarning: No frequency information was provided, so inferred frequency MS will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "D:\\anaconda3\\envs\\quant38\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:471: ValueWarning: No frequency information was provided, so inferred frequency MS will be used.\n",
      "  self._init_dates(dates, freq)\n"
     ]
    }
   ],
   "source": [
    "model1 = tsa.statespace.SARIMAX(industrial_production_log, order=(2,0,2), seasonal_order=(0,1,0,12)).fit()\n",
    "model2 = tsa.statespace.SARIMAX(industrial_production_log_diff, order=(2,0,2), seasonal_order=(0,0,0,12)).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-15T20:41:38.267308Z",
     "start_time": "2021-04-15T20:41:38.260580Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SARIMAX</th>\n",
       "      <th>diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ar.L1</th>\n",
       "      <td>1.767088</td>\n",
       "      <td>1.767088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ar.L2</th>\n",
       "      <td>-0.789440</td>\n",
       "      <td>-0.789440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ma.L1</th>\n",
       "      <td>-0.845173</td>\n",
       "      <td>-0.845173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ma.L2</th>\n",
       "      <td>0.313206</td>\n",
       "      <td>0.313206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sigma2</th>\n",
       "      <td>0.000103</td>\n",
       "      <td>0.000103</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         SARIMAX      diff\n",
       "ar.L1   1.767088  1.767088\n",
       "ar.L2  -0.789440 -0.789440\n",
       "ma.L1  -0.845173 -0.845173\n",
       "ma.L2   0.313206  0.313206\n",
       "sigma2  0.000103  0.000103"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.params.to_frame('SARIMAX').join(model2.params.to_frame('diff'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding the optimal ARMA lags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run candidate models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We iterate over various (p, q) lag combinations and collect diagnostic statistics to compare the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-15T20:42:29.354325Z",
     "start_time": "2021-04-15T20:41:38.268423Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'statsmodels.tsa.api' has no attribute 'ARMA'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[1;32mIn [20]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     13\u001b[0m train_set \u001b[38;5;241m=\u001b[39m industrial_production_log_diff\u001b[38;5;241m.\u001b[39miloc[T\u001b[38;5;241m-\u001b[39mtrain_size:T]\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 15\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mtsa\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mARMA\u001b[49m(endog\u001b[38;5;241m=\u001b[39mtrain_set, order\u001b[38;5;241m=\u001b[39m(p, q))\u001b[38;5;241m.\u001b[39mfit()\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m LinAlgError:\n\u001b[0;32m     17\u001b[0m     convergence_error \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'statsmodels.tsa.api' has no attribute 'ARMA'"
     ]
    }
   ],
   "source": [
    "train_size = 120\n",
    "results = {}\n",
    "y_true = industrial_production_log_diff.iloc[train_size:]\n",
    "for p in range(5):\n",
    "    for q in range(5):\n",
    "        aic, bic = [], []\n",
    "        if p == 0 and q == 0:\n",
    "            continue\n",
    "        print(p, q)\n",
    "        convergence_error = stationarity_error = 0\n",
    "        y_pred = []\n",
    "        for T in range(train_size, len(industrial_production_log_diff)):\n",
    "            train_set = industrial_production_log_diff.iloc[T-train_size:T]\n",
    "            try:\n",
    "                model = tsa.ARMA(endog=train_set, order=(p, q)).fit()\n",
    "            except LinAlgError:\n",
    "                convergence_error += 1\n",
    "            except ValueError:\n",
    "                stationarity_error += 1\n",
    "\n",
    "            forecast, _, _ = model.forecast(steps=1)\n",
    "            y_pred.append(forecast[0])\n",
    "            aic.append(model.aic)\n",
    "            bic.append(model.bic)\n",
    "\n",
    "        result = (pd.DataFrame({'y_true': y_true, 'y_pred': y_pred})\n",
    "                  .replace(np.inf, np.nan)\n",
    "                  .dropna())\n",
    "\n",
    "        rmse = np.sqrt(mean_squared_error(\n",
    "            y_true=result.y_true, y_pred=result.y_pred))\n",
    "\n",
    "        results[(p, q)] = [rmse,\n",
    "                           np.mean(aic),\n",
    "                           np.mean(bic),\n",
    "                           convergence_error,\n",
    "                           stationarity_error]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-15T20:42:29.355690Z",
     "start_time": "2021-04-15T20:41:31.700Z"
    }
   },
   "outputs": [],
   "source": [
    "arma_results = pd.DataFrame(results).T\n",
    "arma_results.columns = ['RMSE', 'AIC', 'BIC', 'convergence', 'stationarity']\n",
    "arma_results.index.names = ['p', 'q']\n",
    "arma_results.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-15T20:42:29.356238Z",
     "start_time": "2021-04-15T20:41:31.701Z"
    }
   },
   "outputs": [],
   "source": [
    "with pd.HDFStore('arima.h5') as store:\n",
    "    store.put('arma', arma_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We aim to minimize both RMSE and BIC:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-15T20:42:29.356657Z",
     "start_time": "2021-04-15T20:41:31.705Z"
    }
   },
   "outputs": [],
   "source": [
    "arma_results.nsmallest(5, columns=['RMSE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-15T20:42:29.358781Z",
     "start_time": "2021-04-15T20:41:31.707Z"
    }
   },
   "outputs": [],
   "source": [
    "arma_results.nsmallest(5, columns=['BIC'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-15T20:42:29.359298Z",
     "start_time": "2021-04-15T20:41:31.709Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(ncols=2, figsize=(10,4), sharex=True, sharey=True)\n",
    "sns.heatmap(arma_results[arma_results.RMSE<.5].RMSE.unstack().mul(10), fmt='.3f', annot=True, cmap='Blues', ax=axes[0], cbar=False);\n",
    "sns.heatmap(arma_results.BIC.unstack(), fmt='.2f', annot=True, cmap='Blues', ax=axes[1], cbar=False)\n",
    "axes[0].set_title('Root Mean Squared Error')\n",
    "axes[1].set_title('Bayesian Information Criterion')\n",
    "fig.tight_layout();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-15T20:42:29.359753Z",
     "start_time": "2021-04-15T20:41:31.711Z"
    }
   },
   "outputs": [],
   "source": [
    "arma_results.rank().loc[:, ['RMSE', 'BIC']].mean(1).nsmallest(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimating the best ARMA Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ARMA(4,0) and ARMA(4,1) are close, so we chose the more parsimonious (4,0) configuration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-15T20:42:29.360162Z",
     "start_time": "2021-04-15T20:41:31.713Z"
    }
   },
   "outputs": [],
   "source": [
    "best_p, best_q = arma_results.rank().loc[:, ['RMSE', 'BIC']].mean(1).idxmin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-15T20:42:29.360728Z",
     "start_time": "2021-04-15T20:41:31.715Z"
    }
   },
   "outputs": [],
   "source": [
    "best_arma_model = tsa.ARMA(endog=industrial_production_log_diff, order=(best_p, best_q)).fit()\n",
    "print(best_arma_model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Residual Correlogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-15T20:42:29.361802Z",
     "start_time": "2021-04-15T20:41:31.718Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_correlogram(best_arma_model.resid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SARIMAX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-15T20:42:29.362288Z",
     "start_time": "2021-04-15T20:41:31.721Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sarimax_model = tsa.SARIMAX(endog=industrial_production_log_diff.dropna().values,\n",
    "                    order=(2, 0, 2),\n",
    "                    seasonal_order=(1, 0, 1, 12)).fit(start_params=[0, 0, 0, 0, 0, 0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-15T20:42:29.362700Z",
     "start_time": "2021-04-15T20:41:31.723Z"
    }
   },
   "outputs": [],
   "source": [
    "print(sarimax_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-15T20:42:29.363145Z",
     "start_time": "2021-04-15T20:41:31.724Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_correlogram(pd.Series(sarimax_model.resid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will build a SARIMAX model for monthly data on an industrial production time series for the 1988-2017 period. As illustrated in the first section on analytical tools, the data has been log-transformed, and we are using seasonal (lag-12) differences. We estimate the model for a range of both ordinary and conventional AR and MA parameters using a rolling window of 10 years of training data, and evaluate the RMSE of the 1-step-ahead forecast."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding the optimal number of lags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This takes a while..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-15T20:42:29.363568Z",
     "start_time": "2021-04-15T20:41:31.727Z"
    }
   },
   "outputs": [],
   "source": [
    "l3 = list(range(3))\n",
    "l4 = list(range(4))\n",
    "params = [t for t in product(l4, l4, l3, l3) if t[0] > 0 and t[1] >  0]\n",
    "len(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-15T20:42:29.364013Z",
     "start_time": "2021-04-15T20:41:31.729Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_size = 120 # 10 years of training data\n",
    "results = {}\n",
    "test_set = industrial_production_log_diff.iloc[train_size:]\n",
    "\n",
    "for p1, q1, p2, q2 in tqdm(params):\n",
    "    preds = test_set.copy().to_frame('y_true').assign(y_pred=np.nan)\n",
    "    aic, bic = [], []\n",
    "    if p1 == 0 and q1 == 0:\n",
    "        continue\n",
    "    convergence_error = stationarity_error = 0\n",
    "    y_pred = []\n",
    "    for i, T in enumerate(range(train_size, len(industrial_production_log_diff))):\n",
    "        train_set = industrial_production_log_diff.iloc[T-train_size:T]\n",
    "        try:\n",
    "            with warnings.catch_warnings():\n",
    "                warnings.filterwarnings(\"ignore\")\n",
    "                model = tsa.SARIMAX(endog=train_set.values,\n",
    "                                order=(p1, 0, q1),\n",
    "                                seasonal_order=(p2, 0, q2, 12)).fit(disp=0)\n",
    "        except LinAlgError:\n",
    "            convergence_error += 1\n",
    "        except ValueError:\n",
    "            stationarity_error += 1\n",
    "\n",
    "        preds.iloc[i, 1] = model.forecast(steps=1)[0]\n",
    "        aic.append(model.aic)\n",
    "        bic.append(model.bic)\n",
    "\n",
    "    preds.dropna(inplace=True)\n",
    "    mse = mean_squared_error(preds.y_true, preds.y_pred)\n",
    "    results[(p1, q1, p2, q2)] = [np.sqrt(mse),\n",
    "                                      preds.y_true.sub(preds.y_pred).pow(2).std(),\n",
    "                                      np.mean(aic),\n",
    "                                      np.std(aic),                                                  \n",
    "                                      np.mean(bic),\n",
    "                                      np.std(bic),                                                  \n",
    "                                      convergence_error,\n",
    "                                      stationarity_error]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare model metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-15T20:42:29.364478Z",
     "start_time": "2021-04-15T20:41:31.732Z"
    }
   },
   "outputs": [],
   "source": [
    "sarimax_results = pd.DataFrame(results).T\n",
    "sarimax_results.columns = ['RMSE', 'RMSE_std', 'AIC', 'AIC_std', 'BIC', 'BIC_std', 'convergence', 'stationarity']\n",
    "sarimax_results['CV'] = sarimax_results.RMSE_std.div(sarimax_results.RMSE)\n",
    "sarimax_results.index.names = ['p1', 'q1', 'p2', 'q2']\n",
    "sarimax_results.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-15T20:42:29.364920Z",
     "start_time": "2021-04-15T20:41:31.734Z"
    }
   },
   "outputs": [],
   "source": [
    "with pd.HDFStore('arima.h5') as store:\n",
    "    store.put('sarimax', sarimax_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-15T20:42:29.365371Z",
     "start_time": "2021-04-15T20:41:31.736Z"
    }
   },
   "outputs": [],
   "source": [
    "with pd.HDFStore('arima.h5') as store:\n",
    "    sarimax_results = store.get('sarimax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-15T20:42:29.365796Z",
     "start_time": "2021-04-15T20:41:31.738Z"
    }
   },
   "outputs": [],
   "source": [
    "sarimax_results.nsmallest(5, columns='RMSE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also collect the AIC and BIC criteria that show a very high rank correlation coefficient of 0.94, with BIC favoring models with slightly fewer parameters than AIC. The best five models by RMSE are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-15T20:42:29.366287Z",
     "start_time": "2021-04-15T20:41:31.741Z"
    }
   },
   "outputs": [],
   "source": [
    "sarimax_results[['RMSE', 'AIC', 'BIC']].sort_values('RMSE').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-15T20:42:29.366749Z",
     "start_time": "2021-04-15T20:41:31.743Z"
    }
   },
   "outputs": [],
   "source": [
    "sarimax_results[['RMSE', 'AIC', 'BIC']].corr('spearman')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-15T20:42:29.367156Z",
     "start_time": "2021-04-15T20:41:31.745Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.jointplot(y='RMSE', x='BIC', data=sarimax_results[['RMSE', 'BIC']].rank());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-15T20:42:29.367619Z",
     "start_time": "2021-04-15T20:41:31.748Z"
    }
   },
   "outputs": [],
   "source": [
    "sarimax_results[(sarimax_results.RMSE < sarimax_results.RMSE.quantile(.05)) &\n",
    "                (sarimax_results.BIC < sarimax_results.BIC.quantile(.1))].sort_values('RMSE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-15T20:42:29.368068Z",
     "start_time": "2021-04-15T20:41:31.750Z"
    }
   },
   "outputs": [],
   "source": [
    "p1, q1, p2, q2 = 2, 3, 1, 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-15T20:42:29.368580Z",
     "start_time": "2021-04-15T20:41:31.752Z"
    }
   },
   "outputs": [],
   "source": [
    "best_model = tsa.SARIMAX(endog=industrial_production_log_diff.values, order=(p1, 0, q1),\n",
    "                         seasonal_order=(p2, 0, q2, 12)).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-15T20:42:29.369014Z",
     "start_time": "2021-04-15T20:41:31.754Z"
    }
   },
   "outputs": [],
   "source": [
    "print(best_model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Residual Correlogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-15T20:42:29.369455Z",
     "start_time": "2021-04-15T20:41:31.757Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_correlogram(pd.Series(best_model.resid),\n",
    "                 lags=20,\n",
    "                 title=f'SARIMAX ({p1}, 0, {q1}) x ({p2}, 0, {q2}, 12) | Model Diagnostics')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": false,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "1186px",
    "left": "50px",
    "top": "111.133px",
    "width": "396px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
